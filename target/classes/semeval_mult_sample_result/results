
Test context:
***************
bright.a	1	13	during the siege , george robertson had appointed shuja-ul-mulk , who was a __bright__ boy only 12 years old and the youngest surviving son of aman-ul-mulk , as the ruler of chitral .
Contexts for target bright are: ['amodI_boy']
Contexts in vocabulary for target bright are: ['amodI_boy']
Top most similar embeddings: bright 0.52094	doe-eyed 0.41514	gawky 0.41350	sweet-natured 0.41056	mousy 0.40966	bright-eyed 0.40897	dark-haired 0.40175	fiesty 0.40049	fair-haired 0.40038	cherubic 0.39885

Generated lemmatized results
***************
GENERATED	bright.a 1 ::: gawky;mousy;fiesty;cherubic;georgeous;youngish;gangly;slutty;rambunctious;beardless

Filtered results
***************
RANKED	bright.a 1	clever 0.36209	brilliant 0.35408	luminous 0.34803	smart 0.34418	talented 0.34272	vivid 0.34195	colourful 0.33918	vibrant 0.33639	good 0.33335	intelligent 0.32975	sharp 0.32932	shining 0.32393	hopeful 0.32295	up-and-coming 0.32167	promising 0.32015	gifted 0.32001	light 0.30569	well-lit 0.30441	great 0.30320	deep 0.30136	positive 0.29992	capable 0.29574	skilled 0.28857	alight 0.28419	motivated 0.28310	gleam 0.28284	clear 0.27826

Test context:
***************
bright.a	2	22	the actual field is not much different than that of a 40mm , only it is smaller and quite a bit noticeably __brighter__ , which is probably the main benefit .
Contexts for target brighter are: ['npadvmod_bit', 'advmod_noticeably', 'conjI_smaller']
Contexts in vocabulary for target brighter are: ['npadvmod_bit', 'advmod_noticeably', 'conjI_smaller']
Top most similar embeddings: brighter 0.15446	greyer 0.12886	redder 0.12769	plumper 0.12748	shinier 0.12503	livelier 0.12348	duller 0.12293	bluer 0.12256	sparser 0.12255	chunkier 0.12168

Generated lemmatized results
***************
GENERATED	bright.a 2 ::: grey;red;plump;shiny;lively;dull;blue;sparse;chunky;sturdy

Filtered results
***************
RANKED	bright.a 2	light 0.11749	sharp 0.11497	smart 0.09944	clever 0.09771	clear 0.09629	good 0.09575	deep 0.09058	luminous 0.07993	great 0.07821	colourful 0.07225	vibrant 0.07065	well-lit 0.06827	hopeful 0.06817	talented 0.06542	positive 0.06542	vivid 0.06408	promising 0.06405	alight 0.06327	shining 0.06133	intelligent 0.06092	capable 0.06075	gleam 0.06074	brilliant 0.05878	motivated 0.05854	skilled 0.05797	gifted 0.05547	up-and-coming 0.05506

Test context:
***************
bright.a	3	13	the roses have grown out of control , wild and carefree , their __bright__ blooming faces turned to bathe in the early autumn sun .
Contexts for target bright are: ['amodI_faces']
Contexts in vocabulary for target bright are: ['amodI_faces']
Top most similar embeddings: bright 0.51168	cherubic 0.40476	yellowy 0.39360	multi-colored 0.39235	ashen 0.39219	brighter 0.38940	hued 0.38856	light-coloured 0.38842	multicolored 0.38751	cadaverous 0.38700

Generated lemmatized results
***************
GENERATED	bright.a 3 ::: cherubic;yellowy;ashen;hued;multicolored;cadaverous;twinkly;opalescent;expressionless;darkish

Filtered results
***************
RANKED	bright.a 3	luminous 0.37061	vibrant 0.35184	vivid 0.35163	colourful 0.35119	sharp 0.34541	shining 0.34015	brilliant 0.33837	well-lit 0.33173	hopeful 0.33000	talented 0.32862	clever 0.32750	smart 0.32521	promising 0.31455	light 0.31391	up-and-coming 0.31049	gleam 0.30817	positive 0.30674	intelligent 0.30432	great 0.30299	good 0.30262	clear 0.29598	deep 0.29391	motivated 0.29285	gifted 0.29105	capable 0.28501	skilled 0.28309	alight 0.28110

Test context:
***************
bright.a	4	2	he was __bright__ and independent and proud .
Contexts for target bright are: ['nsubj_he', 'cop_was', 'rootI_*root*', 'cc_and', 'conj_independent', 'cc_and', 'conj_proud', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target bright are: ['nsubj_he', 'cop_was', 'rootI_*root*', 'cc_and', 'conj_independent', 'cc_and', 'conj_proud', 'punct_.']
Top most similar embeddings: bright 0.00366	strong-willed 0.00360	self-assured 0.00323	clear-headed 0.00323	broad-minded 0.00322	strong-minded 0.00321	self-willed 0.00319	self-confident 0.00319	soft-spoken 0.00315	clean-shaven 0.00314

Generated lemmatized results
***************
GENERATED	bright.a 4 ::: abstemious;unflappable;enthusiastic;unphased;voluble;affable;personable;witted;forthright;headstrong

Filtered results
***************
RANKED	bright.a 4	brilliant 0.00282	gifted 0.00268	clever 0.00251	vivid 0.00235	intelligent 0.00235	vibrant 0.00230	talented 0.00228	sharp 0.00225	positive 0.00216	smart 0.00216	hopeful 0.00216	skilled 0.00208	motivated 0.00208	capable 0.00201	clear 0.00199	colourful 0.00197	luminous 0.00192	light 0.00189	alight 0.00181	shining 0.00177	deep 0.00175	good 0.00167	well-lit 0.00165	gleam 0.00156	great 0.00155	promising 0.00153	up-and-coming 0.00104

Test context:
***************
bright.a	5	30	in fact , during at least six distinct periods in army history since world war i , lack of trust and confidence in senior leaders caused the so-called best and __brightest__ to leave the army in droves .
Contexts for target brightest are: ['conjI_best']
Contexts in vocabulary for target brightest are: ['conjI_best']
Top most similar embeddings: brightest 0.56194	tastiest 0.41049	fairest 0.40878	cleverest 0.40856	boldest 0.40705	healthiest 0.40558	truest 0.40090	bravest 0.40045	sweetest 0.39864	worst 0.39700

Generated lemmatized results
***************
GENERATED	bright.a 5 ::: tasty;fair;clever;bold;healthy;true;brave;sweet;bad;funny

Filtered results
***************
RANKED	bright.a 5	clever 0.40856	light 0.39189	smart 0.38792	clear 0.38562	sharp 0.37272	great 0.36618	talented 0.34010	deep 0.33260	vibrant 0.32800	brilliant 0.32704	up-and-coming 0.32694	luminous 0.32592	shining 0.32404	colourful 0.32368	gifted 0.32078	vivid 0.32074	intelligent 0.31406	promising 0.30901	skilled 0.30635	hopeful 0.29517	capable 0.29011	well-lit 0.28878	gleam 0.28608	good 0.28255	motivated 0.27951	positive 0.27558	alight 0.27488

Test context:
***************
bright.a	6	37	an evening of classical symphonic music , played by the next generation stars in the american orchestral scene , can be savored at the new world symphony , a special miami institution that nurtures the best and __brightest__ young symphonic musicians .
Contexts for target brightest are: ['conjI_best']
Contexts in vocabulary for target brightest are: ['conjI_best']
Top most similar embeddings: brightest 0.56194	tastiest 0.41049	fairest 0.40878	cleverest 0.40856	boldest 0.40705	healthiest 0.40558	truest 0.40090	bravest 0.40045	sweetest 0.39864	worst 0.39700

Generated lemmatized results
***************
GENERATED	bright.a 6 ::: tasty;fair;clever;bold;healthy;true;brave;sweet;bad;funny

Filtered results
***************
RANKED	bright.a 6	clever 0.40856	light 0.39189	smart 0.38792	clear 0.38562	sharp 0.37272	great 0.36618	talented 0.34010	deep 0.33260	vibrant 0.32800	brilliant 0.32704	up-and-coming 0.32694	luminous 0.32592	shining 0.32404	colourful 0.32368	gifted 0.32078	vivid 0.32074	intelligent 0.31406	promising 0.30901	skilled 0.30635	hopeful 0.29517	capable 0.29011	well-lit 0.28878	gleam 0.28608	good 0.28255	motivated 0.27951	positive 0.27558	alight 0.27488

Test context:
***************
bright.a	7	11	there are sound reasons for concluding that the long-run picture remains __bright__ , and even recent signals about the current course of the economy have turned from unremittingly negative through the late fall of last year to a far more mixed set of signals recently .
Contexts for target bright are: ['mark_that', 'nsubj_picture', 'cop_remains', 'nsubjI_turned', 'punct_,', 'cc_and', 'conj_signals']
Contexts in vocabulary for target bright are: ['mark_that', 'nsubj_picture', 'cop_remains', 'nsubjI_turned', 'punct_,', 'cc_and', 'conj_signals']
Top most similar embeddings: bright 0.00567	brighter 0.00503	hazy 0.00473	indistinct 0.00468	unfocused 0.00458	grainy 0.00457	cloudy 0.00455	rosy 0.00453	patchy 0.00451	dim 0.00446

Generated lemmatized results
***************
GENERATED	bright.a 7 ::: hazy;indistinct;unfocused;grainy;cloudy;rosy;patchy;dim;jumpy;gloomy

Filtered results
***************
RANKED	bright.a 7	vivid 0.00439	sharp 0.00409	vibrant 0.00400	luminous 0.00376	clear 0.00362	colourful 0.00354	light 0.00349	well-lit 0.00348	hopeful 0.00341	shining 0.00334	gleam 0.00334	positive 0.00329	alight 0.00326	intelligent 0.00324	brilliant 0.00315	gifted 0.00315	capable 0.00302	smart 0.00296	clever 0.00291	talented 0.00290	motivated 0.00275	deep 0.00272	promising 0.00263	good 0.00242	skilled 0.00242	great 0.00211	up-and-coming 0.00153

Test context:
***************
bright.a	8	4	snow covered areas appear __bright__ blue in the image which was taken in early spring and shows deep snow cover .
Contexts for target bright are: ['amodI_blue']
Contexts in vocabulary for target bright are: ['amodI_blue']
Top most similar embeddings: bright 0.55143	brighter 0.42622	darkish 0.42157	yellowy 0.41716	silver-studded 0.41623	palest 0.41293	blue-white 0.41134	sky-blue 0.40963	rose-coloured 0.40849	bluish 0.40711

Generated lemmatized results
***************
GENERATED	bright.a 8 ::: darkish;yellowy;pale;bluish;grayish;coppery;florescent;iridescent;flourescent;pearlescent

Filtered results
***************
RANKED	bright.a 8	luminous 0.39167	brilliant 0.38045	vivid 0.37999	vibrant 0.36254	colourful 0.35581	light 0.34933	sharp 0.34154	shining 0.34133	smart 0.34121	deep 0.33182	well-lit 0.32460	clear 0.31766	clever 0.31714	gleam 0.30949	great 0.30743	talented 0.30702	good 0.30438	positive 0.30015	hopeful 0.29406	up-and-coming 0.29259	gifted 0.29202	promising 0.29067	intelligent 0.28947	alight 0.28350	skilled 0.27479	motivated 0.26643	capable 0.26417

Test context:
***************
bright.a	9	3	she turns eyes __bright__ with excitement towards fiona , still tugging on the string of the minitiature airship-cum-dance card she has just received at the door .
Contexts for target bright are: ['nsubj_eyes', 'xcompI_turns', 'prep:with_excitement']
Contexts in vocabulary for target bright are: ['nsubj_eyes', 'xcompI_turns', 'prep:with_excitement']
Top most similar embeddings: bright 0.12314	brighter 0.09479	bloodshot 0.09371	glowing 0.09144	redder 0.09096	aglow 0.09074	glinting 0.09065	squinting 0.09052	winking 0.08994	gleam 0.08915

Generated lemmatized results
***************
GENERATED	bright.a 9 ::: bloodshot;glowing;red;aglow;glinting;squinting;winking;gleam;aflame;unfocussed

Filtered results
***************
RANKED	bright.a 9	gleam 0.08915	luminous 0.08637	shining 0.08526	brilliant 0.08167	alight 0.07810	vivid 0.07577	light 0.07301	sharp 0.07045	smart 0.07017	intelligent 0.06925	vibrant 0.06896	deep 0.06823	clever 0.06796	hopeful 0.06676	colourful 0.06601	clear 0.06204	talented 0.06163	positive 0.06141	promising 0.06131	gifted 0.06010	good 0.06000	well-lit 0.05843	capable 0.05801	great 0.05613	motivated 0.05535	skilled 0.05228	up-and-coming 0.04731

Test context:
***************
bright.a	10	13	a short excerpt : i was praying in private until someone got the __bright__ idea of starting a presidential prayer team .
Contexts for target bright are: ['amodI_idea']
Contexts in vocabulary for target bright are: ['amodI_idea']
Top most similar embeddings: bright 0.53135	brilliant 0.39459	brighter 0.38876	brightest 0.37920	hare-brained 0.37725	half-formed 0.37059	faintest 0.36986	far-out 0.36810	good 0.36717	fantasic 0.36684

Generated lemmatized results
***************
GENERATED	bright.a 10 ::: brilliant;faint;good;fantasic;modish;briliant;delusive;pellucid;vague;clever

Filtered results
***************
RANKED	bright.a 10	brilliant 0.39459	good 0.36717	clever 0.35960	vivid 0.35396	smart 0.34829	luminous 0.34402	great 0.34162	clear 0.34066	colourful 0.33445	sharp 0.33225	vibrant 0.32653	intelligent 0.31779	promising 0.31716	positive 0.31610	talented 0.31574	shining 0.30842	gifted 0.30625	well-lit 0.30554	hopeful 0.30149	deep 0.29908	light 0.29419	up-and-coming 0.29262	capable 0.28794	motivated 0.28692	gleam 0.28158	skilled 0.27050	alight 0.26240

Test context:
***************
film.n	11	7	so , unlike studio films , independent __films__ cannot be conceptually geared to a marketing campaign , or used to recruit merchandising tie-ins .
Contexts for target films are: ['amod_independent', 'nsubjpassI_geared']
Contexts in vocabulary for target films are: ['amod_independent', 'nsubjpassI_geared']
Top most similar embeddings: films 0.23986	movies 0.19830	film 0.19757	documentaries 0.18527	filmmaking 0.18490	film-making 0.18453	filmmakers 0.17990	productions 0.17802	movie 0.17660	film-makers 0.17064

Generated lemmatized results
***************
GENERATED	film.n 11 ::: movie;documentary;filmmaking;filmmaker;production;drama;western;novel;blockbuster;thriller

Filtered results
***************
RANKED	film.n 11	movie 0.19830	documentary 0.18527	production 0.17802	picture 0.13700

Test context:
***************
film.n	12	11	the packed screening of about 100 high-level press people loved the __film__ as well .
Contexts for target film are: ['det_the', 'dobjI_loved']
Contexts in vocabulary for target film are: ['det_the', 'dobjI_loved']
Top most similar embeddings: film 0.26273	movie 0.22811	films 0.20869	rutles 0.19771	movies 0.19640	krankies 0.19486	tenenbaums 0.19422	wreccas 0.19096	munsters 0.19082	edukators 0.19031

Generated lemmatized results
***************
GENERATED	film.n 12 ::: movie;rutles;krankies;tenenbaums;wreccas;munsters;edukators;incredibles;boogeyman;prequels

Filtered results
***************
RANKED	film.n 12	movie 0.22811	documentary 0.17786	picture 0.15594	production 0.14466

Test context:
***************
film.n	13	40	i think most filmmakers for the most part right now they 're thinking about the dvd when they go in to production because the reality is dvd is where the great majority of your audience is going to experience the __film__ .
Contexts for target film are: ['det_the', 'dobjI_experience']
Contexts in vocabulary for target film are: ['det_the', 'dobjI_experience']
Top most similar embeddings: film 0.23988	movie 0.20952	films 0.19499	grittiness 0.19115	movies 0.18432	whitsundays 0.17979	cinema 0.17818	shoah 0.17813	edukators 0.17781	rat-race 0.17734

Generated lemmatized results
***************
GENERATED	film.n 13 ::: movie;grittiness;whitsunday;cinema;shoah;edukators;drama;tackiness;cliffhanger;animatrix

Filtered results
***************
RANKED	film.n 13	movie 0.20952	documentary 0.17048	production 0.14736	picture 0.14464

Test context:
***************
film.n	14	5	dune makes the second lynch __film__ to be released in a consumer hd format ( mulholland drive on d-vhs being the first ) .
Contexts for target film are: ['det_the', 'amod_second', 'nn_lynch', 'nsubjpassI_released']
Contexts in vocabulary for target film are: ['det_the', 'amod_second', 'nn_lynch', 'nsubjpassI_released']
Top most similar embeddings: film 0.06948	movie 0.05855	films 0.05170	album 0.04860	mini-series 0.04512	sequel 0.04487	lp 0.04450	box-set 0.04443	screenplay 0.04442	prequel 0.04405

Generated lemmatized results
***************
GENERATED	film.n 14 ::: movie;album;sequel;lp;screenplay;prequel;ep;documentary;trilogy;boxset

Filtered results
***************
RANKED	film.n 14	movie 0.05855	documentary 0.04385	picture 0.03481	production 0.03253

Test context:
***************
film.n	15	6	film music literature cyberplace - includes __film__ reviews , message boards , chat room , and images from various films .
Contexts for target film are: ['nnI_reviews']
Contexts in vocabulary for target film are: ['nnI_reviews']
Top most similar embeddings: film 0.51911	movie 0.45934	yesasia 0.39566	add/read 0.39139	film/tv 0.38709	film/video 0.38660	tv/film 0.38079	b-movie 0.38027	movies 0.37830	films 0.37807

Generated lemmatized results
***************
GENERATED	film.n 15 ::: movie;yesasia;fmz;syriana;gothika;kirkus;lumix;documentary;videogame;mirrormask

Filtered results
***************
RANKED	film.n 15	movie 0.45934	documentary 0.37201	picture 0.29722	production 0.29431

Test context:
***************
film.n	16	2	his feature __film__ debut heroes / de stÃrste helte ( 1996 ) won awards at rouen and madrid .
Contexts for target film are: ['nnI_heroes']
Contexts in vocabulary for target film are: ['nnI_heroes']
Top most similar embeddings: film 0.49222	movie 0.44164	b-movie 0.39173	comic-book 0.39170	sit-com 0.38771	blaxploitation 0.38641	claymation 0.37749	anime 0.37725	sitcom 0.37540	rom-com 0.37368

Generated lemmatized results
***************
GENERATED	film.n 16 ::: movie;blaxploitation;claymation;anime;sitcom;thriller;documentary;eraserhead;comedy;actioner

Filtered results
***************
RANKED	film.n 16	movie 0.44164	documentary 0.37273	picture 0.28734	production 0.27174

Test context:
***************
film.n	17	25	( some people keep their tvs on for company. ) in malta , news is the main reason we turn to tv , followed by __films__ , talk shows , documentaries , serials , and music , in that order .
Contexts for target films are: ['prep:byI_followed', 'punct_,', 'conj_shows', 'punct_,', 'conj_documentaries', 'punct_,', 'conj_serials', 'punct_,', 'cc_and', 'conj_music']
Contexts in vocabulary for target films are: ['prep:byI_followed', 'punct_,', 'conj_shows', 'punct_,', 'conj_documentaries', 'punct_,', 'conj_serials', 'punct_,', 'cc_and', 'conj_music']
Top most similar embeddings: b-movies 0.00120	cabarets 0.00115	documentaries 0.00111	films 0.00107	newsreels 0.00103	quadrilles 0.00100	audiocassettes 0.00099	westerns 0.00098	newscuttings 0.00098	gameshows 0.00095

Generated lemmatized results
***************
GENERATED	film.n 17 ::: cabaret;documentary;newsreel;quadrille;audiocassette;western;newscuttings;gameshows;travelogue;movie

Filtered results
***************
RANKED	film.n 17	documentary 0.00111	movie 0.00093	production 0.00057	picture 0.00049

Test context:
***************
film.n	18	1	the __film__ shows afghan mercenaries to be involved with the separatists , suggesting that the present struggle in kashmir has been hijacked by foreign extremists , who are shown discussing the loss of bangladesh in the 1971 war , providing it as a justification for their present acts of revenge .
Contexts for target film are: ['det_the', 'nsubjI_shows']
Contexts in vocabulary for target film are: ['det_the', 'nsubjI_shows']
Top most similar embeddings: film 0.26275	movie 0.22464	films 0.19658	edukators 0.19623	documentary 0.19016	spectrogram 0.18877	animatrix 0.18870	nftva 0.18852	flim 0.18817	tarnation 0.18816

Generated lemmatized results
***************
GENERATED	film.n 18 ::: movie;edukators;documentary;spectrogram;animatrix;nftva;flim;tarnation;photomicrograph;winline

Filtered results
***************
RANKED	film.n 18	movie 0.22464	documentary 0.19016	picture 0.17828	production 0.14900

Test context:
***************
film.n	19	23	a fine score by george fenton ( the crucible ) and beautiful photograhy by roger pratt add greatly to the effectiveness of the __film__ .
Contexts for target film are: ['det_the', 'prep:ofI_effectiveness']
Contexts in vocabulary for target film are: ['det_the', 'prep:ofI_effectiveness']
Top most similar embeddings: film 0.22998	films 0.18944	movie 0.18874	mini-pill 0.18378	sfvs 0.18182	ms-200 0.17830	jcpsg 0.17568	ndst 0.17560	aidb 0.17431	es4000 0.17427

Generated lemmatized results
***************
GENERATED	film.n 19 ::: movie;sfvs;jcpsg;ndst;aidb;odls;edac;nrl;fsap;pbrs

Filtered results
***************
RANKED	film.n 19	movie 0.18874	documentary 0.17181	production 0.14688	picture 0.13965

Test context:
***************
film.n	20	7	the success of autry ' s early __films__ was not enough to save mascot pictures , which collapsed under the weight of debts held by consolidated film laboratories , which did mascot 's film processing .
Contexts for target films are: ['nn_autry', "punct_'", 'amod_s', 'amod_early', 'prep:ofI_success']
Contexts in vocabulary for target films are: ["punct_'", 'amod_s', 'amod_early', 'prep:ofI_success']
Top most similar embeddings: films 0.05495	novels 0.04571	westerns 0.04562	film 0.04468	movies 0.04464	comedies 0.04369	talkies 0.04345	musicals 0.04306	gialli 0.04294	sitcoms 0.04282

Generated lemmatized results
***************
GENERATED	film.n 20 ::: novel;western;movie;comedy;talkie;musical;gialli;sitcom;noughties;giallo

Filtered results
***************
RANKED	film.n 20	movie 0.04464	documentary 0.03978	production 0.03974	picture 0.02903

Test context:
***************
take.v	21	12	that 's not to say the process of actual negotiating is n't __taking__ place .
Contexts for target taking are: ['nsubj_process', 'aux_is', "neg_n't", 'ccompI_say', 'dobj_place']
Contexts in vocabulary for target taking are: ['nsubj_process', 'aux_is', "neg_n't", 'ccompI_say', 'dobj_place']
Top most similar embeddings: taking 0.03031	take 0.02356	going 0.02021	taken 0.01979	hogging 0.01964	endangering 0.01929	happening 0.01914	hurting 0.01903	getting 0.01881	outgrowing 0.01877

Generated lemmatized results
***************
GENERATED	take.v 21 ::: go;hog;endanger;happen;hurt;get;outgrow;materialise;overstep;takin

Filtered results
***************
RANKED	take.v 21	happen 0.01914	get 0.01881	accept 0.01818	occur 0.01753	run 0.01715	risk 0.01685	consider 0.01573	grasp 0.01573	start 0.01565	assume 0.01557	tolerate 0.01549	occupy 0.01530	last 0.01521	collect 0.01507	undergo 0.01503	begin 0.01448	grow 0.01421	gather 0.01361	include 0.01212	be 0.00931

Test context:
***************
take.v	22	14	" hugh grant and alan rickman , as edward and col. brandon respectively , __took__ the most chances and the various reviewers therefore either love or hate their performances .
Contexts for target took are: ['nsubj_grant', 'rootI_*root*', 'dobj_chances', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target took are: ['nsubj_grant', 'rootI_*root*', 'dobj_chances', 'punct_.']
Top most similar embeddings: took 0.06655	gave 0.05408	takes 0.05087	rued 0.04924	ran 0.04867	gives 0.04860	showed 0.04859	threw 0.04761	bided 0.04748	went 0.04742

Generated lemmatized results
***************
GENERATED	take.v 22 ::: give;rue;run;show;throw;bid;go;concede;total;spurn

Filtered results
***************
RANKED	take.v 22	run 0.04867	begin 0.04664	include 0.04525	assume 0.04263	last 0.04199	start 0.04183	get 0.04156	consider 0.04106	grow 0.04102	accept 0.04066	occur 0.03907	occupy 0.03903	undergo 0.03589	risk 0.03584	grasp 0.03576	happen 0.03473	be 0.03331	gather 0.03301	tolerate 0.03300	collect 0.03299

Test context:
***************
take.v	23	3	it should n't __take__ that long .
Contexts for target take are: ['nsubj_it', 'aux_should', "neg_n't", 'rootI_*root*', 'dobj_long', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target take are: ['nsubj_it', 'aux_should', "neg_n't", 'rootI_*root*', 'dobj_long', 'punct_.']
Top most similar embeddings: take 0.01679	contain 0.01164	include 0.01160	re-occur 0.01141	procrastinate 0.01121	dissapoint 0.01113	sadden 0.01095	outlast 0.01095	have 0.01092	involve 0.01092

Generated lemmatized results
***************
GENERATED	take.v 23 ::: contain;include;procrastinate;dissapoint;sadden;outlast;have;involve;transpire;skimp

Filtered results
***************
RANKED	take.v 23	include 0.01160	assume 0.01075	happen 0.01069	last 0.01060	tolerate 0.01049	consider 0.01017	occur 0.01006	begin 0.00980	accept 0.00954	get 0.00935	occupy 0.00925	start 0.00886	grow 0.00885	risk 0.00838	run 0.00837	undergo 0.00804	collect 0.00798	grasp 0.00774	gather 0.00749	be 0.00655

Test context:
***************
take.v	24	16	it only affects the start up time of a program , and for a process that __takes__ several months ( his code was computing the 196 palindrome quest ) , it does not matter if the initialization code takes 1/1,000th of a second or 1/10,000th of a second .
Contexts for target takes are: ['nsubj_that', 'rcmodI_process', 'dobj_months']
Contexts in vocabulary for target takes are: ['nsubj_that', 'rcmodI_process', 'dobj_months']
Top most similar embeddings: takes 0.13951	lasts 0.10321	took 0.10208	involves 0.10061	energizes 0.09800	unsettles 0.09572	meets 0.09506	precedes 0.09431	requires 0.09409	accompanies 0.09401

Generated lemmatized results
***************
GENERATED	take.v 24 ::: last;involve;energize;unsettle;meet;precede;require;accompany;occur;give

Filtered results
***************
RANKED	take.v 24	last 0.10321	occur 0.09373	begin 0.09004	include 0.08888	undergo 0.08791	start 0.08478	get 0.08448	happen 0.08369	assume 0.08249	collect 0.08241	occupy 0.08234	gather 0.08118	accept 0.08099	grasp 0.07940	run 0.07930	consider 0.07880	grow 0.07879	tolerate 0.07677	risk 0.06297	be 0.05328

Test context:
***************
take.v	25	2	if we __take__ the factual context in which the term is used into consideration , then its extension becomes limited , owing to the context .
Contexts for target take are: ['mark_if', 'nsubj_we', 'advclI_limited', 'dobj_context']
Contexts in vocabulary for target take are: ['mark_if', 'nsubj_we', 'advclI_limited', 'dobj_context']
Top most similar embeddings: take 0.04717	have 0.04349	consider 0.04327	provide 0.04293	want/need 0.04226	require 0.04193	prefer 0.04153	recapitulate 0.04149	assume 0.04143	afford 0.04136

Generated lemmatized results
***************
GENERATED	take.v 25 ::: have;consider;provide;require;prefer;recapitulate;assume;afford;want;misplace

Filtered results
***************
RANKED	take.v 25	consider 0.04327	assume 0.04143	accept 0.03944	get 0.03811	tolerate 0.03713	begin 0.03631	occupy 0.03527	grasp 0.03496	collect 0.03407	gather 0.03386	include 0.03268	occur 0.03219	grow 0.03138	happen 0.03069	start 0.03051	run 0.03050	undergo 0.03032	risk 0.02885	last 0.02852	be 0.02814

Test context:
***************
take.v	26	4	if you do n't __take__ the risk of dying by driving to the store , your house could collapse on you and kill you anyway .
Contexts for target take are: ['mark_if', 'nsubj_you', 'aux_do', "neg_n't", 'advclI_collapse', 'dobj_risk']
Contexts in vocabulary for target take are: ['mark_if', 'nsubj_you', 'aux_do', "neg_n't", 'advclI_collapse', 'dobj_risk']
Top most similar embeddings: take 0.01322	overdo 0.01271	overeat 0.01250	want 0.01235	misplace 0.01186	have 0.01183	want/need 0.01173	overcook 0.01163	overfill 0.01156	ovulate 0.01155

Generated lemmatized results
***************
GENERATED	take.v 26 ::: overdo;overeat;want;misplace;have;overcook;overfill;ovulate;overreact;misjudge

Filtered results
***************
RANKED	take.v 26	accept 0.01119	get 0.01110	assume 0.01072	tolerate 0.01062	consider 0.00939	run 0.00932	happen 0.00922	grasp 0.00849	begin 0.00818	grow 0.00801	occupy 0.00786	collect 0.00782	start 0.00769	occur 0.00752	undergo 0.00751	risk 0.00694	gather 0.00690	include 0.00666	last 0.00621	be 0.00537

Test context:
***************
take.v	27	2	the governor __took__ the big sheets of imitation parchment , glanced over them , signed his name to each , laid down the pen , and handed the papers across the table to dreier .
Contexts for target took are: ['nsubj_governor', 'rootI_*root*', 'dobj_sheets', 'punct_,', 'conj_glanced', 'punct_,', 'conj_signed', 'punct_,', 'conj_laid', 'punct_,', 'cc_and', 'conj_handed', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target took are: ['nsubj_governor', 'rootI_*root*', 'dobj_sheets', 'punct_,', 'conj_glanced', 'punct_,', 'conj_signed', 'punct_,', 'conj_laid', 'punct_,', 'cc_and', 'conj_handed', 'punct_.']
Top most similar embeddings: tutted 0.00013	relented 0.00013	took 0.00013	doffed 0.00012	sighed 0.00012	withdrew 0.00011	demurred 0.00011	retook 0.00011	fidgeted 0.00011	grunted 0.00011

Generated lemmatized results
***************
GENERATED	take.v 27 ::: tutted;relent;doff;sigh;withdraw;demur;retake;fidget;grunt;nod

Filtered results
***************
RANKED	take.v 27	run 0.00009	begin 0.00008	last 0.00007	grow 0.00007	gather 0.00006	start 0.00006	get 0.00006	occupy 0.00006	grasp 0.00006	undergo 0.00005	collect 0.00005	accept 0.00005	assume 0.00005	occur 0.00004	risk 0.00004	happen 0.00004	tolerate 0.00004	include 0.00003	consider 0.00003	be 0.00002

Test context:
***************
take.v	28	25	o'neill and the two men who worked under his supervision maintained the avenue , raking the thin gravel and removing any weed that tried to __take__ root in the stony earth .
Contexts for target take are: ['aux_to', 'xcompI_tried', 'dobj_root', 'prep:in_earth']
Contexts in vocabulary for target take are: ['aux_to', 'xcompI_tried', 'dobj_root', 'prep:in_earth']
Top most similar embeddings: take 0.05946	sublimate 0.04944	dissemble 0.04942	extirpate 0.04939	entangle 0.04909	exhume 0.04844	dethrone 0.04828	re-assert 0.04799	manhandle 0.04787	sieze 0.04739

Generated lemmatized results
***************
GENERATED	take.v 28 ::: sublimate;dissemble;extirpate;entangle;exhume;dethrone;manhandle;sieze;impale;sequester

Filtered results
***************
RANKED	take.v 28	grow 0.04177	occupy 0.04029	get 0.03963	gather 0.03842	tolerate 0.03740	grasp 0.03706	collect 0.03687	accept 0.03473	run 0.03406	consider 0.03398	undergo 0.03368	include 0.03335	assume 0.03335	begin 0.03302	happen 0.03114	occur 0.03097	start 0.03051	last 0.02843	risk 0.02715	be 0.02429

Test context:
***************
take.v	29	7	even if the anglo-french summit did not __take__ place until next year , the prime minister and president chirac were still due to see each other in november and december .
Contexts for target take are: ['advmod_even', 'mark_if', 'nsubj_summit', 'aux_did', 'neg_not', 'advclI_due', 'dobj_place', 'prep:until_year']
Contexts in vocabulary for target take are: ['advmod_even', 'mark_if', 'nsubj_summit', 'aux_did', 'neg_not', 'advclI_due', 'dobj_place', 'prep:until_year']
Top most similar embeddings: take 0.00300	materialize 0.00266	materialise 0.00255	transpire 0.00233	re-occur 0.00225	foreclose 0.00224	concede 0.00223	qualify 0.00221	succeed 0.00221	defer 0.00220

Generated lemmatized results
***************
GENERATED	take.v 29 ::: materialize;materialise;transpire;foreclose;concede;qualify;succeed;defer;ratify;relinquish

Filtered results
***************
RANKED	take.v 29	occupy 0.00212	happen 0.00210	occur 0.00202	begin 0.00202	accept 0.00199	consider 0.00197	assume 0.00189	last 0.00188	get 0.00183	tolerate 0.00173	grasp 0.00162	start 0.00159	grow 0.00158	undergo 0.00148	run 0.00147	gather 0.00146	risk 0.00146	collect 0.00145	include 0.00131	be 0.00092

Test context:
***************
take.v	30	15	40 day-to-day financial and operational management is the responsibility of the chief officer , who __took__ up her post in june 2001 .
Contexts for target took are: ['nsubj_who', 'rcmodI_officer', 'prt_up', 'dobj_post', 'prep:in_june']
Contexts in vocabulary for target took are: ['nsubj_who', 'rcmodI_officer', 'prt_up', 'dobj_post', 'prep:in_june']
Top most similar embeddings: took 0.03421	gave 0.02467	takes 0.02393	relinquished 0.02292	resigned 0.02288	undertook 0.02280	came 0.02279	ran 0.02240	flew 0.02209	wrote 0.02204

Generated lemmatized results
***************
GENERATED	take.v 30 ::: give;relinquish;resign;undertake;come;run;fly;write;ride;storm

Filtered results
***************
RANKED	take.v 30	run 0.02240	start 0.01936	grow 0.01929	begin 0.01878	undergo 0.01782	gather 0.01777	occupy 0.01771	collect 0.01757	get 0.01714	accept 0.01641	assume 0.01545	last 0.01501	risk 0.01490	happen 0.01390	grasp 0.01381	consider 0.01377	occur 0.01333	include 0.01237	tolerate 0.01229	be 0.01038

Test context:
***************
tight.r	31	6	anyway , my pants are getting __tight__ .
Contexts for target tight are: ['advmodI_getting']
Contexts in vocabulary for target tight are: ['advmodI_getting']
Top most similar embeddings: tight 0.49903	tighter 0.41195	niggly 0.37288	inconspicuously 0.35809	dexterously 0.35705	tiddly 0.35686	straggly 0.35609	tightly 0.35489	eventualy 0.35397	scot-free 0.35198

Generated lemmatized results
***************
GENERATED	tight.r 31 ::: tighter;niggly;inconspicuously;dexterously;tiddly;straggly;tightly;eventualy;proably;sluggishly

Filtered results
***************
RANKED	tight.r 31	close 0.34721	firmly 0.32310	cramped 0.31331	low 0.30941	near 0.30725	uncomfortable 0.29953	close-fitting 0.29825	scarce 0.29645	closely 0.29296	constricted 0.29128	small 0.29032	securely 0.29001	sparse 0.28811	pressurised 0.28595	constricting 0.27522	compressed 0.27401	pressured 0.27276	stretched 0.27145	restricted 0.26100	secure 0.24838

Test context:
***************
tight.r	32	5	with the physical market has __tight__ as it has been in memory , silver could fly at any time .
Contexts for target tight are: ['advmodI_has', 'ccomp_been']
Contexts in vocabulary for target tight are: ['advmodI_has', 'ccomp_been']
Top most similar embeddings: tight 0.21587	tighter 0.19221	tightly 0.16941	irrefutably 0.16721	straighter 0.16484	indistinctly 0.16446	conclusively 0.16269	now 0.16060	proberly 0.16051	despairingly 0.16014

Generated lemmatized results
***************
GENERATED	tight.r 32 ::: tighter;tightly;irrefutably;straighter;indistinctly;conclusively;now;proberly;despairingly;dexterously

Filtered results
***************
RANKED	tight.r 32	firmly 0.15525	close 0.14488	scarce 0.13487	low 0.13207	uncomfortable 0.13152	securely 0.13108	cramped 0.13062	sparse 0.12960	closely 0.12952	constricted 0.12469	near 0.12423	close-fitting 0.12311	constricting 0.12234	small 0.12105	pressurised 0.11689	pressured 0.11087	stretched 0.11017	secure 0.11003	restricted 0.10742	compressed 0.10655

Test context:
***************
tight.r	33	8	more ... specialty coffee market quiet , supplies __tight__ posted at 2:57 pm by robert badgett by bruce kamich new york , june 6 ( reuters ) - specialty coffee dealers said on friday that business was unusually quiet with most retailers ' sales numbers down from a year ago , but prices for choice beans remained firm with supplies short until the next crops become available .
Contexts for target tight are: ['amodI_posted']
Contexts in vocabulary for target tight are: ['amodI_posted']
Top most similar embeddings: tight 0.47011	tighter 0.36060	loose 0.33453	tightest 0.33393	rock-hard 0.33367	over-heated 0.33355	cute 0.33134	tough 0.32950	three-cornered 0.32720	unstable 0.32673

Generated lemmatized results
***************
GENERATED	tight.r 33 ::: tighter;loose;tightest;cute;tough;unstable;deep;tricky;skimpy;coquettish

Filtered results
***************
RANKED	tight.r 33	close-fitting 0.32606	small 0.31829	cramped 0.30738	uncomfortable 0.30559	scarce 0.29590	close 0.29584	constricted 0.29050	sparse 0.28720	low 0.28699	restricted 0.28457	stretched 0.27958	pressurised 0.27569	secure 0.27442	firmly 0.27324	near 0.26627	pressured 0.26423	compressed 0.26378	constricting 0.25983	securely 0.25957	closely 0.25806

Test context:
***************
tight.r	34	4	if your money is __tight__ do n't cut corners .
Contexts for target tight are: ['mark_if', 'nsubj_money', 'cop_is', 'rootI_*root*', 'ccomp_cut', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target tight are: ['mark_if', 'nsubj_money', 'cop_is', 'rootI_*root*', 'ccomp_cut', 'punct_.']
Top most similar embeddings: tight 0.01497	tighter 0.01111	debateable 0.01065	unclear 0.01056	unlikley 0.01005	adamant 0.00992	uncertain 0.00990	neccesary 0.00986	scarce 0.00984	unforgiveable 0.00980

Generated lemmatized results
***************
GENERATED	tight.r 34 ::: tighter;debateable;unclear;unlikley;adamant;uncertain;neccesary;scarce;unforgiveable;unlikely

Filtered results
***************
RANKED	tight.r 34	scarce 0.00984	sparse 0.00915	restricted 0.00866	constricted 0.00852	uncomfortable 0.00800	pressured 0.00800	close 0.00780	pressurised 0.00769	cramped 0.00761	compressed 0.00753	low 0.00705	stretched 0.00690	secure 0.00678	firmly 0.00636	close-fitting 0.00623	small 0.00618	constricting 0.00583	near 0.00553	securely 0.00503	closely 0.00265

Test context:
***************
tight.r	35	25	each child lies inside an isolette incubator , a clear acrylic rectangle with ample room for a half-sized premature baby , though the quarters become __tight__ for the full-term eight-pounders .
Contexts for target tight are: ['mark_though', 'nsubj_quarters', 'cop_become', 'advclI_lies', 'prep:for_eight-pounders']
Contexts in vocabulary for target tight are: ['mark_though', 'nsubj_quarters', 'cop_become', 'advclI_lies']
Top most similar embeddings: tight 0.05660	tighter 0.04573	water-logged 0.04257	unnavigable 0.04221	waterlogged 0.04057	overcrowded 0.04030	overfull 0.04004	impassable 0.03978	overburdened 0.03974	impassible 0.03952

Generated lemmatized results
***************
GENERATED	tight.r 35 ::: tighter;unnavigable;waterlogged;overcrowded;overfull;impassable;overburdened;impassible;calcified;congested

Filtered results
***************
RANKED	tight.r 35	cramped 0.03824	scarce 0.03821	constricted 0.03708	uncomfortable 0.03537	sparse 0.03466	close 0.03342	stretched 0.03338	pressurised 0.03243	restricted 0.03226	pressured 0.03097	close-fitting 0.03043	compressed 0.02963	constricting 0.02940	small 0.02929	firmly 0.02919	low 0.02795	secure 0.02730	near 0.02658	securely 0.02460	closely 0.02108

Test context:
***************
tight.r	36	14	" it can be intimidating at first , because they wrap their arms pretty __tight__ around you , and everything they latch onto is pretty much headed straight to their mouth , " schmitz said .
Contexts for target tight are: ['nsubj_arms', 'advmod_pretty', 'xcompI_wrap', 'prep:around_you']
Contexts in vocabulary for target tight are: ['nsubj_arms', 'advmod_pretty', 'xcompI_wrap', 'prep:around_you']
Top most similar embeddings: tight 0.05782	tighter 0.04354	constricting 0.04064	snug 0.03977	snuggly 0.03961	snugly 0.03813	flapping 0.03747	taut 0.03734	tightly 0.03711	loose 0.03700

Generated lemmatized results
***************
GENERATED	tight.r 36 ::: tighter;constricting;snug;snuggly;snugly;flapping;taut;tightly;loose;saggy

Filtered results
***************
RANKED	tight.r 36	constricting 0.04064	close 0.03450	stretched 0.03370	close-fitting 0.03306	uncomfortable 0.03193	secure 0.03172	firmly 0.03148	cramped 0.03080	securely 0.03072	constricted 0.03038	low 0.02841	scarce 0.02803	sparse 0.02780	compressed 0.02762	restricted 0.02617	small 0.02563	pressurised 0.02559	closely 0.02509	pressured 0.02503	near 0.02499

Test context:
***************
tight.r	37	4	the incisions will feel __tight__ for the first 24-48 hours .
Contexts for target tight are: ['acompI_feel']
Contexts in vocabulary for target tight are: ['acompI_feel']
Top most similar embeddings: tight 0.50574	tighter 0.41877	achy 0.37198	light-headed 0.36708	looser 0.36511	anti-climactic 0.36260	taut 0.36237	bouyant 0.36222	cramped 0.36140	flabby 0.36065

Generated lemmatized results
***************
GENERATED	tight.r 37 ::: tighter;achy;looser;taut;bouyant;cramped;flabby;saggy;confortable;nauseated

Filtered results
***************
RANKED	tight.r 37	cramped 0.36140	constricted 0.35693	uncomfortable 0.34681	pressured 0.34066	pressurised 0.33885	close-fitting 0.33482	close 0.33207	stretched 0.32046	restricted 0.31846	sparse 0.31724	secure 0.31678	small 0.31516	low 0.31504	constricting 0.30481	firmly 0.30195	scarce 0.30105	compressed 0.29214	securely 0.28902	near 0.27704	closely 0.26862

Test context:
***************
tight.r	38	9	except for the soldiers , goth was locked up __tight__ .
Contexts for target tight are: ['advmodI_locked']
Contexts in vocabulary for target tight are: ['advmodI_locked']
Top most similar embeddings: tight 0.52107	tightly 0.39519	tighter 0.38367	tidily 0.36205	insecurely 0.35834	limply 0.35590	shallowly 0.35394	hermetically 0.35327	uselessly 0.35194	dexterously 0.35177

Generated lemmatized results
***************
GENERATED	tight.r 38 ::: tightly;tighter;tidily;insecurely;limply;shallowly;hermetically;uselessly;dexterously;convulsively

Filtered results
***************
RANKED	tight.r 38	firmly 0.34847	securely 0.34472	close 0.31300	closely 0.30171	constricted 0.30101	cramped 0.29874	close-fitting 0.29535	near 0.28835	pressurised 0.28745	low 0.28232	uncomfortable 0.28180	scarce 0.27355	small 0.27341	secure 0.27077	pressured 0.27046	stretched 0.26861	compressed 0.26768	constricting 0.26691	sparse 0.26127	restricted 0.25483

Test context:
***************
tight.r	39	7	nathan robins : did well to keep __tight__ on the left winger and was harshly judged by the referee on several occasions to have fouled the opposing player when i felt he just out muscled him .
Contexts for target tight are: ['acompI_keep', 'prep:on_winger']
Contexts in vocabulary for target tight are: ['acompI_keep']
Top most similar embeddings: tight 0.50192	tighter 0.41267	taut 0.37080	weed-free 0.36745	tightest 0.35326	leakproof 0.34962	rigid 0.34857	injury-free 0.34758	well-oiled 0.34735	well-watered 0.34708

Generated lemmatized results
***************
GENERATED	tight.r 39 ::: tighter;taut;tightest;leakproof;rigid;intact;close;snug;quiet;airtight

Filtered results
***************
RANKED	tight.r 39	close 0.34479	close-fitting 0.33454	low 0.31757	cramped 0.30931	pressurised 0.30825	restricted 0.30484	constricted 0.30246	scarce 0.30089	securely 0.30057	secure 0.29971	small 0.29889	sparse 0.29754	uncomfortable 0.29690	pressured 0.29192	firmly 0.28728	stretched 0.28291	compressed 0.28194	constricting 0.28025	near 0.27485	closely 0.27153

Test context:
***************
tight.r	40	6	i know that the market is __tight__ right now .
Contexts for target tight are: ['mark_that', 'nsubj_market', 'cop_is', 'ccompI_know', 'advmod_now']
Contexts in vocabulary for target tight are: ['mark_that', 'nsubj_market', 'cop_is', 'ccompI_know', 'advmod_now']
Top most similar embeddings: tight 0.02823	over-valued 0.02451	tighter 0.02328	overvalued 0.02289	bouyant 0.02264	overpopulated 0.02200	top-heavy 0.02180	salvageable 0.02160	overfull 0.02159	over-priced 0.02153

Generated lemmatized results
***************
GENERATED	tight.r 40 ::: tighter;overvalued;bouyant;overpopulated;salvageable;overfull;buoyant;watertight;ripe;sacrosanct

Filtered results
***************
RANKED	tight.r 40	constricted 0.01932	restricted 0.01863	close 0.01787	scarce 0.01756	pressurised 0.01752	sparse 0.01728	pressured 0.01728	cramped 0.01667	firmly 0.01661	uncomfortable 0.01601	low 0.01552	secure 0.01547	compressed 0.01506	stretched 0.01421	constricting 0.01418	small 0.01408	close-fitting 0.01342	near 0.01234	securely 0.01221	closely 0.00876

Test context:
***************
bar.n	41	6	that 's not a very high __bar__ .
Contexts for target bar are: ['nsubj_that', "cop_'s", 'neg_not', 'det_a', 'amod_high', 'rootI_*root*', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target bar are: ['nsubj_that', "cop_'s", 'neg_not', 'det_a', 'amod_high', 'rootI_*root*', 'punct_.']
Top most similar embeddings: toughie 0.00543	show-stopper 0.00531	platitude 0.00514	bummer 0.00491	biggy 0.00476	cop-out 0.00470	non-story 0.00469	exaggeration 0.00468	time-saver 0.00466	brainer 0.00464

Generated lemmatized results
***************
GENERATED	bar.n 41 ::: toughie;platitude;bummer;biggy;exaggeration;brainer;pricy;showstopper;ripoff;pipedream

Filtered results
***************
RANKED	bar.n 41	indicator 0.00382	hurdle 0.00380	barrier 0.00379	pub 0.00347	block 0.00346	saloon 0.00337	snack 0.00330	hostelry 0.00319	marker 0.00301	biscuit 0.00296	slab 0.00296	ban 0.00293	lounge 0.00285	restriction 0.00277	rod 0.00267	obstruction 0.00264	prohibition 0.00264	pole 0.00251	obstruct 0.00246	handlebar 0.00244	menu 0.00244	exclude 0.00243	metal 0.00242	level 0.00233	banner 0.00229	exclusion 0.00219	crossbar 0.00213	apparatus 0.00201	prevent 0.00178

Test context:
***************
bar.n	42	30	this more upright position is most easily and affordably achieved through slapping a riser bar on your setup , and only requires you to buy a bar instead of a __bar__ and stem .
Contexts for target bar are: ['det_a', 'prep:ofI_buy', 'cc_and', 'conj_stem']
Contexts in vocabulary for target bar are: ['det_a', 'prep:ofI_buy', 'cc_and', 'conj_stem']
Top most similar embeddings: bar 0.05300	bars 0.04497	pestle 0.04137	decanter 0.04066	hasp 0.04043	corm 0.04007	dibber 0.03962	grille 0.03924	lath 0.03905	handlebar 0.03889

Generated lemmatized results
***************
GENERATED	bar.n 42 ::: pestle;decanter;hasp;corm;dibber;grille;lath;handlebar;dartboard;teacup

Filtered results
***************
RANKED	bar.n 42	handlebar 0.03889	crossbar 0.03618	lounge 0.03476	saloon 0.03424	biscuit 0.03409	rod 0.03389	snack 0.03354	pub 0.03311	barrier 0.03222	pole 0.03199	block 0.03092	marker 0.03070	hostelry 0.03032	menu 0.03010	metal 0.03005	slab 0.02976	obstruction 0.02886	hurdle 0.02855	banner 0.02853	ban 0.02833	prohibition 0.02728	indicator 0.02700	apparatus 0.02684	restriction 0.02670	exclusion 0.02457	level 0.02345	obstruct 0.01938	exclude 0.01856	prevent 0.01791

Test context:
***************
bar.n	43	11	for twelve hours livewire will be broadcasting live from the blue __bar__ of union house at uea in an attempt to raise as much money as possible for a very worthy cause .
Contexts for target bar are: ['det_the', 'amod_blue', 'prep:fromI_live', 'prep:of_house']
Contexts in vocabulary for target bar are: ['det_the', 'amod_blue', 'prep:fromI_live', 'prep:of_house']
Top most similar embeddings: bar 0.06276	bars 0.04460	anteroom 0.04352	parlour 0.04345	restroom 0.04327	verandah 0.04322	drawing-room 0.04313	basement 0.04282	nightclub 0.04281	stairwell 0.04251

Generated lemmatized results
***************
GENERATED	bar.n 43 ::: anteroom;parlour;restroom;verandah;basement;nightclub;stairwell;lounge;tavern;ballroom

Filtered results
***************
RANKED	bar.n 43	lounge 0.04236	saloon 0.03823	pub 0.03762	hostelry 0.03490	menu 0.03433	crossbar 0.03327	block 0.03327	banner 0.03273	pole 0.03201	slab 0.03140	handlebar 0.03099	marker 0.03078	barrier 0.03043	rod 0.02960	apparatus 0.02944	obstruction 0.02828	hurdle 0.02792	ban 0.02753	biscuit 0.02732	level 0.02721	metal 0.02712	snack 0.02607	prohibition 0.02551	restriction 0.02455	indicator 0.02449	exclusion 0.02339	exclude 0.01559	obstruct 0.01451	prevent 0.01275

Test context:
***************
bar.n	44	6	the british government imposed a colour __bar__ in its colonies , so young blacks went in only for law or medicine where they could make a living without government support .
Contexts for target bar are: ['det_a', 'nn_colour', 'dobjI_imposed']
Contexts in vocabulary for target bar are: ['det_a', 'nn_colour', 'dobjI_imposed']
Top most similar embeddings: bar 0.11788	pallette 0.08621	bars 0.08593	palette 0.08344	pelmet 0.08049	raita 0.08039	cafeteria 0.08008	graticule 0.07994	corrector 0.07964	restriction 0.07947

Generated lemmatized results
***************
GENERATED	bar.n 44 ::: pallette;palette;pelmet;raita;cafeteria;graticule;corrector;restriction;carafe;backstamp

Filtered results
***************
RANKED	bar.n 44	restriction 0.07947	menu 0.07547	ban 0.07495	barrier 0.07437	marker 0.07282	pub 0.07185	lounge 0.07183	banner 0.07051	saloon 0.07009	snack 0.06999	hurdle 0.06840	handlebar 0.06778	indicator 0.06760	prohibition 0.06737	obstruction 0.06728	crossbar 0.06724	slab 0.06699	apparatus 0.06664	block 0.06650	rod 0.06625	pole 0.06590	hostelry 0.06577	biscuit 0.06518	level 0.06155	exclusion 0.05712	metal 0.05573	exclude 0.04644	obstruct 0.03918	prevent 0.03669

Test context:
***************
bar.n	45	2	put granola __bars__ in bowl .
Contexts for target bars are: ['nn_granola', 'dobjI_put']
Contexts in vocabulary for target bars are: ['dobjI_put']
Top most similar embeddings: bars 0.47558	bar 0.37736	keyholes 0.36433	thumbscrews 0.35796	matchboxes 0.35745	blinders 0.35663	tassles 0.35396	padlocks 0.35371	finger-tips 0.35213	krabs 0.35139

Generated lemmatized results
***************
GENERATED	bar.n 45 ::: keyhole;thumbscrew;matchbox;blinder;tassles;padlock;krabs;headband;dowel;ashtray

Filtered results
***************
RANKED	bar.n 45	pub 0.33809	banner 0.32589	handlebar 0.32331	rod 0.32241	pole 0.31871	biscuit 0.31557	hostelry 0.31306	snack 0.30969	menu 0.30733	barrier 0.30558	marker 0.30412	slab 0.30361	block 0.30335	obstruction 0.29927	crossbar 0.29621	hurdle 0.29373	restriction 0.29272	saloon 0.28601	ban 0.28493	lounge 0.28456	apparatus 0.28172	metal 0.27843	prohibition 0.27615	indicator 0.26751	level 0.26574	exclusion 0.26300	prevent 0.22628	obstruct 0.21237	exclude 0.20946

Test context:
***************
bar.n	46	16	it 's been a criticism of ie 's scrollbar css and also stands for the status __bar__ .
Contexts for target bar are: ['det_the', 'nn_status', 'prep:forI_stands']
Contexts in vocabulary for target bar are: ['det_the', 'nn_status', 'prep:forI_stands']
Top most similar embeddings: bar 0.12392	bars 0.09146	subkey 0.08545	quo 0.08453	symbol 0.08109	toolbar 0.08084	screen 0.08082	dotplot 0.08067	checkbutton 0.08054	scrollbars 0.08041

Generated lemmatized results
***************
GENERATED	bar.n 46 ::: subkey;quo;symbol;toolbar;screen;dotplot;checkbutton;scrollbars;menubar;scrollbar

Filtered results
***************
RANKED	bar.n 46	crossbar 0.07458	banner 0.07445	menu 0.07390	marker 0.07312	indicator 0.07223	lounge 0.07131	saloon 0.07116	pub 0.07095	barrier 0.06993	slab 0.06858	hostelry 0.06851	handlebar 0.06728	block 0.06690	pole 0.06689	prohibition 0.06648	restriction 0.06479	hurdle 0.06453	ban 0.06359	obstruction 0.06264	rod 0.06142	metal 0.06117	apparatus 0.05998	level 0.05997	exclusion 0.05963	biscuit 0.05864	snack 0.05645	exclude 0.04103	obstruct 0.03489	prevent 0.03269

Test context:
***************
bar.n	47	30	2 ) straddling the center bar , your child should be able to keep both feet flat on the ground with about a 1-inch clearance between the crotch and the __bar__ .
Contexts for target bar are: ['det_the', 'conjI_crotch']
Contexts in vocabulary for target bar are: ['det_the']
Top most similar embeddings: bar 0.52139	bars 0.40757	restaurant 0.39583	sugarhouse 0.39172	cafeteria 0.38440	minerva-press 0.38357	side-netting 0.38189	cross-bar 0.38108	bistro 0.38074	cafe 0.38059

Generated lemmatized results
***************
GENERATED	bar.n 47 ::: restaurant;sugarhouse;cafeteria;bistro;cafe;winline;orangerie;doorframe;startline;foundery

Filtered results
***************
RANKED	bar.n 47	pub 0.36776	lounge 0.36700	crossbar 0.36366	menu 0.34224	hostelry 0.34210	saloon 0.34000	handlebar 0.33867	slab 0.32060	barrier 0.31688	banner 0.31596	pole 0.31223	rod 0.31014	block 0.30829	hurdle 0.30760	apparatus 0.30529	ban 0.30277	biscuit 0.30202	obstruction 0.29904	snack 0.29855	restriction 0.29838	marker 0.29804	prohibition 0.29627	level 0.29519	indicator 0.29330	metal 0.28712	exclusion 0.28171	exclude 0.22611	obstruct 0.22149	prevent 0.20659

Test context:
***************
bar.n	49	23	seventy-five percent of my clientele that comes in there , they are just like a person on a friday afternoon going into a __bar__ , and he sits at the counter , and the bartender knows what he wants to drink .
Contexts for target bar are: ['det_a', 'prep:intoI_going']
Contexts in vocabulary for target bar are: ['det_a', 'prep:intoI_going']
Top most similar embeddings: bar 0.24779	restaurant 0.19674	pawnshop 0.19347	public-house 0.19197	restroom 0.19170	nightclub 0.19162	tailspin 0.18972	bar/restaurant 0.18714	store-room 0.18678	cafeteria 0.18657

Generated lemmatized results
***************
GENERATED	bar.n 49 ::: restaurant;pawnshop;restroom;nightclub;tailspin;cafeteria;phonebox;pub;headstand;coldframe

Filtered results
***************
RANKED	bar.n 49	pub 0.18548	hostelry 0.17559	lounge 0.17459	saloon 0.16100	menu 0.15742	slab 0.15089	barrier 0.14630	marker 0.14597	block 0.14413	rod 0.14372	snack 0.14231	pole 0.14179	hurdle 0.14171	biscuit 0.14151	handlebar 0.14136	crossbar 0.13909	ban 0.13776	level 0.13391	banner 0.13345	obstruction 0.13315	restriction 0.13233	apparatus 0.13197	indicator 0.13162	metal 0.13065	prohibition 0.12744	exclusion 0.11295	exclude 0.09448	obstruct 0.09042	prevent 0.08731

Test context:
***************
bar.n	50	24	the night is long at the numerous other discos and clubs , but for those seeking something more sedate there are quieter , sophisticated __bars__ in the hotels .
Contexts for target bars are: ['advmod_quieter', 'punct_,', 'amod_sophisticated', 'nsubjI_are', 'prep:in_hotels']
Contexts in vocabulary for target bars are: ['advmod_quieter', 'punct_,', 'amod_sophisticated', 'nsubjI_are', 'prep:in_hotels']
Top most similar embeddings: bars 0.02531	nightclubs 0.02132	eateries 0.02032	tavernas 0.02027	pizzerias 0.02018	resturants 0.01976	restaurants 0.01958	cafes 0.01920	motels 0.01890	bistros 0.01873

Generated lemmatized results
***************
GENERATED	bar.n 50 ::: nightclub;eatery;tavernas;pizzeria;resturants;restaurant;cafe;motel;bistro;restuarants

Filtered results
***************
RANKED	bar.n 50	lounge 0.01819	pub 0.01777	hostelry 0.01629	saloon 0.01597	menu 0.01576	snack 0.01547	rod 0.01477	pole 0.01341	biscuit 0.01319	banner 0.01300	block 0.01298	handlebar 0.01273	obstruction 0.01267	marker 0.01244	metal 0.01242	slab 0.01210	barrier 0.01199	apparatus 0.01161	ban 0.01160	hurdle 0.01159	restriction 0.01151	indicator 0.01142	level 0.01092	prohibition 0.01077	exclusion 0.00978	crossbar 0.00872	prevent 0.00718	exclude 0.00663	obstruct 0.00656

Test context:
***************
bar.n.v	48	23	abstract : analysis of contact between two chromosomal races of house mice in northern italy show that natural selection will produce alleles that __bar__ interracial matings if the resulting offspring are unfit hybrids .
Contexts for target bar are: ['nsubj_that', 'rcmodI_alleles', 'dobj_matings', 'advcl_hybrids']
Contexts in vocabulary for target bar are: ['nsubj_that']
Top most similar embeddings: bar 0.43979	bars 0.35821	occour 0.34494	disgusts 0.34186	harmonizes 0.33916	befit 0.33766	mystifies 0.33557	thwarts 0.33323	energizes 0.33181	feareth 0.33177

Generated lemmatized results
***************
GENERATED	bar.n.v 48 ::: occour;disgust;harmonize;befit;mystify;thwart;energize;feareth;energise;surround

Filtered results
***************
RANKED	bar.n.v 48	exclude 0.30717	obstruct 0.30502	pub 0.30432	prevent 0.30322	lounge 0.29860	block 0.29738	ban 0.29301	saloon 0.29237	hostelry 0.29032	barrier 0.28984	crossbar 0.28785	hurdle 0.28365	indicator 0.27839	snack 0.27461	slab 0.27383	biscuit 0.27379	handlebar 0.26928	marker 0.26925	obstruction 0.26815	menu 0.26761	metal 0.26356	restriction 0.26297	pole 0.26044	rod 0.26004	prohibition 0.25573	level 0.25222	banner 0.25177	apparatus 0.24014	exclusion 0.22793

Test context:
***************
cross.n	51	15	when time magazine 's cover portrays millennium nuts as deranged , crazy christians holding a __cross__ as it did last month , boycott their magazine and the products it advertises .
Contexts for target cross are: ['det_a', 'dobjI_holding']
Contexts in vocabulary for target cross are: ['det_a', 'dobjI_holding']
Top most similar embeddings: cross 0.24716	cross-shot 0.19155	crucifix 0.18898	throughball 0.18766	free-kick 0.18538	drumstick 0.18527	through-ball 0.18487	freekick 0.18414	headstand 0.18404	shuttlecock 0.18264

Generated lemmatized results
***************
GENERATED	cross.n 51 ::: crucifix;throughball;drumstick;freekick;headstand;shuttlecock;circlet;censer;hankie;pennon

Filtered results
***************
RANKED	cross.n 51	crucifix 0.18898	mixture 0.14244	sample 0.13935	hybrid 0.13799	sequence 0.13494	transverse 0.13385	segment 0.13151	x 0.12141	irate 0.11005	irritated 0.10820	annoyed 0.10302	angry 0.09486

Test context:
***************
cross.n	52	3	four-set in a __cross__ , the points meeting in water surrounded by luminous crescents .
Contexts for target cross are: ['det_a', 'prep:inI_four-set']
Contexts in vocabulary for target cross are: ['det_a']
Top most similar embeddings: cross 0.50454	throughball 0.38563	flick-on 0.38303	through-ball 0.38096	free-kick 0.37996	cross-shot 0.37942	freekick 0.37619	goal-kick 0.37412	bordure 0.36533	backpass 0.36491

Generated lemmatized results
***************
GENERATED	cross.n 52 ::: throughball;freekick;bordure;backpass;bonboniere;longship;crucifix;totso;cartwheel;fesse

Filtered results
***************
RANKED	cross.n 52	crucifix 0.35862	hybrid 0.30420	sample 0.30068	mixture 0.29653	transverse 0.29205	sequence 0.29031	segment 0.28825	x 0.27757	irritated 0.26366	irate 0.26032	annoyed 0.25844	angry 0.23554

Test context:
***************
cross.n	53	8	it was designed in the form of a __cross__ with a cast iron sword placed where the cross members join .
Contexts for target cross are: ['det_a', 'prep:ofI_form', 'dep_placed']
Contexts in vocabulary for target cross are: ['det_a', 'prep:ofI_form', 'dep_placed']
Top most similar embeddings: cross 0.11340	crucifix 0.08767	crosses 0.08357	swastika 0.08108	fleur-de-lys 0.08084	free-kick 0.08048	throw-in 0.08027	finial 0.07995	pentagram 0.07982	horse-shoe 0.07881

Generated lemmatized results
***************
GENERATED	cross.n 53 ::: crucifix;swastika;finial;pentagram;wreath;saltire;breastplate;scarab;pentacle;tumulus

Filtered results
***************
RANKED	cross.n 53	crucifix 0.08767	transverse 0.06417	hybrid 0.06337	sequence 0.06251	sample 0.06059	mixture 0.06041	segment 0.05675	x 0.05563	irritated 0.04854	irate 0.04629	annoyed 0.04367	angry 0.04059

Test context:
***************
cross.n	54	3	triticale , a __cross__ between wheat and rye , matures later than rye but earlier than wheat .
Contexts for target cross are: ['det_a', 'apposI_triticale', 'prep:between_wheat']
Contexts in vocabulary for target cross are: ['det_a']
Top most similar embeddings: cross 0.50454	throughball 0.38563	flick-on 0.38303	through-ball 0.38096	free-kick 0.37996	cross-shot 0.37942	freekick 0.37619	goal-kick 0.37412	bordure 0.36533	backpass 0.36491

Generated lemmatized results
***************
GENERATED	cross.n 54 ::: throughball;freekick;bordure;backpass;bonboniere;longship;crucifix;totso;cartwheel;fesse

Filtered results
***************
RANKED	cross.n 54	crucifix 0.35862	hybrid 0.30420	sample 0.30068	mixture 0.29653	transverse 0.29205	sequence 0.29031	segment 0.28825	x 0.27757	irritated 0.26366	irate 0.26032	annoyed 0.25844	angry 0.23554

Test context:
***************
cross.n	55	27	old nick got tired of cussing , was humiliated at being sat on , and hurting like the torments of hell for being so close to the __cross__ .
Contexts for target cross are: ['det_the', 'prep:toI_close']
Contexts in vocabulary for target cross are: ['det_the', 'prep:toI_close']
Top most similar embeddings: cross 0.24361	touch-line 0.20363	trailhead 0.19602	roadhead 0.19371	a189 0.19194	treeline 0.19189	startline 0.19173	goalline 0.19172	a390 0.19156	a217 0.19106

Generated lemmatized results
***************
GENERATED	cross.n 55 ::: trailhead;roadhead;treeline;startline;goalline;lecht;hellespont;seacoast;foundery;catafalque

Filtered results
***************
RANKED	cross.n 55	crucifix 0.16887	transverse 0.13550	sample 0.13380	segment 0.12959	hybrid 0.12855	sequence 0.12645	x 0.12112	mixture 0.12057	irate 0.10230	irritated 0.09995	angry 0.09676	annoyed 0.09040

Test context:
***************
cross.n	56	16	by 1924 he managed to transmit across a few feet the flickering image of a maltese __cross__ and on 26th january 1926 he gave the world 's first demonstration of true television in his attic workshop before some fifty scientists .
Contexts for target cross are: ['det_a', 'amod_maltese', 'prep:ofI_image']
Contexts in vocabulary for target cross are: ['det_a', 'amod_maltese', 'prep:ofI_image']
Top most similar embeddings: cross 0.12874	swastika 0.09087	longship 0.09053	crucifix 0.08871	battleaxe 0.08825	noblewoman 0.08813	coat-of-arms 0.08693	charioteer 0.08671	crosses 0.08665	longboat 0.08661

Generated lemmatized results
***************
GENERATED	cross.n 56 ::: swastika;longship;crucifix;battleaxe;noblewoman;charioteer;longboat;cockerel;chessboard;shuttlecock

Filtered results
***************
RANKED	cross.n 56	crucifix 0.08871	sample 0.06374	hybrid 0.06306	transverse 0.06037	sequence 0.05877	segment 0.05868	mixture 0.05731	x 0.05477	irate 0.04559	irritated 0.04223	annoyed 0.03926	angry 0.03687

Test context:
***************
cross.n	57	30	he appeared to his apostles and spoke to them about god 's kingdom. ' acts 1:3 jesus took the consequences of our self-centredness by giving up his life on the __cross__ .
Contexts for target cross are: ['det_the', 'prep:onI_giving']
Contexts in vocabulary for target cross are: ['det_the', 'prep:onI_giving']
Top most similar embeddings: cross 0.24391	otherhand 0.19237	winline 0.18098	mercy-seat 0.17402	touch-line 0.17373	backburner 0.17369	warpath 0.17043	goalline 0.17040	startline 0.17035	quarter-deck 0.16903

Generated lemmatized results
***************
GENERATED	cross.n 57 ::: otherhand;winline;backburner;warpath;goalline;startline;copperbelt;roodee;shroppie;naze

Filtered results
***************
RANKED	cross.n 57	crucifix 0.16265	transverse 0.13016	sample 0.12938	hybrid 0.12900	segment 0.12534	mixture 0.12379	sequence 0.12300	x 0.12115	irate 0.09712	angry 0.08847	irritated 0.08517	annoyed 0.08034

Test context:
***************
cross.n	58	25	if power cycling occurs , care must be taken to account for the " dead time " between shutdown and power up when the latchup __cross__ section is evaluated .
Contexts for target cross are: ['nnI_section']
Contexts in vocabulary for target cross are: ['nnI_section']
Top most similar embeddings: cross 0.53649	crosses 0.39050	monkbar 0.36283	cesarean 0.36187	caesarian 0.35960	uhb 0.34544	quick-reference 0.34465	bracebridge 0.34422	naca 0.34280	hollywell 0.34256

Generated lemmatized results
***************
GENERATED	cross.n 58 ::: monkbar;cesarean;caesarian;uhb;bracebridge;naca;hollywell;churnet;learnmoney;bmaf

Filtered results
***************
RANKED	cross.n 58	transverse 0.31649	crucifix 0.30173	hybrid 0.28593	sample 0.27987	x 0.27199	segment 0.26036	sequence 0.25066	mixture 0.24391	angry 0.23802	irritated 0.23537	irate 0.23408	annoyed 0.22046

Test context:
***************
cross.n	59	7	" mixed race people represent a diverse __cross__ section of racial , ethnic , and cultural heritages , with many multiracial individuals identifying with multiple communities , " the organizations stated .
Contexts for target cross are: ['nnI_section']
Contexts in vocabulary for target cross are: ['nnI_section']
Top most similar embeddings: cross 0.53649	crosses 0.39050	monkbar 0.36283	cesarean 0.36187	caesarian 0.35960	uhb 0.34544	quick-reference 0.34465	bracebridge 0.34422	naca 0.34280	hollywell 0.34256

Generated lemmatized results
***************
GENERATED	cross.n 59 ::: monkbar;cesarean;caesarian;uhb;bracebridge;naca;hollywell;churnet;learnmoney;bmaf

Filtered results
***************
RANKED	cross.n 59	transverse 0.31649	crucifix 0.30173	hybrid 0.28593	sample 0.27987	x 0.27199	segment 0.26036	sequence 0.25066	mixture 0.24391	angry 0.23802	irritated 0.23537	irate 0.23408	annoyed 0.22046

Test context:
***************
cross.n.a	60	37	i can only judge keyboards by going into somewhere like pc world and physically trying them , and i do not want to go into somewhere like pc world , as i do not want to get __cross__ .
Contexts for target cross are: ['dobjI_get']
Contexts in vocabulary for target cross are: ['dobjI_get']
Top most similar embeddings: cross 0.47510	crosses 0.38946	come-uppance 0.36508	freekick 0.35816	flick-on 0.35689	free-kick 0.35242	cross-shot 0.35194	shirty 0.34739	throughball 0.34719	holeshot 0.33964

Generated lemmatized results
***************
GENERATED	cross.n.a 60 ::: crosses;freekick;shirty;throughball;holeshot;jiggy;conformer;earful;payrise;huffy

Filtered results
***************
RANKED	cross.n.a 60	crucifix 0.33135	angry 0.30713	irate 0.29781	irritated 0.29265	transverse 0.28573	sample 0.28065	mixture 0.26509	sequence 0.26400	annoyed 0.26378	hybrid 0.26031	x 0.25824	segment 0.25284

Test context:
***************
finally.r	61	20	mr. hall 's old factory is still on oklahoma avenue , but the metal fabrication plant where mr. larson worked __finally__ closed last year after withering for decades .
Contexts for target finally are: ['advmodI_closed']
Contexts in vocabulary for target finally are: ['advmodI_closed']
Top most similar embeddings: finally 0.54536	eventually 0.42450	eventualy 0.41594	duely 0.40960	however 0.40767	ceremoniously 0.40405	bloodily 0.40204	then 0.40077	indefinately 0.40029	unfortuantely 0.39989

Generated lemmatized results
***************
GENERATED	finally.r 61 ::: eventually;eventualy;duely;however;ceremoniously;bloodily;then;indefinately;unfortuantely;meanwhile

Filtered results
***************
RANKED	finally.r 61	eventually 0.42450	also 0.39237	ultimately 0.38591	lastly 0.38119

Test context:
***************
finally.r	62	0	__finally__ , this new rule will also have the effect of encouraging existing corporations to produce safer products , in keeping with the public policy goals that underlie product liability law generally. [ fn .
Contexts for target finally are: ['advmodI_have']
Contexts in vocabulary for target finally are: ['advmodI_have']
Top most similar embeddings: finally 0.53233	proably 0.43771	futhermore 0.43743	however 0.43518	unfortuantely 0.43195	also 0.42797	regretably 0.42145	apprently 0.41881	eventually 0.41821	then 0.41801

Generated lemmatized results
***************
GENERATED	finally.r 62 ::: proably;futhermore;however;unfortuantely;also;regretably;apprently;eventually;then;furthermore

Filtered results
***************
RANKED	finally.r 62	also 0.42797	eventually 0.41821	lastly 0.41549	ultimately 0.40447

Test context:
***************
finally.r	63	29	however , this easy clearing method has muddled the issue quite a bit , since now explorer is not actually being cleared at all , while gecko browsers have __finally__ been corrected so they do clear all previous floats .
Contexts for target finally are: ['advmodI_corrected']
Contexts in vocabulary for target finally are: ['advmodI_corrected']
Top most similar embeddings: finally 0.51569	duely 0.42652	eventually 0.41720	eventualy 0.40739	however 0.40505	bloodily 0.39945	then 0.39755	reproducibly 0.39696	dexterously 0.39602	feasibly 0.39560

Generated lemmatized results
***************
GENERATED	finally.r 63 ::: duely;eventually;eventualy;however;bloodily;then;reproducibly;dexterously;feasibly;ceremonially

Filtered results
***************
RANKED	finally.r 63	eventually 0.41720	also 0.39482	lastly 0.38264	ultimately 0.38140

Test context:
***************
finally.r	64	0	__finally__ , adam sees the id card being used as an authenticator because it might be declared " trustworthy " .
Contexts for target finally are: ['advmodI_sees']
Contexts in vocabulary for target finally are: ['advmodI_sees']
Top most similar embeddings: finally 0.52884	however 0.41546	also 0.40945	eventually 0.40867	futhermore 0.40808	meanwhile 0.40647	proably 0.40292	coincidently 0.40176	then 0.40103	unfortuantely 0.40068

Generated lemmatized results
***************
GENERATED	finally.r 64 ::: however;also;eventually;futhermore;meanwhile;proably;coincidently;then;unfortuantely;thus

Filtered results
***************
RANKED	finally.r 64	also 0.40945	eventually 0.40867	ultimately 0.39624	lastly 0.39038

Test context:
***************
finally.r	65	31	he said , " ok , first , i 'd like to have a face like clark gable , then , i 'd like a build like arnold schwarzenegger , and __finally__ , i 'd like sexual equipment like this here horse i 'm riding .
Contexts for target finally are: ['advmodI_like']
Contexts in vocabulary for target finally are: ['advmodI_like']
Top most similar embeddings: finally 0.53512	lastly 0.41877	however 0.41695	also 0.41625	proably 0.41325	eventually 0.40926	personnally 0.40400	then 0.40200	nonetheless 0.39994	futhermore 0.39953

Generated lemmatized results
***************
GENERATED	finally.r 65 ::: lastly;however;also;proably;eventually;personnally;then;nonetheless;futhermore;defintely

Filtered results
***************
RANKED	finally.r 65	lastly 0.41877	also 0.41625	eventually 0.40926	ultimately 0.39443

Test context:
***************
finally.r	66	0	__finally__ , i interviewed eric howes , a noted spyware researcher at the university of illinois , who has found that today 's most popular anti-spyware software packages are far less effective than many believe ( see sidebar , below ) .
Contexts for target finally are: ['advmodI_interviewed']
Contexts in vocabulary for target finally are: ['advmodI_interviewed']
Top most similar embeddings: finally 0.51001	duely 0.41281	however 0.40980	also 0.40936	eventually 0.40936	then 0.40248	subsequently 0.40158	additionally 0.39760	eventualy 0.39618	publickly 0.39470

Generated lemmatized results
***************
GENERATED	finally.r 66 ::: duely;however;also;eventually;then;subsequently;additionally;eventualy;publickly;dually

Filtered results
***************
RANKED	finally.r 66	also 0.40936	eventually 0.40936	lastly 0.38191	ultimately 0.37562

Test context:
***************
finally.r	67	21	however , you will get those nsf fees reimbursed by the bank as well - it will just come when they __finally__ process everything together .
Contexts for target finally are: ['advmodI_process']
Contexts in vocabulary for target finally are: ['advmodI_process']
Top most similar embeddings: finally 0.50411	however 0.42475	thus 0.41371	ultimately 0.40810	then 0.40698	proably 0.40355	futhermore 0.40228	furthermore 0.40216	nonetheless 0.40144	eventually 0.40010

Generated lemmatized results
***************
GENERATED	finally.r 67 ::: however;thus;ultimately;then;proably;futhermore;furthermore;nonetheless;eventually;also

Filtered results
***************
RANKED	finally.r 67	ultimately 0.40810	eventually 0.40010	also 0.39980	lastly 0.39115

Test context:
***************
finally.r	68	0	__finally__ , the army has conducted range characterization activities regarding the potential for contamination from munitions residues at 17 ranges throughout the united states , assessing the different types of ranges used by the army .
Contexts for target finally are: ['advmodI_conducted']
Contexts in vocabulary for target finally are: ['advmodI_conducted']
Top most similar embeddings: finally 0.50925	however 0.41086	duely 0.41067	also 0.40890	moreover 0.40103	furthermore 0.40060	eventually 0.39960	purposively 0.39862	additionally 0.39770	then 0.39729

Generated lemmatized results
***************
GENERATED	finally.r 68 ::: however;duely;also;moreover;furthermore;eventually;purposively;additionally;then;subsequently

Filtered results
***************
RANKED	finally.r 68	also 0.40890	eventually 0.39960	ultimately 0.38934	lastly 0.38455

Test context:
***************
finally.r	69	0	__finally__ , it is outlined how a mesoscopic theory should be constructed for a particular scanning tunneling microscopy experiment in order to overcome the failure of a corresponding reaction diffusion model to quantitatively reproduce the experiments .
Contexts for target finally are: ['advmodI_outlined']
Contexts in vocabulary for target finally are: ['advmodI_outlined']
Top most similar embeddings: finally 0.51909	lastly 0.40355	also 0.40046	however 0.39971	then 0.39939	meanwhile 0.39368	trenchantly 0.39219	thus 0.39115	contrastingly 0.38894	duely 0.38836

Generated lemmatized results
***************
GENERATED	finally.r 69 ::: lastly;also;however;then;meanwhile;trenchantly;thus;contrastingly;duely;moreover

Filtered results
***************
RANKED	finally.r 69	lastly 0.40355	also 0.40046	eventually 0.37935	ultimately 0.36518

Test context:
***************
finally.r	70	0	__finally__ , the proposed disposal rule would apply to transfer agents registered with the commission .
Contexts for target finally are: ['advmodI_apply']
Contexts in vocabulary for target finally are: ['advmodI_apply']
Top most similar embeddings: finally 0.50492	however 0.42162	also 0.41423	then 0.41084	futhermore 0.40845	eventually 0.40124	therefore 0.40040	nonetheless 0.39922	furthermore 0.39732	additionally 0.39574

Generated lemmatized results
***************
GENERATED	finally.r 70 ::: however;also;then;futhermore;eventually;therefore;nonetheless;furthermore;additionally;legislatively

Filtered results
***************
RANKED	finally.r 70	also 0.41423	eventually 0.40124	lastly 0.39395	ultimately 0.38526

Test context:
***************
find.v	71	19	up to sixty percent of the fatty acid content in the grasses on the plains contain omega-3 and are __found__ in abundance in buffalo allowed to graze on the natural grasses .
Contexts for target found are: ['auxpass_are', 'conjI_contain', 'prep:in_abundance']
Contexts in vocabulary for target found are: ['auxpass_are', 'conjI_contain', 'prep:in_abundance']
Top most similar embeddings: found 0.11611	secreted 0.08578	consumed 0.08500	sprinkled 0.08491	recombined 0.08465	intermixed 0.08453	combusted 0.08413	displayed 0.08401	used 0.08383	up-regulated 0.08331

Generated lemmatized results
***************
GENERATED	find.v 71 ::: secrete;consume;sprinkle;recombine;intermix;combust;display;use;scatter;replenish

Filtered results
***************
RANKED	find.v 71	show 0.08204	discover 0.08099	obtain 0.08064	see 0.08014	detect 0.07987	believe 0.07433	consider 0.07381	present 0.07350	locate 0.07293	determine 0.07051	felt 0.06813	calculate 0.06810	write 0.06718	buy 0.06622	seek 0.06537	get 0.06311	realise 0.06296	exist 0.06242	invent 0.05888	evident 0.05769	think 0.05692	feel 0.04894

Test context:
***************
find.v	72	10	if you find yourself caught up in negative thoughts and __find__ that you suddenly expect the worst it will be impossible to perform at your peak .
Contexts for target find are: ['conjI_caught', 'ccomp_expect']
Contexts in vocabulary for target find are: ['conjI_caught', 'ccomp_expect']
Top most similar embeddings: find 0.20785	know 0.17003	finding 0.16891	finds 0.16801	found 0.16594	figuring 0.16551	knew 0.16280	wondering 0.15986	realize 0.15984	realise 0.15945

Generated lemmatized results
***************
GENERATED	find.v 72 ::: know;figure;wonder;realize;realise;loose;discover;reassure;moan;tell

Filtered results
***************
RANKED	find.v 72	realise 0.15945	discover 0.15708	show 0.15445	think 0.15379	get 0.14862	believe 0.14825	feel 0.14741	see 0.14402	consider 0.13965	felt 0.13920	write 0.13695	seek 0.13681	locate 0.13499	determine 0.13498	buy 0.13323	detect 0.12979	obtain 0.12979	evident 0.12900	calculate 0.12830	invent 0.12538	exist 0.12044	present 0.12026

Test context:
***************
find.v	73	7	search customer reviews 9 of 10 people __found__ the following review helpful : early feminist literature - memorable , november 21 , 2000 reviewer : m. j. smith ( seattle , wa usa ) - see all my reviews this book consists of a gem of a story and a mediocre afterward .
Contexts for target found are: ['nsubj_people', 'ccompI_reviews', 'dobj_the']
Contexts in vocabulary for target found are: ['nsubj_people', 'ccompI_reviews', 'dobj_the']
Top most similar embeddings: found 0.10974	find 0.08893	discovered 0.08596	learned 0.08190	encountered 0.08135	misunderstand 0.08112	co-create 0.07853	discovering 0.07847	read 0.07841	misinterpret 0.07827

Generated lemmatized results
***************
GENERATED	find.v 73 ::: discover;learn;encounter;misunderstand;read;misinterpret;visit;see;add;rediscover

Filtered results
***************
RANKED	find.v 73	discover 0.08596	see 0.07703	believe 0.07533	write 0.07248	buy 0.07229	consider 0.07220	felt 0.07186	show 0.07163	locate 0.07112	get 0.07061	invent 0.07033	realise 0.06957	feel 0.06746	detect 0.06738	obtain 0.06736	seek 0.06724	think 0.06636	determine 0.06555	calculate 0.06480	present 0.06313	exist 0.06242	evident 0.04660

Test context:
***************
find.v	74	12	well they have a friend named morgan and morgan told them to __find__ an object that he wants .
Contexts for target find are: ['aux_to', 'xcompI_told', 'dobj_object']
Contexts in vocabulary for target find are: ['aux_to', 'xcompI_told', 'dobj_object']
Top most similar embeddings: find 0.12178	locate 0.10873	retreive 0.10784	re-activate 0.10063	retrieve 0.10051	descibe 0.09943	wheedle 0.09933	sanitise 0.09908	mass-produce 0.09896	reenter 0.09870

Generated lemmatized results
***************
GENERATED	find.v 74 ::: locate;retreive;retrieve;descibe;wheedle;sanitise;reenter;retype;unhook;exhume

Filtered results
***************
RANKED	find.v 74	locate 0.10873	obtain 0.09422	get 0.09378	discover 0.09350	invent 0.09061	write 0.08761	see 0.08751	detect 0.08658	buy 0.08496	consider 0.08413	seek 0.08226	calculate 0.08190	determine 0.08037	realise 0.07752	show 0.07422	think 0.06957	believe 0.06957	feel 0.06846	present 0.06752	exist 0.06180	felt 0.05703	evident 0.04912

Test context:
***************
find.v	75	9	consistent with previous findings , lack of congruence was __found__ to be a precursor of intrusiveness .
Contexts for target found are: ['nsubjpass_lack', 'auxpass_was', 'rootI_*root*', 'xcomp_precursor', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target found are: ['nsubjpass_lack', 'auxpass_was', 'rootI_*root*', 'punct_.']
Top most similar embeddings: found 0.07112	discovered 0.05507	highlighted 0.05427	revealed 0.05359	noted 0.05314	seen 0.05210	demonstrated 0.05199	shown 0.05198	countered 0.05187	compounded 0.05147

Generated lemmatized results
***************
GENERATED	find.v 75 ::: discover;highlight;reveal;note;see;demonstrate;show;counter;compound;identify

Filtered results
***************
RANKED	find.v 75	discover 0.05507	see 0.05210	show 0.05198	felt 0.05106	believe 0.04970	consider 0.04930	detect 0.04881	obtain 0.04580	present 0.04549	think 0.04396	locate 0.04333	determine 0.04317	realise 0.04307	calculate 0.04293	buy 0.04128	seek 0.04106	invent 0.04072	write 0.04042	evident 0.03474	get 0.03449	exist 0.03121	feel 0.03028

Test context:
***************
find.v	76	28	nokia mobile phone cases , motorola cell phone cases , motorola cell phone case , body glove cell phone case i think the best place where you can __find__ cell phone carrying case is ebay .
Contexts for target find are: ['advmod_where', 'nsubj_you', 'aux_can', 'rcmodI_place', 'dobj_phone']
Contexts in vocabulary for target find are: ['advmod_where', 'nsubj_you', 'aux_can', 'rcmodI_place', 'dobj_phone']
Top most similar embeddings: find 0.03483	see/hear 0.02813	buy 0.02453	get 0.02443	locate 0.02440	choose 0.02367	misplace 0.02327	aquire 0.02321	recive 0.02317	lipread 0.02281

Generated lemmatized results
***************
GENERATED	find.v 76 ::: buy;get;locate;choose;misplace;aquire;recive;lipread;enjoy;overhear

Filtered results
***************
RANKED	find.v 76	buy 0.02453	get 0.02443	locate 0.02440	discover 0.02231	obtain 0.02154	see 0.02096	feel 0.01927	seek 0.01810	invent 0.01789	detect 0.01756	think 0.01753	write 0.01746	realise 0.01673	consider 0.01615	calculate 0.01583	believe 0.01566	exist 0.01544	determine 0.01534	felt 0.01509	show 0.01396	present 0.01383	evident 0.00965

Test context:
***************
find.v	77	10	oh , and as far as the kool-aid jokes , __find__ your own material .
Contexts for target find are: ['discourse_oh', 'punct_,', 'rootI_*root*', 'dobj_material', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target find are: ['discourse_oh', 'punct_,', 'rootI_*root*', 'dobj_material', 'punct_.']
Top most similar embeddings: find 0.02656	drawled 0.02337	betcha 0.02282	chorused 0.02280	rememeber 0.02244	remember 0.02241	t'was 0.02202	harpoole 0.02201	gloats 0.02197	gots 0.02193

Generated lemmatized results
***************
GENERATED	find.v 77 ::: drawl;betcha;chorus;rememeber;remember;harpoole;gloat;gots;pant;see

Filtered results
***************
RANKED	find.v 77	see 0.02166	write 0.02121	think 0.02097	discover 0.02006	believe 0.01962	consider 0.01939	get 0.01928	show 0.01917	present 0.01881	invent 0.01846	locate 0.01831	felt 0.01809	feel 0.01781	buy 0.01753	realise 0.01727	seek 0.01713	detect 0.01656	calculate 0.01632	exist 0.01605	obtain 0.01604	evident 0.01562	determine 0.01552

Test context:
***************
find.v	78	11	but much that we once accepted as inevitable , we now __find__ absolutely intolerable .
Contexts for target find are: ['advmod_much', 'punct_,', 'nsubj_we', 'advmod_now', 'rootI_*root*', 'acomp_intolerable', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target find are: ['advmod_much', 'punct_,', 'nsubj_we', 'advmod_now', 'rootI_*root*', 'acomp_intolerable', 'punct_.']
Top most similar embeddings: find 0.00698	found 0.00571	felt 0.00534	proved 0.00518	becoming 0.00507	appreciate 0.00503	apreciate 0.00501	deplore 0.00497	grown 0.00492	laughed 0.00491

Generated lemmatized results
***************
GENERATED	find.v 78 ::: felt;prove;become;appreciate;apreciate;deplore;grow;laugh;seem;enjoy

Filtered results
***************
RANKED	find.v 78	felt 0.00534	feel 0.00483	believe 0.00483	discover 0.00477	consider 0.00476	seek 0.00472	get 0.00464	think 0.00442	see 0.00439	realise 0.00428	show 0.00397	write 0.00395	buy 0.00386	determine 0.00382	evident 0.00373	invent 0.00372	obtain 0.00371	exist 0.00368	locate 0.00362	calculate 0.00353	detect 0.00350	present 0.00336

Test context:
***************
find.v	79	2	speedupmypc automatically __finds__ the best settings for your pc and carefully controls your system resources to give you the best performance .
Contexts for target finds are: ['nsubj_speedupmypc', 'advmod_automatically', 'rootI_*root*', 'dobj_settings', 'cc_and', 'conj_controls', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target finds are: ['advmod_automatically', 'rootI_*root*', 'dobj_settings', 'cc_and', 'conj_controls', 'punct_.']
Top most similar embeddings: recalculates 0.01341	finds 0.01339	prioritizes 0.01294	rearranges 0.01285	detects 0.01276	configures 0.01267	standardises 0.01258	synchronizes 0.01253	transcribes 0.01251	synchronises 0.01221

Generated lemmatized results
***************
GENERATED	find.v 79 ::: recalculate;prioritize;rearrange;detect;configure;standardise;synchronize;transcribe;synchronise;annotate

Filtered results
***************
RANKED	find.v 79	detect 0.01276	locate 0.01117	calculate 0.01106	determine 0.01041	discover 0.01029	obtain 0.00982	invent 0.00953	buy 0.00922	present 0.00914	see 0.00892	consider 0.00874	get 0.00862	realise 0.00848	seek 0.00846	show 0.00842	write 0.00831	feel 0.00784	exist 0.00749	believe 0.00730	think 0.00719	evident 0.00608	felt 0.00570

Test context:
***************
find.v	80	24	if bessler had indeed discovered some mechanical way of creating perpetual motion , perhaps the only way it is explainable is if he had __found__ a way of extracting the energy from this aether .
Contexts for target found are: ['mark_if', 'nsubj_he', 'aux_had', 'advclI_is', 'dobj_way']
Contexts in vocabulary for target found are: ['mark_if', 'nsubj_he', 'aux_had', 'advclI_is', 'dobj_way']
Top most similar embeddings: found 0.03028	misbehaved 0.02547	discovered 0.02458	recanted 0.02369	burrowed 0.02346	sneezed 0.02344	divined 0.02326	overdosed 0.02306	puked 0.02299	fantasised 0.02299

Generated lemmatized results
***************
GENERATED	find.v 80 ::: misbehave;discover;recant;burrow;sneeze;divine;overdose;puke;fantasise;urinate

Filtered results
***************
RANKED	find.v 80	discover 0.02458	get 0.02152	felt 0.02096	see 0.02082	detect 0.02023	invent 0.02015	believe 0.02011	buy 0.01997	realise 0.01987	show 0.01932	think 0.01928	exist 0.01898	feel 0.01897	seek 0.01851	consider 0.01841	obtain 0.01838	write 0.01725	determine 0.01721	calculate 0.01593	present 0.01566	locate 0.01543	evident 0.01195

Test context:
***************
fix.v	81	10	the transcendental meditation people advertised this : " meditation can __fix__ many sicknesses .
Contexts for target fix are: ['nsubj_meditation', 'aux_can', 'ccompI_advertised', 'dobj_sicknesses']
Contexts in vocabulary for target fix are: ['nsubj_meditation', 'aux_can', 'ccompI_advertised']
Top most similar embeddings: fix 0.09956	cure 0.07623	mend 0.07431	affect 0.07335	re-set 0.07315	aggravate 0.07309	relieve 0.07276	fixed 0.07247	shorten 0.07173	soothe 0.07130

Generated lemmatized results
***************
GENERATED	fix.v 81 ::: cure;mend;affect;aggravate;relieve;shorten;soothe;enlighten;exacerbate;sweeten

Filtered results
***************
RANKED	fix.v 81	cure 0.07623	mend 0.07431	correct 0.06919	solve 0.06914	resolve 0.06796	repair 0.06794	heal 0.06590	determine 0.06419	improve 0.06122	patch 0.06021	stick 0.05966	do 0.05894	set 0.05490	intent 0.04618

Test context:
***************
fix.v	82	19	now , i 'm not sure how i went from missing two weeks to six , but intend to __fix__ that as i go .
Contexts for target fix are: ['aux_to', 'xcompI_intend', 'dobj_that']
Contexts in vocabulary for target fix are: ['aux_to', 'xcompI_intend', 'dobj_that']
Top most similar embeddings: fix 0.12794	rectify 0.10215	exploit 0.09305	proove 0.09225	enunciate 0.09214	televise 0.09176	solve 0.09148	expiate 0.09059	foist 0.09007	mass-produce 0.08997

Generated lemmatized results
***************
GENERATED	fix.v 82 ::: rectify;exploit;proove;enunciate;televise;solve;expiate;foist;recalibrate;do

Filtered results
***************
RANKED	fix.v 82	solve 0.09148	do 0.08989	resolve 0.08682	mend 0.08483	cure 0.08286	improve 0.07675	repair 0.07614	correct 0.07601	heal 0.07573	determine 0.07546	stick 0.07465	set 0.07024	patch 0.06594	intent 0.05166

Test context:
***************
fix.v	83	18	' ' i feel i can get a lot more done as a selectman by being innovative and __fixing__ the problems we have with cash flows , because they occur every year .
Contexts for target fixing are: ['conjI_innovative']
Contexts in vocabulary for target fixing are: ['conjI_innovative']
Top most similar embeddings: fixing 0.43437	value-adding 0.33436	innovative 0.33369	correcting 0.33217	timesaving 0.32809	impactful 0.32723	eyecatching 0.32701	cutting 0.32695	customer-focussed 0.32634	fix 0.32558

Generated lemmatized results
***************
GENERATED	fix.v 83 ::: innovative;correct;timesaving;impactful;eyecatching;cut;fabricate;fasten;stimulate;cement

Filtered results
***************
RANKED	fix.v 83	correct 0.33217	repair 0.31878	patch 0.29890	stick 0.29735	resolve 0.29409	mend 0.29386	improve 0.29172	cure 0.29080	set 0.28567	determine 0.28070	solve 0.27937	heal 0.25976	do 0.25756	intent 0.23605

Test context:
***************
fix.v	84	19	getting back to the day when doctors looked at the whole person .and did not expect a pill to __fix__ the mind .
Contexts for target fix are: ['nsubj_pill', 'aux_to', 'xcompI_expect', 'dobj_mind']
Contexts in vocabulary for target fix are: ['nsubj_pill', 'aux_to', 'xcompI_expect', 'dobj_mind']
Top most similar embeddings: fix 0.05746	solve 0.04404	relieve 0.04277	mend 0.04242	make 0.04219	cure 0.04188	stabilize 0.04181	supress 0.04179	change 0.04140	quieten 0.04128

Generated lemmatized results
***************
GENERATED	fix.v 84 ::: solve;relieve;mend;make;cure;stabilize;supress;change;quieten;rectify

Filtered results
***************
RANKED	fix.v 84	solve 0.04404	mend 0.04242	cure 0.04188	heal 0.03985	improve 0.03817	resolve 0.03700	repair 0.03532	stick 0.03506	correct 0.03446	do 0.03423	determine 0.03188	patch 0.02987	set 0.02822	intent 0.02122

Test context:
***************
fix.v	85	28	and thanks to our users , we now have around 30 engines in the database ... new features : - better layout - better copy - small bugs __fixed__ bugs : - ie hell + much more posted by eric at 05:24 pm | comments ( 3 ) investment news as part of the new international expansion strategy 24hdc.com now accepts usd for investments .
Contexts for target fixed are: ['amodI_bugs']
Contexts in vocabulary for target fixed are: ['amodI_bugs']
Top most similar embeddings: fixed 0.52481	fix 0.36230	fixing 0.36214	exploitable 0.35628	itty 0.35435	unfixed 0.35423	member-only 0.35172	mealy 0.35036	vendor-specific 0.34994	certian 0.34983

Generated lemmatized results
***************
GENERATED	fix.v 85 ::: exploitable;itty;unfixed;mealy;certian;unhealed;fixable;attachable;unpatched;correct

Filtered results
***************
RANKED	fix.v 85	correct 0.34008	repair 0.31912	solve 0.31693	patch 0.31647	mend 0.30765	cure 0.30534	determine 0.29399	stick 0.29160	resolve 0.28966	improve 0.27872	heal 0.26894	set 0.26406	do 0.26283	intent 0.22177

Test context:
***************
fix.v	86	38	er , tilty. by anna at july 17 , 2003 03:37 pm yeah , in our case , whoever did the foundation fucked up royally. when the house settled , it was fubar. should be pretty easy to __fix__ though...just a matter of getting the pilings set to the right heights. by jc at july 17 , 2003 06:32 pm add a comment name : email address : url : remember personal info ?
Contexts for target fix are: ['aux_to', 'xcompI_easy', 'advcl_matter']
Contexts in vocabulary for target fix are: ['aux_to', 'xcompI_easy', 'advcl_matter']
Top most similar embeddings: fix 0.12771	solve 0.08963	reprogram 0.08910	rectify 0.08872	unpick 0.08855	proove 0.08844	enunciate 0.08777	diagnose 0.08757	retune 0.08720	manhandle 0.08702

Generated lemmatized results
***************
GENERATED	fix.v 86 ::: solve;reprogram;rectify;unpick;proove;enunciate;diagnose;retune;manhandle;unscramble

Filtered results
***************
RANKED	fix.v 86	solve 0.08963	mend 0.08429	resolve 0.08307	cure 0.08226	determine 0.07970	stick 0.07560	heal 0.07556	repair 0.07469	do 0.07323	correct 0.07315	patch 0.06806	set 0.06697	improve 0.06429	intent 0.05102

Test context:
***************
fix.v	87	23	i guess i 'll be able to hit the hot button many times as i 'm always at the dealer getting my car __fixed__ .
Contexts for target fixed are: ['nsubj_car', 'ccompI_getting']
Contexts in vocabulary for target fixed are: ['nsubj_car', 'ccompI_getting']
Top most similar embeddings: fixed 0.25470	valeted 0.20521	repaired 0.19346	resprayed 0.19226	fettled 0.18940	clamped 0.18885	sorted 0.18754	serviced 0.18393	jacked 0.18361	mended 0.17900

Generated lemmatized results
***************
GENERATED	fix.v 87 ::: valet;repair;resprayed;fettle;clamp;sort;service;jack;mend;bolt

Filtered results
***************
RANKED	fix.v 87	repair 0.19346	mend 0.17900	stick 0.17451	correct 0.16397	patch 0.15987	do 0.15732	solve 0.15048	cure 0.14543	improve 0.14427	resolve 0.13791	set 0.13667	heal 0.12793	determine 0.12512	intent 0.09913

Test context:
***************
fix.v	88	11	the long-term problem with social security after 2042 could be totally __fixed__ by raising the cap on income to a level needed to generate sufficient income to enable the system to continue to pay 100 percent indefinitely .
Contexts for target fixed are: ['nsubjpass_problem', 'aux_could', 'auxpass_be', 'advmod_totally', 'rootI_*root*', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target fixed are: ['nsubjpass_problem', 'aux_could', 'auxpass_be', 'advmod_totally', 'rootI_*root*', 'punct_.']
Top most similar embeddings: fixed 0.01572	solved 0.01319	avoided 0.01291	circumvented 0.01270	obviated 0.01266	corrected 0.01256	alleviated 0.01255	eliminated 0.01242	remedied 0.01221	overstressed 0.01217

Generated lemmatized results
***************
GENERATED	fix.v 88 ::: solve;avoid;circumvent;obviate;correct;alleviate;eliminate;remedied;overstress;unravel

Filtered results
***************
RANKED	fix.v 88	solve 0.01319	correct 0.01256	resolve 0.01184	cure 0.01148	repair 0.01114	determine 0.01040	mend 0.01011	patch 0.01002	improve 0.00973	stick 0.00954	do 0.00916	heal 0.00912	set 0.00787	intent 0.00402

Test context:
***************
fix.v	89	4	the only way to __fix__ this is for linux to get enough market share to be able to make demands for hardware support. [ reply ] [ top ] [ Â » ] releasing specs is the only answer. by the nose who knows - feb 26th 2001 04:29:40 &gt; the other reason why vendors do n't support linux &gt; most of the time for commidity hardware such as &gt; webcam is low returns on investments .
Contexts for target fix are: ['aux_to', 'infmodI_way', 'dobj_this']
Contexts in vocabulary for target fix are: ['aux_to', 'infmodI_way', 'dobj_this']
Top most similar embeddings: fix 0.14479	rectify 0.10810	solve 0.10355	proove 0.10221	circumvent 0.09991	recondition 0.09909	accomplish 0.09857	achive 0.09817	descibe 0.09802	retreive 0.09787

Generated lemmatized results
***************
GENERATED	fix.v 89 ::: rectify;solve;proove;circumvent;recondition;accomplish;achive;descibe;retreive;monetise

Filtered results
***************
RANKED	fix.v 89	solve 0.10355	resolve 0.09638	do 0.09318	mend 0.09282	cure 0.09204	determine 0.08614	correct 0.08402	repair 0.08400	improve 0.08359	heal 0.07901	stick 0.07322	set 0.07120	patch 0.06793	intent 0.04493

Test context:
***************
fix.v	90	18	but if no prayers can alter your purpose , dear one , husband , if you are so __fixed__ on going , take me with you , also !
Contexts for target fixed are: ['mark_if', 'nsubjpass_you', 'auxpass_are', 'advmod_so', 'depI_one', 'dep_<eol>']
Contexts in vocabulary for target fixed are: ['mark_if', 'nsubjpass_you', 'auxpass_are', 'advmod_so', 'depI_one']
Top most similar embeddings: fixed 0.02503	fixated 0.02166	stuck 0.02078	intersted 0.02060	strapped 0.02056	overexposed 0.01987	intrested 0.01972	screwed 0.01963	clued 0.01953	transfixed 0.01936

Generated lemmatized results
***************
GENERATED	fix.v 90 ::: fixate;stick;intersted;strap;overexpose;intrested;screw;clue;transfix;worry

Filtered results
***************
RANKED	fix.v 90	stick 0.02078	correct 0.01799	cure 0.01769	determine 0.01758	patch 0.01747	heal 0.01715	solve 0.01694	do 0.01656	mend 0.01620	repair 0.01612	resolve 0.01554	set 0.01441	improve 0.01250	intent 0.00978

Test context:
***************
manage.v	91	27	suddenly there was a scattering of fire , which three outfielders caught the brunt ; the centerfield was hit and was captured , left and right field __managed__ to get back to our lines .
Contexts for target managed are: ['nsubj_field', 'conjI_hit', 'xcomp_get']
Contexts in vocabulary for target managed are: ['nsubj_field', 'conjI_hit', 'xcomp_get']
Top most similar embeddings: managed 0.12017	manged 0.08948	manages 0.08932	manage 0.08501	struggled 0.08405	proceded 0.08332	swerved 0.08194	swivelled 0.08155	failed 0.08085	coasted 0.08059

Generated lemmatized results
***************
GENERATED	manage.v 91 ::: manged;struggle;proceded;swerve;swivel;fail;coast;nip;sprint;volley

Filtered results
***************
RANKED	manage.v 91	run 0.07440	contrive 0.07154	endeavour 0.07091	succeed 0.06485	handle 0.06375	direct 0.06293	control 0.06170	oversee 0.06068	coordinate 0.06005	conduct 0.05957	undertake 0.05819	administer 0.05756	organise 0.05740	govern 0.05266	success 0.04202

Test context:
***************
manage.v	92	31	" c158 ( cf ex r145 ) " the provincial in councilor the superior ofthe delegation in councilsets the financial competency of local superiorsand their councilsand determines which assets can be __managed__ by individualoblates and by local superiors and their councils .
Contexts for target managed are: ['dobj_which', 'nsubjpass_assets', 'aux_can', 'auxpass_be', 'ccompI_determines', 'prep:by_individualoblates', 'cc_and', 'conj_by', 'conj:by_superiors']
Contexts in vocabulary for target managed are: ['dobj_which', 'nsubjpass_assets', 'aux_can', 'auxpass_be', 'ccompI_determines', 'cc_and', 'conj_by']
Top most similar embeddings: managed 0.00647	monetised 0.00557	handled 0.00556	administered 0.00536	remediated 0.00535	controled 0.00532	safeguarded 0.00531	financed 0.00526	disbursed 0.00523	procured 0.00521

Generated lemmatized results
***************
GENERATED	manage.v 92 ::: monetise;handle;administer;remediate;control;safeguard;finance;disburse;procure;instantiate

Filtered results
***************
RANKED	manage.v 92	handle 0.00556	administer 0.00536	control 0.00532	govern 0.00436	direct 0.00432	coordinate 0.00431	undertake 0.00412	conduct 0.00409	oversee 0.00405	organise 0.00390	succeed 0.00382	run 0.00339	contrive 0.00288	endeavour 0.00274	success 0.00153

Test context:
***************
manage.v	93	18	business development manager strategic alliances this individual will be responsible for coordinating , negotiating , launching , and __managing__ accuity 's partner relationships .
Contexts for target managing are: ['conjI_coordinating', 'dobj_relationships']
Contexts in vocabulary for target managing are: ['conjI_coordinating', 'dobj_relationships']
Top most similar embeddings: managing 0.28271	overseeing 0.20715	maintaining 0.20616	coordinating 0.20583	co-coordinating 0.20517	facilitating 0.20366	co-ordinating 0.20351	developing 0.19610	manage 0.19538	architecting 0.19388

Generated lemmatized results
***************
GENERATED	manage.v 93 ::: oversee;maintain;coordinate;facilitate;develop;architecting;reorient;formalize;sustain;assess

Filtered results
***************
RANKED	manage.v 93	oversee 0.20715	coordinate 0.20583	administer 0.18551	control 0.18207	organise 0.17920	direct 0.17875	conduct 0.16507	govern 0.16442	handle 0.15686	contrive 0.15594	succeed 0.14615	undertake 0.13902	endeavour 0.13414	run 0.12982	success 0.09262

Test context:
***************
manage.v	94	21	a married woman retains ownership of any property she brought to the marriage , but the husband has the right to __manage__ the property and to enjoy profits from the property .
Contexts for target manage are: ['aux_to', 'infmodI_right', 'dobj_property', 'cc_and', 'conj_enjoy']
Contexts in vocabulary for target manage are: ['aux_to', 'infmodI_right', 'dobj_property', 'cc_and', 'conj_enjoy']
Top most similar embeddings: manage 0.03225	enfranchise 0.02523	administrate 0.02485	expropriate 0.02436	acquire 0.02427	fumigate 0.02414	vandalise 0.02413	redecorate 0.02389	repossess 0.02358	sightsee 0.02351

Generated lemmatized results
***************
GENERATED	manage.v 94 ::: enfranchise;administrate;expropriate;acquire;fumigate;vandalise;redecorate;repossess;sightsee;inspect

Filtered results
***************
RANKED	manage.v 94	administer 0.02292	organise 0.02228	oversee 0.02094	handle 0.02052	govern 0.01980	succeed 0.01927	undertake 0.01779	contrive 0.01710	coordinate 0.01701	conduct 0.01582	control 0.01574	run 0.01556	direct 0.01347	endeavour 0.01130	success 0.00883

Test context:
***************
manage.v	95	34	we do not need to ask for your specific permission to do these things , as explained below : treatment partners health care providers will use and share your health information to provide and __manage__ your health care and related services .
Contexts for target manage are: ['conjI_provide']
Contexts in vocabulary for target manage are: ['conjI_provide']
Top most similar embeddings: manage 0.52221	administer 0.39609	oversee 0.39075	administrate 0.39031	manages 0.38945	maintain 0.38550	supervise 0.38174	managing 0.37202	organise 0.37153	managed 0.37108

Generated lemmatized results
***************
GENERATED	manage.v 95 ::: administer;oversee;administrate;maintain;supervise;organise;troubleshoot;indentify;orchestrate;integrate

Filtered results
***************
RANKED	manage.v 95	administer 0.39609	oversee 0.39075	organise 0.37153	undertake 0.35330	coordinate 0.33741	handle 0.33716	govern 0.33025	contrive 0.32208	succeed 0.30615	control 0.30216	conduct 0.29631	run 0.29282	endeavour 0.28845	direct 0.28054	success 0.23621

Test context:
***************
manage.v	96	15	according to a white house press release , al-taqwa and its affiliates " raise , __manage__ , invest , and distribute funds for al-qaeda ; provide terrorist supporters with internet service and secure telephone communications ; and arrange for the shipment of weapons .
Contexts for target manage are: ['conjI_raise']
Contexts in vocabulary for target manage are: ['conjI_raise']
Top most similar embeddings: manage 0.49723	administer 0.37765	maintain 0.37639	oversee 0.37546	improve 0.36956	administrate 0.36915	promote 0.36782	manages 0.36459	develop 0.36325	motivate 0.36235

Generated lemmatized results
***************
GENERATED	manage.v 96 ::: administer;maintain;oversee;improve;administrate;promote;develop;motivate;monetise;privatize

Filtered results
***************
RANKED	manage.v 96	administer 0.37765	oversee 0.37546	organise 0.35979	undertake 0.33904	coordinate 0.32986	handle 0.32882	contrive 0.32321	govern 0.32279	succeed 0.31732	control 0.29418	run 0.28351	conduct 0.28301	endeavour 0.27727	direct 0.26955	success 0.24610

Test context:
***************
manage.v	97	22	that is , if the average person ( say this is 98 % of people ) amasses 10 things , if i __manage__ to acquire 20 things then perhaps my account is not worth twice as much but maybe 10x or 100x as much as average .
Contexts for target manage are: ['mark_if', 'nsubj_i', 'advclI_is', 'xcomp_acquire']
Contexts in vocabulary for target manage are: ['mark_if', 'nsubj_i', 'advclI_is', 'xcomp_acquire']
Top most similar embeddings: manage 0.08146	manages 0.06748	want 0.06712	managed 0.06489	wnat 0.06480	intend 0.06151	decide 0.06075	want/need 0.06063	decides 0.06040	cohabit 0.06000

Generated lemmatized results
***************
GENERATED	manage.v 97 ::: want;wnat;intend;decide;cohabit;contrive;prefer;have;fail;wiling

Filtered results
***************
RANKED	manage.v 97	contrive 0.05962	succeed 0.05242	endeavour 0.05051	administer 0.05034	undertake 0.04938	direct 0.04899	organise 0.04837	oversee 0.04610	govern 0.04541	handle 0.04518	control 0.04448	conduct 0.04352	run 0.04166	coordinate 0.04048	success 0.02614

Test context:
***************
manage.v	98	5	there are different types of __managed__ care systems .
Contexts for target managed are: ['amodI_systems']
Contexts in vocabulary for target managed are: ['amodI_systems']
Top most similar embeddings: managed 0.47122	insurance-based 0.41326	linux-based 0.39244	unix-based 0.39183	siphonic 0.39068	all-optical 0.38937	non-windows 0.38914	multi-access 0.38842	finite-state 0.38831	grid-based 0.38820

Generated lemmatized results
***************
GENERATED	manage.v 98 ::: siphonic;autopoietic;microfluidic;mechatronic;avionic;multicomponent;architected;rainfed;lentiviral;integumentary

Filtered results
***************
RANKED	manage.v 98	control 0.34726	coordinate 0.34045	administer 0.32679	contrive 0.31666	oversee 0.31328	organise 0.30551	handle 0.29646	govern 0.28656	succeed 0.28550	conduct 0.28200	run 0.27917	direct 0.27891	undertake 0.26992	endeavour 0.26828	success 0.21926

Test context:
***************
manage.v	99	4	saddam hussein did n't __manage__ to defeat the iranians .
Contexts for target manage are: ['nsubj_hussein', 'aux_did', "neg_n't", 'rootI_*root*', 'xcomp_defeat', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target manage are: ['nsubj_hussein', 'aux_did', "neg_n't", 'rootI_*root*', 'xcomp_defeat', 'punct_.']
Top most similar embeddings: manage 0.01462	contrive 0.01132	managed 0.01103	procrastinate 0.01081	succumb 0.01079	seem 0.01074	flinch 0.01061	invent 0.01057	intend 0.01056	threaten 0.01052

Generated lemmatized results
***************
GENERATED	manage.v 99 ::: contrive;procrastinate;succumb;seem;flinch;invent;intend;threaten;squander;want

Filtered results
***************
RANKED	manage.v 99	contrive 0.01132	succeed 0.00960	administer 0.00905	organise 0.00891	handle 0.00830	oversee 0.00768	coordinate 0.00765	run 0.00757	govern 0.00757	endeavour 0.00735	undertake 0.00719	control 0.00712	conduct 0.00638	direct 0.00634	success 0.00394

Test context:
***************
manage.v	100	4	the m107 program is __managed__ by the project manager soldier weapons with engineering support provided by picatinnyÂs armament research , development and engineering center .
Contexts for target managed are: ['nsubjpass_program', 'auxpass_is', 'rootI_*root*', 'prep:by_weapons', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target managed are: ['nsubjpass_program', 'auxpass_is', 'rootI_*root*', 'prep:by_weapons', 'punct_.']
Top most similar embeddings: managed 0.02926	administrated 0.02610	supported 0.02442	sponsered 0.02433	co-funded 0.02422	overseen 0.02421	co-supervised 0.02397	administered 0.02337	complemented 0.02307	provided 0.02299

Generated lemmatized results
***************
GENERATED	manage.v 100 ::: administrate;support;sponsered;oversee;administer;complement;provide;spearhead;target;underpin

Filtered results
***************
RANKED	manage.v 100	oversee 0.02421	administer 0.02337	control 0.02163	handle 0.02132	direct 0.02089	coordinate 0.02083	govern 0.02052	succeed 0.01990	conduct 0.01972	undertake 0.01945	organise 0.01911	run 0.01868	endeavour 0.01479	contrive 0.01296	success 0.00806

Test context:
***************
neat.a	101	4	it is really a __neat__ plan , well documented and a model for libraries that are still working on their plans. ~ ~ ~ corrections to april 2003 issue of ldd on the road : some things slipped by when putting together last month 's issue of ldd on the road .
Contexts for target neat are: ['amodI_plan']
Contexts in vocabulary for target neat are: ['amodI_plan']
Top most similar embeddings: neat 0.49126	nine-point 0.40142	well-conceived 0.40101	eight-point 0.40054	seven-point 0.39579	ten-point 0.39352	five-point 0.39029	well-thought-out 0.38989	well-worked 0.38447	easy-to-navigate 0.38423

Generated lemmatized results
***************
GENERATED	neat.a 101 ::: ingenious;simple;definative;quadrangular;cunning;coherent;tidy;elegant;workable;nifty

Filtered results
***************
RANKED	neat.a 101	simple 0.36998	tidy 0.35922	clever 0.35649	nice 0.35065	smart 0.34467	orderly 0.33923	good 0.33075	terrific 0.31868	compact 0.31825	great 0.31789	cool 0.31643	trim 0.30436	uniform 0.29773	pleasing 0.29317	ordered 0.25209	order 0.21037

Test context:
***************
neat.a	102	4	and the prize for __neatest__ , simplest idea has to go to britkid.org , a resource for opening children 's eyes to the diversity of our culture. www.skoool.com www.nrich.maths.org.uk www.stagework.org.uk www.learningcurve.gov.uk www.britkid.org email hotmail is the free email service everyone knows .
Contexts for target neatest are: ['amodI_idea']
Contexts in vocabulary for target neatest are: ['amodI_idea']
Top most similar embeddings: neatest 0.52893	vaguest 0.44668	hare-brained 0.43431	dumbest 0.43162	maddest 0.43096	silliest 0.42900	craziest 0.42800	weirdest 0.42432	wackiest 0.42347	oddest 0.42239

Generated lemmatized results
***************
GENERATED	neat.a 102 ::: vague;dumb;mad;silly;crazy;weird;wacky;odd;foggy;stupid

Filtered results
***************
RANKED	neat.a 102	nice 0.40532	clever 0.40488	smart 0.39124	simple 0.38511	cool 0.38505	good 0.37886	great 0.34596	tidy 0.33337	terrific 0.33127	pleasing 0.31313	orderly 0.30968	compact 0.29217	uniform 0.28617	trim 0.28185	ordered 0.23247	order 0.20742

Test context:
***************
neat.a	103	18	over the course of the 20th century scholars have learned that such images tried to make messy reality __neater__ than it really is .
Contexts for target neater are: ['depI_reality', 'dep_is']
Contexts in vocabulary for target neater are: ['depI_reality', 'dep_is']
Top most similar embeddings: neater 0.20594	bleaker 0.17128	odder 0.17072	sleeker 0.17006	uglier 0.16656	sexier 0.16591	scarier 0.16584	sadder 0.16568	sillier 0.16450	nicer 0.16330

Generated lemmatized results
***************
GENERATED	neat.a 103 ::: bleak;odd;sleek;ugly;sexy;scary;sad;silly;nice;funny

Filtered results
***************
RANKED	neat.a 103	nice 0.16330	simple 0.16077	tidy 0.15803	clever 0.15766	smart 0.15081	good 0.14858	cool 0.14229	pleasing 0.13026	compact 0.12378	trim 0.12264	orderly 0.11918	terrific 0.11749	great 0.11004	uniform 0.10341	order 0.10275	ordered 0.10215

Test context:
***************
neat.a	104	10	strong field patterns created by hedgerows give the landscape a __neat__ , well structured appearance .
Contexts for target neat are: ['amodI_appearance']
Contexts in vocabulary for target neat are: ['amodI_appearance']
Top most similar embeddings: neat 0.53213	box-like 0.39821	plasticky 0.39820	clean-cut 0.39713	jewel-like 0.39293	time-worn 0.39158	now-familiar 0.39040	filmy 0.38993	odd-looking 0.38966	cadaverous 0.38808

Generated lemmatized results
***************
GENERATED	neat.a 104 ::: plasticky;filmy;cadaverous;slick;tidy;metalic;unprepossessing;darkish;cartoony;curvy

Filtered results
***************
RANKED	neat.a 104	tidy 0.38633	smart 0.37239	nice 0.36563	simple 0.34729	pleasing 0.34679	orderly 0.34304	clever 0.33322	cool 0.32752	terrific 0.32584	compact 0.32207	uniform 0.32068	good 0.31834	trim 0.31594	great 0.29848	ordered 0.22594	order 0.20764

Test context:
***************
neat.a	105	21	besides a list of specific things you wish they would talk about , the following things are helpful additions to the __neat__ packet you hand them when you ask them to write the letter .
Contexts for target neat are: ['amodI_packet']
Contexts in vocabulary for target neat are: ['amodI_packet']
Top most similar embeddings: neat 0.51611	resealable 0.38113	decent-sized 0.37756	nice 0.37735	four-card 0.37374	two-inch 0.37355	a4-sized 0.37306	super-duper 0.37258	re-sealable 0.37255	over-sized 0.37101

Generated lemmatized results
***************
GENERATED	neat.a 105 ::: resealable;nice;largish;tidy;smallish;leakproof;crisp;plasticky;spiffy;multicolored

Filtered results
***************
RANKED	neat.a 105	nice 0.37735	tidy 0.37054	simple 0.35631	clever 0.33243	smart 0.33115	orderly 0.32286	compact 0.32262	cool 0.31164	terrific 0.30846	good 0.30734	great 0.30000	trim 0.29976	uniform 0.28586	pleasing 0.27625	ordered 0.24904	order 0.22378

Test context:
***************
neat.a	106	41	" -4 time iroc champion mark martin indy 500 , cart and iroc champion , al unser jr. said , " i watched my father and uncle bobby race in iroc and as a kid i thought it would be really __neat__ if someday i would get an opportunity to run iroc .
Contexts for target neat are: ['nsubj_it', 'aux_would', 'cop_be', 'advmod_really', 'ccompI_thought', 'advcl_get']
Contexts in vocabulary for target neat are: ['nsubj_it', 'aux_would', 'cop_be', 'advmod_really', 'ccompI_thought', 'advcl_get']
Top most similar embeddings: nice 0.01611	neat 0.01539	usefull 0.01370	dificult 0.01353	doable 0.01349	painfull 0.01343	scarey 0.01342	worth-while 0.01330	helpfull 0.01318	pointless 0.01306

Generated lemmatized results
***************
GENERATED	neat.a 106 ::: nice;usefull;dificult;doable;painfull;scarey;helpfull;pointless;helpful;toughie

Filtered results
***************
RANKED	neat.a 106	nice 0.01611	cool 0.01220	good 0.01128	clever 0.01102	great 0.01066	terrific 0.01052	simple 0.01019	tidy 0.01014	pleasing 0.00964	smart 0.00855	orderly 0.00665	compact 0.00632	trim 0.00590	uniform 0.00546	ordered 0.00430	order 0.00374

Test context:
***************
neat.a	107	8	the society for academic emergency medicine is a __neat__ little bunch of people who are dedicated to furthering the interests of academia and research in the youngest of the medical specialties .
Contexts for target neat are: ['amodI_bunch']
Contexts in vocabulary for target neat are: ['amodI_bunch']
Top most similar embeddings: neat 0.49710	nice 0.39878	fine-looking 0.39688	plasticky 0.39050	nice-looking 0.39016	ornery 0.38654	odd-looking 0.38602	decent-sized 0.38366	great-looking 0.38249	tight-knit 0.38245

Generated lemmatized results
***************
GENERATED	neat.a 107 ::: nice;plasticky;ornery;lovely;scuzzy;nifty;tidy;unprepossessing;poky;smallish

Filtered results
***************
RANKED	neat.a 107	nice 0.39878	tidy 0.37802	clever 0.36958	smart 0.35279	terrific 0.34834	cool 0.34322	simple 0.34026	orderly 0.33908	good 0.33713	great 0.33709	pleasing 0.31819	compact 0.31476	trim 0.30399	uniform 0.30152	ordered 0.24132	order 0.20664

Test context:
***************
neat.a	108	8	a weblog by tom coates who thinks up __neat__ stuff for yahoo !
Contexts for target neat are: ['amodI_stuff']
Contexts in vocabulary for target neat are: ['amodI_stuff']
Top most similar embeddings: neat 0.52772	nifty 0.41464	whizzy 0.41333	swirly 0.41099	plasticky 0.40771	great-looking 0.40567	kitschy 0.40537	old-skool 0.40102	snazzy 0.39896	gloopy 0.39613

Generated lemmatized results
***************
GENERATED	neat.a 108 ::: nifty;whizzy;swirly;plasticky;kitschy;snazzy;gloopy;splashy;metalic;twiddly

Filtered results
***************
RANKED	neat.a 108	nice 0.38843	clever 0.38059	tidy 0.37017	simple 0.36904	cool 0.36649	smart 0.35467	good 0.35210	terrific 0.35174	great 0.34168	trim 0.31588	orderly 0.31018	pleasing 0.30941	compact 0.30688	uniform 0.28913	ordered 0.23430	order 0.20874

Test context:
***************
neat.a	109	17	but not as odd as the 35 others who bedded down with him each night in a __neat__ row down the street on a carpet of cardboard boxes and multicoloured raffia beach mats .
Contexts for target neat are: ['amodI_row']
Contexts in vocabulary for target neat are: ['amodI_row']
Top most similar embeddings: neat 0.52109	shortish 0.37572	tidy 0.37398	fair-sized 0.37130	five-foot 0.37037	fine-looking 0.36939	y-shaped 0.36851	nifty 0.36842	nice 0.36832	five-way 0.36672

Generated lemmatized results
***************
GENERATED	neat.a 109 ::: shortish;tidy;nifty;nice;curvy;largish;elegant;sparkly;scuzzy;castellated

Filtered results
***************
RANKED	neat.a 109	tidy 0.37398	nice 0.36832	terrific 0.33729	smart 0.33658	simple 0.33372	clever 0.33033	orderly 0.32697	cool 0.32392	trim 0.31588	good 0.31354	great 0.31188	pleasing 0.30933	compact 0.30639	uniform 0.29675	ordered 0.24203	order 0.21030

Test context:
***************
neat.a	110	33	link to the full federal government debt report with pictures - there are 9 color graphics that tell the whole story - - so , give the next page time to load those __neat__ pictures .
Contexts for target neat are: ['amodI_pictures']
Contexts in vocabulary for target neat are: ['amodI_pictures']
Top most similar embeddings: neat 0.51016	great-looking 0.41508	cartoon-style 0.40302	professional-looking 0.40226	soft-focus 0.39984	nice 0.39649	swirly 0.39631	nice-looking 0.39443	brightly-coloured 0.39270	high-contrast 0.39265

Generated lemmatized results
***************
GENERATED	neat.a 110 ::: nice;swirly;snazzy;kitschy;cute;multicolored;lovely;beatiful;contrasty;nifty

Filtered results
***************
RANKED	neat.a 110	nice 0.39649	simple 0.36547	tidy 0.36205	clever 0.35353	terrific 0.34323	cool 0.34271	good 0.33634	smart 0.33557	great 0.33232	orderly 0.32547	pleasing 0.32435	compact 0.30834	trim 0.29770	uniform 0.29141	ordered 0.24081	order 0.20936

Test context:
***************
rich.a	111	8	what are the important variables that create a __rich__ online learning experience , one that makes real improvements in academic practice ?
Contexts for target rich are: ['amodI_experience']
Contexts in vocabulary for target rich are: ['amodI_experience']
Top most similar embeddings: rich 0.51644	richer 0.42749	richest 0.39465	synaesthetic 0.37332	ultra-realistic 0.37192	hand-on 0.37040	out-of-body 0.36847	wealthy 0.36782	highest-quality 0.36685	well-rounded 0.36643

Generated lemmatized results
***************
GENERATED	rich.a 111 ::: synaesthetic;wealthy;unforgetable;leisured;wondeful;mediumistic;fecund;sensorial;kaleidoscopic;monied

Filtered results
***************
RANKED	rich.a 111	wealthy 0.36782	valuable 0.34951	rewarding 0.33833	well-off 0.33703	abundant 0.33479	vibrant 0.33277	lavish 0.32766	lush 0.32626	full 0.31711	significant 0.31676	ample 0.31057	high 0.30056	elaborate 0.29588	detailed 0.29060	abounding 0.28930	detail 0.23246

Test context:
***************
rich.a	112	20	trees on anmyeondo used to be thick and lush to the extent of prompting a saying , Â¡Â°you can become __rich__ with an axe.Â¡Â± but now only few trees are left due to reckless deforestation since the time of koreaÂ¡Â¯s liberation from japanese colonial rule .
Contexts for target rich are: ['nsubj_you', 'aux_can', 'cop_become', 'rcmodI_\xc2\xb0', 'prep:with_\xc2\xb1', 'cc_but', 'conj_left']
Contexts in vocabulary for target rich are: ['nsubj_you', 'aux_can', 'cop_become', 'cc_but', 'conj_left']
Top most similar embeddings: rich 0.02479	richer 0.02189	wealthy 0.02152	satiated 0.02120	dehydrated 0.02084	disorientated 0.02044	short-tempered 0.02023	over-familiar 0.02022	self-absorbed 0.02012	thick-skinned 0.02008

Generated lemmatized results
***************
GENERATED	rich.a 112 ::: wealthy;satiated;dehydrated;disorientated;anaemic;desensitised;disoriented;constipated;finicky;nauseated

Filtered results
***************
RANKED	rich.a 112	wealthy 0.02152	well-off 0.01785	elaborate 0.01580	abundant 0.01579	lavish 0.01464	rewarding 0.01389	valuable 0.01384	lush 0.01306	vibrant 0.01204	full 0.01191	high 0.01166	detailed 0.01122	ample 0.01120	significant 0.01074	abounding 0.01060	detail 0.00851

Test context:
***************
rich.a	113	11	no , we 're not talking about the fortunes of a __rich__ and powerful democracy .
Contexts for target rich are: ['amodI_democracy', 'cc_and', 'conj_powerful']
Contexts in vocabulary for target rich are: ['amodI_democracy', 'cc_and', 'conj_powerful']
Top most similar embeddings: rich 0.14224	richest 0.11130	richer 0.11021	wealthy 0.10846	vibrant 0.09906	freest 0.09644	pliant 0.09600	powerful 0.09553	non-sexist 0.09542	virile 0.09522

Generated lemmatized results
***************
GENERATED	rich.a 113 ::: wealthy;vibrant;free;pliant;powerful;virile;prosperous;moneyed;sonorous;robust

Filtered results
***************
RANKED	rich.a 113	wealthy 0.10846	vibrant 0.09906	well-off 0.08431	abundant 0.08364	full 0.07915	lush 0.07895	lavish 0.07645	elaborate 0.07415	valuable 0.07220	rewarding 0.07098	significant 0.06495	abounding 0.06480	high 0.06431	ample 0.06372	detailed 0.06367	detail 0.04219

Test context:
***************
rich.a	114	18	functional foods and drinks , sports drinks , slimming , supplements functional foods : glico launches this chocolate __rich__ in gaba for its relaxing effect .
Contexts for target rich are: ['amodI_chocolate', 'prep:in_gaba']
Contexts in vocabulary for target rich are: ['amodI_chocolate']
Top most similar embeddings: rich 0.51985	richer 0.40096	full-flavoured 0.39751	chocolatey 0.39404	richest 0.39304	yeasty 0.38947	home-baked 0.38657	shop-bought 0.38439	flavourful 0.38315	oaky 0.38171

Generated lemmatized results
***************
GENERATED	rich.a 114 ::: chocolatey;yeasty;flavourful;oaky;flavorful;unsweetened;floury;gloopy;biscuity;wealthy

Filtered results
***************
RANKED	rich.a 114	wealthy 0.37493	abundant 0.34307	lavish 0.33796	well-off 0.33317	lush 0.32027	vibrant 0.31877	ample 0.31442	high 0.30502	elaborate 0.30439	full 0.29781	valuable 0.29628	abounding 0.29000	significant 0.27582	rewarding 0.27432	detailed 0.27128	detail 0.23331

Test context:
***************
rich.a	115	14	africas central problems in the wto revolve around the imbalances and biases created by __rich__ countries in the uruguay round agreement ( ura ) .
Contexts for target rich are: ['amodI_countries']
Contexts in vocabulary for target rich are: ['amodI_countries']
Top most similar embeddings: rich 0.53373	richer 0.42944	richest 0.42668	least-developed 0.42466	resource-rich 0.42448	wealthy 0.41966	less-developed 0.41670	oil-producing 0.40716	wine-producing 0.39961	non-english-speaking 0.39931

Generated lemmatized results
***************
GENERATED	rich.a 115 ::: wealthy;industrialized;industrialised;poor;malarious;impoverished;monied;affluent;industrialising;prosperous

Filtered results
***************
RANKED	rich.a 115	wealthy 0.41966	well-off 0.37324	lush 0.32765	abundant 0.32538	vibrant 0.31400	lavish 0.31244	high 0.29693	rewarding 0.29565	valuable 0.28934	full 0.28926	significant 0.28459	elaborate 0.28420	abounding 0.27896	ample 0.27858	detailed 0.26212	detail 0.23451

Test context:
***************
rich.a	116	39	today half the world 's population lives on less than $ 2 a day , 80 percent of the global population has only 20 percent of global gdp , and within each country there is a massive imbalance between __rich__ and poor .
Contexts for target rich are: ['prep:betweenI_imbalance', 'cc_and', 'conj_poor']
Contexts in vocabulary for target rich are: ['prep:betweenI_imbalance', 'cc_and', 'conj_poor']
Top most similar embeddings: rich 0.14252	richest 0.10671	wealthy 0.10370	richer 0.10142	affluent 0.10015	super-rich 0.09639	haves 0.09515	well-off 0.09316	well-to-do 0.09147	landless 0.09096

Generated lemmatized results
***************
GENERATED	rich.a 116 ::: wealthy;affluent;haves;landless;poor;impoverished;oligotrophic;underprivileged;advantaged;uncultured

Filtered results
***************
RANKED	rich.a 116	wealthy 0.10370	well-off 0.09316	vibrant 0.07300	abundant 0.07190	lush 0.06391	full 0.06334	lavish 0.06139	valuable 0.05988	ample 0.05936	elaborate 0.05862	high 0.05807	rewarding 0.05796	abounding 0.05648	detailed 0.05110	significant 0.05042	detail 0.04708

Test context:
***************
rich.a	117	14	here wagner , in depicting every shade of sexual love , developed a style __richer__ and more chromatic than anyone had previously attempted , using dissonance and its urge for resolution in a continuing pattem to build up tension and a sense of profound yearning ; act 2 is virtually a continuous love duet , touching every emotion from the tenderest to the most passionately erotic .
Contexts for target richer are: ['npadvmod_style', 'acompI_developed', 'cc_and', 'conj_chromatic']
Contexts in vocabulary for target richer are: ['acompI_developed', 'cc_and']
Top most similar embeddings: richer 0.24536	rich 0.20014	stronger 0.19227	wealthier 0.18423	poorer 0.18290	smoother 0.18233	leaner 0.18018	hungrier 0.17870	pliant 0.17833	weaker 0.17746

Generated lemmatized results
***************
GENERATED	rich.a 117 ::: strong;wealthy;poor;smooth;lean;hungry;pliant;weak;thin;plump

Filtered results
***************
RANKED	rich.a 117	wealthy 0.18423	full 0.16805	vibrant 0.15583	well-off 0.15259	lush 0.15121	high 0.14862	abundant 0.14524	valuable 0.14371	elaborate 0.14322	detailed 0.14024	rewarding 0.13977	lavish 0.13772	significant 0.12827	ample 0.12752	abounding 0.12077	detail 0.10052

Test context:
***************
rich.a	118	4	he brings an incredibly __rich__ and diverse background that includes everything from executive coaching , learning & development and management consulting , to senior operations roles , mixed with a masters in organizational development .
Contexts for target rich are: ['advmod_incredibly', 'amodI_background', 'cc_and', 'conj_diverse']
Contexts in vocabulary for target rich are: ['advmod_incredibly', 'amodI_background', 'cc_and', 'conj_diverse']
Top most similar embeddings: rich 0.07745	wealthy 0.05481	richest 0.05297	richer 0.05213	vibrant 0.05182	diverse 0.05155	colourful 0.05051	opulent 0.04932	well-balanced 0.04865	well-resourced 0.04842

Generated lemmatized results
***************
GENERATED	rich.a 118 ::: wealthy;vibrant;diverse;colourful;opulent;lively;vivacious;strong;fecund;erudite

Filtered results
***************
RANKED	rich.a 118	wealthy 0.05481	vibrant 0.05182	well-off 0.04342	lush 0.04331	abundant 0.04276	valuable 0.04090	rewarding 0.04026	lavish 0.03951	elaborate 0.03629	detailed 0.03603	ample 0.03388	full 0.03373	significant 0.03282	high 0.03240	abounding 0.02823	detail 0.02328

Test context:
***************
rich.a	119	0	__rich__ people manage their money well .
Contexts for target rich are: ['amodI_people']
Contexts in vocabulary for target rich are: ['amodI_people']
Top most similar embeddings: rich 0.51296	wealthy 0.41813	richest 0.41197	freedom-loving 0.41045	richer 0.41015	right-minded 0.40756	non-english-speaking 0.40110	hard-up 0.39913	monied 0.39888	middleclass 0.39244

Generated lemmatized results
***************
GENERATED	rich.a 119 ::: wealthy;monied;middleclass;likeminded;indiginous;necessitous;unchurched;youngish;impoverished;frail

Filtered results
***************
RANKED	rich.a 119	wealthy 0.41813	well-off 0.38442	vibrant 0.32399	abundant 0.31609	rewarding 0.30448	valuable 0.30135	lavish 0.30092	lush 0.29746	full 0.29094	high 0.29071	significant 0.29023	ample 0.28019	abounding 0.27690	elaborate 0.27683	detailed 0.26139	detail 0.22036

Test context:
***************
rich.a	120	46	i also think that it will probably take the " sword " of nations ( ala rom 13 ) combined with the good news offered by the body of christ to touch the hearts and change the ways of the " rich africans " ( and __rich__ americans and other westerners , frankly ) to bring change .
Contexts for target rich are: ['conjI_americans']
Contexts in vocabulary for target rich are: ['conjI_americans']
Top most similar embeddings: rich 0.48567	wealthy 0.38953	super-rich 0.37938	richest 0.37590	richer 0.37237	americans 0.35532	african-americans 0.35095	scandinavians 0.34675	ukrainians 0.34563	well-heeled 0.34523

Generated lemmatized results
***************
GENERATED	rich.a 120 ::: wealthy;americans;scandinavians;ukrainians;fijians;amerindians;ricans;bulgarians;europeans;turkomans

Filtered results
***************
RANKED	rich.a 120	wealthy 0.38953	well-off 0.34391	vibrant 0.29479	lush 0.28325	lavish 0.27794	abundant 0.27780	full 0.27456	abounding 0.27328	valuable 0.26866	rewarding 0.25501	high 0.25425	elaborate 0.25330	ample 0.25216	significant 0.23950	detailed 0.23447	detail 0.21528

Test context:
***************
severely.r	121	17	rubinstein held the gambit pawn with 4.bf4 and 7.qd5 , but his neglect of kingside development was __severely__ punished .
Contexts for target severely are: ['advmodI_punished']
Contexts in vocabulary for target severely are: ['advmodI_punished']
Top most similar embeddings: severely 0.55617	severly 0.44418	grievously 0.43137	mortally 0.40493	callously 0.40291	ferociously 0.40110	bloodily 0.40107	cruelly 0.40092	savagely 0.40081	harshly 0.40013

Generated lemmatized results
***************
GENERATED	severely.r 121 ::: severly;grievously;mortally;callously;ferociously;bloodily;cruelly;savagely;harshly;irreparably

Filtered results
***************
RANKED	severely.r 121	harshly 0.40013	seriously 0.38105	heavily 0.37843	badly 0.37726	gravely 0.37060	devastatingly 0.35291	sternly 0.34993	dramatically 0.31618	critically 0.30701	extremely 0.30475	highly 0.30118

Test context:
***************
severely.r	122	18	this veteran , the oldest pensioner in great britain , entered the army in 1758 , and was __severely__ wounded at the battle of quebec under general wolfe , in consequence of which he became an out-pensioner of chelsea hospital , and continued so for the period of seventy-five years .
Contexts for target severely are: ['advmodI_wounded']
Contexts in vocabulary for target severely are: ['advmodI_wounded']
Top most similar embeddings: severely 0.55838	severly 0.44791	mortally 0.44141	grievously 0.43757	irreparably 0.41370	seriously 0.41289	badly 0.40575	horrifically 0.40059	savagely 0.40011	murderously 0.39757

Generated lemmatized results
***************
GENERATED	severely.r 122 ::: severly;mortally;grievously;irreparably;seriously;badly;horrifically;savagely;murderously;chronically

Filtered results
***************
RANKED	severely.r 122	seriously 0.41289	badly 0.40575	gravely 0.38735	heavily 0.35994	harshly 0.35973	devastatingly 0.35129	critically 0.32591	sternly 0.32181	extremely 0.32121	dramatically 0.31405	highly 0.30190

Test context:
***************
severely.r	123	14	perhaps the effect of west nile virus is sufficient to extinguish endemic birds already __severely__ stressed by habitat losses .
Contexts for target severely are: ['advmodI_stressed']
Contexts in vocabulary for target severely are: ['advmodI_stressed']
Top most similar embeddings: severely 0.53237	severly 0.43119	chronically 0.39621	ferociously 0.39609	grievously 0.39606	acutely 0.38411	egregiously 0.38290	comically 0.38135	wretchedly 0.38102	horrifically 0.38078

Generated lemmatized results
***************
GENERATED	severely.r 123 ::: severly;chronically;ferociously;grievously;acutely;egregiously;comically;wretchedly;horrifically;savagely

Filtered results
***************
RANKED	severely.r 123	seriously 0.37959	heavily 0.37237	harshly 0.36853	devastatingly 0.35590	badly 0.35264	gravely 0.35202	extremely 0.35002	highly 0.34353	sternly 0.32467	dramatically 0.31696	critically 0.31244

Test context:
***************
severely.r	124	3	she looked as __severely__ as she could muster at draco .
Contexts for target severely are: ['advmod_as', 'advmodI_looked', 'ccomp_muster']
Contexts in vocabulary for target severely are: ['advmod_as', 'advmodI_looked', 'ccomp_muster']
Top most similar embeddings: severely 0.10153	quickly 0.08219	dexterously 0.08219	sourly 0.08184	soon 0.08173	badly 0.08109	sharply 0.08073	seriously 0.08020	savagely 0.07859	harshly 0.07854

Generated lemmatized results
***************
GENERATED	severely.r 124 ::: quickly;dexterously;sourly;soon;badly;sharply;seriously;savagely;harshly;shabbily

Filtered results
***************
RANKED	severely.r 124	badly 0.08109	seriously 0.08020	harshly 0.07854	sternly 0.07274	gravely 0.07209	heavily 0.07077	dramatically 0.06567	devastatingly 0.06481	critically 0.06332	highly 0.05432	extremely 0.04788

Test context:
***************
severely.r	125	14	a day before he was due to return to the united states patton was __severely__ injured in a road accident .
Contexts for target severely are: ['advmodI_injured']
Contexts in vocabulary for target severely are: ['advmodI_injured']
Top most similar embeddings: severely 0.55074	severly 0.45844	grievously 0.43296	seriously 0.41684	mortally 0.41584	chronically 0.41283	irreparably 0.40506	horrifically 0.40301	badly 0.39911	sorely 0.39699

Generated lemmatized results
***************
GENERATED	severely.r 125 ::: severly;grievously;seriously;mortally;chronically;irreparably;horrifically;badly;sorely;fatally

Filtered results
***************
RANKED	severely.r 125	seriously 0.41684	badly 0.39911	gravely 0.37734	heavily 0.36608	harshly 0.34178	devastatingly 0.34055	critically 0.33522	extremely 0.31738	dramatically 0.31483	highly 0.31104	sternly 0.29863

Test context:
***************
severely.r	126	15	use market tools to address environmental issues , such as eliminating subsidies for industries that __severely__ harm the environment , like coal .
Contexts for target severely are: ['advmodI_harm']
Contexts in vocabulary for target severely are: ['advmodI_harm']
Top most similar embeddings: severely 0.53485	severly 0.45174	irreparably 0.40741	seriously 0.40412	grievously 0.40260	detrimentally 0.40122	mortally 0.39556	gravely 0.39335	horrifically 0.38161	chronically 0.38130

Generated lemmatized results
***************
GENERATED	severely.r 126 ::: severly;irreparably;seriously;grievously;detrimentally;mortally;gravely;horrifically;chronically;prejudicially

Filtered results
***************
RANKED	severely.r 126	seriously 0.40412	gravely 0.39335	badly 0.37380	harshly 0.34899	devastatingly 0.34501	heavily 0.34367	dramatically 0.32812	extremely 0.31549	critically 0.31534	sternly 0.30780	highly 0.30282

Test context:
***************
severely.r	127	3	this picture was __severely__ damaged in the flood of 1913 and has rarely been seen until now .
Contexts for target severely are: ['advmodI_damaged']
Contexts in vocabulary for target severely are: ['advmodI_damaged']
Top most similar embeddings: severely 0.55353	severly 0.46657	irreparably 0.45042	grievously 0.42883	seriously 0.41106	badly 0.40605	chronically 0.40350	horrifically 0.40148	mortally 0.39855	savagely 0.39337

Generated lemmatized results
***************
GENERATED	severely.r 127 ::: severly;irreparably;grievously;seriously;badly;chronically;horrifically;mortally;savagely;irredeemably

Filtered results
***************
RANKED	severely.r 127	seriously 0.41106	badly 0.40605	heavily 0.37998	gravely 0.37581	harshly 0.35205	devastatingly 0.34990	extremely 0.33216	critically 0.32254	dramatically 0.32210	highly 0.31902	sternly 0.29502

Test context:
***************
severely.r	128	21	i was very disappointed when the author did not go into detail about how he regained his faith after having it __severely__ undermined by his early studies in theology at university .
Contexts for target severely are: ['advmodI_undermined']
Contexts in vocabulary for target severely are: ['advmodI_undermined']
Top most similar embeddings: severely 0.54369	severly 0.45576	grievously 0.42750	irreparably 0.41425	bloodily 0.41044	seriously 0.40703	catastrophically 0.40092	chronically 0.39577	irretrievably 0.39369	comically 0.39294

Generated lemmatized results
***************
GENERATED	severely.r 128 ::: severly;grievously;irreparably;bloodily;seriously;catastrophically;chronically;irretrievably;comically;savagely

Filtered results
***************
RANKED	severely.r 128	seriously 0.40703	badly 0.37997	heavily 0.37130	gravely 0.36650	devastatingly 0.35949	harshly 0.35919	dramatically 0.34618	critically 0.32453	sternly 0.31147	extremely 0.30970	highly 0.30670

Test context:
***************
severely.r	129	21	we do continue to support research on the differentiation of adult precursor cells into beta cells , but that 's a __severely__ limited field in terms of how successful it has been .
Contexts for target severely are: ['advmodI_limited']
Contexts in vocabulary for target severely are: ['advmodI_limited']
Top most similar embeddings: severely 0.54917	severly 0.43001	grievously 0.38396	infinitesimally 0.38223	seriously 0.38200	kinetically 0.38090	symptomatically 0.37763	scandalously 0.37688	murderously 0.37600	stringently 0.37400

Generated lemmatized results
***************
GENERATED	severely.r 129 ::: severly;grievously;infinitesimally;seriously;kinetically;symptomatically;scandalously;murderously;stringently;sharply

Filtered results
***************
RANKED	severely.r 129	seriously 0.38200	extremely 0.36191	gravely 0.35380	badly 0.35113	heavily 0.34880	harshly 0.34485	devastatingly 0.33330	highly 0.32574	dramatically 0.32040	sternly 0.31121	critically 0.30249

Test context:
***************
severely.r	130	4	mutual funds are so __severely__ conflicted that they will not avail themselves of the alleged benefits of the proposed rule .
Contexts for target severely are: ['advmod_so', 'advmodI_conflicted']
Contexts in vocabulary for target severely are: ['advmod_so', 'advmodI_conflicted']
Top most similar embeddings: severely 0.26907	grievously 0.22368	severly 0.22222	egregiously 0.21398	wretchedly 0.20946	abominably 0.20937	flagrantly 0.20882	comically 0.20774	dexterously 0.20746	callously 0.20732

Generated lemmatized results
***************
GENERATED	severely.r 130 ::: grievously;severly;egregiously;wretchedly;abominably;flagrantly;comically;dexterously;callously;cruelly

Filtered results
***************
RANKED	severely.r 130	badly 0.19562	seriously 0.19248	devastatingly 0.18843	gravely 0.18836	harshly 0.18761	heavily 0.18747	dramatically 0.17201	highly 0.16568	sternly 0.15972	extremely 0.14777	critically 0.14299

Test context:
***************
stand.n.v	131	11	leaders of some of the most powerful states in the world __stand__ by and give the impression that this is just the new way of life for zimbabweans .
Contexts for target stand are: ['det_the', 'nn_world', 'prep:inI_states']
Contexts in vocabulary for target stand are: ['det_the', 'nn_world', 'prep:inI_states']
Top most similar embeddings: stand 0.09233	marketplace 0.07980	war 0.07936	economy 0.07800	record-holder 0.07783	u.s.s.r. 0.07752	arena 0.07750	presidium 0.07747	hegemon 0.07711	yamato 0.07647

Generated lemmatized results
***************
GENERATED	stand.n.v 131 ::: marketplace;war;economy;arena;presidium;hegemon;yamato;occident;bloc;imbroglio

Filtered results
***************
RANKED	stand.n.v 131	table 0.06939	stance 0.06930	platform 0.06586	position 0.06469	structure 0.06320	base 0.06293	attitude 0.06132	place 0.06106	frame 0.06086	sit 0.05875	upright 0.05814	watch 0.05600	location 0.05507	placement 0.05316	wait 0.05293	support 0.05244	remain 0.04982	endure 0.04889	prevail 0.04773	stay 0.04731	symbolize 0.04336	abbreviate 0.04157	rely 0.03829	continue 0.03803	represent 0.03412

Test context:
***************
stand.n.v	132	2	we cannot __stand__ as helpless spectators while millions die for want in a world of plenty .
Contexts for target stand are: ['nsubj_we', 'aux_can', 'neg_not', 'rootI_*root*', 'prep:as_spectators', 'advcl_die', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target stand are: ['nsubj_we', 'aux_can', 'neg_not', 'rootI_*root*', 'prep:as_spectators', 'advcl_die', 'punct_.']
Top most similar embeddings: stand 0.00665	sit 0.00524	cower 0.00509	luxuriate 0.00499	exult 0.00497	overemphasise 0.00497	delude 0.00493	tolerate 0.00491	forbear 0.00484	loiter 0.00483

Generated lemmatized results
***************
GENERATED	stand.n.v 132 ::: sit;cower;luxuriate;exult;overemphasise;delude;tolerate;forbear;loiter;endure

Filtered results
***************
RANKED	stand.n.v 132	sit 0.00524	endure 0.00478	wait 0.00462	continue 0.00431	rely 0.00425	prevail 0.00417	watch 0.00381	represent 0.00376	remain 0.00375	abbreviate 0.00372	stay 0.00365	symbolize 0.00358	position 0.00341	place 0.00330	support 0.00327	frame 0.00321	table 0.00300	structure 0.00273	base 0.00253	upright 0.00247	attitude 0.00184	stance 0.00175	platform 0.00154	location 0.00136	placement 0.00131

Test context:
***************
stand.n.v	133	65	she knew that behind this remarkable new event that had overwhelmed allahÂs messenger ( sallallahu Âalayhi wa sallam ) lay something great that allah ( subhanahu wa taÂala ) had prepared for his messenger , so she spoke her kind and sweet words of encouragement , filling him with confidence , tranquility and firm conviction : Âbe of good cheer , o cousin , and __stand__ firm .
Contexts for target stand are: ['depI_firm']
Contexts in vocabulary for target stand are: ['depI_firm']
Top most similar embeddings: stand 0.49162	stands 0.40134	stood 0.37296	standing 0.34881	foothold 0.33433	07810 0.32570	stall 0.32536	tread 0.31973	waver 0.31314	upright 0.31223

Generated lemmatized results
***************
GENERATED	stand.n.v 133 ::: foothold;stall;tread;waver;upright;ashfords;unshaken;clintons;footstool;permira

Filtered results
***************
RANKED	stand.n.v 133	upright 0.31223	stance 0.30812	sit 0.30791	base 0.28560	position 0.28473	platform 0.28035	endure 0.28026	stay 0.27491	attitude 0.27410	place 0.27408	frame 0.26792	prevail 0.26630	rely 0.26394	structure 0.26364	support 0.26173	table 0.26115	remain 0.26108	continue 0.25925	symbolize 0.25827	represent 0.25684	watch 0.25623	abbreviate 0.25609	wait 0.25477	location 0.25234	placement 0.24539

Test context:
***************
stand.n.v	134	10	liberals(135)+ndp(19)=154=the usual yapping ndp of no consequence liberals(135)+bloc(54)=189=oui the government __stands__ or non it falls do n't count on the bloc to squander their good fortune like they did the last time they had 54 either .
Contexts for target stands are: ['nsubj_liberals', 'dep_135', 'dep_+', 'nn_bloc', 'dep_54', 'dep_=', 'nsubj_189', 'dep_=', 'dep_oui', 'nsubj_government', 'depI_ndp', 'cc_or', 'conj_non']
Contexts in vocabulary for target stands are: ['nsubj_liberals', 'dep_135', 'dep_+', 'nn_bloc', 'dep_54', 'dep_=', 'dep_=', 'nsubj_government', 'cc_or', 'conj_non']
Top most similar embeddings: nf 0.00044	equiv 0.00044	nl 0.00042	+2 0.00042	+1 0.00041	e0 0.00040	equals 0.00040	gly 0.00039	fp 0.00039	modulo 0.00039

Generated lemmatized results
***************
GENERATED	stand.n.v 134 ::: nf;equiv;nl;equal;gly;fp;modulo;resp;cond;std

Filtered results
***************
RANKED	stand.n.v 134	table 0.00023	abbreviate 0.00023	represent 0.00022	base 0.00022	frame 0.00021	upright 0.00020	watch 0.00019	stay 0.00019	wait 0.00019	prevail 0.00018	support 0.00018	sit 0.00018	stance 0.00016	remain 0.00016	structure 0.00016	endure 0.00016	platform 0.00016	place 0.00015	symbolize 0.00015	rely 0.00015	position 0.00015	attitude 0.00014	continue 0.00014	location 0.00013	placement 0.00010

Test context:
***************
stand.n.v	138	2	1 mcas __stands__ for the massachusetts comprehensive assessment system , a standards test administered to students in grades 3 , 4 , 5 , 6 , 7 , 8 , and 10 throughout the state .
Contexts for target stands are: ['nsubj_mcas', 'rootI_*root*', 'prep:for_system', 'punct_,', 'dobj_test', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target stands are: ['rootI_*root*', 'prep:for_system', 'punct_,', 'dobj_test', 'punct_.']
Top most similar embeddings: stands 0.03608	stood 0.02799	stand 0.02439	sits 0.02348	provides 0.02235	lays 0.02186	proposes 0.02156	contends 0.02141	computes 0.02132	envisions 0.02108

Generated lemmatized results
***************
GENERATED	stand.n.v 138 ::: sit;provide;lay;propose;contend;compute;envision;codify;foresee;argue

Filtered results
***************
RANKED	stand.n.v 138	sit 0.02348	represent 0.01998	support 0.01905	wait 0.01843	rely 0.01833	symbolize 0.01824	endure 0.01777	continue 0.01759	table 0.01652	position 0.01636	prevail 0.01634	remain 0.01582	watch 0.01517	place 0.01512	frame 0.01474	stay 0.01474	abbreviate 0.01419	base 0.01372	structure 0.01271	platform 0.01247	upright 0.01144	stance 0.01064	location 0.01017	attitude 0.00986	placement 0.00805

Test context:
***************
stand.n.v	140	13	and secondly , the consensus demonstrated to the world that africa no longer __stands__ on the fridges or sit on the fence when issues likely to have impacts on its economies and its people are being discussed .
Contexts for target stands are: ['nsubj_africa', 'advmod_longer', 'rcmodI_world', 'prep:on_fridges', 'cc_or', 'conj_sit', 'advcl_discussed']
Contexts in vocabulary for target stands are: ['nsubj_africa', 'advmod_longer', 'rcmodI_world', 'cc_or', 'conj_sit', 'advcl_discussed']
Top most similar embeddings: stands 0.01135	stand 0.01056	exists 0.00909	resides 0.00860	thrives 0.00858	hangs 0.00840	suffers 0.00839	lags 0.00833	sits 0.00827	lingers 0.00817

Generated lemmatized results
***************
GENERATED	stand.n.v 140 ::: exist;reside;thrive;hang;suffer;lag;sit;linger;hesitate;endure

Filtered results
***************
RANKED	stand.n.v 140	sit 0.00827	endure 0.00803	prevail 0.00779	stay 0.00745	wait 0.00712	rely 0.00667	watch 0.00620	represent 0.00619	symbolize 0.00619	continue 0.00604	remain 0.00597	support 0.00593	frame 0.00577	position 0.00567	place 0.00548	abbreviate 0.00543	upright 0.00526	table 0.00511	structure 0.00485	base 0.00468	platform 0.00389	stance 0.00373	placement 0.00323	location 0.00319	attitude 0.00314

Test context:
***************
stand.n	135	42	sapling and pole stages to maturity growth and yield- mature northern red oaks are usually from 20 to 30 m ( 65 to 98 ft ) tall and 61 to 91 cm ( 24 to 36 in ) in d.b.h. in undisturbed __stands__ on good sites .
Contexts for target stands are: ['amod_undisturbed', 'prep:inI_from', 'prep:on_sites']
Contexts in vocabulary for target stands are: ['amod_undisturbed', 'prep:inI_from', 'prep:on_sites']
Top most similar embeddings: stands 0.08809	pinewoods 0.07866	situ 0.07664	vegetation 0.07601	roosts 0.07489	clearings 0.07451	microhabitats 0.07437	ploughsoil 0.07431	mangroves 0.07366	herbage 0.07337

Generated lemmatized results
***************
GENERATED	stand.n 135 ::: pinewoods;situ;vegetation;roost;clearing;microhabitats;ploughsoil;mangrove;herbage;topsoil

Filtered results
***************
RANKED	stand.n 135	place 0.06468	location 0.06226	position 0.06054	stance 0.05875	frame 0.05851	platform 0.05826	table 0.05756	stay 0.05684	base 0.05647	structure 0.05570	upright 0.05567	placement 0.05181	attitude 0.05030	wait 0.05018	watch 0.05014	sit 0.04929	prevail 0.04708	remain 0.04544	support 0.04451	rely 0.04112	endure 0.04108	continue 0.03850	represent 0.03663	symbolize 0.03469	abbreviate 0.02728

Test context:
***************
stand.n	136	1	the __stand__ is not included .
Contexts for target stand are: ['det_the', 'nsubjpassI_included']
Contexts in vocabulary for target stand are: ['det_the', 'nsubjpassI_included']
Top most similar embeddings: stand 0.20032	headcover 0.17694	racecard 0.16906	baseboards 0.16596	hetatms 0.16489	website/services 0.16380	lectern 0.16355	stands 0.16265	antibiograms 0.16154	grandstand 0.16146

Generated lemmatized results
***************
GENERATED	stand.n 136 ::: headcover;racecard;baseboard;hetatms;lectern;antibiograms;grandstand;mihrab;rack;headrest

Filtered results
***************
RANKED	stand.n 136	table 0.14868	upright 0.14575	frame 0.14164	stance 0.13975	base 0.13753	platform 0.13681	position 0.13520	structure 0.13247	attitude 0.12893	wait 0.12783	placement 0.12687	support 0.12679	place 0.12516	location 0.12406	watch 0.12282	stay 0.12201	sit 0.10396	prevail 0.09544	endure 0.09233	symbolize 0.09030	remain 0.08963	abbreviate 0.08753	continue 0.08493	represent 0.08476	rely 0.08334

Test context:
***************
stand.n	137	11	here , its walnut case has been mounted on an adjustable __stand__ to make one of the earliest desk sets .
Contexts for target stand are: ['det_an', 'amod_adjustable', 'prep:onI_mounted', 'infmod_make']
Contexts in vocabulary for target stand are: ['det_an', 'amod_adjustable', 'prep:onI_mounted', 'infmod_make']
Top most similar embeddings: stand 0.05336	backrest 0.05045	footrest 0.04922	armrest 0.04852	handgrip 0.04678	headrest 0.04613	tripod 0.04513	floorboard 0.04486	baseplate 0.04457	nosepiece 0.04426

Generated lemmatized results
***************
GENERATED	stand.n 137 ::: backrest;footrest;armrest;handgrip;headrest;tripod;floorboard;baseplate;nosepiece;rack

Filtered results
***************
RANKED	stand.n 137	platform 0.04034	frame 0.03736	base 0.03707	position 0.03514	stance 0.03472	upright 0.03420	table 0.03194	structure 0.03044	attitude 0.02745	placement 0.02596	support 0.02563	watch 0.02542	stay 0.02513	location 0.02507	place 0.02467	wait 0.02435	sit 0.02119	endure 0.01853	prevail 0.01815	remain 0.01787	continue 0.01693	symbolize 0.01626	rely 0.01533	abbreviate 0.01409	represent 0.01237

Test context:
***************
stand.n	139	8	the denomination essentially voted to take a neutral __stand__ on many varying interpretations of genesis 1. feedback letter >from : stephen craig comment : first , let me compliment all of you for a great site .
Contexts for target stand are: ['det_a', 'amod_neutral', 'dobjI_take', 'prep:on_interpretations']
Contexts in vocabulary for target stand are: ['det_a', 'amod_neutral', 'dobjI_take', 'prep:on_interpretations']
Top most similar embeddings: stand 0.04990	stance 0.04752	slant 0.03784	disquisition 0.03664	dampener 0.03620	hinge 0.03605	standpoint 0.03586	position 0.03569	place 0.03557	sidelight 0.03541

Generated lemmatized results
***************
GENERATED	stand.n 139 ::: stance;slant;disquisition;dampener;hinge;standpoint;position;place;sidelight;viewpoint

Filtered results
***************
RANKED	stand.n 139	stance 0.04752	position 0.03569	place 0.03557	base 0.03303	attitude 0.03231	platform 0.03153	frame 0.02794	structure 0.02617	upright 0.02575	table 0.02559	placement 0.02557	wait 0.02427	stay 0.02376	location 0.02307	watch 0.02274	sit 0.02206	rely 0.01968	support 0.01926	prevail 0.01895	symbolize 0.01628	represent 0.01618	remain 0.01615	endure 0.01600	continue 0.01552	abbreviate 0.01436

Test context:
***************
well.r	141	32	attorney general 's page the connecticut attorney general 's website includes a discussion of current health topics , including hmos , medicare , current connecticut health legislation , and insurance issues as __well__ as information on your rights when it comes to making health care decisions .
Contexts for target well are: ['advmod_as', 'ccI_issues', 'mwe_as']
Contexts in vocabulary for target well are: ['advmod_as', 'ccI_issues', 'mwe_as']
Top most similar embeddings: well 0.17641	rather 0.07071	soon 0.06478	quickly 0.06458	yet 0.06380	smoothly 0.06255	badly 0.06227	poorly 0.06189	easily 0.06142	instead 0.06138

Generated lemmatized results
***************
GENERATED	well.r 141 ::: rather;soon;quickly;yet;smoothly;badly;poorly;easily;instead;plus

Filtered results
***************
RANKED	well.r 141	efficiently 0.05961	excellently 0.05761	carefully 0.05742	successfully 0.05545	long 0.05434	satisfactorily 0.05315	properly 0.05288	much 0.05286	and 0.05166	healthily 0.04968	indeed 0.04594	so 0.04335	safely 0.04264	then 0.04099	including 0.03821	nice 0.03761	goodbye 0.03482	sufficient 0.03140	with 0.03044

Test context:
***************
well.r	142	4	we needed to plan __well__ in advanced to give schools enough warning but not too much choice on times and dates as this seemed to make decisions harder !
Contexts for target well are: ['advmodI_plan']
Contexts in vocabulary for target well are: ['advmodI_plan']
Top most similar embeddings: well 0.50243	proably 0.40648	apprently 0.39323	defintely 0.39038	personnally 0.38679	probally 0.38542	actaully 0.38495	unfortuantely 0.38366	idealy 0.38138	dexterously 0.38126

Generated lemmatized results
***************
GENERATED	well.r 142 ::: proably;apprently;defintely;personnally;probally;actaully;unfortuantely;idealy;dexterously;probaly

Filtered results
***************
RANKED	well.r 142	properly 0.37475	carefully 0.36767	then 0.35199	successfully 0.35091	satisfactorily 0.35041	efficiently 0.35031	so 0.34647	excellently 0.34339	indeed 0.34197	healthily 0.32333	long 0.32015	safely 0.31436	much 0.30956	and 0.26929	nice 0.24275	including 0.23510	goodbye 0.23488	with 0.23447	sufficient 0.22188

Test context:
***************
well.r	143	12	and be ready to move elsewhere if you are not being treated __well__ .
Contexts for target well are: ['advmodI_treated']
Contexts in vocabulary for target well are: ['advmodI_treated']
Top most similar embeddings: well 0.50686	insensitively 0.42275	shabbily 0.41644	hospitably 0.41302	shoddily 0.41125	symptomatically 0.41076	deterministically 0.40916	dexterously 0.40473	unsuitably 0.40352	dually 0.40338

Generated lemmatized results
***************
GENERATED	well.r 143 ::: insensitively;shabbily;hospitably;shoddily;symptomatically;deterministically;dexterously;unsuitably;dually;abominably

Filtered results
***************
RANKED	well.r 143	properly 0.37054	successfully 0.36478	satisfactorily 0.36364	excellently 0.36313	carefully 0.35672	then 0.35462	indeed 0.34184	so 0.33786	efficiently 0.33548	healthily 0.33030	safely 0.32322	long 0.31819	much 0.30374	and 0.26617	goodbye 0.25309	nice 0.24984	with 0.24766	including 0.24369	sufficient 0.23425

Test context:
***************
well.r	144	12	treatment of physical problems , particularly chronic ones , is possible as __well__ as psychological therapy .
Contexts for target well are: ['advmod_as', 'ccI_possible', 'mwe_as']
Contexts in vocabulary for target well are: ['advmod_as', 'ccI_possible', 'mwe_as']
Top most similar embeddings: well 0.16332	yet 0.07070	rather 0.06816	soon 0.06650	quickly 0.06526	either 0.06308	easily 0.06303	smoothly 0.06183	poorly 0.06080	and/or 0.06080

Generated lemmatized results
***************
GENERATED	well.r 144 ::: yet;rather;soon;quickly;either;easily;smoothly;poorly;instead;nor

Filtered results
***************
RANKED	well.r 144	efficiently 0.05710	carefully 0.05640	successfully 0.05570	excellently 0.05508	long 0.05451	satisfactorily 0.05343	much 0.05295	properly 0.05279	and 0.05057	healthily 0.04975	indeed 0.04651	so 0.04470	safely 0.04293	then 0.04130	including 0.03900	nice 0.03806	goodbye 0.03549	with 0.03176	sufficient 0.03160

Test context:
***************
well.r	145	17	fades the light ; and afar goeth day , and the stars shineth bright , fare thee __well__ ; day has gone , night is on .
Contexts for target well are: ['advmodI_thee']
Contexts in vocabulary for target well are: ['advmodI_thee']
Top most similar embeddings: well 0.51324	dexterously 0.38624	deceitfully 0.38607	breezily 0.37748	bountifully 0.37378	presumptuously 0.37355	everlastingly 0.37337	proably 0.37134	resignedly 0.36904	prosperously 0.36887

Generated lemmatized results
***************
GENERATED	well.r 145 ::: dexterously;deceitfully;breezily;bountifully;presumptuously;everlastingly;proably;resignedly;prosperously;virtuously

Filtered results
***************
RANKED	well.r 145	then 0.34026	properly 0.33837	indeed 0.33688	excellently 0.33221	satisfactorily 0.32916	carefully 0.32734	so 0.31405	successfully 0.31379	efficiently 0.31362	long 0.31264	healthily 0.30808	safely 0.30361	much 0.29055	goodbye 0.26040	and 0.25433	nice 0.24928	with 0.23399	including 0.22302	sufficient 0.22074

Test context:
***************
well.r	146	18	half the phones , half the computers , half the consumer electronic products we buy are not as __well__ made or designed as the other half .
Contexts for target well are: ['advmodI_made']
Contexts in vocabulary for target well are: ['advmodI_made']
Top most similar embeddings: well 0.51015	proably 0.41187	dexterously 0.41100	sportingly 0.40900	insensitively 0.40750	duely 0.40583	apprently 0.40580	hospitably 0.40519	usally 0.40382	shoddily 0.40112

Generated lemmatized results
***************
GENERATED	well.r 146 ::: proably;dexterously;sportingly;insensitively;duely;apprently;hospitably;usally;shoddily;eventualy

Filtered results
***************
RANKED	well.r 146	excellently 0.36347	then 0.36099	properly 0.35942	indeed 0.35638	successfully 0.35138	satisfactorily 0.35120	carefully 0.35016	so 0.34491	efficiently 0.33105	long 0.32214	healthily 0.31878	safely 0.31414	much 0.31375	nice 0.26779	and 0.26326	goodbye 0.25217	including 0.25079	with 0.24706	sufficient 0.22731

Test context:
***************
well.r	147	0	__well__ , perhaps not .
Contexts for target well are: ['advmodI_not']
Contexts in vocabulary for target well are: ['advmodI_not']
Top most similar embeddings: well 0.50451	certainly 0.38816	apparently 0.38461	obviously 0.38281	defintely 0.38226	proably 0.38181	surely 0.37862	definitely 0.37459	definetely 0.37453	just 0.37334

Generated lemmatized results
***************
GENERATED	well.r 147 ::: certainly;apparently;obviously;defintely;proably;surely;definitely;definetely;just;probally

Filtered results
***************
RANKED	well.r 147	indeed 0.34841	so 0.34741	properly 0.33972	then 0.33334	satisfactorily 0.32640	carefully 0.32188	excellently 0.31772	successfully 0.31731	efficiently 0.30299	much 0.29936	healthily 0.29708	long 0.28918	safely 0.27703	and 0.27515	nice 0.23825	with 0.22756	goodbye 0.22735	sufficient 0.22275	including 0.21633

Test context:
***************
well.r	148	12	cupertino-based apple is known for aggressively protecting its intellectual property , as __well__ as its image .
Contexts for target well are: ['advmod_as', 'ccI_protecting', 'mwe_as']
Contexts in vocabulary for target well are: ['advmod_as', 'ccI_protecting', 'mwe_as']
Top most similar embeddings: well 0.17231	rather 0.07005	quickly 0.06493	soon 0.06477	badly 0.06364	smoothly 0.06253	easily 0.06105	instead 0.06091	yet 0.06052	far 0.06048

Generated lemmatized results
***************
GENERATED	well.r 148 ::: rather;quickly;soon;badly;smoothly;easily;instead;yet;far;poorly

Filtered results
***************
RANKED	well.r 148	efficiently 0.05794	carefully 0.05712	excellently 0.05647	successfully 0.05558	long 0.05417	much 0.05267	properly 0.05264	satisfactorily 0.05196	and 0.05022	healthily 0.04947	indeed 0.04470	so 0.04426	safely 0.04231	then 0.04099	nice 0.03871	including 0.03676	goodbye 0.03507	sufficient 0.03142	with 0.03092

Test context:
***************
well.r	149	0	__well__ , one of alf 's intentions when he first conceived the newsletter was that it should serve as a continuous record of the activities of the society , and as we all know , the contents of a web page can change or disappear as fast as a bottle of wine at hogmanay !
Contexts for target well are: ['advmodI_was']
Contexts in vocabulary for target well are: ['advmodI_was']
Top most similar embeddings: well 0.50198	proably 0.42068	apprently 0.40722	defintely 0.40342	unfortuantely 0.40331	actaully 0.40014	usally 0.39935	probaly 0.39871	regretably 0.39861	bascially 0.39684

Generated lemmatized results
***************
GENERATED	well.r 149 ::: proably;apprently;defintely;unfortuantely;actaully;usally;probaly;regretably;bascially;dexterously

Filtered results
***************
RANKED	well.r 149	indeed 0.36582	then 0.36453	so 0.34619	excellently 0.34197	properly 0.33929	satisfactorily 0.32688	successfully 0.32368	long 0.32236	carefully 0.31768	healthily 0.31659	much 0.31367	efficiently 0.31045	safely 0.29804	nice 0.27298	and 0.26601	with 0.25325	goodbye 0.25324	sufficient 0.23461	including 0.23268

Test context:
***************
well.r	150	0	__well__ now we have. ' plain english campaign is n't stopping there , though .
Contexts for target well are: ['advmodI_now']
Contexts in vocabulary for target well are: ['advmodI_now']
Top most similar embeddings: well 0.50751	proably 0.40216	probally 0.39879	probaly 0.39002	breezily 0.38722	idealy 0.38535	even 0.38227	bascially 0.38214	actaully 0.38104	usally 0.38052

Generated lemmatized results
***************
GENERATED	well.r 150 ::: proably;probally;probaly;breezily;idealy;even;bascially;actaully;usally;personnally

Filtered results
***************
RANKED	well.r 150	so 0.35534	properly 0.34118	excellently 0.33955	indeed 0.33599	carefully 0.33459	satisfactorily 0.33048	successfully 0.32654	then 0.32573	long 0.32087	much 0.31994	healthily 0.31633	efficiently 0.31509	safely 0.30736	and 0.27325	goodbye 0.26108	nice 0.25375	with 0.24136	sufficient 0.23853	including 0.23234

Test context:
***************
wild.a	151	25	modern hunting methods have been introduced , undermining the traditional hunting practices of the local people who have for generations sought to protect and preserve __wild__ life .
Contexts for target wild are: ['amodI_life']
Contexts in vocabulary for target wild are: ['amodI_life']
Top most similar embeddings: wild 0.52731	care-free 0.38187	fucked-up 0.37942	free-ranging 0.37871	drug-fuelled 0.37679	depression-era 0.37518	fish-eating 0.37435	long-ago 0.37368	dissolute 0.37266	messed-up 0.37170

Generated lemmatized results
***************
GENERATED	wild.a 151 ::: dissolute;leisured;torrid;bacchanalian;bucolic;deathless;diabolic;vampiric;sapphic;somnolent

Filtered results
***************
RANKED	wild.a 151	untamed 0.34903	feral 0.34652	crazy 0.34628	chaotic 0.33457	undisciplined 0.32674	reckless 0.32663	amazing 0.32223	dramatic 0.31657	unpredictable 0.31539	unrestrained 0.31297	natural 0.31289	unbelievable 0.30969	huge 0.30680	incredible 0.30321	extreme 0.30236	free 0.29869	garish 0.29829	animal 0.29052	wilderness 0.28891	patterned 0.28716	irregular 0.28421	coloured 0.27731	non-domestic 0.27556	outside 0.27191	striking 0.27044

Test context:
***************
wild.a	152	16	it is presumed that this is because the level of infection of ihhn virus in the __wild__ population is relatively low , and when these wild stocks are held in captivity , the virus quickly spreads from infected broodstock to non-infected broodstock .
Contexts for target wild are: ['amodI_population']
Contexts in vocabulary for target wild are: ['amodI_population']
Top most similar embeddings: wild 0.52253	ungulate 0.39353	fish-eating 0.38766	free-ranging 0.38632	pure-bred 0.38040	free-living 0.37995	white-clawed 0.37805	non-breeding 0.37760	neotropical 0.37626	sub-arctic 0.37573

Generated lemmatized results
***************
GENERATED	wild.a 152 ::: ungulate;neotropical;indiginous;epiphytic;planktonic;acadian;micronesian;purebred;macroinvertebrate;indochinese

Filtered results
***************
RANKED	wild.a 152	feral 0.36708	untamed 0.33623	crazy 0.32458	huge 0.32384	reckless 0.31252	undisciplined 0.31231	chaotic 0.31140	extreme 0.30823	unrestrained 0.30774	natural 0.30315	free 0.29565	dramatic 0.29521	unpredictable 0.29348	patterned 0.29065	amazing 0.28486	coloured 0.28355	animal 0.28156	non-domestic 0.28114	irregular 0.28034	unbelievable 0.27952	incredible 0.27694	striking 0.27518	garish 0.27453	wilderness 0.27435	outside 0.25774

Test context:
***************
wild.a	153	11	freya , orphaned as a baby and now something of a __wild__ spirit , shares her secrets with danny in their private place on the nearby rocky crags .
Contexts for target wild are: ['amodI_spirit']
Contexts in vocabulary for target wild are: ['amodI_spirit']
Top most similar embeddings: wild 0.50699	tutelary 0.38209	fervid 0.38174	unconquerable 0.38018	irrepressible 0.37871	deathless 0.37867	hot-blooded 0.37665	dionysian 0.37656	keltic 0.37604	bacchanalian 0.37592

Generated lemmatized results
***************
GENERATED	wild.a 153 ::: tutelary;fervid;unconquerable;irrepressible;deathless;dionysian;keltic;bacchanalian;revengeful;diabolic

Filtered results
***************
RANKED	wild.a 153	untamed 0.35007	feral 0.34841	crazy 0.34069	reckless 0.33553	free 0.32875	unrestrained 0.32866	amazing 0.31873	huge 0.31636	undisciplined 0.31452	incredible 0.30835	chaotic 0.30747	natural 0.30301	dramatic 0.30215	unpredictable 0.30196	extreme 0.30028	unbelievable 0.29781	garish 0.28709	striking 0.28042	patterned 0.27873	non-domestic 0.27623	wilderness 0.27522	animal 0.27355	coloured 0.27185	irregular 0.26367	outside 0.25588

Test context:
***************
wild.a	154	33	these wounds may be from a variety of sources : fish hooks , barbed wire , lawnmowers , traps , tree branches , cats , dogs , bullets , or , even other __wild__ animals .
Contexts for target wild are: ['amodI_animals']
Contexts in vocabulary for target wild are: ['amodI_animals']
Top most similar embeddings: wild 0.55176	four-footed 0.43417	free-ranging 0.43137	pure-bred 0.42943	fish-eating 0.42627	factory-farmed 0.42293	semi-wild 0.42109	food-producing 0.41812	wild-caught 0.41093	free-living 0.41033

Generated lemmatized results
***************
GENERATED	wild.a 154 ::: unvaccinated;purebred;nonhuman;epiphytic;herbivorous;longhaired;exotic;caprine;crossbred;flightless

Filtered results
***************
RANKED	wild.a 154	feral 0.37857	untamed 0.35427	crazy 0.34709	unrestrained 0.33300	amazing 0.32567	unpredictable 0.31962	huge 0.31476	undisciplined 0.30968	incredible 0.30966	reckless 0.30918	dramatic 0.29902	natural 0.29836	non-domestic 0.29824	garish 0.29802	chaotic 0.29657	extreme 0.29406	unbelievable 0.29342	coloured 0.29288	animal 0.28762	wilderness 0.28615	free 0.28586	patterned 0.28480	striking 0.28201	irregular 0.26695	outside 0.26018

Test context:
***************
wild.a	155	5	in the genealogy section a __wild__ story about someone 's great great grandfather !
Contexts for target wild are: ['amodI_story']
Contexts in vocabulary for target wild are: ['amodI_story']
Top most similar embeddings: wild 0.49415	tragi-comic 0.39507	rags-to-riches 0.39295	true-life 0.38900	spine-chilling 0.38869	doom-laden 0.38283	tear-jerking 0.38282	well-told 0.38069	wonderous 0.37658	scabrous 0.37614

Generated lemmatized results
***************
GENERATED	wild.a 155 ::: wonderous;scabrous;heartrending;lovecraftian;tragicomic;doleful;druggy;bacchanalian;rumbustious;neverending

Filtered results
***************
RANKED	wild.a 155	crazy 0.35816	amazing 0.33826	huge 0.33454	dramatic 0.33233	feral 0.32712	unbelievable 0.32447	incredible 0.32259	untamed 0.31826	reckless 0.31648	unpredictable 0.30917	chaotic 0.30786	garish 0.30400	unrestrained 0.29980	free 0.29848	natural 0.29514	extreme 0.29129	striking 0.28979	undisciplined 0.27686	non-domestic 0.27627	patterned 0.27493	coloured 0.27288	wilderness 0.27050	outside 0.26649	irregular 0.26442	animal 0.26284

Test context:
***************
wild.a	156	13	now it is the gw doomsayers that ignore similar geological evidence that show __wild__ and mini climatic swings throughout the earth 's history .
Contexts for target wild are: ['amodI_swings', 'cc_and', 'conj_mini']
Contexts in vocabulary for target wild are: ['amodI_swings', 'cc_and', 'conj_mini']
Top most similar embeddings: wild 0.12152	splashy 0.08586	wildest 0.08497	colourful 0.08453	2-tone 0.08346	sinuous 0.08296	low-speed 0.08253	raunchy 0.08122	scabby 0.08098	curvy 0.08080

Generated lemmatized results
***************
GENERATED	wild.a 156 ::: splashy;colourful;sinuous;raunchy;scabby;curvy;reptilian;boisterous;curvaceous;dodgems

Filtered results
***************
RANKED	wild.a 156	garish 0.07670	chaotic 0.07597	huge 0.07514	dramatic 0.07421	unpredictable 0.07407	feral 0.07308	extreme 0.07271	crazy 0.07235	untamed 0.07099	irregular 0.06869	reckless 0.06792	undisciplined 0.06782	natural 0.06675	patterned 0.06618	amazing 0.06551	unrestrained 0.06502	coloured 0.06444	free 0.06324	unbelievable 0.06311	incredible 0.06230	striking 0.06010	wilderness 0.05644	outside 0.05634	animal 0.05537	non-domestic 0.05268

Test context:
***************
wild.a	157	12	lovely venue ( well as long as you go in for the __wild__ wallpaper ) , fantastic sound system , great staff , nice cocktails and a great time had by all .
Contexts for target wild are: ['amodI_wallpaper']
Contexts in vocabulary for target wild are: ['amodI_wallpaper']
Top most similar embeddings: wild 0.46341	brightly-coloured 0.38141	day-glo 0.37531	multicoloured 0.37382	swirly 0.37335	dayglo 0.37322	filmy 0.37302	glow-in-the-dark 0.36831	soft-focus 0.36797	multi-colored 0.36734

Generated lemmatized results
***************
GENERATED	wild.a 157 ::: multicoloured;swirly;dayglo;filmy;raggedy;multicolored;brassy;hued;stripy;metalic

Filtered results
***************
RANKED	wild.a 157	garish 0.35425	crazy 0.34105	huge 0.31838	patterned 0.31318	reckless 0.31303	amazing 0.31275	untamed 0.31221	feral 0.30702	dramatic 0.30663	free 0.30516	coloured 0.30167	extreme 0.29897	chaotic 0.29705	unrestrained 0.29244	incredible 0.29053	natural 0.28875	striking 0.28873	unbelievable 0.28666	unpredictable 0.28036	undisciplined 0.27483	wilderness 0.26774	non-domestic 0.26685	animal 0.26593	irregular 0.26456	outside 0.25542

Test context:
***************
wild.a	158	29	you 'll accuse me of being off track , and rightly so , but should n't we first ask what solution our dear islam has provided for satisfying your __wild__ god-given instincts , beside suppressing them for years until you get the chance to get married ?
Contexts for target wild are: ['amodI_instincts']
Contexts in vocabulary for target wild are: ['amodI_instincts']
Top most similar embeddings: wild 0.50930	animalistic 0.38197	wildest 0.37660	atavistic 0.37491	free-ranging 0.37421	primeval 0.37044	freakish 0.36663	cannibalistic 0.36661	cat-like 0.36643	bloodthirsty 0.36578

Generated lemmatized results
***************
GENERATED	wild.a 158 ::: animalistic;atavistic;primeval;freakish;cannibalistic;bloodthirsty;base;egoistic;uncivilized;diabolic

Filtered results
***************
RANKED	wild.a 158	feral 0.35777	untamed 0.34703	crazy 0.34465	unrestrained 0.33420	natural 0.32806	reckless 0.32459	dramatic 0.31580	free 0.31384	unpredictable 0.31203	undisciplined 0.31091	extreme 0.30961	amazing 0.30717	chaotic 0.30460	unbelievable 0.29773	huge 0.29716	incredible 0.29004	animal 0.28790	garish 0.28572	patterned 0.27204	striking 0.27159	wilderness 0.27112	irregular 0.26908	non-domestic 0.26695	outside 0.26413	coloured 0.25448

Test context:
***************
wild.a	159	12	the riverine habitat is extremely beautiful and the chances of seeing large __wild__ animals are high .
Contexts for target wild are: ['amodI_animals']
Contexts in vocabulary for target wild are: ['amodI_animals']
Top most similar embeddings: wild 0.55176	four-footed 0.43417	free-ranging 0.43137	pure-bred 0.42943	fish-eating 0.42627	factory-farmed 0.42293	semi-wild 0.42109	food-producing 0.41812	wild-caught 0.41093	free-living 0.41033

Generated lemmatized results
***************
GENERATED	wild.a 159 ::: unvaccinated;purebred;nonhuman;epiphytic;herbivorous;longhaired;exotic;caprine;crossbred;flightless

Filtered results
***************
RANKED	wild.a 159	feral 0.37857	untamed 0.35427	crazy 0.34709	unrestrained 0.33300	amazing 0.32567	unpredictable 0.31962	huge 0.31476	undisciplined 0.30968	incredible 0.30966	reckless 0.30918	dramatic 0.29902	natural 0.29836	non-domestic 0.29824	garish 0.29802	chaotic 0.29657	extreme 0.29406	unbelievable 0.29342	coloured 0.29288	animal 0.28762	wilderness 0.28615	free 0.28586	patterned 0.28480	striking 0.28201	irregular 0.26695	outside 0.26018

Test context:
***************
wild.a.n	160	11	an endangered species is one that could become extinct in the __wild__ in 10 to 20 years , if nothing is done to protect it .
Contexts for target wild are: ['det_the', 'prep:inI_extinct']
Contexts in vocabulary for target wild are: ['det_the', 'prep:inI_extinct']
Top most similar embeddings: wild 0.27700	mid-1800s 0.19595	palaearctic 0.19051	brecks 0.18702	negeb 0.18572	ozarks 0.18565	1680s 0.18472	1530s 0.18393	sandlings 0.18362	minch 0.18341

Generated lemmatized results
***************
GENERATED	wild.a.n 160 ::: palaearctic;brecks;negeb;ozarks;sandlings;minch;sundarbans;moluccas;carpathians;faeroes

Filtered results
***************
RANKED	wild.a.n 160	wilderness 0.16618	untamed 0.15741	feral 0.14274	extreme 0.14027	reckless 0.13739	animal 0.13258	crazy 0.12693	natural 0.12512	outside 0.12184	irregular 0.12012	chaotic 0.12004	unpredictable 0.11869	dramatic 0.11774	unrestrained 0.11666	unbelievable 0.11249	non-domestic 0.11220	undisciplined 0.11189	striking 0.11041	garish 0.10994	patterned 0.10864	amazing 0.10661	incredible 0.10627	free 0.10406	coloured 0.10253	huge 0.09823

Test context:
***************
can.n	161	10	&#8226 ; what happened to the big , new garbage __can__ at church and chambers streets ?
Contexts for target can are: ['depI_garbage', 'prep:at_streets']
Contexts in vocabulary for target can are: ['depI_garbage', 'prep:at_streets']
Top most similar embeddings: can 0.24608	could 0.20568	cuid 0.20126	glowered 0.20105	scuttles 0.19619	rummaged 0.19496	peeked 0.19434	look 0.19231	couldst 0.19223	gazed 0.19192

Generated lemmatized results
***************
GENERATED	can.n 161 ::: could;cuid;glowered;scuttle;rummaged;peeked;look;couldst;gazed;whould

Filtered results
***************
RANKED	can.n 161	cannister 0.17070	receptacle 0.16700	tin 0.16299	container 0.15993	bin 0.15924	disposal 0.13513

Test context:
***************
can.n	162	13	after the coin has been sleeved , there is no hesitation as the __can__ apparently covers the coin in the lh .
Contexts for target can are: ['auxI_covers']
Contexts in vocabulary for target can are: ['auxI_covers']
Top most similar embeddings: can 0.49826	could 0.43424	should 0.40907	would 0.40504	must 0.39812	will 0.39466	to 0.38204	might 0.37921	does 0.36948	did 0.36416

Generated lemmatized results
***************
GENERATED	can.n 162 ::: could;should;would;must;will;to;might;doe;did;may

Filtered results
***************
RANKED	can.n 162	tin 0.25109	cannister 0.23936	receptacle 0.23691	container 0.23683	bin 0.23631	disposal 0.20126

Test context:
***************
can.n	163	23	instead of cleverly tricking prosser into lying down in the mud , ford simply distracts the workmen with a shopping trolley full of __cans__ of lager which he just happens to have with him .
Contexts for target cans are: ['prep:ofI_full', 'prep:of_lager']
Contexts in vocabulary for target cans are: ['prep:ofI_full', 'prep:of_lager']
Top most similar embeddings: cans 0.28252	bottles 0.24097	kegs 0.21364	tins 0.21323	jars 0.20612	cartons 0.20509	crates 0.20269	punnets 0.20210	buckets 0.20154	pints 0.19936

Generated lemmatized results
***************
GENERATED	can.n 163 ::: bottle;keg;tin;jar;carton;crate;punnet;bucket;pint;phial

Filtered results
***************
RANKED	can.n 163	tin 0.21323	container 0.19450	cannister 0.17625	bin 0.16207	receptacle 0.15623	disposal 0.11466

Test context:
***************
can.n	164	15	no hazardous materials such as paint , noxious chemicals , solvents , oil , petrol __cans__ , gas bottles , tyres , asbestos , vehicle batteries , medical or biological waste .
Contexts for target cans are: ['nn_petrol', 'conjI_paint']
Contexts in vocabulary for target cans are: ['nn_petrol', 'conjI_paint']
Top most similar embeddings: cans 0.25951	bottles 0.21221	tins 0.20378	cartons 0.20253	thinners 0.19241	containers 0.19190	jars 0.18680	canisters 0.18621	plastics 0.18489	briquettes 0.18462

Generated lemmatized results
***************
GENERATED	can.n 164 ::: bottle;tin;carton;thinner;container;jar;canister;plastic;briquette;tippex

Filtered results
***************
RANKED	can.n 164	tin 0.20378	container 0.19190	cannister 0.17256	bin 0.15936	receptacle 0.15444	disposal 0.12243

Test context:
***************
can.n	165	9	sources of standing water include old tires , metal __cans__ , ceramic pots , clogged drain covers , wading pools , pool covers , bird baths , and rain barrels. " visit the cdc west nile website at http://www.cdc.gov/ncidod/dvbid/westnile / .
Contexts for target cans are: ['nn_metal', 'conjI_tires']
Contexts in vocabulary for target cans are: ['nn_metal', 'conjI_tires']
Top most similar embeddings: cans 0.26811	bottles 0.21509	canisters 0.20639	tubes 0.20527	tins 0.20420	containers 0.20345	preforms 0.19870	bumpers 0.19722	buckets 0.19618	cartons 0.19435

Generated lemmatized results
***************
GENERATED	can.n 165 ::: bottle;canister;tube;tin;container;preforms;bumper;bucket;carton;crate

Filtered results
***************
RANKED	can.n 165	tin 0.20420	container 0.20345	cannister 0.18485	bin 0.17800	receptacle 0.16436	disposal 0.12684

Test context:
***************
can.n	166	6	q : do you take steel __cans__ at the curbside ?
Contexts for target cans are: ['nn_steel', 'dobjI_take']
Contexts in vocabulary for target cans are: ['nn_steel', 'dobjI_take']
Top most similar embeddings: cans 0.26459	bottles 0.20934	tins 0.20483	containers 0.19519	pails 0.19477	cartons 0.19195	off-cuts 0.18704	saucepans 0.18660	canisters 0.18625	bedpan 0.18531

Generated lemmatized results
***************
GENERATED	can.n 166 ::: bottle;tin;container;pail;carton;saucepan;canister;bedpan;bucket;ingot

Filtered results
***************
RANKED	can.n 166	tin 0.20483	container 0.19519	cannister 0.18296	bin 0.17981	receptacle 0.15398	disposal 0.12919

Test context:
***************
can.n	167	9	aluminum & steel cans - rinse aluminum and steel __cans__ .
Contexts for target cans are: ['nn_steel', 'conjI_aluminum']
Contexts in vocabulary for target cans are: ['nn_steel', 'conjI_aluminum']
Top most similar embeddings: cans 0.26902	tins 0.20613	ingots 0.20495	ferrules 0.20431	briquettes 0.20383	bottles 0.20201	aluminium 0.20095	off-cuts 0.19960	offcuts 0.19901	canisters 0.19889

Generated lemmatized results
***************
GENERATED	can.n 167 ::: tin;ingot;ferrule;briquette;bottle;aluminium;offcuts;canister;saucepan;backplate

Filtered results
***************
RANKED	can.n 167	tin 0.20613	container 0.19525	cannister 0.17699	bin 0.16165	receptacle 0.15698	disposal 0.12418

Test context:
***************
can.n	168	7	packed the soil itself into huge trash __cans__ and in the 14 truckloads , two a day , carried soil to new house .
Contexts for target cans are: ['amod_huge', 'nn_trash', 'prep:intoI_packed']
Contexts in vocabulary for target cans are: ['amod_huge', 'nn_trash', 'prep:intoI_packed']
Top most similar embeddings: cans 0.13481	containers 0.10818	bottles 0.10719	bags 0.10497	sacks 0.10444	tins 0.10345	cartons 0.10263	jars 0.10250	crates 0.09967	bins 0.09960

Generated lemmatized results
***************
GENERATED	can.n 168 ::: container;bottle;bag;sack;tin;carton;jar;crate;bin;suitcase

Filtered results
***************
RANKED	can.n 168	container 0.10818	tin 0.10345	bin 0.09960	cannister 0.09228	receptacle 0.08498	disposal 0.05743

Test context:
***************
can.n	169	11	facilities are available for the recycling of paper , glass , __cans__ , textiles , shoes , plastic bottles , cardboard , and oil .
Contexts for target cans are: ['conjI_paper']
Contexts in vocabulary for target cans are: ['conjI_paper']
Top most similar embeddings: cans 0.56060	bottles 0.45097	tins 0.44107	cartons 0.42978	paperboard 0.42414	cardboard 0.41110	containers 0.40993	jars 0.40659	punnets 0.40054	matchboxes 0.39842

Generated lemmatized results
***************
GENERATED	can.n 169 ::: bottle;tin;carton;paperboard;cardboard;container;jar;punnet;matchbox;plastic

Filtered results
***************
RANKED	can.n 169	tin 0.44107	container 0.40993	bin 0.35405	cannister 0.33283	receptacle 0.32680	disposal 0.29122

Test context:
***************
can.n	170	37	jan replies ... hi linda , one cat owner reported , " we are now back on maintenance dose of 3/4 tablespoon of essiac mixed with one tablespoon of tuna juice ( the spring water from a __can__ of tuna ) .
Contexts for target can are: ['det_a', 'prep:fromI_water', 'prep:of_tuna']
Contexts in vocabulary for target can are: ['det_a', 'prep:fromI_water', 'prep:of_tuna']
Top most similar embeddings: plateful 0.09112	carafe 0.08930	colander 0.08872	skillet 0.08594	punnet 0.08576	strainer 0.08548	bottle 0.08541	cupful 0.08528	flagon 0.08494	bucketful 0.08465

Generated lemmatized results
***************
GENERATED	can.n 170 ::: plateful;carafe;colander;skillet;punnet;strainer;bottle;cupful;flagon;bucketful

Filtered results
***************
RANKED	can.n 170	tin 0.08155	container 0.07840	receptacle 0.07747	cannister 0.07681	bin 0.06473	disposal 0.05690

Test context:
***************
dark.n	171	37	so we all went out to dinner , and i found myself sitting between light and dark , which is where we all are , is n't it , and i kept feeling more attracted to the __dark__ .
Contexts for target dark are: ['det_the', 'prep:toI_attracted']
Contexts in vocabulary for target dark are: ['det_the', 'prep:toI_attracted']
Top most similar embeddings: dark 0.21769	semi-darkness 0.18581	half-light 0.18559	firelight 0.18500	tree-tops 0.18427	duat 0.18123	darkness 0.18031	hurly-burly 0.17949	lamplight 0.17883	gloaming 0.17861

Generated lemmatized results
***************
GENERATED	dark.n 171 ::: firelight;duat;darkness;lamplight;gloaming;greyness;brecks;heavenlies;hellmouth;darker

Filtered results
***************
RANKED	dark.n 171	darkness 0.18031	dimness 0.16755	gloom 0.16737	shadow 0.16618	dusk 0.16553	shade 0.16163	mystery 0.15431	black 0.14567	sunset 0.14327	sombre 0.13550	secret 0.13499	night 0.13343	oblivion 0.13049	nightfall 0.12583	uninformed 0.12516	ignorance 0.12371	ignorant 0.11899	oblivious 0.11112	uncertain 0.10640	unsure 0.09785	unaware 0.09680	unclear 0.09151

Test context:
***************
dark.n	172	11	i think that the work i do is done in the __dark__ .
Contexts for target dark are: ['det_the', 'prep:inI_done']
Contexts in vocabulary for target dark are: ['det_the', 'prep:inI_done']
Top most similar embeddings: dark 0.24733	semi-darkness 0.22197	heavenlies 0.20819	gloaming 0.20593	half-light 0.19949	mid-60s 0.19577	mid-90s 0.19570	mid-70s 0.19374	mid-1800s 0.19194	mid-1920s 0.19189

Generated lemmatized results
***************
GENERATED	dark.n 172 ::: heavenlies;gloaming;wintertime;afternoone;darkness;firelight;anteroom;meantime;lent;gameswhen

Filtered results
***************
RANKED	dark.n 172	darkness 0.18800	dimness 0.17272	dusk 0.16621	shadow 0.16609	gloom 0.16062	secret 0.15911	shade 0.15825	black 0.14382	sunset 0.14318	mystery 0.14249	night 0.14148	ignorance 0.14037	nightfall 0.13672	oblivion 0.13419	sombre 0.12806	uninformed 0.12364	ignorant 0.11886	oblivious 0.10606	uncertain 0.10462	unclear 0.09813	unsure 0.09527	unaware 0.09418

Test context:
***************
dark.n	173	6	" one was so in the __dark__ as to what they wanted , " complained edwin lutyens , the greatest british architect of the day , " the site so lovely , the conditions so difficult .
Contexts for target dark are: ['det_the', 'prep:inI_was']
Contexts in vocabulary for target dark are: ['det_the', 'prep:inI_was']
Top most similar embeddings: dark 0.24985	semi-darkness 0.23754	gloaming 0.22648	mid-fifties 0.21189	heavenlies 0.20899	mid-50s 0.20847	half-light 0.20815	mid-60s 0.20672	mid-sixties 0.20660	mid-eighties 0.20616

Generated lemmatized results
***************
GENERATED	dark.n 173 ::: gloaming;heavenlies;afternoone;endzone;firelight;anteroom;woodshed;antartic;darkness;offing

Filtered results
***************
RANKED	dark.n 173	darkness 0.19488	dimness 0.19101	shadow 0.17462	gloom 0.17454	dusk 0.16884	shade 0.16658	secret 0.15139	sunset 0.14772	night 0.14656	black 0.14642	mystery 0.14302	ignorance 0.14204	oblivion 0.13984	nightfall 0.13809	sombre 0.13255	uninformed 0.12963	ignorant 0.12452	oblivious 0.11538	uncertain 0.11085	unaware 0.10270	unclear 0.09940	unsure 0.09879

Test context:
***************
dark.n	174	13	i think overtly making out in public can be kept somewhere in the __dark__ .
Contexts for target dark are: ['det_the', 'prep:inI_somewhere']
Contexts in vocabulary for target dark are: ['det_the', 'prep:inI_somewhere']
Top most similar embeddings: dark 0.25251	gloaming 0.20993	semi-darkness 0.20978	half-light 0.20224	heavenlies 0.19666	murk 0.19549	darkness 0.19472	tree-tops 0.19156	mid-west 0.19059	darkest 0.19004

Generated lemmatized results
***************
GENERATED	dark.n 174 ::: gloaming;heavenlies;murk;darkness;darkest;woodshed;brecks;negeb;duat;empyrean

Filtered results
***************
RANKED	dark.n 174	darkness 0.19472	dimness 0.18042	shadow 0.18030	gloom 0.17547	dusk 0.16522	shade 0.15941	sunset 0.15042	night 0.14670	secret 0.14422	mystery 0.14092	oblivion 0.13986	nightfall 0.13915	black 0.13837	sombre 0.13605	ignorance 0.13200	uninformed 0.12406	ignorant 0.11793	oblivious 0.11291	uncertain 0.10950	unclear 0.10099	unsure 0.09898	unaware 0.09720

Test context:
***************
dark.n	175	18	conversely , the most successful ceo 's seem to have a knack for finding their way in the __dark__ .
Contexts for target dark are: ['det_the', 'prep:inI_finding']
Contexts in vocabulary for target dark are: ['det_the', 'prep:inI_finding']
Top most similar embeddings: dark 0.24981	semi-darkness 0.22348	half-light 0.20663	heavenlies 0.20146	gloaming 0.20133	darkness 0.19416	murk 0.18961	mid-90s 0.18872	hurly-burly 0.18814	spring-time 0.18785

Generated lemmatized results
***************
GENERATED	dark.n 175 ::: heavenlies;gloaming;darkness;murk;firelight;undergrowth;brecks;midst;shallow;anteroom

Filtered results
***************
RANKED	dark.n 175	darkness 0.19416	dimness 0.17974	shadow 0.17447	dusk 0.16817	gloom 0.16753	shade 0.16400	mystery 0.14820	secret 0.14670	sunset 0.14396	oblivion 0.14086	night 0.13708	black 0.13617	nightfall 0.13304	sombre 0.13113	ignorance 0.12862	uninformed 0.12648	ignorant 0.11900	oblivious 0.11079	uncertain 0.10571	unaware 0.09711	unsure 0.09302	unclear 0.09239

Test context:
***************
dark.n	176	36	so to be " able to read the handwriting on the wall " has ever since been a metaphor for being able to see what 's coming , especially when those around you remain in the __dark__ .
Contexts for target dark are: ['det_the', 'prep:inI_remain']
Contexts in vocabulary for target dark are: ['det_the', 'prep:inI_remain']
Top most similar embeddings: dark 0.25017	semi-darkness 0.21739	heavenlies 0.20417	gloaming 0.20001	half-light 0.19509	darkness 0.19360	in-goal 0.18964	senate-house 0.18862	waiting-room 0.18816	doldrums 0.18673

Generated lemmatized results
***************
GENERATED	dark.n 176 ::: heavenlies;gloaming;darkness;doldrums;shadow;antartic;endzone;negeb;firelight;anteroom

Filtered results
***************
RANKED	dark.n 176	darkness 0.19360	shadow 0.18666	dimness 0.17421	gloom 0.16910	shade 0.16870	dusk 0.15744	ignorance 0.14681	black 0.14390	secret 0.14336	mystery 0.14299	oblivion 0.14193	sunset 0.14191	night 0.13545	sombre 0.13328	uninformed 0.13082	ignorant 0.12902	nightfall 0.12192	uncertain 0.11179	oblivious 0.10942	unsure 0.10101	unclear 0.10039	unaware 0.10011

Test context:
***************
dark.n	177	15	go out to get some chow , and they had all slipped away in the __dark__ of the night .
Contexts for target dark are: ['det_the', 'prep:inI_slipped', 'prep:of_night']
Contexts in vocabulary for target dark are: ['det_the', 'prep:inI_slipped', 'prep:of_night']
Top most similar embeddings: dark 0.12779	semi-darkness 0.11240	half-light 0.11144	darkness 0.10518	gloaming 0.10499	murk 0.09831	hurly-burly 0.09723	firelight 0.09707	gloom 0.09599	dimness 0.09598

Generated lemmatized results
***************
GENERATED	dark.n 177 ::: darkness;gloaming;murk;firelight;gloom;dimness;blackness;middle;greyness;inning

Filtered results
***************
RANKED	dark.n 177	darkness 0.10518	gloom 0.09599	dimness 0.09598	shadow 0.09127	dusk 0.08686	shade 0.08138	sunset 0.07569	night 0.07456	nightfall 0.07165	secret 0.06966	oblivion 0.06939	mystery 0.06916	ignorance 0.06274	sombre 0.06269	black 0.06218	oblivious 0.05529	uninformed 0.05359	ignorant 0.05306	unaware 0.04629	unsure 0.04549	uncertain 0.04445	unclear 0.04116

Test context:
***************
dark.n	178	30	part of it is her unique view of the world , whether walking around the room telling people they are her friends , or riding around in the car after __dark__ telling me she wants to " touch the purple night. " part of it is that she has down syndrome .
Contexts for target dark are: ['advmodI_wants']
Contexts in vocabulary for target dark are: ['advmodI_wants']
Top most similar embeddings: dark 0.42146	darker 0.34645	desparately 0.34068	desperatly 0.33544	childishly 0.33174	surreally 0.32880	archly 0.32816	moodily 0.32769	proverbially 0.32754	blackly 0.32621

Generated lemmatized results
***************
GENERATED	dark.n 178 ::: darker;desparately;desperatly;childishly;surreally;archly;moodily;proverbially;blackly;despairingly

Filtered results
***************
RANKED	dark.n 178	black 0.28859	dusk 0.28763	darkness 0.28709	nightfall 0.28109	shade 0.27685	shadow 0.27315	oblivious 0.27134	sombre 0.27075	secret 0.26845	gloom 0.26803	uninformed 0.26147	ignorant 0.25819	sunset 0.25814	dimness 0.25390	unaware 0.25272	unclear 0.25085	uncertain 0.24712	mystery 0.24539	unsure 0.24023	night 0.23639	oblivion 0.23306	ignorance 0.22578

Test context:
***************
dark.n	179	30	another remarkable subject is " reality ( play loud ) " , the artist embarks in a alucinogeno trip soul simply to demonstrate its vocal capacities , africanismo and the __dark__ to us in a threatening atmosphere .
Contexts for target dark are: ['det_the', 'conjI_capacities', 'prep:to_us']
Contexts in vocabulary for target dark are: ['det_the', 'conjI_capacities', 'prep:to_us']
Top most similar embeddings: dark 0.09360	unknowable 0.07725	physicality 0.07577	nearness 0.07428	inaccessibility 0.07421	preciousness 0.07377	closeness 0.07368	darkest 0.07355	depths 0.07351	after-life 0.07349

Generated lemmatized results
***************
GENERATED	dark.n 179 ::: unknowable;physicality;nearness;inaccessibility;preciousness;closeness;darkest;depth;unknown;affordances

Filtered results
***************
RANKED	dark.n 179	darkness 0.07128	mystery 0.06590	gloom 0.06535	shadow 0.06525	dimness 0.06518	dusk 0.06354	secret 0.06211	shade 0.06046	nightfall 0.05994	ignorance 0.05876	black 0.05707	oblivion 0.05646	uninformed 0.05497	sunset 0.05476	unclear 0.05382	uncertain 0.05298	sombre 0.05288	oblivious 0.05285	night 0.05217	ignorant 0.05173	unaware 0.04552	unsure 0.04476

Test context:
***************
dark.n	180	13	the cells were resuspended in 0.1 % saponin wash and mixed in the __dark__ for 1 h. the cells were pelleted and the supernatant was discarded .
Contexts for target dark are: ['det_the', 'prep:inI_mixed']
Contexts in vocabulary for target dark are: ['det_the', 'prep:inI_mixed']
Top most similar embeddings: dark 0.22662	semi-darkness 0.20717	half-light 0.19790	gloaming 0.19483	heavenlies 0.18803	mid-80s 0.18295	tree-tops 0.18259	plughole 0.18246	tandoor 0.18223	mid-90s 0.18190

Generated lemmatized results
***************
GENERATED	dark.n 180 ::: gloaming;heavenlies;plughole;tandoor;clag;murk;darkness;firelight;wintertime;meantime

Filtered results
***************
RANKED	dark.n 180	darkness 0.17977	dimness 0.17547	shadow 0.16835	gloom 0.16784	shade 0.16703	dusk 0.16365	night 0.14590	sunset 0.14379	mystery 0.14233	black 0.14004	oblivion 0.13962	nightfall 0.13832	secret 0.13825	ignorance 0.13525	sombre 0.13240	uninformed 0.13057	ignorant 0.12174	oblivious 0.11052	uncertain 0.11030	unsure 0.09851	unaware 0.09788	unclear 0.09701

Test context:
***************
examination.n	181	3	however , the __examination__ will be detailed if the applicant expressly requests it ( for example , at the same time as filing the demand ) , or if the applicant files amendments and/or arguments ( for example , in response to the international search report , with the demand or in response to a written opinion ; see below ) .
Contexts for target examination are: ['det_the', 'nsubjpassI_detailed']
Contexts in vocabulary for target examination are: ['det_the', 'nsubjpassI_detailed']
Top most similar embeddings: examination 0.23582	examinations 0.19776	exam 0.19442	assessment 0.17593	bmat 0.17524	exams 0.17498	investigation 0.17364	syllabus 0.17181	inspection 0.17178	re-inspection 0.17175

Generated lemmatized results
***************
GENERATED	examination.n 181 ::: exam;assessment;bmat;investigation;syllabus;inspection;stoplist;coursework;criterion;interrogation

Filtered results
***************
RANKED	examination.n 181	exam 0.19442	assessment 0.17593	investigation 0.17364	inspection 0.17178	analysis 0.16597	assesment 0.16382	scrutiny 0.15763	test 0.15545	study 0.14940	enquiry 0.14565	consultation 0.14246

Test context:
***************
examination.n	182	3	from the previous __examination__ last week the auto-immune deficiency could also be excluded .
Contexts for target examination are: ['det_the', 'amod_previous', 'prep:fromI_excluded']
Contexts in vocabulary for target examination are: ['det_the', 'amod_previous', 'prep:fromI_excluded']
Top most similar embeddings: examination 0.11401	examinations 0.10349	exam 0.09851	triennium 0.09790	exams 0.08851	scrutinies 0.08710	salaah 0.08678	escp 0.08634	inspection 0.08609	investigation 0.08584

Generated lemmatized results
***************
GENERATED	examination.n 182 ::: exam;triennium;scrutiny;salaah;escp;inspection;investigation;assessment;analysis;calculation

Filtered results
***************
RANKED	examination.n 182	exam 0.09851	scrutiny 0.08710	inspection 0.08609	investigation 0.08584	assessment 0.08567	analysis 0.08519	study 0.08242	assesment 0.07935	consultation 0.07861	test 0.07822	enquiry 0.07302

Test context:
***************
examination.n	183	5	readers will appreciate this well-researched __examination__ .
Contexts for target examination are: ['det_this', 'amod_well-researched', 'dobjI_appreciate']
Contexts in vocabulary for target examination are: ['det_this', 'amod_well-researched', 'dobjI_appreciate']
Top most similar embeddings: examination 0.11059	contextualisation 0.08645	re-examination 0.08499	disquisition 0.08387	exposition 0.08333	essay 0.08279	explication 0.08242	excursus 0.08239	exam 0.08095	dicussion 0.08035

Generated lemmatized results
***************
GENERATED	examination.n 183 ::: contextualisation;disquisition;exposition;essay;explication;excursus;exam;dicussion;memoir;reassessment

Filtered results
***************
RANKED	examination.n 183	exam 0.08095	investigation 0.07870	analysis 0.07720	assessment 0.07344	scrutiny 0.07293	study 0.07087	assesment 0.07067	enquiry 0.07066	inspection 0.06751	test 0.06324	consultation 0.06175

Test context:
***************
examination.n	184	7	as well , he will continue his __examination__ of the transatlantic connections that fuelled the slave trade .
Contexts for target examination are: ['poss_his', 'dobjI_continue', 'prep:of_connections']
Contexts in vocabulary for target examination are: ['poss_his', 'dobjI_continue', 'prep:of_connections']
Top most similar embeddings: examination 0.11555	re-examination 0.09169	interrogation 0.08940	investigation 0.08939	dissection 0.08871	exploration 0.08829	peregrinations 0.08778	reassessment 0.08665	examinations 0.08632	explorations 0.08452

Generated lemmatized results
***************
GENERATED	examination.n 184 ::: interrogation;investigation;dissection;exploration;peregrination;reassessment;tryal;recuperation;reexamination;explication

Filtered results
***************
RANKED	examination.n 184	investigation 0.08939	scrutiny 0.07838	analysis 0.07813	exam 0.07660	study 0.07574	inspection 0.07543	assessment 0.07449	assesment 0.07180	test 0.06765	enquiry 0.06622	consultation 0.06151

Test context:
***************
examination.n	185	9	the us ranks 37th in a world health organization __examination__ of the world 's health care systems .
Contexts for target examination are: ['det_a', 'nn_world', 'nn_health', 'nn_organization', 'prep:inI_ranks', 'prep:of_systems']
Contexts in vocabulary for target examination are: ['det_a', 'nn_world', 'nn_health', 'nn_organization', 'prep:inI_ranks', 'prep:of_systems']
Top most similar embeddings: examination 0.01084	organization 0.01036	encyclopaedia 0.00900	survey 0.00886	databank 0.00875	atlas 0.00872	organisation 0.00870	assessment 0.00869	comparison 0.00863	inventory 0.00860

Generated lemmatized results
***************
GENERATED	examination.n 185 ::: organization;encyclopaedia;survey;databank;atlas;organisation;assessment;comparison;inventory;investigation

Filtered results
***************
RANKED	examination.n 185	assessment 0.00869	investigation 0.00851	inspection 0.00842	assesment 0.00838	analysis 0.00836	study 0.00803	exam 0.00729	scrutiny 0.00701	test 0.00662	enquiry 0.00605	consultation 0.00597

Test context:
***************
examination.n	186	38	40 among studies that found differences in procedure use in sex-discordant pairings , these differences have been seen largely in sex-specific services such as mammography screening , 25 , 35 , 39 prostate examination , 39 and pelvic __examination__ or papanicolaou smear testing , 25 , 35 , 39 selected procedures that may have produced differences in use rates because of their sex-specific nature .
Contexts for target examination are: ['num_39', 'apposI_screening', 'cc_or', 'conj_testing', 'punct_,', 'appos_25']
Contexts in vocabulary for target examination are: ['num_39', 'apposI_screening', 'cc_or', 'conj_testing', 'punct_,', 'appos_25']
Top most similar embeddings: examination 0.01184	electrocardiography 0.01113	urinalysis 0.01078	serology 0.01049	examinations 0.01043	laparoscopy 0.01036	ultrasounds 0.01035	amniocentesis 0.01019	spirometry 0.01011	tonsillectomy 0.00997

Generated lemmatized results
***************
GENERATED	examination.n 186 ::: electrocardiography;urinalysis;serology;laparoscopy;ultrasound;amniocentesis;spirometry;tonsillectomy;echocardiography;gmat

Filtered results
***************
RANKED	examination.n 186	exam 0.00887	inspection 0.00879	test 0.00819	investigation 0.00804	assessment 0.00782	assesment 0.00726	analysis 0.00719	study 0.00674	consultation 0.00667	scrutiny 0.00647	enquiry 0.00579

Test context:
***************
examination.n	187	17	the photograph on the surface does not show a conflict or an irony , but with close __examination__ , the punctum - the element which stands out and punctures the stadium - becomes apparent .
Contexts for target examination are: ['amod_close', 'prep:withI_apparent']
Contexts in vocabulary for target examination are: ['amod_close', 'prep:withI_apparent']
Top most similar embeddings: examination 0.24393	examinations 0.18799	inspection 0.18275	exam 0.17653	scrutiny 0.17426	flybys 0.17162	observation 0.17130	re-examination 0.16955	interrogation 0.16951	lymphadenectomy 0.16251

Generated lemmatized results
***************
GENERATED	examination.n 187 ::: inspection;exam;scrutiny;flybys;observation;interrogation;lymphadenectomy;reassessment;perusal;dissection

Filtered results
***************
RANKED	examination.n 187	inspection 0.18275	exam 0.17653	scrutiny 0.17426	analysis 0.15662	investigation 0.15429	assessment 0.15240	consultation 0.15066	assesment 0.14812	study 0.14539	test 0.13688	enquiry 0.12751

Test context:
***************
examination.n	188	0	__examination__ questions , 1961-1965 examination questions , ca 1961-1965 , 30 cm ( c.1 , c.21 ) examination question papers for various courses arranged alphabetically by subject and session .
Contexts for target examination are: ['nnI_questions']
Contexts in vocabulary for target examination are: ['nnI_questions']
Top most similar embeddings: examination 0.52596	exam 0.47781	examinations 0.42661	mcq 0.40931	contact_person 0.40405	exams 0.39085	re-examination 0.38837	lsat 0.38115	assesment 0.37848	assessment 0.37681

Generated lemmatized results
***************
GENERATED	examination.n 188 ::: exam;mcq;lsat;assesment;assessment;gmat;coursework;essay;bmat;mcqs

Filtered results
***************
RANKED	examination.n 188	exam 0.47781	assesment 0.37848	assessment 0.37681	test 0.35188	scrutiny 0.34755	inspection 0.34749	investigation 0.34385	analysis 0.33213	study 0.32513	enquiry 0.32370	consultation 0.31888

Test context:
***************
examination.n	189	27	examination leave also includes the mornings of days in which examinations are held in the afternoon as well as the time spent travelling to and from the __examination__ centre .
Contexts for target examination are: ['nnI_centre']
Contexts in vocabulary for target examination are: ['nnI_centre']
Top most similar embeddings: examination 0.48524	exam 0.42294	examinations 0.40318	botnar 0.39290	peepul 0.39072	e-innovation 0.38746	sgdp 0.38255	adsetts 0.37431	biocomposites 0.37357	parkridge 0.37124

Generated lemmatized results
***************
GENERATED	examination.n 189 ::: exam;botnar;peepul;sgdp;adsetts;biocomposites;parkridge;assessment;lymefield;oxstalls

Filtered results
***************
RANKED	examination.n 189	exam 0.42294	assessment 0.37084	assesment 0.35394	inspection 0.34623	investigation 0.34178	test 0.33241	enquiry 0.32770	analysis 0.32554	scrutiny 0.32384	study 0.32058	consultation 0.29612

Test context:
***************
examination.n	190	12	i was given cardiovascular tests , including treadmill stress tests and ultrasound __examinations__ of my heart , but apparently , things werenÂt bad enough that i was singled out for consultation .
Contexts for target examinations are: ['nn_ultrasound', 'conjI_tests', 'prep:of_heart']
Contexts in vocabulary for target examinations are: ['nn_ultrasound', 'conjI_tests', 'prep:of_heart']
Top most similar embeddings: examinations 0.14442	examination 0.11807	exams 0.11532	ultrasounds 0.11172	exam 0.10444	xrays 0.10358	radiographs 0.10093	tests 0.10040	angiograms 0.09946	echocardiogram 0.09940

Generated lemmatized results
***************
GENERATED	examination.n 190 ::: exam;ultrasound;xrays;radiograph;test;angiogram;echocardiogram;auscultation;ultrasonography;scan

Filtered results
***************
RANKED	examination.n 190	exam 0.11532	test 0.10040	investigation 0.08881	assessment 0.08872	inspection 0.07956	assesment 0.07749	consultation 0.07410	scrutiny 0.07348	analysis 0.07328	study 0.06932	enquiry 0.05649

Test context:
***************
fear.v	191	1	i __feared__ only her car , and she was like a ghost , an apparition haunting the car , only a part of it , not a person .
Contexts for target feared are: ['nsubj_i', 'ccompI_<eol>', 'dobj_car', 'punct_,', 'cc_and', 'conj_was']
Contexts in vocabulary for target feared are: ['nsubj_i', 'dobj_car', 'punct_,', 'cc_and', 'conj_was']
Top most similar embeddings: feared 0.03482	catched 0.03241	tutted 0.03238	espied 0.03213	bayoneted 0.03208	wheezed 0.03206	scooted 0.03175	clanged 0.03169	dismasted 0.03153	dynamited 0.03148

Generated lemmatized results
***************
GENERATED	fear.v 191 ::: catch;tutted;espy;bayonet;wheeze;scoot;clang;dismasted;dynamite;refloat

Filtered results
***************
RANKED	fear.v 191	suspect 0.02520	dread 0.02451	expect 0.02424	anticipate 0.02388	believe 0.02356	worry 0.02301	scare 0.01711	unfortunately 0.01350

Test context:
***************
fear.v	192	5	" she asked , already __fearing__ a negative answer but impressed by the merit of his constructive reply .
Contexts for target fearing are: ['advmod_already', 'partmodI_asked', 'dobj_answer']
Contexts in vocabulary for target fearing are: ['advmod_already', 'partmodI_asked', 'dobj_answer']
Top most similar embeddings: fearing 0.12837	suspecting 0.10086	knowing 0.09608	foreseeing 0.09379	anticipating 0.09114	realising 0.08910	realizing 0.08868	noticing 0.08824	presupposing 0.08821	expecting 0.08780

Generated lemmatized results
***************
GENERATED	fear.v 192 ::: suspect;know;foresee;anticipate;realise;realize;notice;presuppose;expect;indicate

Filtered results
***************
RANKED	fear.v 192	suspect 0.10086	anticipate 0.09114	expect 0.08780	believe 0.08577	dread 0.08067	worry 0.06880	scare 0.04572	unfortunately 0.03980

Test context:
***************
fear.v	193	1	he __fears__ that she will die while he is gone .
Contexts for target fears are: ['nsubj_he', 'rootI_*root*', 'ccomp_die', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target fears are: ['nsubj_he', 'rootI_*root*', 'ccomp_die', 'punct_.']
Top most similar embeddings: fears 0.06096	gloats 0.05692	brags 0.05413	says 0.05336	reckons 0.05328	despairs 0.05301	feared 0.05271	surmises 0.05260	predicts 0.05237	warns 0.05219

Generated lemmatized results
***************
GENERATED	fear.v 193 ::: gloat;brag;say;reckon;despair;surmise;predict;warn;believe;contend

Filtered results
***************
RANKED	fear.v 193	believe 0.05211	anticipate 0.04811	expect 0.04596	worry 0.04563	dread 0.03853	suspect 0.03775	scare 0.03155	unfortunately 0.02392

Test context:
***************
fear.v	194	2	when esther __fears__ to enter the court unsummoned , a capital offense unless the king holds out the golden sceptre , mordecai says " think not with thyself that thou shalt escape in the king 's house , more than all the jews .
Contexts for target fears are: ['advmod_when', 'nsubj_esther', 'rootI_*root*', 'xcomp_enter']
Contexts in vocabulary for target fears are: ['advmod_when', 'nsubj_esther', 'rootI_*root*', 'xcomp_enter']
Top most similar embeddings: fears 0.04533	implores 0.04514	asks 0.04433	hopes 0.04371	prays 0.04293	hears 0.04265	wants 0.04255	entreated 0.04215	deigns 0.04206	refuses 0.04176

Generated lemmatized results
***************
GENERATED	fear.v 194 ::: implore;ask;hop;pray;hear;want;entreat;deign;refuse;motion

Filtered results
***************
RANKED	fear.v 194	expect 0.04031	worry 0.03619	dread 0.03475	anticipate 0.03471	believe 0.03456	suspect 0.02996	scare 0.02662	unfortunately 0.01819

Test context:
***************
fear.v	195	15	though the act was well supported , it also aroused vehement opposition from those who __feared__ it would promote the evils it was intended to remedy .
Contexts for target feared are: ['nsubj_who', 'rcmodI_those', 'ccomp_promote']
Contexts in vocabulary for target feared are: ['nsubj_who', 'rcmodI_those', 'ccomp_promote']
Top most similar embeddings: feared 0.12821	believed 0.09612	self-injure 0.09136	fearful 0.09131	oppose 0.08999	hoped 0.08998	allege 0.08959	foresaw 0.08958	profess 0.08893	fear 0.08864

Generated lemmatized results
***************
GENERATED	fear.v 195 ::: believe;fearful;oppose;hop;allege;foresee;profess;wish;perpetrate;disbelieve

Filtered results
***************
RANKED	fear.v 195	believe 0.09612	suspect 0.08399	anticipate 0.08172	dread 0.07997	worry 0.07813	expect 0.07109	scare 0.04927	unfortunately 0.03974

Test context:
***************
fear.v	196	33	6th february , 2004 - view article ... extra home threat to green belt the new targets published last week could force st albans into sacrificing more green belt land than was first __feared__ .
Contexts for target feared are: ['mark_than', 'auxpass_was', 'advmod_first', 'depI_albans']
Contexts in vocabulary for target feared are: ['mark_than', 'auxpass_was', 'advmod_first', 'depI_albans']
Top most similar embeddings: feared 0.06198	anticipated 0.04446	imagined 0.04429	suspected 0.04168	envisioned 0.04059	batted 0.04037	predicted 0.04010	mooted 0.03993	believed 0.03981	envisaged 0.03874

Generated lemmatized results
***************
GENERATED	fear.v 196 ::: anticipate;imagine;suspect;envision;bat;predict;moot;believe;envisage;hop

Filtered results
***************
RANKED	fear.v 196	anticipate 0.04446	suspect 0.04168	believe 0.03981	expect 0.03794	dread 0.03703	worry 0.03321	scare 0.02188	unfortunately 0.01737

Test context:
***************
fear.v	197	23	muslim-americans need to do this bit by bit , word by word , to show our fellow citizens that america has nothing to __fear__ from islam .
Contexts for target fear are: ['aux_to', 'infmodI_nothing', 'prep:from_islam']
Contexts in vocabulary for target fear are: ['aux_to', 'infmodI_nothing', 'prep:from_islam']
Top most similar embeddings: fear 0.12793	distrust 0.09283	worry 0.08999	wrest 0.08775	disassociate 0.08738	dissociate 0.08618	dislike 0.08566	derogate 0.08528	feare 0.08528	deter 0.08483

Generated lemmatized results
***************
GENERATED	fear.v 197 ::: distrust;worry;wrest;disassociate;dissociate;dislike;derogate;feare;deter;dissuade

Filtered results
***************
RANKED	fear.v 197	worry 0.08999	scare 0.07339	dread 0.07284	suspect 0.06769	anticipate 0.06394	believe 0.06301	expect 0.06184	unfortunately 0.03632

Test context:
***************
fear.v	198	9	many of those who founded the wargame publishing business __feared__ that , with the anti-militarism caused by the vietnam , and ( later ) with the adoption of the all-volunteer army , american society would become estranged from all things military , leaving ordinary citizens too ignorant to make meaningful democratic judgments where war is concerned .
Contexts for target feared are: ['nsubj_many', 'rootI_*root*', 'ccomp_estranged', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target feared are: ['nsubj_many', 'rootI_*root*', 'punct_.']
Top most similar embeddings: feared 0.13945	speculated 0.10616	believed 0.10464	sniggered 0.10391	hoped 0.10266	felt 0.10055	lamented 0.09936	chorused 0.09924	honeymooned 0.09887	said 0.09877

Generated lemmatized results
***************
GENERATED	fear.v 198 ::: speculate;believe;snigger;hop;felt;lament;chorus;honeymoon;say;sympathise

Filtered results
***************
RANKED	fear.v 198	believe 0.10464	anticipate 0.09861	suspect 0.08940	expect 0.08933	worry 0.08869	dread 0.08301	scare 0.05765	unfortunately 0.05483

Test context:
***************
fear.v	199	9	genetic engineering and human cloning are not to be __feared__ but cherished , as they will liberate humanity from nature .
Contexts for target feared are: ['nsubjpass_engineering', 'auxpass_are', 'neg_not', 'aux_to', 'auxpass_be', 'rootI_*root*', 'cc_but', 'conj_cherished', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target feared are: ['nsubjpass_engineering', 'auxpass_are', 'neg_not', 'aux_to', 'auxpass_be', 'rootI_*root*', 'cc_but', 'conj_cherished', 'punct_.']
Top most similar embeddings: feared 0.00175	regarded 0.00148	applauded 0.00147	reckoned 0.00146	recognized 0.00144	understood 0.00143	discouraged 0.00140	appreciated 0.00139	recognised 0.00138	distrusted 0.00137

Generated lemmatized results
***************
GENERATED	fear.v 199 ::: regard;applaud;reckon;recognize;understand;discourage;appreciate;recognise;distrust;use

Filtered results
***************
RANKED	fear.v 199	believe 0.00128	expect 0.00127	worry 0.00124	anticipate 0.00111	suspect 0.00105	dread 0.00096	scare 0.00053	unfortunately 0.00023

Test context:
***************
fear.v	200	3	nothing , i __fear__ , i haven’t said already .
Contexts for target fear are: ['nn_i', 'conjI_nothing']
Contexts in vocabulary for target fear are: ['nn_i', 'conjI_nothing']
Top most similar embeddings: fear 0.23446	dread 0.19462	feare 0.18831	dispair 0.17929	mistrust 0.17912	self-pity 0.17895	hatred 0.17837	sorrow 0.17639	ioy 0.17610	hate 0.17498

Generated lemmatized results
***************
GENERATED	fear.v 200 ::: dread;feare;dispair;mistrust;hatred;sorrow;ioy;hate;distrust;dout

Filtered results
***************
RANKED	fear.v 200	dread 0.19462	worry 0.16144	suspect 0.14566	scare 0.13125	believe 0.12278	anticipate 0.11178	expect 0.10868	unfortunately 0.10480

Test context:
***************
forget.v	201	2	do n't __forget__ about the revolutionary exercise program and the lifestyle modification program. ) you will also learn , on the topic of diet : how to eliminate those crazy , irresistible cravings forever .
Contexts for target forget are: ['aux_do', "neg_n't", 'depI_learn', 'prep:about_program', 'punct_.', 'punct_-rrb-']
Contexts in vocabulary for target forget are: ['aux_do', "neg_n't", 'depI_learn', 'prep:about_program', 'punct_.']
Top most similar embeddings: forget 0.03442	worry 0.02351	remember 0.02229	know 0.02167	hesitate 0.02147	procrastinate 0.02137	rememeber 0.02118	learn 0.02104	fret 0.02097	overdo 0.02088

Generated lemmatized results
***************
GENERATED	forget.v 201 ::: worry;remember;know;hesitate;procrastinate;rememeber;learn;fret;overdo;remeber

Filtered results
***************
RANKED	forget.v 201	remember 0.02229	ignore 0.01805	overlook 0.01797	neglect 0.01606	lose 0.01557	omit 0.01551	fail 0.01536	disregard 0.01398

Test context:
***************
forget.v	202	8	but mr. schickeleÂs own music has not been __forgotten__ ; his eagerly-awaited concerto for viola and orchestra will receive its world premiere with the pasadena symphony and danielle farina , viola .
Contexts for target forgotten are: ['cc_but', 'nsubj_music', 'aux_has', 'neg_not', 'auxpass_been', 'rootI_*root*', 'punct_;', 'parataxis_receive']
Contexts in vocabulary for target forgotten are: ['cc_but', 'nsubj_music', 'aux_has', 'neg_not', 'auxpass_been', 'rootI_*root*', 'punct_;', 'parataxis_receive']
Top most similar embeddings: forgotten 0.00308	quieted 0.00261	abated 0.00257	stilled 0.00256	neglected 0.00254	diminished 0.00252	forsaken 0.00249	cheapened 0.00246	changed 0.00245	foreordained 0.00244

Generated lemmatized results
***************
GENERATED	forget.v 202 ::: quiet;abate;still;neglect;diminish;forsake;cheapen;change;foreordain;overdo

Filtered results
***************
RANKED	forget.v 202	neglect 0.00254	overlook 0.00241	ignore 0.00225	disregard 0.00217	lose 0.00214	omit 0.00211	remember 0.00198	fail 0.00176

Test context:
***************
forget.v	203	2	do n't __forget__ to do the quick inventory and again tape it to the outside of the box .
Contexts for target forget are: ['aux_do', "neg_n't", 'rootI_*root*', 'xcomp_do', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target forget are: ['aux_do', "neg_n't", 'rootI_*root*', 'xcomp_do', 'punct_.']
Top most similar embeddings: forget 0.04062	remember 0.02947	want 0.02802	rememeber 0.02799	hesitate 0.02715	skimp 0.02698	wnat 0.02545	overcook 0.02539	intend 0.02532	procrastinate 0.02520

Generated lemmatized results
***************
GENERATED	forget.v 203 ::: remember;want;rememeber;hesitate;skimp;wnat;overcook;intend;procrastinate;think

Filtered results
***************
RANKED	forget.v 203	remember 0.02947	overlook 0.02226	ignore 0.02170	fail 0.02161	omit 0.02116	neglect 0.01943	lose 0.01871	disregard 0.01470

Test context:
***************
forget.v	204	28	finally being super christian , i was reminded of the 2nd greatest commandment of all " you shall love your neighbour as yourself ' " its easy to __forget__ when you losing .
Contexts for target forget are: ['aux_to', 'ccompI_easy', 'advcl_losing']
Contexts in vocabulary for target forget are: ['aux_to', 'ccompI_easy', 'advcl_losing']
Top most similar embeddings: forget 0.11796	understand 0.09841	ignore 0.09450	remember 0.09279	relearn 0.09125	overcook 0.09113	overlook 0.09047	learn 0.09002	misjudge 0.08874	comprehend 0.08777

Generated lemmatized results
***************
GENERATED	forget.v 204 ::: understand;ignore;remember;relearn;overcook;overlook;learn;misjudge;comprehend;misplace

Filtered results
***************
RANKED	forget.v 204	ignore 0.09450	remember 0.09279	overlook 0.09047	lose 0.08604	omit 0.07861	neglect 0.07167	disregard 0.06914	fail 0.06830

Test context:
***************
forget.v	205	28	sometimes you might be out of the office but want to know how your database is doing , sometimes you might be in vacation , sometimes you simply __forgot__ to run the script ( weÂre humans ) ... how can you be notified with these details ?
Contexts for target forgot are: ['advmod_sometimes', 'nsubj_you', 'advmod_simply', 'conjI_be', 'xcomp_run']
Contexts in vocabulary for target forgot are: ['advmod_sometimes', 'nsubj_you', 'advmod_simply', 'conjI_be', 'xcomp_run']
Top most similar embeddings: forgot 0.02803	forget 0.02292	condescend 0.02279	forgotten 0.02166	forgets 0.02161	want 0.02049	forgetting 0.02010	wnat 0.02001	wish 0.01993	misspell 0.01935

Generated lemmatized results
***************
GENERATED	forget.v 205 ::: condescend;want;wnat;wish;misspell;unable;fail;afford;prefer;omit

Filtered results
***************
RANKED	forget.v 205	fail 0.01894	omit 0.01875	neglect 0.01793	remember 0.01714	ignore 0.01695	lose 0.01553	overlook 0.01520	disregard 0.01440

Test context:
***************
forget.v	206	3	one must not __forget__ that the reason why the conflict has become difficult to handle over the years is because it has grown in complexity and become something of a family war .
Contexts for target forget are: ['nsubj_one', 'aux_must', 'neg_not', 'rootI_*root*', 'ccomp_is', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target forget are: ['nsubj_one', 'aux_must', 'neg_not', 'rootI_*root*', 'ccomp_is', 'punct_.']
Top most similar embeddings: forget 0.01873	assume 0.01468	remember 0.01430	realize 0.01342	presume 0.01303	overemphasise 0.01299	underestimate 0.01290	deny 0.01267	conclude 0.01251	over-emphasise 0.01246

Generated lemmatized results
***************
GENERATED	forget.v 206 ::: assume;remember;realize;presume;overemphasise;underestimate;deny;conclude;overlook;doubt

Filtered results
***************
RANKED	forget.v 206	remember 0.01430	overlook 0.01241	ignore 0.01161	omit 0.01047	fail 0.00977	disregard 0.00879	lose 0.00859	neglect 0.00836

Test context:
***************
forget.v	207	30	since the last issue of britannia we have at last seen a bit of barrack life and all rumours about the issue of the ' sennelager star ' are being __forgotten__ .
Contexts for target forgotten are: ['nsubjpass_bit', 'aux_are', 'auxpass_being', 'ccompI_seen']
Contexts in vocabulary for target forgotten are: ['nsubjpass_bit', 'aux_are', 'auxpass_being', 'ccompI_seen']
Top most similar embeddings: forgotten 0.05548	overlooked 0.04768	ignored 0.04756	neglected 0.04603	sidelined 0.04581	eroded 0.04527	clobbered 0.04488	swamped 0.04424	fleeced 0.04396	forgotton 0.04346

Generated lemmatized results
***************
GENERATED	forget.v 207 ::: overlook;ignore;neglect;sideline;erode;clobber;swamp;fleece;forgotton;misunderstand

Filtered results
***************
RANKED	forget.v 207	overlook 0.04768	ignore 0.04756	neglect 0.04603	lose 0.04014	disregard 0.03811	omit 0.03716	remember 0.03533	fail 0.02818

Test context:
***************
forget.v	208	11	someone from the event forwarded me this quote which i had __forgotten__ .
Contexts for target forgotten are: ['dobj_which', 'nsubj_i', 'aux_had', 'rcmodI_quote']
Contexts in vocabulary for target forgotten are: ['dobj_which', 'nsubj_i', 'aux_had', 'rcmodI_quote']
Top most similar embeddings: forgotten 0.08278	forgotton 0.07146	receved 0.06803	forgot 0.06615	heared 0.06306	forseen 0.06302	divined 0.06222	noticed 0.06143	twigged 0.06137	misheard 0.06136

Generated lemmatized results
***************
GENERATED	forget.v 208 ::: forgotton;receved;hear;forseen;divine;notice;twig;misheard;vsed;fathom

Filtered results
***************
RANKED	forget.v 208	neglect 0.05971	overlook 0.05839	ignore 0.05710	remember 0.05633	lose 0.05593	fail 0.05406	omit 0.05153	disregard 0.05132

Test context:
***************
forget.v	209	8	then to top it all off the docs __forgot__ to enter the med rates so the oncall doc needed to be called which takes a long time .
Contexts for target forgot are: ['nsubj_docs', 'ccompI_top', 'xcomp_enter']
Contexts in vocabulary for target forgot are: ['nsubj_docs', 'ccompI_top', 'xcomp_enter']
Top most similar embeddings: forgot 0.11053	forgotten 0.08200	forget 0.08096	forgets 0.07721	forgotton 0.07627	want/need 0.07625	presume 0.07308	forgetting 0.07266	supose 0.07140	wish 0.07139

Generated lemmatized results
***************
GENERATED	forget.v 209 ::: forgotton;presume;supose;wish;manage;remember;loath;manged;want;remeber

Filtered results
***************
RANKED	forget.v 209	remember 0.07012	omit 0.06369	fail 0.06333	neglect 0.06295	ignore 0.06233	lose 0.06011	overlook 0.05759	disregard 0.05358

Test context:
***************
forget.v	210	2	does he __forget__ that it was his ministry that issued the final set of licences some three months prior to the collapse of principal trust ?
Contexts for target forget are: ['aux_does', 'nsubj_he', 'rootI_*root*', 'ccomp_ministry', 'punct_?', 'dep_<eol>']
Contexts in vocabulary for target forget are: ['aux_does', 'nsubj_he', 'rootI_*root*', 'punct_?']
Top most similar embeddings: forget 0.06029	remember 0.05195	rememeber 0.04890	forgets 0.04667	know 0.04614	mean 0.04562	agree/disagree 0.04530	gainsay 0.04530	bother 0.04518	begrudge 0.04509

Generated lemmatized results
***************
GENERATED	forget.v 210 ::: remember;rememeber;know;mean;gainsay;bother;begrudge;flinch;want;procrastinate

Filtered results
***************
RANKED	forget.v 210	remember 0.05195	ignore 0.04285	omit 0.04141	overlook 0.04099	lose 0.03865	fail 0.03847	neglect 0.03556	disregard 0.03264

Test context:
***************
gall.n	211	43	galls indeed arise from the stinging of the plant tissues by the ovipositors of female gall wasps , and the egg laid in the plant tissues develops inside the gall into a grub , which eventually emerges full-grown and transformed into a mature __gall__ wasp .
Contexts for target gall are: ['nnI_wasp']
Contexts in vocabulary for target gall are: ['nnI_wasp']
Top most similar embeddings: gall 0.53743	carnea 0.36263	euphorbia 0.35567	lacewing 0.35415	vitis 0.35292	echium 0.35283	grandiflora 0.35110	sawfly 0.34995	spinifex 0.34969	fusarium 0.34914

Generated lemmatized results
***************
GENERATED	gall.n 211 ::: carnea;euphorbia;lacewing;vitis;echium;grandiflora;sawfly;spinifex;fusarium;javan

Filtered results
***************
RANKED	gall.n 211	cheek 0.30155	blister 0.29760	bile 0.29119	effrontery 0.29117	poison 0.28409	nerve 0.28384	grub 0.28295	audacity 0.28070	pustule 0.27631	temerity 0.27286	impudence 0.27026	pn 0.24769

Test context:
***************
gall.n	212	3	these include laparoscopic __gall__ bladder surgery and reflux disease surgery , non-cardiac thoracoscopic chest surgery , and certain cardiotomy procedures such as mitral valve repair .
Contexts for target gall are: ['nnI_surgery']
Contexts in vocabulary for target gall are: ['nnI_surgery']
Top most similar embeddings: gall 0.50613	mohs 0.38469	open-heart 0.37132	toenail 0.36228	gallbladder 0.36222	kidney 0.36009	oropharyngeal 0.35829	bladder 0.35799	trichiasis 0.35793	blackhead 0.35562

Generated lemmatized results
***************
GENERATED	gall.n 212 ::: mohs;toenail;gallbladder;kidney;oropharyngeal;bladder;trichiasis;blackhead;gallstone;tonsil

Filtered results
***************
RANKED	gall.n 212	nerve 0.32216	cheek 0.31958	blister 0.31906	bile 0.31478	temerity 0.29373	effrontery 0.28683	pustule 0.28165	impudence 0.27651	audacity 0.27494	pn 0.26956	poison 0.26615	grub 0.26191

Test context:
***************
gall.n	213	9	" ( adams , pp.196-9 ) what arrogance and __gall__ it took to write those words and demand that they be spoken by native tongues .
Contexts for target gall are: ['conjI_adams']
Contexts in vocabulary for target gall are: ['conjI_adams']
Top most similar embeddings: gall 0.50982	brackenridge 0.36897	fallick 0.35788	dubinsky 0.35740	bruck 0.35538	deaville 0.35458	cottrill 0.35406	sankar 0.35404	hoekstra 0.35278	brasier 0.35256

Generated lemmatized results
***************
GENERATED	gall.n 213 ::: brackenridge;fallick;dubinsky;bruck;deaville;cottrill;sankar;hoekstra;brasier;popovic

Filtered results
***************
RANKED	gall.n 213	cheek 0.30461	bile 0.30116	audacity 0.29709	temerity 0.29163	effrontery 0.28425	blister 0.28243	impudence 0.27997	grub 0.27302	nerve 0.26740	poison 0.26684	pustule 0.26507	pn 0.25626

Test context:
***************
gall.n	214	5	in the case of my __gall__ bladder removal , i was out the next day .
Contexts for target gall are: ['nnI_removal']
Contexts in vocabulary for target gall are: ['nnI_removal']
Top most similar embeddings: gall 0.52551	blackhead 0.37931	earwax 0.37573	gallbladder 0.37296	gallstone 0.37172	rust 0.36417	floc 0.36246	chondrocyte 0.36147	toenail 0.36087	gonad 0.35745

Generated lemmatized results
***************
GENERATED	gall.n 214 ::: blackhead;earwax;gallbladder;gallstone;rust;floc;chondrocyte;toenail;gonad;tonsil

Filtered results
***************
RANKED	gall.n 214	bile 0.34011	cheek 0.32563	blister 0.31884	nerve 0.31736	pustule 0.29926	impudence 0.29102	effrontery 0.29084	temerity 0.28566	audacity 0.28230	poison 0.27756	grub 0.27236	pn 0.27181

Test context:
***************
gall.n	215	1	even __galls__ that formed on their trunks were eaten .
Contexts for target galls are: ['advmod_even', 'rootI_*root*', 'rcmod_eaten', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target galls are: ['advmod_even', 'rootI_*root*', 'rcmod_eaten', 'punct_.']
Top most similar embeddings: galls 0.05326	leaves 0.04303	arcite 0.04237	dioecious 0.04162	stems 0.04095	sheesh 0.04081	harpoole 0.04049	fruitbodies 0.04003	omnivores 0.03992	capensis 0.03991

Generated lemmatized results
***************
GENERATED	gall.n 215 ::: leaf;arcite;dioecious;stem;sheesh;harpoole;fruitbodies;omnivore;capensis;palamon

Filtered results
***************
RANKED	gall.n 215	grub 0.03499	poison 0.03287	blister 0.03116	pustule 0.02919	impudence 0.02668	bile 0.02436	nerve 0.02422	cheek 0.02283	pn 0.02129	effrontery 0.02065	audacity 0.02062	temerity 0.01680

Test context:
***************
gall.n	216	12	come to my woman 's breasts , and take my milk for __gall__ , you murdering ministers , wherever in your sightless substances you wait on nature 's mischief !
Contexts for target gall are: ['prep:forI_take']
Contexts in vocabulary for target gall are: ['prep:forI_take']
Top most similar embeddings: gall 0.46577	indigestion 0.32809	afters 0.32561	gallbladder 0.32487	rashness 0.32198	ringworm 0.32144	heatstroke 0.32016	mange 0.31965	blether 0.31933	feare 0.31908

Generated lemmatized results
***************
GENERATED	gall.n 216 ::: indigestion;afters;gallbladder;rashness;ringworm;heatstroke;mange;blether;feare;toenail

Filtered results
***************
RANKED	gall.n 216	impudence 0.31513	temerity 0.31248	bile 0.30912	blister 0.30532	audacity 0.29686	effrontery 0.29558	cheek 0.29294	grub 0.28458	nerve 0.28322	pustule 0.28237	poison 0.27101	pn 0.25734

Test context:
***************
gall.n	217	5	and the morans have the __gall__ to ruin beethovens 6th in the process , too .
Contexts for target gall are: ['det_the', 'dobjI_have', 'infmod_ruin']
Contexts in vocabulary for target gall are: ['det_the', 'dobjI_have', 'infmod_ruin']
Top most similar embeddings: gall 0.12198	temerity 0.10936	gumption 0.10569	effrontery 0.09643	audacity 0.08989	tendancy 0.08896	impudence 0.08637	tendency 0.08637	oppurtunity 0.08624	wherewithal 0.08570

Generated lemmatized results
***************
GENERATED	gall.n 217 ::: temerity;gumption;effrontery;audacity;tendancy;impudence;tendency;oppurtunity;wherewithal;misfortune

Filtered results
***************
RANKED	gall.n 217	temerity 0.10936	effrontery 0.09643	audacity 0.08989	impudence 0.08637	cheek 0.08103	nerve 0.07703	bile 0.07043	blister 0.06928	grub 0.06452	poison 0.06333	pustule 0.06179	pn 0.05118

Test context:
***************
gall.n	218	14	etym : from the gaelic name dubhghall , from dubh " black " + __gall__ " stranger " .
Contexts for target gall are: ['nnI_stranger']
Contexts in vocabulary for target gall are: ['nnI_stranger']
Top most similar embeddings: gall 0.46249	vincenzo 0.32968	grete 0.32890	kinna 0.32682	blacke 0.32650	blackhead 0.32592	sterne 0.32586	shalimar 0.32486	redcap 0.32444	spinifex 0.32399

Generated lemmatized results
***************
GENERATED	gall.n 218 ::: vincenzo;grete;kinna;blacke;blackhead;sterne;shalimar;redcap;spinifex;barkin

Filtered results
***************
RANKED	gall.n 218	cheek 0.31497	bile 0.29752	audacity 0.29706	effrontery 0.29620	blister 0.28978	nerve 0.28291	temerity 0.28286	impudence 0.27981	poison 0.27251	grub 0.25475	pn 0.25384	pustule 0.25296

Test context:
***************
gall.n	219	0	__galls__ indeed arise from the stinging of the plant tissues by the ovipositors of female gall wasps , and the egg laid in the plant tissues develops inside the gall into a grub , which eventually emerges full-grown and transformed into a mature gall wasp .
Contexts for target galls are: ['nsubjI_arise']
Contexts in vocabulary for target galls are: ['nsubjI_arise']
Top most similar embeddings: galls 0.50208	fruitbodies 0.37393	sporangia 0.37200	cankers 0.36259	sclerotia 0.36185	hetus 0.36178	cysts 0.36156	rupas 0.36021	pustules 0.35810	bccs 0.35607

Generated lemmatized results
***************
GENERATED	gall.n 219 ::: fruitbodies;sporangium;canker;sclerotium;hetus;cyst;rupas;pustule;bccs;coccoliths

Filtered results
***************
RANKED	gall.n 219	pustule 0.35810	blister 0.32284	grub 0.29706	poison 0.28957	nerve 0.28304	bile 0.27000	cheek 0.26988	effrontery 0.26476	temerity 0.26241	impudence 0.24476	audacity 0.24140	pn 0.23155

Test context:
***************
gall.n	220	14	in boston magazine 's glowing blurb on via matta , it had the extraordinary __gall__ to say this : " via matta has unquestionably found its niche with boston 's it crowd .
Contexts for target gall are: ['det_the', 'amod_extraordinary', 'dobjI_had', 'infmod_say']
Contexts in vocabulary for target gall are: ['det_the', 'amod_extraordinary', 'dobjI_had', 'infmod_say']
Top most similar embeddings: gall 0.06590	effrontery 0.05907	temerity 0.05681	gumption 0.05583	impudence 0.05280	audacity 0.05115	courage 0.04975	chutzpah 0.04826	priviledge 0.04797	oppertunity 0.04683

Generated lemmatized results
***************
GENERATED	gall.n 220 ::: effrontery;temerity;gumption;impudence;audacity;courage;chutzpah;priviledge;oppertunity;prescience

Filtered results
***************
RANKED	gall.n 220	effrontery 0.05907	temerity 0.05681	impudence 0.05280	audacity 0.05115	nerve 0.04181	cheek 0.04033	blister 0.03390	bile 0.03250	grub 0.02781	poison 0.02646	pustule 0.02597	pn 0.02537

Test context:
***************
grim.a	221	12	" what is the world to do in the face of these __grim__ predictions ?
Contexts for target grim are: ['amodI_predictions']
Contexts in vocabulary for target grim are: ['amodI_predictions']
Top most similar embeddings: grim 0.52050	gloomy 0.43317	bleak 0.41583	doom-laden 0.40933	dismal 0.39624	gloomier 0.39506	doleful 0.39079	horrific 0.38995	dire 0.38979	horrifying 0.38476

Generated lemmatized results
***************
GENERATED	grim.a 221 ::: gloomy;bleak;dismal;doleful;horrific;dire;horrifying;nightmarish;stark;ghastly

Filtered results
***************
RANKED	grim.a 221	gloomy 0.43317	bleak 0.41583	dismal 0.39624	horrific 0.38995	dire 0.38979	ghastly 0.37736	gruesome 0.37671	awful 0.36634	horrible 0.36095	terrible 0.36053	unpromising 0.36001	appalling 0.35762	harrowing 0.35572	doomy 0.35333	severe 0.34981	harsh 0.34976	sinister 0.34906	depressing 0.34753	unpleasant 0.34711	horrid 0.34206	dark 0.33945	stern 0.33760	morbid 0.33563	unrelenting 0.32333	serious 0.31464	negative 0.31099	difficult 0.29250	forbidding 0.27458

Test context:
***************
grim.a	222	11	" he too can only watch in deepening despair as the __grim__ work proceeds. " looks more like resignation to me , but audiovision is not interested in letting us make up our own minds. " finally , the military police carry the crates away for disposal. " no , they just take them away .
Contexts for target grim are: ['amodI_proceeds']
Contexts in vocabulary for target grim are: ['amodI_proceeds']
Top most similar embeddings: grim 0.43314	ineluctable 0.35923	ghastly 0.35537	kafkaesque 0.35499	grisly 0.35339	bleak 0.35158	doom-laden 0.35045	macabre 0.35027	much-touted 0.34983	gruesome 0.34969

Generated lemmatized results
***************
GENERATED	grim.a 222 ::: ineluctable;ghastly;kafkaesque;grisly;bleak;macabre;gruesome;remorseless;dismal;gloomy

Filtered results
***************
RANKED	grim.a 222	ghastly 0.35537	bleak 0.35158	gruesome 0.34969	dismal 0.34911	gloomy 0.34857	horrific 0.34066	harrowing 0.33852	doomy 0.33761	sinister 0.33575	dire 0.33299	severe 0.33269	horrible 0.32807	unpromising 0.32706	dark 0.32666	depressing 0.32558	horrid 0.32484	terrible 0.32415	morbid 0.32041	stern 0.31845	appalling 0.31748	unpleasant 0.31679	harsh 0.31562	awful 0.31186	negative 0.30828	unrelenting 0.30491	serious 0.30409	forbidding 0.29341	difficult 0.27313

Test context:
***************
grim.a	223	18	id rather go face down , fast , in a plate of chili at 76 than suffer the __grim__ attenuations of mental decay and wander off this mortal plane at 78 .
Contexts for target grim are: ['amodI_attenuations']
Contexts in vocabulary for target grim are: []
Top most similar embeddings: grim 1.00000	bleak 0.80907	gloomy 0.78416	doleful 0.76275	ghastly 0.75826	horrific 0.75807	dreary 0.75331	cheerless 0.75294	kafkaesque 0.75216	gruesome 0.75200

Generated lemmatized results
***************
GENERATED	grim.a 223 ::: bleak;gloomy;doleful;ghastly;horrific;dreary;cheerless;kafkaesque;gruesome;grisly

Filtered results
***************
RANKED	grim.a 223	bleak 0.80907	gloomy 0.78416	ghastly 0.75826	horrific 0.75807	gruesome 0.75200	dismal 0.75126	doomy 0.74142	horrible 0.73984	awful 0.73770	terrible 0.73047	depressing 0.72729	harrowing 0.72401	unpleasant 0.71727	horrid 0.71604	dire 0.71550	appalling 0.71389	harsh 0.71062	unpromising 0.70344	sinister 0.70214	severe 0.70002	dark 0.68768	stern 0.68252	morbid 0.68115	unrelenting 0.67638	difficult 0.64534	serious 0.64306	negative 0.62059	forbidding 0.62046

Test context:
***************
grim.a	224	17	vincent van gogh in 1880 was a 27-year-old failure : a despised and rejected clergyman in a __grim__ backwater mining town in belgium .
Contexts for target grim are: ['amodI_town']
Contexts in vocabulary for target grim are: ['amodI_town']
Top most similar embeddings: grim 0.52426	godforsaken 0.42055	bleak 0.41287	picture-postcard 0.40847	one-horse 0.40338	dreary 0.40178	picture-perfect 0.40005	god-forsaken 0.39865	gloomy 0.39843	fine-looking 0.39662

Generated lemmatized results
***************
GENERATED	grim.a 224 ::: godforsaken;bleak;dreary;gloomy;grimy;beggarly;kitschy;cheerless;unprepossessing;doleful

Filtered results
***************
RANKED	grim.a 224	bleak 0.41287	gloomy 0.39843	dismal 0.38557	ghastly 0.37325	gruesome 0.36891	horrible 0.36299	depressing 0.36129	awful 0.36046	unpromising 0.36021	horrific 0.35586	horrid 0.35390	doomy 0.35142	terrible 0.34741	unpleasant 0.34664	sinister 0.34545	harsh 0.33152	dark 0.32987	morbid 0.32782	dire 0.32761	appalling 0.32735	harrowing 0.32448	stern 0.31569	severe 0.31376	unrelenting 0.30485	forbidding 0.30201	serious 0.29215	difficult 0.28279	negative 0.27679

Test context:
***************
grim.a	225	5	hoarding and saving react with __grim__ vengeance .
Contexts for target grim are: ['amodI_vengeance']
Contexts in vocabulary for target grim are: ['amodI_vengeance']
Top most similar embeddings: grim 0.52551	grisly 0.41501	pitiless 0.41100	ghastly 0.40768	hellish 0.40693	doleful 0.40598	sanguinary 0.40406	frightful 0.40357	terrible 0.40082	blood-curdling 0.39863

Generated lemmatized results
***************
GENERATED	grim.a 225 ::: grisly;pitiless;ghastly;hellish;doleful;sanguinary;frightful;terrible;horrific;dreadful

Filtered results
***************
RANKED	grim.a 225	ghastly 0.40768	terrible 0.40082	horrific 0.39843	gruesome 0.39538	bleak 0.39247	horrible 0.38913	horrid 0.38549	gloomy 0.38323	awful 0.38194	harrowing 0.38061	harsh 0.37115	sinister 0.36757	severe 0.36751	dire 0.36645	doomy 0.36148	appalling 0.36053	unrelenting 0.36024	dismal 0.35716	unpleasant 0.35235	dark 0.34933	morbid 0.34230	depressing 0.33973	stern 0.33145	unpromising 0.32792	serious 0.31218	negative 0.28985	forbidding 0.28433	difficult 0.27488

Test context:
***************
grim.a	226	3	" once that __grim__ reality had sunk in , kubrick 's response was an extraordinary tribute to sellers as an actor : " we ca n't replace him with another actor , we 've got to get an authentic character from life , someone whose acting career is secondary-a real-life cowboy .
Contexts for target grim are: ['amodI_reality']
Contexts in vocabulary for target grim are: ['amodI_reality']
Top most similar embeddings: grim 0.55907	bleak 0.43119	hellish 0.41748	gruesome 0.41563	nightmarish 0.40990	horrific 0.40719	kafkaesque 0.40492	dreary 0.40384	ghastly 0.40355	dystopian 0.40306

Generated lemmatized results
***************
GENERATED	grim.a 226 ::: bleak;hellish;gruesome;nightmarish;horrific;kafkaesque;dreary;ghastly;dystopian;stark

Filtered results
***************
RANKED	grim.a 226	bleak 0.43119	gruesome 0.41563	horrific 0.40719	ghastly 0.40355	gloomy 0.40227	dismal 0.39677	horrible 0.39268	harsh 0.38881	depressing 0.38765	terrible 0.38600	awful 0.38462	doomy 0.38059	horrid 0.37989	harrowing 0.37565	unpleasant 0.37482	appalling 0.37428	dire 0.36708	unpromising 0.35945	sinister 0.35823	severe 0.35816	stern 0.34262	dark 0.34157	unrelenting 0.33882	morbid 0.33602	difficult 0.30880	negative 0.30489	serious 0.30461	forbidding 0.29614

Test context:
***************
grim.a	227	5	their trip had been a __grim__ struggle with wet pitches , friable rock and bad bolts : they had reached the 1979 limit , but failed to go further .
Contexts for target grim are: ['amodI_struggle']
Contexts in vocabulary for target grim are: ['amodI_struggle']
Top most similar embeddings: grim 0.51752	life-and-death 0.41612	centuries-long 0.41496	life-or-death 0.41436	sanguinary 0.41005	bleak 0.40643	hellish 0.39374	ill-starred 0.39328	horrific 0.39287	long-ago 0.39033

Generated lemmatized results
***************
GENERATED	grim.a 227 ::: sanguinary;bleak;hellish;horrific;doleful;gloomy;ghastly;gruesome;remorseless;tragical

Filtered results
***************
RANKED	grim.a 227	bleak 0.40643	horrific 0.39287	gloomy 0.38736	ghastly 0.38687	gruesome 0.38637	terrible 0.38312	harrowing 0.38040	dismal 0.37709	awful 0.37580	unrelenting 0.37298	horrible 0.37154	severe 0.36800	dire 0.36576	horrid 0.35818	appalling 0.35771	stern 0.35545	doomy 0.35519	unpleasant 0.35148	harsh 0.35133	depressing 0.34851	sinister 0.34499	unpromising 0.34085	morbid 0.33474	dark 0.32680	serious 0.32184	difficult 0.31834	negative 0.29863	forbidding 0.28224

Test context:
***************
grim.a	228	7	i 'm concerned that they 're so __grim__ and angry .
Contexts for target grim are: ['mark_that', 'nsubj_they', "cop_'re", 'advmod_so', 'ccompI_concerned', 'cc_and', 'conj_angry']
Contexts in vocabulary for target grim are: ['mark_that', 'nsubj_they', "cop_'re", 'advmod_so', 'ccompI_concerned', 'cc_and', 'conj_angry']
Top most similar embeddings: unlovable 0.00682	snobby 0.00654	improvident 0.00619	angry 0.00612	oversensitive 0.00611	unloving 0.00605	clingy 0.00600	bloody-minded 0.00597	weak-willed 0.00595	remorseful 0.00595

Generated lemmatized results
***************
GENERATED	grim.a 228 ::: unlovable;snobby;improvident;angry;oversensitive;unloving;clingy;remorseful;underfed;ungrateful

Filtered results
***************
RANKED	grim.a 228	gloomy 0.00554	bleak 0.00542	harsh 0.00518	horrible 0.00482	awful 0.00480	depressing 0.00463	horrid 0.00459	unpleasant 0.00448	dire 0.00444	serious 0.00442	terrible 0.00437	morbid 0.00427	horrific 0.00424	appalling 0.00415	sinister 0.00409	dismal 0.00409	gruesome 0.00406	ghastly 0.00399	dark 0.00387	unrelenting 0.00386	severe 0.00377	harrowing 0.00377	difficult 0.00365	negative 0.00358	unpromising 0.00349	doomy 0.00327	forbidding 0.00273	stern 0.00264

Test context:
***************
grim.a	229	7	" that 's lawrence kaplan ' s __grim__ verdict from baghdad .
Contexts for target grim are: ['amodI_verdict']
Contexts in vocabulary for target grim are: ['amodI_verdict']
Top most similar embeddings: grim 0.51239	bleak 0.40972	gloomy 0.40517	horrific 0.38971	kafkaesque 0.38586	gruesome 0.38168	doleful 0.37891	tragic 0.37680	grisly 0.37627	disasterous 0.37461

Generated lemmatized results
***************
GENERATED	grim.a 229 ::: bleak;gloomy;horrific;kafkaesque;gruesome;doleful;tragic;grisly;disasterous;dismal

Filtered results
***************
RANKED	grim.a 229	bleak 0.40972	gloomy 0.40517	horrific 0.38971	gruesome 0.38168	dismal 0.37331	harsh 0.37179	ghastly 0.36891	severe 0.36471	harrowing 0.35864	terrible 0.35581	horrible 0.35343	appalling 0.35298	doomy 0.35268	sinister 0.34977	depressing 0.34905	stern 0.34713	unpleasant 0.34567	unpromising 0.34540	awful 0.34528	horrid 0.34461	dire 0.34036	morbid 0.33061	unrelenting 0.32600	dark 0.32245	negative 0.31466	serious 0.30505	forbidding 0.29685	difficult 0.29395

Test context:
***************
grim.a	230	5	it started out looking pretty __grim__ but we had pretty good rainfall in april and may .
Contexts for target grim are: ['advmod_pretty', 'acompI_looking']
Contexts in vocabulary for target grim are: ['advmod_pretty', 'acompI_looking']
Top most similar embeddings: grim 0.29635	bleak 0.23878	gloomy 0.22453	cheerless 0.21419	wintery 0.21391	uninviting 0.21286	sheepish 0.21278	dismal 0.21183	unappetising 0.21182	tarty 0.21107

Generated lemmatized results
***************
GENERATED	grim.a 230 ::: bleak;gloomy;cheerless;wintery;uninviting;sheepish;dismal;unappetising;tarty;unprepossessing

Filtered results
***************
RANKED	grim.a 230	bleak 0.23878	gloomy 0.22453	dismal 0.21183	awful 0.21072	ghastly 0.20972	gruesome 0.20560	doomy 0.20394	dire 0.20217	unpromising 0.19914	horrible 0.19904	horrid 0.19756	terrible 0.19423	horrific 0.19221	depressing 0.18900	unpleasant 0.18461	sinister 0.18320	appalling 0.18285	harsh 0.18146	harrowing 0.17554	dark 0.17325	serious 0.17148	morbid 0.16892	stern 0.16146	unrelenting 0.15855	difficult 0.15455	severe 0.15354	negative 0.15201	forbidding 0.13661

Test context:
***************
lie.v	231	8	" Â " 50 dollars " , i __lie__ .
Contexts for target lie are: ['nn_i', 'apposI_dollars']
Contexts in vocabulary for target lie are: ['nn_i', 'apposI_dollars']
Top most similar embeddings: lie 0.18572	fib 0.15149	dollars 0.15050	innit 0.14954	livres 0.14709	lire 0.14559	ducats 0.14550	hing 0.14512	ov 0.14490	laff 0.14433

Generated lemmatized results
***************
GENERATED	lie.v 231 ::: fib;dollars;innit;livres;lire;ducats;hing;ov;laff;gyd

Filtered results
***************
RANKED	lie.v 231	fib 0.15149	wait 0.12820	hide 0.12781	lay 0.12754	falsehoods 0.12589	untruths 0.12356	rest 0.11954	be 0.11924	sit 0.11755	situate 0.11503	resting 0.11258	place 0.11157	recline 0.11104	position 0.11076	deceive 0.10895	stay 0.10502	falsify 0.10281	leave 0.10223	get 0.10216	extend 0.09518	remain 0.09438	arrange 0.09410	put 0.09164

Test context:
***************
lie.v	232	46	but in spite of this truth , just as you in the position of aspirants and disciples know much about the hierarchy , its life , aims and conditioning rules , so do i , a master of the fifth degree , know much concerning what __lies__ ahead of me ; i can therefore endeavor to make some small part of these essential truths clearer to those who can profit by them .
Contexts for target lies are: ['nsubj_what', 'pcompI_concerning', 'advmod_ahead']
Contexts in vocabulary for target lies are: ['nsubj_what', 'pcompI_concerning', 'advmod_ahead']
Top most similar embeddings: lies 0.13387	lie 0.10423	lay 0.09718	lurks 0.09049	transpiring 0.08265	lying 0.08074	resides 0.08057	lays 0.08056	going 0.08003	constitutes 0.07916

Generated lemmatized results
***************
GENERATED	lie.v 232 ::: lay;lurk;transpire;reside;go;constitute;happen;unfold;rankle;emerge

Filtered results
***************
RANKED	lie.v 232	lay 0.09718	rest 0.07358	sit 0.07317	remain 0.07224	put 0.07094	stay 0.07016	get 0.06726	wait 0.06655	place 0.06493	extend 0.06444	untruths 0.06364	position 0.06355	situate 0.06330	hide 0.06320	fib 0.06088	deceive 0.05976	leave 0.05936	falsify 0.05877	recline 0.05848	resting 0.05835	be 0.05823	falsehoods 0.05515	arrange 0.05364

Test context:
***************
lie.v	233	1	i __lie__ down on my futon -bed with a tiny bean-filled pillow under my neck .
Contexts for target lie are: ['nsubj_i', 'rootI_*root*', 'prt_down', 'prep:on_futon', 'punct_-', 'dep_bed', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target lie are: ['nsubj_i', 'rootI_*root*', 'prt_down', 'punct_-', 'dep_bed', 'punct_.']
Top most similar embeddings: lie 0.01936	lies 0.01634	tchiowa 0.01576	jal1628 0.01558	b'fast 0.01538	rebolted 0.01522	hmph 0.01520	harpoole 0.01515	phil_uk 0.01512	vg/f 0.01478

Generated lemmatized results
***************
GENERATED	lie.v 233 ::: tchiowa;rebolted;hmph;harpoole;chim;crouch;arcite;zzzz;mreasy;lay

Filtered results
***************
RANKED	lie.v 233	lay 0.01439	sit 0.01385	recline 0.01375	situate 0.01181	rest 0.01166	stay 0.01118	extend 0.01115	hide 0.01075	position 0.01059	put 0.01045	wait 0.01039	get 0.01006	arrange 0.00981	fib 0.00964	leave 0.00961	resting 0.00945	place 0.00909	remain 0.00887	be 0.00875	deceive 0.00864	falsify 0.00824	untruths 0.00769	falsehoods 0.00633

Test context:
***************
lie.v	234	15	for example , suppose that on the return trip from deneb to earth the astronauts __lay__ down tube ii rather than traveling back in tube i , the first tube they produced .
Contexts for target lay are: ['mark_that', 'prep:on_trip', 'nsubj_astronauts', 'ccompI_suppose', 'prt_down', 'dobj_tube']
Contexts in vocabulary for target lay are: ['mark_that', 'prep:on_trip', 'nsubj_astronauts', 'ccompI_suppose', 'prt_down', 'dobj_tube']
Top most similar embeddings: lay 0.01265	lain 0.00949	lugged 0.00913	lie 0.00911	laying 0.00904	plopped 0.00901	trod 0.00896	lying 0.00888	laid 0.00887	ventured 0.00886

Generated lemmatized results
***************
GENERATED	lie.v 234 ::: lug;lay;plop;tread;venture;trudge;descend;drift;raft;wear

Filtered results
***************
RANKED	lie.v 234	lay 0.01265	rest 0.00839	hide 0.00760	resting 0.00756	put 0.00754	sit 0.00744	recline 0.00725	get 0.00712	leave 0.00701	wait 0.00674	place 0.00666	stay 0.00655	extend 0.00621	position 0.00601	deceive 0.00598	situate 0.00586	remain 0.00582	arrange 0.00532	be 0.00504	falsify 0.00476	fib 0.00436	untruths 0.00282	falsehoods 0.00256

Test context:
***************
lie.v	235	1	what __lies__ beneath the amphoras and the muck -- perhaps the ship 's wooden hull , tools , personal items and coins , which would help pinpoint the date of the sinking -- can only be learned by excavation .
Contexts for target lies are: ['nsubj_what', 'nsubjpassI_learned', 'prep:beneath_amphoras']
Contexts in vocabulary for target lies are: ['nsubj_what', 'nsubjpassI_learned']
Top most similar embeddings: lies 0.22447	lie 0.17537	lurks 0.17095	untruth 0.16377	constitutes 0.15933	lay 0.15859	falsehoods 0.15847	lessons 0.15798	newes 0.15510	fallacies 0.15420

Generated lemmatized results
***************
GENERATED	lie.v 235 ::: lurk;untruth;constitute;lay;falsehoods;lessons;newes;fallacies;untruths;motivate

Filtered results
***************
RANKED	lie.v 235	lay 0.15859	falsehoods 0.15847	untruths 0.15385	rest 0.13955	fib 0.13729	remain 0.13469	sit 0.13385	deceive 0.13113	hide 0.12775	wait 0.12608	extend 0.12476	stay 0.12468	leave 0.11851	position 0.11708	put 0.11678	falsify 0.11597	be 0.11594	situate 0.11511	place 0.11395	get 0.11385	recline 0.11179	resting 0.10688	arrange 0.09607

Test context:
***************
lie.v	236	5	" " you ca n't __lie__ in front of the bulldozer indefinitely " " i 'm game ... " " zaphod , you look good .
Contexts for target lie are: ["punct_''", "punct_''", 'nsubj_you', 'aux_ca', "neg_n't", 'depI_game', 'prep:in_front', 'advmod_indefinitely', "punct_''", "punct_''"]
Contexts in vocabulary for target lie are: ['nsubj_you', 'aux_ca', "neg_n't", 'depI_game', 'prep:in_front', 'advmod_indefinitely']
Top most similar embeddings: lie 0.01277	sit 0.01067	wait 0.01026	cower 0.01005	stand 0.01002	mope 0.00961	procrastinate 0.00957	dawdle 0.00942	masturbate 0.00940	recline 0.00939

Generated lemmatized results
***************
GENERATED	lie.v 236 ::: sit;wait;cower;stand;mope;procrastinate;dawdle;masturbate;recline;linger

Filtered results
***************
RANKED	lie.v 236	sit 0.01067	wait 0.01026	recline 0.00939	hide 0.00882	stay 0.00869	lay 0.00857	get 0.00790	put 0.00755	rest 0.00741	leave 0.00734	deceive 0.00712	fib 0.00707	resting 0.00696	extend 0.00665	remain 0.00653	falsify 0.00616	situate 0.00607	position 0.00524	place 0.00515	arrange 0.00497	be 0.00450	untruths 0.00444	falsehoods 0.00398

Test context:
***************
lie.v	237	25	he went on farther , and in the great hall he saw the whole of the court lying asleep , and up by the throne __lay__ the king and queen .
Contexts for target lay are: ['advmod_up', 'conjI_went', 'dobj_king']
Contexts in vocabulary for target lay are: ['advmod_up', 'conjI_went', 'dobj_king']
Top most similar embeddings: lay 0.11427	laying 0.08701	pranced 0.08556	espied 0.08549	stood 0.08452	layd 0.08448	waked 0.08425	digged 0.08351	girded 0.08306	knelt 0.08282

Generated lemmatized results
***************
GENERATED	lie.v 237 ::: lay;prance;espy;stand;layd;wake;digged;gird;kneel;lounge

Filtered results
***************
RANKED	lie.v 237	lay 0.11427	rest 0.07858	hide 0.07781	sit 0.07605	put 0.07123	stay 0.07117	get 0.07116	recline 0.06914	wait 0.06803	leave 0.06640	remain 0.06615	resting 0.06326	deceive 0.06235	place 0.06225	be 0.05909	situate 0.05800	extend 0.05663	position 0.05572	arrange 0.05268	falsify 0.05241	untruths 0.04791	fib 0.04715	falsehoods 0.04500

Test context:
***************
lie.v	238	3	grabbed the blaster __lying__ on the seat next to her and fired up at him .
Contexts for target lying are: ['depI_grabbed', 'prep:on_seat', 'advmod_next']
Contexts in vocabulary for target lying are: ['depI_grabbed', 'prep:on_seat', 'advmod_next']
Top most similar embeddings: lying 0.13019	sitting 0.10594	cross-legged 0.09814	kneeling 0.09792	snoozing 0.09578	lolling 0.09565	propped 0.09422	snuggled 0.09377	sprawled 0.09332	resting 0.09239

Generated lemmatized results
***************
GENERATED	lie.v 238 ::: sit;kneel;snooze;loll;prop;snuggle;sprawl;rest;perch;crouch

Filtered results
***************
RANKED	lie.v 238	sit 0.10594	rest 0.09239	resting 0.09239	recline 0.08877	lay 0.08207	place 0.07614	put 0.07528	position 0.07403	hide 0.07393	leave 0.06846	wait 0.06676	situate 0.06544	get 0.06529	stay 0.06428	remain 0.06150	deceive 0.05886	be 0.05644	arrange 0.05417	falsify 0.05340	fib 0.05255	extend 0.05254	untruths 0.04938	falsehoods 0.04804

Test context:
***************
lie.v	239	6	whether itÃ¢ÂÂs lying through omission , __lying__ through misdirection , or outright lies , itÃ¢ÂÂs awfully hard to extract nuggets of truth from the noise .
Contexts for target lying are: ['partmodI_s', 'prep:through_omission']
Contexts in vocabulary for target lying are: ['partmodI_s']
Top most similar embeddings: lying 0.48069	lolling 0.37161	cavorting 0.35969	reposing 0.35763	resting 0.35431	sitting 0.35346	dotting 0.35285	dallying 0.35159	writhing 0.35071	snuggling 0.35005

Generated lemmatized results
***************
GENERATED	lie.v 239 ::: loll;cavort;repose;rest;sit;dot;dally;writhe;snuggle;snooze

Filtered results
***************
RANKED	lie.v 239	rest 0.35431	resting 0.35431	sit 0.35346	wait 0.34389	lay 0.33483	recline 0.32862	hide 0.32317	get 0.32059	remain 0.31550	leave 0.31053	extend 0.30871	stay 0.30590	deceive 0.30473	situate 0.30395	put 0.30128	place 0.29836	fib 0.29320	falsify 0.29239	position 0.28955	arrange 0.27888	untruths 0.27253	be 0.27196	falsehoods 0.24259

Test context:
***************
lie.v	240	22	you 're naked , lying in your bed surrounded by sex toys , with an empty bottle of lube and a videotape __lying__ next to you .
Contexts for target lying are: ['partmodI_videotape', 'advmod_next']
Contexts in vocabulary for target lying are: ['partmodI_videotape', 'advmod_next']
Top most similar embeddings: lying 0.24753	sitting 0.19024	kneeling 0.16745	hovering 0.16682	showing 0.16680	seated 0.16432	crouching 0.16362	appearing 0.16287	languishing 0.16283	leaning 0.16275

Generated lemmatized results
***************
GENERATED	lie.v 240 ::: sit;kneel;hover;show;seat;crouch;appear;languish;lean;sleep

Filtered results
***************
RANKED	lie.v 240	sit 0.19024	recline 0.15992	rest 0.15936	resting 0.15936	lay 0.15887	position 0.15258	hide 0.15174	place 0.14747	situate 0.14494	wait 0.14442	put 0.13889	leave 0.13865	get 0.13461	extend 0.13434	stay 0.13345	remain 0.13201	arrange 0.13004	falsify 0.12916	deceive 0.12573	be 0.11420	fib 0.10624	untruths 0.10571	falsehoods 0.10310

Test context:
***************
nasty.a	241	30	it is human nature to fight unfairly ; therefore , we need to think in advance and rehearse in advance how to fight fairly , so we wo n't get __nasty__ when we get angry .
Contexts for target nasty are: ['acompI_get']
Contexts in vocabulary for target nasty are: ['acompI_get']
Top most similar embeddings: nasty 0.52949	horrible 0.40222	stroppy 0.39764	snotty 0.39671	uppity 0.39566	big-headed 0.39450	scummy 0.39421	nastier 0.39339	shirty 0.39075	sozzled 0.39036

Generated lemmatized results
***************
GENERATED	nasty.a 241 ::: horrible;stroppy;snotty;uppity;scummy;shirty;sozzled;repetative;snobby;tetchy

Filtered results
***************
RANKED	nasty.a 241	horrible 0.40222	unpleasant 0.38763	vicious 0.38445	spiteful 0.37971	annoying 0.36439	bad 0.36369	dirty 0.35772	painful 0.35242	vindictive 0.34781	bitter 0.34267	dangerous 0.34219	disagreeable 0.34124	mean 0.33766	malicious 0.32736	foul 0.31910	inhospitable 0.31902	formidable 0.31120	unpalatable 0.30673	objectionable 0.30611	offensive 0.30423

Test context:
***************
nasty.a	242	11	he did n't say anything and kept smiling an insincere and __nasty__ smile .
Contexts for target nasty are: ['conjI_insincere']
Contexts in vocabulary for target nasty are: []
Top most similar embeddings: nasty 1.00000	horrible 0.80408	unpleasant 0.78156	horrid 0.76509	spiteful 0.76507	viscious 0.76440	yucky 0.76419	vicious 0.76262	well-aimed 0.76074	cretinous 0.75767

Generated lemmatized results
***************
GENERATED	nasty.a 242 ::: horrible;unpleasant;horrid;spiteful;viscious;yucky;vicious;cretinous;snobby;ugly

Filtered results
***************
RANKED	nasty.a 242	horrible 0.80408	unpleasant 0.78156	spiteful 0.76507	vicious 0.76262	annoying 0.72611	bad 0.71761	vindictive 0.71604	disagreeable 0.71437	foul 0.71409	dangerous 0.70297	painful 0.69884	dirty 0.68997	bitter 0.68263	mean 0.67540	malicious 0.67296	inhospitable 0.65806	objectionable 0.65753	formidable 0.65395	offensive 0.64910	unpalatable 0.64643

Test context:
***************
nasty.a	243	9	the mountain : " conditions are about to get __nasty__ .
Contexts for target nasty are: ['aux_to', 'dep_get', 'xcompI_about']
Contexts in vocabulary for target nasty are: ['aux_to', 'dep_get', 'xcompI_about']
Top most similar embeddings: nasty 0.10653	gatecrash 0.09431	rid 0.09333	overexcited 0.09232	squished 0.09009	shafted 0.08900	decapitate 0.08848	worse 0.08780	nuked 0.08734	sidetracked 0.08722

Generated lemmatized results
***************
GENERATED	nasty.a 243 ::: gatecrash;rid;overexcited;squished;shafted;decapitate;bad;nuked;sidetracked;disabuse

Filtered results
***************
RANKED	nasty.a 243	bad 0.08780	spiteful 0.08014	horrible 0.07426	dirty 0.07365	annoying 0.07104	vicious 0.07062	unpleasant 0.07009	dangerous 0.07007	mean 0.07005	foul 0.06907	vindictive 0.06905	malicious 0.06740	offensive 0.06668	disagreeable 0.06528	painful 0.06487	bitter 0.06297	objectionable 0.06045	unpalatable 0.06037	inhospitable 0.06025	formidable 0.05159

Test context:
***************
nasty.a	244	4	and will probably stay __nasty__ during the next administration , no matter who wins .
Contexts for target nasty are: ['cc_and', 'aux_will', 'advmod_probably', 'cop_stay', 'rootI_*root*', 'prep:during_administration', 'punct_,', 'npadvmod_matter', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target nasty are: ['cc_and', 'aux_will', 'advmod_probably', 'cop_stay', 'rootI_*root*', 'prep:during_administration', 'punct_,', 'npadvmod_matter', 'punct_.']
Top most similar embeddings: unchanged 0.00109	counterproductive 0.00107	unplayable 0.00103	unsettled 0.00101	unrecognisable 0.00101	counter-productive 0.00101	abhorrent 0.00101	remembered 0.00100	true 0.00100	unpleasant 0.00100

Generated lemmatized results
***************
GENERATED	nasty.a 244 ::: unchanged;counterproductive;unplayable;unsettled;unrecognisable;abhorrent;remembered;true;unpleasant;sober

Filtered results
***************
RANKED	nasty.a 244	unpleasant 0.00100	painful 0.00096	bad 0.00096	bitter 0.00089	dangerous 0.00088	annoying 0.00087	dirty 0.00087	horrible 0.00086	spiteful 0.00083	disagreeable 0.00083	unpalatable 0.00079	objectionable 0.00077	mean 0.00075	vicious 0.00074	vindictive 0.00074	inhospitable 0.00073	offensive 0.00073	foul 0.00068	formidable 0.00061	malicious 0.00058

Test context:
***************
nasty.a	245	27	the nasty party after all october 10 , leader : iain duncan smith delivered a speech to the 2003 tory party conference in blackpool yesterday that was __nasty__ , brutish and long .
Contexts for target nasty are: ['nsubj_that', 'cop_was', 'depI_delivered', 'punct_,', 'conj_brutish', 'cc_and', 'conj_long']
Contexts in vocabulary for target nasty are: ['nsubj_that', 'cop_was', 'depI_delivered', 'punct_,', 'conj_brutish', 'cc_and', 'conj_long']
Top most similar embeddings: nasty 0.00631	ornery 0.00555	brutish 0.00554	vile 0.00553	filthy 0.00532	unfunny 0.00531	humourless 0.00529	spiteful 0.00527	ugly 0.00523	insolent 0.00521

Generated lemmatized results
***************
GENERATED	nasty.a 245 ::: ornery;brutish;vile;filthy;unfunny;humourless;spiteful;ugly;insolent;graceless

Filtered results
***************
RANKED	nasty.a 245	spiteful 0.00527	vicious 0.00502	horrible 0.00502	disagreeable 0.00480	unpleasant 0.00465	bitter 0.00459	vindictive 0.00457	dirty 0.00423	painful 0.00418	annoying 0.00418	bad 0.00408	dangerous 0.00396	foul 0.00392	mean 0.00390	unpalatable 0.00374	malicious 0.00357	offensive 0.00353	formidable 0.00343	objectionable 0.00322	inhospitable 0.00311

Test context:
***************
nasty.a	246	9	" ( on playing verdasco ) " he 's __nasty__ .
Contexts for target nasty are: ["punct_''", 'punct_-lrb-', 'punct_-rrb-', "punct_''", 'nsubj_he', "cop_'s", 'rootI_*root*', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target nasty are: ['nsubj_he', "cop_'s", 'rootI_*root*', 'punct_.']
Top most similar embeddings: nasty 0.05403	hillarious 0.05119	horrible 0.04981	ho-hum 0.04951	mindblowing 0.04903	un-pc 0.04841	unforgiveable 0.04803	funny 0.04724	scary 0.04715	toughie 0.04701

Generated lemmatized results
***************
GENERATED	nasty.a 246 ::: hillarious;horrible;mindblowing;unforgiveable;funny;scary;toughie;livid;indeede;cagey

Filtered results
***************
RANKED	nasty.a 246	horrible 0.04981	annoying 0.04504	bad 0.04174	unpleasant 0.04162	spiteful 0.04105	dangerous 0.04014	vindictive 0.03881	vicious 0.03816	painful 0.03812	dirty 0.03787	disagreeable 0.03761	bitter 0.03735	mean 0.03439	objectionable 0.03401	unpalatable 0.03275	foul 0.03263	offensive 0.03242	formidable 0.03184	malicious 0.02990	inhospitable 0.02876

Test context:
***************
nasty.a	247	26	lewis gilbert’s 1966 misogynistic rake’s progress always depended on the cheek , charm and chutzpah of the kohl-eyed caine’s iconic cockney cocksman to take away the __nasty__ taste in one’s mouth .
Contexts for target nasty are: ['amodI_taste']
Contexts in vocabulary for target nasty are: ['amodI_taste']
Top most similar embeddings: nasty 0.53413	unpleasant 0.42664	horrible 0.42146	yucky 0.40828	yeasty 0.40295	bitter-sweet 0.39954	horrid 0.39938	plummy 0.39616	flavorful 0.39559	chocolatey 0.39544

Generated lemmatized results
***************
GENERATED	nasty.a 247 ::: unpleasant;horrible;yucky;yeasty;horrid;plummy;flavorful;chocolatey;putrid;peppery

Filtered results
***************
RANKED	nasty.a 247	unpleasant 0.42664	horrible 0.42146	bad 0.38536	disagreeable 0.37501	spiteful 0.37454	foul 0.37046	bitter 0.36223	vicious 0.35953	annoying 0.34552	dirty 0.34014	vindictive 0.33872	mean 0.33500	painful 0.33385	dangerous 0.33195	unpalatable 0.33011	objectionable 0.31956	offensive 0.31691	formidable 0.31441	malicious 0.31079	inhospitable 0.30105

Test context:
***************
nasty.a	248	6	i would like a big , __nasty__ , mean , ugly automatic rifle or grenade launcher that i could fire at any car whose alarm blares repeatedly .
Contexts for target nasty are: ['amod_big', 'punct_,', 'amodI_mean']
Contexts in vocabulary for target nasty are: ['amod_big', 'punct_,', 'amodI_mean']
Top most similar embeddings: nasty 0.11363	spiteful 0.08701	ugly 0.08649	trashy 0.08510	mouthy 0.08387	sleazy 0.08385	artsy 0.08367	pervy 0.08357	imponderable 0.08350	slimy 0.08350

Generated lemmatized results
***************
GENERATED	nasty.a 248 ::: spiteful;ugly;trashy;mouthy;sleazy;artsy;pervy;imponderable;slimy;noisey

Filtered results
***************
RANKED	nasty.a 248	spiteful 0.08701	vicious 0.08259	horrible 0.08244	vindictive 0.07844	unpleasant 0.07771	bad 0.07666	mean 0.07598	dirty 0.07493	bitter 0.07380	offensive 0.07365	disagreeable 0.07090	annoying 0.07073	foul 0.06893	dangerous 0.06843	unpalatable 0.06775	malicious 0.06769	objectionable 0.06516	inhospitable 0.06515	painful 0.06482	formidable 0.06166

Test context:
***************
nasty.a	249	23	a few years ago , when most monitors used 256 colours , it was important to use the web safe palette to avoid __nasty__ dithering .
Contexts for target nasty are: ['amodI_dithering']
Contexts in vocabulary for target nasty are: []
Top most similar embeddings: nasty 1.00000	horrible 0.80408	unpleasant 0.78156	horrid 0.76509	spiteful 0.76507	viscious 0.76440	yucky 0.76419	vicious 0.76262	well-aimed 0.76074	cretinous 0.75767

Generated lemmatized results
***************
GENERATED	nasty.a 249 ::: horrible;unpleasant;horrid;spiteful;viscious;yucky;vicious;cretinous;snobby;ugly

Filtered results
***************
RANKED	nasty.a 249	horrible 0.80408	unpleasant 0.78156	spiteful 0.76507	vicious 0.76262	annoying 0.72611	bad 0.71761	vindictive 0.71604	disagreeable 0.71437	foul 0.71409	dangerous 0.70297	painful 0.69884	dirty 0.68997	bitter 0.68263	mean 0.67540	malicious 0.67296	inhospitable 0.65806	objectionable 0.65753	formidable 0.65395	offensive 0.64910	unpalatable 0.64643

Test context:
***************
nasty.a	250	8	these programs , called malware , can do __nasty__ things like spy on you when you use your pc and allow hackers to access your hard drive .
Contexts for target nasty are: ['amodI_things']
Contexts in vocabulary for target nasty are: ['amodI_things']
Top most similar embeddings: nasty 0.53974	horrible 0.44122	yucky 0.42002	unpleasant 0.41762	horrid 0.41537	niggly 0.41259	whizzy 0.41202	god-awful 0.41135	teensy 0.40956	kitschy 0.40338

Generated lemmatized results
***************
GENERATED	nasty.a 250 ::: horrible;yucky;unpleasant;horrid;niggly;whizzy;teensy;kitschy;cretinous;icky

Filtered results
***************
RANKED	nasty.a 250	horrible 0.44122	unpleasant 0.41762	disagreeable 0.38827	spiteful 0.38527	annoying 0.38345	vicious 0.38195	foul 0.37959	bad 0.37952	dirty 0.36027	mean 0.35923	dangerous 0.35629	painful 0.35388	vindictive 0.35238	malicious 0.34447	bitter 0.34415	objectionable 0.33648	unpalatable 0.32517	offensive 0.31985	inhospitable 0.31966	formidable 0.31962

Test context:
***************
nearly.r	251	12	" i 'm glad we made lots of money , though it __nearly__ cost the two of you your sanity .
Contexts for target nearly are: ['advmodI_cost']
Contexts in vocabulary for target nearly are: ['advmodI_cost']
Top most similar embeddings: nearly 0.51837	almost 0.42604	typically 0.37369	roughly 0.37304	virtually 0.36935	approximately 0.36908	probably 0.36670	just 0.36560	extrememly 0.36529	usually 0.36518

Generated lemmatized results
***************
GENERATED	nearly.r 251 ::: almost;typically;roughly;virtually;approximately;probably;just;extrememly;usually;proably

Filtered results
***************
RANKED	nearly.r 251	almost 0.42604	approximately 0.36908	practically 0.35900	quite 0.34709	anyway 0.31928	remotely 0.30169	half 0.27665

Test context:
***************
nearly.r	252	7	in the 1997 elections , constitutional nationalism __nearly__ lost out to republicanism .
Contexts for target nearly are: ['advmodI_lost']
Contexts in vocabulary for target nearly are: ['advmodI_lost']
Top most similar embeddings: nearly 0.53075	almost 0.43581	long-since 0.39526	humiliatingly 0.38973	bloodily 0.38810	proably 0.38802	inexcusably 0.38663	singlehandedly 0.38571	irretrievably 0.38566	unaccountably 0.38462

Generated lemmatized results
***************
GENERATED	nearly.r 252 ::: almost;humiliatingly;bloodily;proably;inexcusably;singlehandedly;irretrievably;unaccountably;unluckily;aparently

Filtered results
***************
RANKED	nearly.r 252	almost 0.43581	practically 0.36328	quite 0.35671	approximately 0.34570	anyway 0.32757	remotely 0.29107	half 0.27587

Test context:
***************
nearly.r	253	31	fire lookout museum 123 w. westview spokane , wa 99218 ( 509)466-9171 email : rkresek@webtv.net introduction during the summer of 2000 , the inland northwest united states experienced a wildfire season __nearly__ unprecedented in america .
Contexts for target nearly are: ['advmodI_unprecedented']
Contexts in vocabulary for target nearly are: ['advmodI_unprecedented']
Top most similar embeddings: nearly 0.50992	almost 0.45606	quite 0.38690	virtually 0.38641	practically 0.37197	truly 0.36579	seemingly 0.36511	probably 0.36178	apparently 0.35964	absolutely 0.35921

Generated lemmatized results
***************
GENERATED	nearly.r 253 ::: almost;quite;virtually;practically;truly;seemingly;probably;apparently;absolutely;completely

Filtered results
***************
RANKED	nearly.r 253	almost 0.45606	quite 0.38690	practically 0.37197	approximately 0.33799	anyway 0.30938	remotely 0.29343	half 0.25892

Test context:
***************
nearly.r	254	39	houston , texas ( cnn ) -- human remains found in a field in texas late saturday are believed to be those of at least one of the seven astronauts who perished aboard space shuttle columbia when it disintegrated __nearly__ 40 miles above the earth .
Contexts for target nearly are: ['quantmodI_40']
Contexts in vocabulary for target nearly are: ['quantmodI_40']
Top most similar embeddings: nearly 0.54597	almost 0.44504	approximately 0.39557	roughly 0.37661	just 0.36879	over 0.35515	than 0.35485	only 0.34966	virtually 0.34684	aproximately 0.34519

Generated lemmatized results
***************
GENERATED	nearly.r 254 ::: almost;approximately;roughly;just;over;than;only;virtually;aproximately;typically

Filtered results
***************
RANKED	nearly.r 254	almost 0.44504	approximately 0.39557	practically 0.34119	quite 0.31297	remotely 0.27838	anyway 0.27562	half 0.26429

Test context:
***************
nearly.r	255	15	geographically , the west bank , then under jordanian rule and occupation , cut israel __nearly__ in half .
Contexts for target nearly are: ['advmodI_in']
Contexts in vocabulary for target nearly are: ['advmodI_in']
Top most similar embeddings: nearly 0.51436	almost 0.42888	even 0.39222	just 0.38795	particularly 0.37761	roughly 0.37398	usually 0.37286	especially 0.37250	mainly 0.37067	still 0.37065

Generated lemmatized results
***************
GENERATED	nearly.r 255 ::: almost;even;just;particularly;roughly;usually;especially;mainly;still;already

Filtered results
***************
RANKED	nearly.r 255	almost 0.42888	practically 0.36845	approximately 0.36529	quite 0.35237	anyway 0.32328	remotely 0.29308	half 0.26549

Test context:
***************
nearly.r	256	3	i had n't __nearly__ finished the work at hand .
Contexts for target nearly are: ['advmodI_finished']
Contexts in vocabulary for target nearly are: ['advmodI_finished']
Top most similar embeddings: nearly 0.53294	almost 0.43579	just 0.38897	cooly 0.37775	long-since 0.37518	duely 0.37340	proably 0.37050	virtually 0.36714	practically 0.36712	respectably 0.36643

Generated lemmatized results
***************
GENERATED	nearly.r 256 ::: almost;just;cooly;duely;proably;virtually;practically;respectably;aparently;dexterously

Filtered results
***************
RANKED	nearly.r 256	almost 0.43579	practically 0.36712	quite 0.36170	approximately 0.35087	anyway 0.32384	remotely 0.29579	half 0.28634

Test context:
***************
nearly.r	257	13	comprised of thousands of small , independent units , the printing industry employs __nearly__ 1 million in some 60,000-100,000 plants and accounts for somewhere in the neighborhood of 100 billion dollars in business every single year , while at the same time , contributing to toxic air emissions and solid and chemical waste problems on an ever-growing scale .
Contexts for target nearly are: ['quantmodI_million']
Contexts in vocabulary for target nearly are: ['quantmodI_million']
Top most similar embeddings: nearly 0.54472	almost 0.44434	approximately 0.39408	roughly 0.37877	aproximately 0.37666	over 0.35919	just 0.35764	than 0.35487	around 0.34417	perhaps 0.34172

Generated lemmatized results
***************
GENERATED	nearly.r 257 ::: almost;approximately;roughly;aproximately;over;just;than;around;perhaps;typically

Filtered results
***************
RANKED	nearly.r 257	almost 0.44434	approximately 0.39408	practically 0.32943	half 0.32305	quite 0.32279	remotely 0.28839	anyway 0.28304

Test context:
***************
nearly.r	258	36	in fact , according to his congressional biography , murtha was on active duty for six years at most ( 1952-55 and 1966-67 ) ; the rest of the time , including some 16 of his __nearly__ 32 years in the house , he was a reservist .
Contexts for target nearly are: ['quantmodI_32']
Contexts in vocabulary for target nearly are: ['quantmodI_32']
Top most similar embeddings: nearly 0.52845	almost 0.43222	approximately 0.39173	just 0.37530	roughly 0.36986	only 0.36075	aproximately 0.34949	over 0.34944	exactly 0.34618	than 0.34270

Generated lemmatized results
***************
GENERATED	nearly.r 258 ::: almost;approximately;just;roughly;only;aproximately;over;exactly;than;at

Filtered results
***************
RANKED	nearly.r 258	almost 0.43222	approximately 0.39173	practically 0.33003	quite 0.31370	remotely 0.27726	anyway 0.27528	half 0.27122

Test context:
***************
nearly.r	259	26	semantically , fdr could be the cause of the great depression if you think , as i do , that the recession wouldn 't have lasted __nearly__ as long without all his taxes , price fixing , wage fixing , and regulations .
Contexts for target nearly are: ['advmodI_long']
Contexts in vocabulary for target nearly are: ['advmodI_long']
Top most similar embeddings: nearly 0.50730	almost 0.42119	freakishly 0.37753	comparitively 0.37573	too 0.37020	fearsomely 0.36982	just 0.36737	as 0.36457	inexcusably 0.36340	infinitesimally 0.36333

Generated lemmatized results
***************
GENERATED	nearly.r 259 ::: almost;freakishly;comparitively;too;fearsomely;just;as;inexcusably;infinitesimally;numbingly

Filtered results
***************
RANKED	nearly.r 259	almost 0.42119	quite 0.36231	approximately 0.36078	practically 0.33064	anyway 0.31432	remotely 0.28178	half 0.28123

Test context:
***************
nearly.r	260	20	in the preceding decade of political struggle , ms. bhutto was arrested on numerous occasions ; in all she spent __nearly__ 6 years either in prison or under detention for her dedicated leadership of the then opposition pakistan peoples party .
Contexts for target nearly are: ['quantmodI_6']
Contexts in vocabulary for target nearly are: ['quantmodI_6']
Top most similar embeddings: nearly 0.53787	almost 0.43380	approximately 0.39721	roughly 0.38036	just 0.37815	aproximately 0.36851	only 0.35692	at 0.35325	than 0.35135	barely 0.35069

Generated lemmatized results
***************
GENERATED	nearly.r 260 ::: almost;approximately;roughly;just;aproximately;only;at;than;barely;over

Filtered results
***************
RANKED	nearly.r 260	almost 0.43380	approximately 0.39721	practically 0.33881	quite 0.31618	anyway 0.28694	remotely 0.28458	half 0.27484

Test context:
***************
outdoor.a	261	36	" our peak is early november , but it has gotten a little later as the years go by , " said dave menke , the u. s. fish and wildlife service 's klamath refuge complex __outdoor__ recreation specialist .
Contexts for target outdoor are: ['amodI_specialist']
Contexts in vocabulary for target outdoor are: ['amodI_specialist']
Top most similar embeddings: outdoor 0.52108	indoor 0.41005	out-door 0.40437	kent-based 0.39816	essex-based 0.39700	coventry-based 0.39449	boston-based 0.39389	leicester-based 0.39265	swansea-based 0.39214	berlin-based 0.39176

Generated lemmatized results
***************
GENERATED	outdoor.a 261 ::: indoor;landbased;sportsturf;horological;vetinary;inground;multisport;extramural;biopharmaceutical;prestigeous

Filtered results
***************
RANKED	outdoor.a 261	all-weather 0.37514	open-air 0.34732	outward-bound 0.34713	external 0.33223	alfresco 0.32119	outside 0.31468	roadside 0.28938	uncovered 0.26068

Test context:
***************
outdoor.a	262	55	the goals for the camp include : 1 ) outdoor experiences 2 ) social integration ( english and spanish speakers ) 3 ) academic learning in the outdoors students will plan and lead a variety of games and activities including , but not limited to : math lessons , art projects , games , and __outdoor__ leadership/teambuilding initiatives .
Contexts for target outdoor are: ['amodI_initiatives']
Contexts in vocabulary for target outdoor are: ['amodI_initiatives']
Top most similar embeddings: outdoor 0.49594	drama-based 0.39757	community-focused 0.39600	indoor 0.39537	regional/national 0.39505	government-supported 0.39414	multi-partner 0.39000	regional/local 0.38944	anti-crime 0.38906	out-of-school-hours 0.38900

Generated lemmatized results
***************
GENERATED	outdoor.a 262 ::: indoor;consortial;intersectoral;extramural;microfinancial;extracurricular;landbased;workbased;largescale;sectorial

Filtered results
***************
RANKED	outdoor.a 262	open-air 0.34728	outward-bound 0.33903	alfresco 0.32903	all-weather 0.32312	external 0.32120	outside 0.30027	roadside 0.25940	uncovered 0.25412

Test context:
***************
outdoor.a	263	0	__outdoor__ electrical safety check tips for the safe outdoor use of electricity esfi electrical safety foundation international published as a public service by the electrical safety foundation international in cooperation with the u.s. consumer product safety commission and the canada safety council .
Contexts for target outdoor are: ['amodI_tips']
Contexts in vocabulary for target outdoor are: ['amodI_tips']
Top most similar embeddings: outdoor 0.49287	indoor 0.40187	stress-busting 0.38782	water-saving 0.38485	2-cent 0.38405	wet-weather 0.37264	indoor/outdoor 0.37042	fishkeeping 0.36863	bite-size 0.36643	hyphal 0.36613

Generated lemmatized results
***************
GENERATED	outdoor.a 263 ::: indoor;fishkeeping;hyphal;additonal;addtional;interdental;horological;horticultural;occassional;inground

Filtered results
***************
RANKED	outdoor.a 263	open-air 0.35683	all-weather 0.34645	alfresco 0.34156	outward-bound 0.33490	external 0.30835	outside 0.30076	roadside 0.28447	uncovered 0.27763

Test context:
***************
outdoor.a	264	39	according to john reichling of camp , dresser & mckee , an environmental engineering firm in cambridge , mass. , " shelter in place " also involves architectural changes such as widening hallways , enlarging rooms , and enclosing __outdoor__ hallways .
Contexts for target outdoor are: ['amodI_hallways']
Contexts in vocabulary for target outdoor are: ['amodI_hallways']
Top most similar embeddings: outdoor 0.47189	indoor 0.39651	dimly-lit 0.38005	open-air 0.37543	out-door 0.37376	horseshoe-shaped 0.36891	indoor/outdoor 0.36869	wood-panelled 0.36629	rain-soaked 0.36623	colonnaded 0.36513

Generated lemmatized results
***************
GENERATED	outdoor.a 264 ::: indoor;colonnaded;pillared;communal;arcaded;unventilated;sunlit;cavernous;moonlit;airless

Filtered results
***************
RANKED	outdoor.a 264	open-air 0.37543	all-weather 0.35254	alfresco 0.32380	outward-bound 0.31734	outside 0.30604	external 0.29340	roadside 0.26993	uncovered 0.26311

Test context:
***************
outdoor.a	265	7	a bridge takes one over into the __outdoor__ space that is the heart of the home , the nucleus , held on each side by the three structures that surround it .
Contexts for target outdoor are: ['amodI_space']
Contexts in vocabulary for target outdoor are: ['amodI_space']
Top most similar embeddings: outdoor 0.53197	indoor 0.43162	out-door 0.43004	indoor/outdoor 0.40780	non-breaking 0.40648	climate-controlled 0.40139	light-filled 0.39882	multi-sport 0.39536	semi-private 0.39178	25-metre 0.39024

Generated lemmatized results
***************
GENERATED	outdoor.a 265 ::: indoor;rentable;addtional;illusionistic;tional;lettable;dramaturgical;inground;intercostal;additonal

Filtered results
***************
RANKED	outdoor.a 265	open-air 0.38458	all-weather 0.36111	outward-bound 0.35093	alfresco 0.34510	outside 0.32416	external 0.32284	roadside 0.28158	uncovered 0.26466

Test context:
***************
outdoor.a	266	21	work : in a landscape protected area , making the birds little wooden houses , springs and little rivers cleaning , __outdoor__ environmental work .
Contexts for target outdoor are: ['amodI_work']
Contexts in vocabulary for target outdoor are: ['amodI_work']
Top most similar embeddings: outdoor 0.51421	street-based 0.42989	out-door 0.41549	indoor 0.41514	drama-based 0.41387	media-based 0.39698	pro-bono 0.39656	church-related 0.39316	construction-related 0.39268	on-the-ground 0.38565

Generated lemmatized results
***************
GENERATED	outdoor.a 266 ::: indoor;medicolegal;sheetmetal;extramural;durational;backbreaking;homebased;extracurricular;lexicographical;ufological

Filtered results
***************
RANKED	outdoor.a 266	open-air 0.36433	outward-bound 0.36386	all-weather 0.34592	external 0.32427	alfresco 0.32313	outside 0.31904	roadside 0.27232	uncovered 0.26908

Test context:
***************
outdoor.a	267	6	iatse donated free labor and an __outdoor__ sound system .
Contexts for target outdoor are: ['amodI_system']
Contexts in vocabulary for target outdoor are: ['amodI_system']
Top most similar embeddings: outdoor 0.49753	siphonic 0.42479	indoor 0.41144	needle-free 0.40966	in-cab 0.40815	three-level 0.40036	multi-access 0.39961	newly-developed 0.39814	open-field 0.39801	integumentary 0.39771

Generated lemmatized results
***************
GENERATED	outdoor.a 267 ::: siphonic;indoor;integumentary;microfluidic;mechatronic;fibreoptic;hydroponic;multistage;saturnian;unvented

Filtered results
***************
RANKED	outdoor.a 267	all-weather 0.37042	open-air 0.35810	outward-bound 0.34667	external 0.32624	alfresco 0.32486	outside 0.29617	roadside 0.26767	uncovered 0.26709

Test context:
***************
outdoor.a	268	14	this is about as big as most finecky fine-art photographers require , and even __outdoor__ billboards are routinely made from files with less resolution that this .
Contexts for target outdoor are: ['advmod_even', 'amodI_billboards']
Contexts in vocabulary for target outdoor are: ['advmod_even', 'amodI_billboards']
Top most similar embeddings: outdoor 0.23041	indoor 0.18484	ostentatious 0.16935	smaller-scale 0.16854	kitschy 0.16710	sillier 0.16554	oversized 0.16516	flashier 0.16465	garish 0.16397	x-rated 0.16222

Generated lemmatized results
***************
GENERATED	outdoor.a 268 ::: indoor;ostentatious;kitschy;silly;oversized;flashy;garish;cinematographic;whizzy;downright

Filtered results
***************
RANKED	outdoor.a 268	all-weather 0.15748	open-air 0.15663	outside 0.14412	alfresco 0.14138	outward-bound 0.13306	external 0.13062	roadside 0.12870	uncovered 0.11541

Test context:
***************
outdoor.a	269	30	active children and adults , and people with respiratory disease , such as asthma , should avoid prolonged outdoor exertion ; everyone else , especially children , should limit prolonged __outdoor__ exertion .
Contexts for target outdoor are: ['amodI_exertion']
Contexts in vocabulary for target outdoor are: ['amodI_exertion']
Top most similar embeddings: outdoor 0.48796	indoor 0.39204	out-door 0.39185	unwonted 0.37366	leisure-time 0.36557	wet-weather 0.36476	full-body 0.36249	high-intensity 0.36095	super-slow 0.36049	long-duration 0.35991

Generated lemmatized results
***************
GENERATED	outdoor.a 269 ::: indoor;unwonted;physical;submaximal;strenuous;extracurricular;sportive;inspiratory;recuperative;nightime

Filtered results
***************
RANKED	outdoor.a 269	all-weather 0.34261	outward-bound 0.33717	open-air 0.33706	external 0.30387	alfresco 0.30113	outside 0.28747	roadside 0.26147	uncovered 0.24297

Test context:
***************
outdoor.a	270	22	with the growing demand for these fine garden furnishings , they found it necessary to dedicate a portion of their business to __outdoor__ living and patio furnishings .
Contexts for target outdoor are: ['amodI_living']
Contexts in vocabulary for target outdoor are: ['amodI_living']
Top most similar embeddings: outdoor 0.53397	indoor 0.42026	out-door 0.41405	low-impact 0.38881	open-air 0.38460	indoor/outdoor 0.38365	twenty-first-century 0.37502	multi-sport 0.37081	single-person 0.37064	communal 0.36729

Generated lemmatized results
***************
GENERATED	outdoor.a 270 ::: indoor;communal;leisured;bhutanese;maldivian;sedentary;beachside;majorcan;urban;comtemporary

Filtered results
***************
RANKED	outdoor.a 270	open-air 0.38460	outward-bound 0.35984	all-weather 0.35735	alfresco 0.35189	outside 0.31005	external 0.30003	roadside 0.27348	uncovered 0.26671

Test context:
***************
reasonable.a	271	25	due to china 's economic reliance on trade , balance of payments should be the main factor for judging whether the yuan exchange rate is __reasonable__ .
Contexts for target reasonable are: ['mark_whether', 'nsubj_rate', 'cop_is', 'ccompI_judging']
Contexts in vocabulary for target reasonable are: ['mark_whether', 'nsubj_rate', 'cop_is', 'ccompI_judging']
Top most similar embeddings: reasonable 0.06845	justifiable 0.05645	unreasonable 0.05355	feasible 0.04955	proportionate 0.04950	justified 0.04936	acceptable 0.04930	satisfactory 0.04844	sufficent 0.04807	appropriate 0.04755

Generated lemmatized results
***************
GENERATED	reasonable.a 271 ::: justifiable;unreasonable;feasible;proportionate;justified;acceptable;satisfactory;sufficent;appropriate;achievable

Filtered results
***************
RANKED	reasonable.a 271	justifiable 0.05645	acceptable 0.04930	appropriate 0.04755	adequate 0.04728	sufficient 0.04661	likely 0.04601	sensible 0.04449	tolerable 0.04255	credible 0.04099	rational 0.03945	fair 0.03940	manageable 0.03884	good 0.03831	equitable 0.03669	reliable 0.03603	affordable 0.03426	well-judged 0.03416	moderate 0.03401	enough 0.03259	inexpensive 0.03111	measured 0.02744	just 0.01822

Test context:
***************
reasonable.a	272	10	copyright law already addressed the issue in a much more __reasonable__ manner .
Contexts for target reasonable are: ['advmod_more', 'amodI_manner']
Contexts in vocabulary for target reasonable are: ['advmod_more', 'amodI_manner']
Top most similar embeddings: reasonable 0.25882	seemly 0.21984	sensible 0.21949	resonable 0.21930	decorous 0.21552	expeditious 0.21538	equable 0.21496	businesslike 0.21485	statesmanlike 0.21444	customer-friendly 0.21208

Generated lemmatized results
***************
GENERATED	reasonable.a 272 ::: seemly;sensible;resonable;decorous;expeditious;equable;businesslike;statesmanlike;realistic;rational

Filtered results
***************
RANKED	reasonable.a 272	sensible 0.21949	rational 0.20946	appropriate 0.19714	credible 0.19282	acceptable 0.19272	justifiable 0.19096	tolerable 0.18936	manageable 0.18627	equitable 0.18282	reliable 0.18151	likely 0.18006	well-judged 0.17957	adequate 0.17909	affordable 0.17795	moderate 0.17061	fair 0.16738	good 0.15832	inexpensive 0.15666	sufficient 0.15206	measured 0.14507	enough 0.12989	just 0.12959

Test context:
***************
reasonable.a	273	22	" what we require now is the co-operation from the federal government to provide a flow of mortgage money through cmhc at __reasonable__ interest rates and to encourage the conventional loans to be channelled into smaller units so that we may have the opportunity of the best housing and building programme in canada in 1971 .
Contexts for target reasonable are: ['amodI_rates']
Contexts in vocabulary for target reasonable are: ['amodI_rates']
Top most similar embeddings: reasonable 0.52850	resonable 0.45781	much-reduced 0.42403	below-average 0.40648	cost-based 0.40382	age-standardised 0.40091	age-adjusted 0.40069	eye-watering 0.39962	lawyer-free 0.39712	extortionate 0.39376

Generated lemmatized results
***************
GENERATED	reasonable.a 273 ::: resonable;extortionate;lowish;unreasonable;exorbitant;competative;submaximal;concessional;sensible;competitve

Filtered results
***************
RANKED	reasonable.a 273	sensible 0.38055	adequate 0.35898	justifiable 0.35390	affordable 0.35369	appropriate 0.35272	acceptable 0.35020	good 0.34584	sufficient 0.34217	fair 0.33817	tolerable 0.33341	moderate 0.32949	rational 0.32889	credible 0.32860	inexpensive 0.32606	manageable 0.32482	well-judged 0.32460	equitable 0.32099	likely 0.31744	reliable 0.31601	measured 0.30691	enough 0.29247	just 0.26911

Test context:
***************
reasonable.a	274	1	for __reasonable__ people , sure that 'll suffice .
Contexts for target reasonable are: ['amodI_people']
Contexts in vocabulary for target reasonable are: ['amodI_people']
Top most similar embeddings: reasonable 0.49654	right-minded 0.42673	sensible 0.39630	unreasonable 0.39317	certian 0.39239	right-thinking 0.39171	resonable 0.38917	fair-minded 0.38135	children/young 0.38086	freedom-loving 0.38048

Generated lemmatized results
***************
GENERATED	reasonable.a 274 ::: sensible;unreasonable;certian;resonable;rational;decent;respectable;likeminded;geniune;necessitous

Filtered results
***************
RANKED	reasonable.a 274	sensible 0.39630	rational 0.37967	sufficient 0.34808	good 0.34551	appropriate 0.34542	credible 0.34056	justifiable 0.33932	adequate 0.33215	acceptable 0.33120	fair 0.32814	likely 0.31968	enough 0.31768	tolerable 0.31730	moderate 0.31710	reliable 0.31623	affordable 0.31137	well-judged 0.30565	inexpensive 0.30429	manageable 0.30229	equitable 0.29841	measured 0.27878	just 0.27142

Test context:
***************
reasonable.a	275	22	your objective should be to negotiate a contract type and price ( or estimated fee and cost ) that will result in __reasonable__ contractor risk and provide the contractor with the greatest incentive for efficient and economical contract performance .
Contexts for target reasonable are: ['amodI_risk']
Contexts in vocabulary for target reasonable are: ['amodI_risk']
Top most similar embeddings: reasonable 0.49304	resonable 0.41826	unreasonable 0.41059	much-reduced 0.40437	sensible 0.37985	ever-rising 0.37965	below-average 0.37902	reputational 0.37789	prudent 0.37629	age-adjusted 0.37438

Generated lemmatized results
***************
GENERATED	reasonable.a 275 ::: resonable;unreasonable;sensible;reputational;prudent;negligible;justifiable;minimal;unacceptable;signficant

Filtered results
***************
RANKED	reasonable.a 275	sensible 0.37985	justifiable 0.37199	acceptable 0.36718	adequate 0.35626	sufficient 0.35494	tolerable 0.35394	rational 0.35248	credible 0.34644	appropriate 0.34379	well-judged 0.34327	moderate 0.33887	manageable 0.33113	good 0.32828	likely 0.32571	fair 0.32020	equitable 0.31615	affordable 0.31592	measured 0.30106	reliable 0.29912	inexpensive 0.29789	enough 0.29611	just 0.26950

Test context:
***************
reasonable.a	276	14	and if no exact & safe equilibrium can be introduced , it is more __reasonable__ that a preponderating weight shd. be allowed to the greater interest than to the lesser .
Contexts for target reasonable are: ['advcl_introduced', 'punct_,', 'nsubj_it', 'cop_is', 'advmod_more', 'rootI_*root*', 'ccomp_allowed', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target reasonable are: ['advcl_introduced', 'punct_,', 'nsubj_it', 'cop_is', 'advmod_more', 'rootI_*root*', 'ccomp_allowed', 'punct_.']
Top most similar embeddings: arguable 0.00348	probable 0.00339	regrettable 0.00335	reasonable 0.00333	inconceivable 0.00331	surprising 0.00329	debatable 0.00328	debateable 0.00326	evident 0.00326	questionable 0.00321

Generated lemmatized results
***************
GENERATED	reasonable.a 276 ::: arguable;probable;regrettable;inconceivable;surprising;debatable;debateable;evident;questionable;ludicrous

Filtered results
***************
RANKED	reasonable.a 276	likely 0.00308	sensible 0.00280	justifiable 0.00274	acceptable 0.00268	tolerable 0.00255	credible 0.00219	appropriate 0.00214	manageable 0.00214	sufficient 0.00212	rational 0.00203	fair 0.00200	inexpensive 0.00193	adequate 0.00186	reliable 0.00180	good 0.00173	well-judged 0.00170	affordable 0.00167	moderate 0.00162	measured 0.00156	equitable 0.00152	enough 0.00151	just 0.00093

Test context:
***************
reasonable.a	277	25	besides overseeing the operation of pipeda and dealing with complaints , i can conduct audits into organizations ' personal information-handling practices , if we have __reasonable__ grounds .
Contexts for target reasonable are: ['amodI_grounds']
Contexts in vocabulary for target reasonable are: ['amodI_grounds']
Top most similar embeddings: reasonable 0.54455	resonable 0.42031	unreasonable 0.41440	rational 0.39139	park-like 0.38948	justifiable 0.38904	sensible 0.38430	adequate 0.38166	legitimate 0.38050	plausible 0.37998

Generated lemmatized results
***************
GENERATED	reasonable.a 277 ::: resonable;unreasonable;rational;justifiable;sensible;adequate;legitimate;plausible;defensible;sufficient

Filtered results
***************
RANKED	reasonable.a 277	rational 0.39139	justifiable 0.38904	sensible 0.38430	adequate 0.38166	sufficient 0.37633	acceptable 0.35308	credible 0.35129	good 0.34826	appropriate 0.34506	fair 0.34002	tolerable 0.33639	well-judged 0.33499	equitable 0.32740	affordable 0.31858	manageable 0.31670	likely 0.31493	reliable 0.30737	enough 0.30472	moderate 0.30327	inexpensive 0.29863	measured 0.28124	just 0.26986

Test context:
***************
reasonable.a	278	16	the matter of the further evidence may then be heard when the other party has had __reasonable__ opportunity to prepare submissions on the matter .
Contexts for target reasonable are: ['amodI_opportunity']
Contexts in vocabulary for target reasonable are: ['amodI_opportunity']
Top most similar embeddings: reasonable 0.52173	resonable 0.41375	realistic 0.37733	unreasonable 0.37645	adequate 0.37352	well-taken 0.36999	no-risk 0.36759	not-to-be-missed 0.36653	sensible 0.36550	sufficient 0.36494

Generated lemmatized results
***************
GENERATED	reasonable.a 278 ::: resonable;realistic;unreasonable;adequate;sensible;sufficient;legitimate;sufficent;exceptional;suberb

Filtered results
***************
RANKED	reasonable.a 278	adequate 0.37352	sensible 0.36550	sufficient 0.36494	good 0.36039	appropriate 0.35162	credible 0.34612	fair 0.34187	justifiable 0.34173	rational 0.33459	acceptable 0.33383	affordable 0.33205	well-judged 0.33194	equitable 0.32595	inexpensive 0.31977	tolerable 0.31829	manageable 0.31169	moderate 0.30611	enough 0.30139	likely 0.30090	reliable 0.29865	measured 0.26546	just 0.26235

Test context:
***************
reasonable.a	279	18	this will allow state-licensed health-care providers to utilize safe , non-fda approved , alternative therapies that have a __reasonable__ expectation of therapeutic gain if the patient has been fully informed about the treatment .
Contexts for target reasonable are: ['amodI_expectation']
Contexts in vocabulary for target reasonable are: ['amodI_expectation']
Top most similar embeddings: reasonable 0.55220	unreasonable 0.44543	resonable 0.43260	realistic 0.40539	unrealistic 0.39964	legitimate 0.38939	much-reduced 0.38834	rational 0.38720	justifiable 0.38373	sensible 0.37850

Generated lemmatized results
***************
GENERATED	reasonable.a 279 ::: unreasonable;resonable;realistic;unrealistic;legitimate;rational;justifiable;sensible;immoderate;inordinate

Filtered results
***************
RANKED	reasonable.a 279	rational 0.38720	justifiable 0.38373	sensible 0.37850	adequate 0.34227	appropriate 0.33850	credible 0.33844	well-judged 0.33819	fair 0.33612	tolerable 0.33474	sufficient 0.33271	acceptable 0.33271	equitable 0.32284	moderate 0.31794	good 0.31767	likely 0.31643	manageable 0.30716	affordable 0.30588	measured 0.29864	reliable 0.29751	enough 0.28344	just 0.27362	inexpensive 0.27314

Test context:
***************
reasonable.a	280	36	( 2 ) in a civil action under subsection ( a ) of this section , the court , in its discretion , may allow the prevailing party , other than the united states , a __reasonable__ attorney 's fee and costs .
Contexts for target reasonable are: ['amodI_attorney']
Contexts in vocabulary for target reasonable are: ['amodI_attorney']
Top most similar embeddings: reasonable 0.52309	court-appointed 0.40051	prudent 0.39414	unreasonable 0.38761	resonable 0.38520	sensible 0.37636	respectable 0.36826	legitimate 0.36733	competent 0.36574	right-minded 0.36486

Generated lemmatized results
***************
GENERATED	reasonable.a 280 ::: prudent;unreasonable;resonable;sensible;respectable;legitimate;competent;rational;justifiable;decent

Filtered results
***************
RANKED	reasonable.a 280	sensible 0.37636	rational 0.36291	justifiable 0.35400	credible 0.34371	appropriate 0.34109	adequate 0.33939	good 0.33644	acceptable 0.33400	sufficient 0.32153	well-judged 0.31969	tolerable 0.31591	affordable 0.31442	fair 0.31327	reliable 0.30098	inexpensive 0.29764	manageable 0.29457	likely 0.29005	moderate 0.28767	equitable 0.28679	enough 0.27831	just 0.27253	measured 0.26035

Test context:
***************
rough.a	281	46	but i think we can already see from this and other defenses coming from administration officials that the white house 's line on this is filled with clear distortions and misstatements of fact -- most of which are easily identifiable by people who have even a __rough__ understanding of the timing and issues involved .
Contexts for target rough are: ['amodI_understanding']
Contexts in vocabulary for target rough are: ['amodI_understanding']
Top most similar embeddings: rough 0.48952	rough-and-ready 0.37406	multi-perspective 0.35414	anthroposophical 0.35387	metalinguistic 0.35348	lockean 0.35190	firmer 0.34981	baconian 0.34916	foucauldian 0.34842	non-literal 0.34841

Generated lemmatized results
***************
GENERATED	rough.a 281 ::: anthroposophical;metalinguistic;lockean;firm;baconian;foucauldian;geomantic;etymological;goethean;wholistic

Filtered results
***************
RANKED	rough.a 281	vague 0.34305	broad 0.34165	rudimentary 0.34154	basic 0.34040	inexact 0.33528	imperfect 0.33208	crude 0.32650	approximate 0.32526	tough 0.32391	coarse 0.32265	poor 0.32219	uneven 0.31958	harsh 0.31759	preliminary 0.31562	wild 0.31097	simple 0.30484	general 0.29934	violent 0.29509	jagged 0.29470	unrefined 0.29389	hard 0.28991	dangerous 0.28934	uncivil 0.28890	unfinished 0.28758	difficult 0.28535	unpleasant 0.28084	raucous 0.28078	irregular 0.27833	disorderly 0.27114	demanding 0.26982	uncut 0.26720

Test context:
***************
rough.a	282	10	on right there is a steep fall of 10ft. to __rough__ grass between 4th and adjacent fairway .
Contexts for target rough are: ['amodI_grass']
Contexts in vocabulary for target rough are: ['amodI_grass']
Top most similar embeddings: rough 0.54538	tussocky 0.41390	sun-baked 0.39047	hummocky 0.38974	scrubby 0.38615	miry 0.38593	flower-rich 0.38591	herb-rich 0.38462	windblown 0.38443	heathery 0.38410

Generated lemmatized results
***************
GENERATED	rough.a 282 ::: tussocky;hummocky;scrubby;miry;windblown;heathery;scraggy;bristly;ungrazed;flinty

Filtered results
***************
RANKED	rough.a 282	coarse 0.35557	tough 0.35477	harsh 0.34776	wild 0.34699	jagged 0.34366	uneven 0.33646	vague 0.32596	irregular 0.32469	uncut 0.32376	broad 0.32036	crude 0.31515	unrefined 0.31456	basic 0.31443	inexact 0.31161	rudimentary 0.30945	poor 0.30815	raucous 0.30683	dangerous 0.30280	approximate 0.30195	unpleasant 0.29903	hard 0.29698	imperfect 0.29431	unfinished 0.29366	simple 0.28734	violent 0.28662	difficult 0.28658	disorderly 0.28374	preliminary 0.27820	demanding 0.26800	general 0.26602	uncivil 0.25783

Test context:
***************
rough.a	283	7	the surface of the keyboard is a __rough__ metal ( a wrought iron feel , if you will ) , and two black wooden braces support the frame on either side .
Contexts for target rough are: ['amodI_metal']
Contexts in vocabulary for target rough are: ['amodI_metal']
Top most similar embeddings: rough 0.49725	sludgy 0.38750	flinty 0.38251	rough-hewn 0.38199	nickel-plated 0.37929	dark-coloured 0.37894	non-porous 0.37777	squelchy 0.37438	sharp-edged 0.37435	jelly-like 0.37354

Generated lemmatized results
***************
GENERATED	rough.a 283 ::: sludgy;flinty;squelchy;gloopy;unworked;metalic;darkish;vaporous;heavy;rubberized

Filtered results
***************
RANKED	rough.a 283	coarse 0.35343	tough 0.35234	jagged 0.34821	harsh 0.33862	crude 0.33514	unrefined 0.33268	raucous 0.32759	hard 0.32338	wild 0.32184	uneven 0.31830	rudimentary 0.31413	dangerous 0.31212	basic 0.31200	vague 0.31052	violent 0.30853	approximate 0.30647	simple 0.30641	broad 0.30558	irregular 0.30390	unpleasant 0.30065	imperfect 0.29925	inexact 0.29797	disorderly 0.29791	uncut 0.29497	unfinished 0.29360	difficult 0.29251	poor 0.28820	demanding 0.28000	preliminary 0.27834	general 0.27503	uncivil 0.27342

Test context:
***************
rough.a	284	2	a very __rough__ way of gauging your so-called preferred weight is to use the body mass index ( bmi ) .
Contexts for target rough are: ['advmod_very', 'amodI_way']
Contexts in vocabulary for target rough are: ['advmod_very', 'amodI_way']
Top most similar embeddings: rough 0.26057	rough-and-ready 0.21624	sharp-edged 0.19567	straight-laced 0.19548	untraditional 0.19453	fiesty 0.19413	peacefull 0.19339	time-efficient 0.19288	uncomplimentary 0.19276	slutty 0.19273

Generated lemmatized results
***************
GENERATED	rough.a 284 ::: untraditional;fiesty;peacefull;uncomplimentary;slutty;humerous;resonable;repetative;ceremonious;clubby

Filtered results
***************
RANKED	rough.a 284	harsh 0.17811	tough 0.17760	vague 0.17669	uncivil 0.17593	crude 0.17447	simple 0.17312	unpleasant 0.17241	hard 0.17214	inexact 0.17210	rudimentary 0.17041	approximate 0.16842	uneven 0.16623	broad 0.16617	dangerous 0.16583	coarse 0.16500	violent 0.16375	imperfect 0.16353	basic 0.16212	irregular 0.16185	jagged 0.16142	disorderly 0.15992	difficult 0.15950	unrefined 0.15904	wild 0.15862	poor 0.15847	raucous 0.15468	preliminary 0.15047	demanding 0.14695	unfinished 0.14628	general 0.14170	uncut 0.12458

Test context:
***************
rough.a	285	22	note : for the aviation and mrf models , the lifted index field is not broadcast so the showalter index ( a __rough__ equivalent ) is plotted instead .
Contexts for target rough are: ['amodI_equivalent']
Contexts in vocabulary for target rough are: ['amodI_equivalent']
Top most similar embeddings: rough 0.52394	database-specific 0.37469	rough-and-ready 0.37140	vendor-specific 0.35515	coarsest 0.35396	approximate 0.35263	american-made 0.35161	12-point 0.35098	etymological 0.34962	old-skool 0.34935

Generated lemmatized results
***************
GENERATED	rough.a 285 ::: coarse;approximate;etymological;metronomic;exact;crude;covariant;chaucerian;laotian;flinty

Filtered results
***************
RANKED	rough.a 285	coarse 0.35396	approximate 0.35263	crude 0.34576	tough 0.33430	harsh 0.33402	vague 0.31952	rudimentary 0.31922	unrefined 0.31834	wild 0.31738	basic 0.31724	inexact 0.31486	raucous 0.31349	violent 0.30524	irregular 0.30497	uneven 0.30338	jagged 0.30297	hard 0.30277	simple 0.30121	broad 0.30043	preliminary 0.29905	poor 0.29776	imperfect 0.29584	unpleasant 0.29379	uncut 0.29144	dangerous 0.28882	unfinished 0.28756	general 0.28333	demanding 0.28162	disorderly 0.27991	uncivil 0.27310	difficult 0.26072

Test context:
***************
rough.a	286	0	__rough__ estimates show that there are between 75,000 and 100,000 professional speakers in the u.s. alone and when you add trainers the number goes up into the millions .
Contexts for target rough are: ['amodI_estimates']
Contexts in vocabulary for target rough are: ['amodI_estimates']
Top most similar embeddings: rough 0.53346	rough-and-ready 0.38640	thermospheric 0.36496	survey-based 0.36457	nonparametric 0.35918	risk-adjusted 0.35863	approximate 0.35702	gridded 0.35683	broad-brush 0.35596	precise 0.35383

Generated lemmatized results
***************
GENERATED	rough.a 286 ::: thermospheric;nonparametric;approximate;gridded;precise;unrevised;crude;semiclassical;perturbative;sketchy

Filtered results
***************
RANKED	rough.a 286	approximate 0.35702	crude 0.34936	inexact 0.34309	tough 0.33501	vague 0.33351	preliminary 0.33195	coarse 0.33142	harsh 0.32812	wild 0.32794	rudimentary 0.32357	broad 0.32314	irregular 0.31639	imperfect 0.31575	unrefined 0.30873	uneven 0.30764	basic 0.30722	poor 0.30445	jagged 0.30438	simple 0.30399	hard 0.29735	dangerous 0.29427	violent 0.29333	unpleasant 0.29159	raucous 0.28897	unfinished 0.28622	general 0.28349	uncut 0.28284	disorderly 0.28174	difficult 0.28150	uncivil 0.27511	demanding 0.26925

Test context:
***************
rough.a	287	5	he was apparently given a __rough__ ride by the interviewer , cathal maccoille .
Contexts for target rough are: ['amodI_ride']
Contexts in vocabulary for target rough are: ['amodI_ride']
Top most similar embeddings: rough 0.54559	white-knuckle 0.40411	bumpy 0.40168	roughest 0.39736	100-mile 0.39597	rougher 0.39262	5-hour 0.38816	3-mile 0.38539	three-mile 0.38513	35-minute 0.38504

Generated lemmatized results
***************
GENERATED	rough.a 287 ::: bumpy;choppy;longish;wintery;steepish;shortish;gnarly;squelchy;flattish;flinty

Filtered results
***************
RANKED	rough.a 287	tough 0.36202	wild 0.34864	harsh 0.34815	uneven 0.33377	jagged 0.32842	raucous 0.32816	dangerous 0.32154	approximate 0.32136	coarse 0.32119	unpleasant 0.31933	crude 0.31792	hard 0.31716	violent 0.31329	irregular 0.31305	broad 0.31196	basic 0.30980	preliminary 0.30785	vague 0.30604	disorderly 0.30573	poor 0.30524	unfinished 0.30509	demanding 0.30274	inexact 0.30209	rudimentary 0.30099	difficult 0.29951	unrefined 0.29835	simple 0.29794	imperfect 0.29001	uncut 0.28583	uncivil 0.28372	general 0.27253

Test context:
***************
rough.a	288	17	next , the piece went to the " smoother " , who went back over all the __rough__ cuts with stone wheels called " craighleiths .
Contexts for target rough are: ['amodI_cuts']
Contexts in vocabulary for target rough are: ['amodI_cuts']
Top most similar embeddings: rough 0.53089	rougher 0.37419	gnarly 0.36914	roughest 0.36602	sludgy 0.36103	gravity-defying 0.36010	squelchy 0.35911	slabby 0.35841	choppy 0.35784	rough-and-ready 0.35747

Generated lemmatized results
***************
GENERATED	rough.a 288 ::: gnarly;sludgy;squelchy;slabby;choppy;sinewy;precipitous;unpolished;flinty;drastic

Filtered results
***************
RANKED	rough.a 288	harsh 0.35224	tough 0.34834	jagged 0.33718	crude 0.33694	coarse 0.33479	uneven 0.33032	wild 0.32625	approximate 0.32512	dangerous 0.32090	uncut 0.32081	vague 0.31881	irregular 0.31874	violent 0.31777	raucous 0.31726	basic 0.31648	rudimentary 0.31402	unpleasant 0.30467	unfinished 0.30452	simple 0.30334	hard 0.30255	unrefined 0.30180	broad 0.29822	poor 0.29598	preliminary 0.29425	difficult 0.29357	uncivil 0.29192	imperfect 0.29172	inexact 0.28997	disorderly 0.28964	demanding 0.28765	general 0.28452

Test context:
***************
rough.a	289	13	it was a very poor area and stanway street was very overcrowded and __rough__ .
Contexts for target rough are: ['conjI_overcrowded']
Contexts in vocabulary for target rough are: ['conjI_overcrowded']
Top most similar embeddings: rough 0.49326	insanitary 0.41839	unsanitary 0.41099	overcrowded 0.39009	squalid 0.37720	over-crowded 0.37705	potholed 0.37629	unhygienic 0.37560	delapidated 0.37355	uninviting 0.37221

Generated lemmatized results
***************
GENERATED	rough.a 289 ::: insanitary;unsanitary;overcrowded;squalid;potholed;unhygienic;delapidated;uninviting;unwelcoming;unpaved

Filtered results
***************
RANKED	rough.a 289	dangerous 0.34114	uneven 0.33657	tough 0.33262	harsh 0.33239	unpleasant 0.33213	poor 0.32542	irregular 0.32057	disorderly 0.32003	vague 0.31877	raucous 0.31626	violent 0.31597	rudimentary 0.31158	crude 0.31105	imperfect 0.30959	wild 0.30922	difficult 0.30882	coarse 0.30166	inexact 0.30119	jagged 0.29916	unfinished 0.29749	hard 0.29698	approximate 0.29472	unrefined 0.29240	basic 0.28668	demanding 0.28628	broad 0.28398	uncivil 0.28075	preliminary 0.27167	uncut 0.27071	general 0.25539	simple 0.24763

Test context:
***************
rough.a	290	8	col. berry led again so it was a __rough__ job .
Contexts for target rough are: ['amodI_job']
Contexts in vocabulary for target rough are: ['amodI_job']
Top most similar embeddings: rough 0.49291	tough 0.37706	back-breaking 0.37506	backbreaking 0.37311	roughest 0.37055	high-paying 0.36949	shitty 0.36830	nine-to-five 0.36612	less-than-perfect 0.36208	godawful 0.36208

Generated lemmatized results
***************
GENERATED	rough.a 290 ::: tough;backbreaking;shitty;godawful;cushy;lonely;unenviable;grotty;lousy;arduous

Filtered results
***************
RANKED	rough.a 290	tough 0.37706	harsh 0.33248	dangerous 0.32842	difficult 0.32727	coarse 0.32525	hard 0.32426	unpleasant 0.32324	approximate 0.31902	unfinished 0.31873	poor 0.31729	jagged 0.31655	demanding 0.31608	crude 0.31598	basic 0.31581	simple 0.31489	inexact 0.31401	rudimentary 0.30808	imperfect 0.30719	irregular 0.30689	uneven 0.30543	wild 0.30221	raucous 0.30165	vague 0.29902	preliminary 0.29895	violent 0.29726	uncivil 0.29075	broad 0.28793	disorderly 0.28649	unrefined 0.28006	uncut 0.27918	general 0.27434

Test context:
***************
run.v	291	26	" while washington 's attention focuses on key congressional races and contests for governor , ballot measures have a direct impact on how u.s. society is __run__ and often presage future national political debates .
Contexts for target run are: ['advmod_how', 'nsubjpass_society', 'auxpass_is', 'pcompI_on', 'cc_and', 'conj_presage']
Contexts in vocabulary for target run are: ['advmod_how', 'nsubjpass_society', 'auxpass_is', 'pcompI_on', 'cc_and']
Top most similar embeddings: run 0.02929	structured 0.02209	conceptualised 0.02170	parented 0.02162	governed 0.02140	organized 0.02125	underfunded 0.02115	administrated 0.02113	policed 0.02111	organised 0.02093

Generated lemmatized results
***************
GENERATED	run.v 291 ::: structure;conceptualise;parent;govern;organize;underfunded;administrate;police;organise;finance

Filtered results
***************
RANKED	run.v 291	govern 0.02140	organise 0.02093	manage 0.02044	operate 0.01987	handle 0.01893	control 0.01833	fill 0.01671	use 0.01636	stretch 0.01610	execute 0.01588	chair 0.01578	avoid 0.01544	function 0.01527	rush 0.01515	go 0.01513	contradict 0.01504	work 0.01504	extend 0.01491	cover 0.01472	include 0.01431	complete 0.01426	proceed 0.01422	flee 0.01348	flow 0.01322	sprint 0.01263	last 0.01232	total 0.01228	functioning 0.01212	scurry 0.01161	appear 0.01108	working 0.01071	training 0.00858

Test context:
***************
run.v	292	10	no one becomes a teacher until after interning in a __running__ school .
Contexts for target running are: ['amodI_school']
Contexts in vocabulary for target running are: ['amodI_school']
Top most similar embeddings: running 0.45564	research-engaged 0.39196	state-sector 0.36415	community-run 0.35902	lea-maintained 0.35797	newly-founded 0.35532	smooth-running 0.35260	privately-run 0.35204	company-sponsored 0.35154	voluntary-aided 0.35027

Generated lemmatized results
***************
GENERATED	run.v 292 ::: wizarding;landbased;rid;senatorial;loadbearing;fly;glide;prestigeous;lead;prestigous

Filtered results
***************
RANKED	run.v 292	functioning 0.32241	function 0.32241	organise 0.30425	sprint 0.30205	working 0.30179	work 0.30179	operate 0.29816	control 0.29679	rush 0.29613	scurry 0.29534	flow 0.29499	extend 0.29339	chair 0.28906	execute 0.28825	last 0.28487	manage 0.28445	use 0.28393	flee 0.27957	stretch 0.27653	govern 0.27525	complete 0.27510	total 0.27364	go 0.27267	proceed 0.27082	fill 0.26824	handle 0.26803	cover 0.25925	training 0.25892	contradict 0.25743	include 0.25024	appear 0.24940	avoid 0.24601

Test context:
***************
run.v	293	21	it ran six to seven pages single spaced ; the calculation for determining how much the farmers would get paid alone __ran__ several pages .
Contexts for target ran are: ['dep_calculation', 'mark_for', 'dep_determining', 'csubj_paid', 'parataxisI_ran', 'dobj_pages']
Contexts in vocabulary for target ran are: ['dep_calculation', 'mark_for', 'dep_determining', 'csubj_paid', 'parataxisI_ran', 'dobj_pages']
Top most similar embeddings: ran 0.00860	runs 0.00720	necessitated 0.00693	multiply 0.00692	iterate 0.00671	calculates 0.00670	paste 0.00669	incur 0.00658	execute 0.00657	precluded 0.00654

Generated lemmatized results
***************
GENERATED	run.v 293 ::: necessitate;multiply;iterate;calculate;paste;incur;execute;preclude;crawl;accrue

Filtered results
***************
RANKED	run.v 293	execute 0.00657	flow 0.00643	total 0.00638	complete 0.00618	last 0.00609	fill 0.00602	extend 0.00600	proceed 0.00583	operate 0.00556	flee 0.00553	include 0.00546	manage 0.00539	govern 0.00535	rush 0.00535	scurry 0.00533	go 0.00531	cover 0.00528	avoid 0.00518	use 0.00513	appear 0.00492	handle 0.00490	sprint 0.00485	work 0.00474	function 0.00456	contradict 0.00450	stretch 0.00442	organise 0.00440	control 0.00437	chair 0.00432	functioning 0.00384	working 0.00343	training 0.00252

Test context:
***************
run.v	294	8	chapters from this book by paul collins have __run__ in mcsweeney 's quarterly concern .
Contexts for target run are: ['nsubj_chapters', 'aux_have', 'rootI_*root*', 'prep:in_concern', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target run are: ['nsubj_chapters', 'aux_have', 'rootI_*root*', 'prep:in_concern', 'punct_.']
Top most similar embeddings: run 0.02478	mushroomed 0.02117	calendared 0.02082	resulted 0.02058	included 0.02046	adressed 0.02042	re-numbered 0.02041	proliferated 0.02020	echoed 0.02007	ranged 0.02005

Generated lemmatized results
***************
GENERATED	run.v 294 ::: mushroom;calendar;result;include;adressed;proliferate;echo;range;focus;snowball

Filtered results
***************
RANKED	run.v 294	include 0.02046	organise 0.01900	appear 0.01850	flee 0.01824	function 0.01797	go 0.01777	work 0.01771	last 0.01694	flow 0.01683	cover 0.01674	handle 0.01668	total 0.01666	operate 0.01637	proceed 0.01637	avoid 0.01635	extend 0.01614	chair 0.01601	rush 0.01591	manage 0.01585	contradict 0.01576	scurry 0.01575	fill 0.01568	complete 0.01512	execute 0.01501	govern 0.01497	stretch 0.01465	sprint 0.01454	use 0.01388	control 0.01336	working 0.01298	functioning 0.01003	training 0.00765

Test context:
***************
run.v	295	13	" donÂt be afraid to bring in a professional negotiator , someone to __run__ a meeting , anyone you need to work through the issues,Â johnson advises .
Contexts for target run are: ['aux_to', 'infmodI_someone', 'dobj_meeting']
Contexts in vocabulary for target run are: ['aux_to', 'infmodI_someone', 'dobj_meeting']
Top most similar embeddings: run 0.12215	invigilate 0.09901	gatecrash 0.09642	superintend 0.09554	televise 0.09518	organise 0.09476	attend 0.09321	re-schedule 0.09210	baby-sit 0.09146	administrate 0.09088

Generated lemmatized results
***************
GENERATED	run.v 295 ::: invigilate;gatecrash;superintend;televise;organise;attend;administrate;organize;reschedule;inaugurate

Filtered results
***************
RANKED	run.v 295	organise 0.09476	manage 0.07973	execute 0.07905	handle 0.07782	operate 0.07612	govern 0.07573	fill 0.07474	go 0.07329	chair 0.07189	avoid 0.07180	cover 0.07153	extend 0.07092	flee 0.06972	use 0.06814	contradict 0.06789	scurry 0.06783	sprint 0.06686	rush 0.06662	complete 0.06657	proceed 0.06628	include 0.06435	work 0.06428	stretch 0.06305	control 0.06298	appear 0.05635	last 0.05414	flow 0.05355	function 0.05097	total 0.04864	functioning 0.04640	working 0.04570	training 0.04018

Test context:
***************
run.v	296	25	anyway here are some static pictures of the boat - it is driven by a brushless motor driving a prop - but when it 's __running__ you ca n't see it .
Contexts for target running are: ['advmod_when', 'nsubj_it', "aux_'s", 'conjI_prop', 'ccomp_see']
Contexts in vocabulary for target running are: ['advmod_when', 'nsubj_it', "aux_'s", 'conjI_prop', 'ccomp_see']
Top most similar embeddings: running 0.02568	runing 0.02082	raining 0.02064	snowing 0.02047	pissing 0.01910	drizzling 0.01881	peeing 0.01875	shining 0.01865	shinning 0.01849	hurting 0.01847

Generated lemmatized results
***************
GENERATED	run.v 296 ::: rain;snow;piss;drizzle;pee;shin;hurt;misbehave;reboot;short

Filtered results
***************
RANKED	run.v 296	flow 0.01760	go 0.01704	functioning 0.01642	function 0.01642	execute 0.01606	sprint 0.01592	stretch 0.01588	working 0.01577	work 0.01577	operate 0.01544	scurry 0.01524	rush 0.01519	control 0.01510	use 0.01495	fill 0.01465	appear 0.01451	proceed 0.01446	chair 0.01446	contradict 0.01405	flee 0.01356	extend 0.01356	last 0.01337	organise 0.01328	handle 0.01309	avoid 0.01255	govern 0.01254	manage 0.01230	complete 0.01194	cover 0.01193	total 0.01103	include 0.01067	training 0.00879

Test context:
***************
run.v	297	7	last year , for example , we __ran__ 2,659 elections in a median time of 40 days. and , 92.5 % of these elections were run within 56 days. this is quite a remarkable record and we are very proud of it .
Contexts for target ran are: ['tmod_year', 'punct_,', 'prep:for_example', 'punct_,', 'nsubj_we', 'rootI_*root*', 'dobj_elections', 'prep:in_time', 'punct_.', 'cc_and', 'punct_,', 'conj_run', 'punct_.', 'dep_record', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target ran are: ['tmod_year', 'punct_,', 'prep:for_example', 'punct_,', 'nsubj_we', 'rootI_*root*', 'dobj_elections', 'prep:in_time', 'punct_.', 'cc_and', 'punct_,', 'conj_run', 'punct_.', 'dep_record', 'punct_.']
Top most similar embeddings: ran 0.00003	undertook 0.00002	began 0.00002	totaled 0.00002	oversaw 0.00002	gigged 0.00002	leapt 0.00002	rallied 0.00002	totalled 0.00002	runs 0.00002

Generated lemmatized results
***************
GENERATED	run.v 297 ::: undertake;begin;total;oversee;gigged;leap;rally;win;organise;compete

Filtered results
***************
RANKED	run.v 297	total 0.00002	organise 0.00002	rush 0.00002	go 0.00002	last 0.00001	sprint 0.00001	manage 0.00001	proceed 0.00001	operate 0.00001	flee 0.00001	complete 0.00001	scurry 0.00001	work 0.00001	cover 0.00001	extend 0.00001	appear 0.00001	chair 0.00001	function 0.00001	handle 0.00001	flow 0.00001	avoid 0.00001	execute 0.00001	stretch 0.00001	include 0.00001	govern 0.00001	use 0.00001	control 0.00001	fill 0.00001	contradict 0.00001	working 0.00001	functioning 0.00000	training 0.00000

Test context:
***************
run.v	298	9	this is an excellent and important discussion because it __runs__ counter to most of the stock talk of the past generation .
Contexts for target runs are: ['mark_because', 'nsubj_it', 'advclI_discussion', 'advmod_counter']
Contexts in vocabulary for target runs are: ['mark_because', 'nsubj_it', 'advclI_discussion', 'advmod_counter']
Top most similar embeddings: runs 0.05920	ran 0.04302	run 0.04149	goes 0.04044	veers 0.03975	executes 0.03926	feels 0.03879	impinges 0.03873	rotates 0.03861	circulates 0.03860

Generated lemmatized results
***************
GENERATED	run.v 298 ::: go;veer;execute;feel;impinge;rotate;circulate;proliferate;oscillate;disappear

Filtered results
***************
RANKED	run.v 298	go 0.04044	execute 0.03926	operate 0.03825	appear 0.03759	last 0.03643	avoid 0.03526	function 0.03504	flow 0.03479	use 0.03436	extend 0.03411	contradict 0.03406	complete 0.03386	manage 0.03384	stretch 0.03345	cover 0.03293	fill 0.03231	proceed 0.03172	organise 0.03100	handle 0.03092	work 0.03001	rush 0.02940	govern 0.02918	flee 0.02899	include 0.02893	control 0.02844	total 0.02745	scurry 0.02689	functioning 0.02619	chair 0.02554	sprint 0.02488	working 0.02218	training 0.01647

Test context:
***************
run.v	299	17	rumor has it that apple is just b4 offering a cheap ( $ 500 ) computer that __runs__ the bullet-proof os-x operating system .
Contexts for target runs are: ['nsubj_that', 'rcmodI_computer', 'dobj_system']
Contexts in vocabulary for target runs are: ['nsubj_that', 'rcmodI_computer', 'dobj_system']
Top most similar embeddings: runs 0.13435	calibrates 0.10702	reconfigures 0.10417	emulates 0.10157	syncs 0.10127	operates 0.10027	synchronises 0.09808	enslaves 0.09803	installs 0.09801	simulates 0.09650

Generated lemmatized results
***************
GENERATED	run.v 299 ::: calibrate;reconfigures;emulate;sync;operate;synchronise;enslave;install;simulate;circumvent

Filtered results
***************
RANKED	run.v 299	operate 0.10027	use 0.09076	govern 0.09076	manage 0.08870	execute 0.08842	organise 0.08110	extend 0.08084	control 0.07970	handle 0.07957	complete 0.07906	include 0.07758	cover 0.07732	stretch 0.07622	last 0.07581	fill 0.07408	flow 0.07198	avoid 0.07160	work 0.07159	function 0.07144	contradict 0.06983	go 0.06948	flee 0.06582	functioning 0.06402	appear 0.06397	scurry 0.06236	total 0.06102	proceed 0.06045	sprint 0.06033	rush 0.05844	chair 0.05513	working 0.05502	training 0.04060

Test context:
***************
run.v	300	4	" why do you __run__ from me ?
Contexts for target run are: ["punct_''", 'advmod_why', 'aux_do', 'nsubj_you', 'rootI_*root*', 'prep:from_me', 'punct_?', 'dep_<eol>']
Contexts in vocabulary for target run are: ['advmod_why', 'aux_do', 'nsubj_you', 'rootI_*root*', 'prep:from_me', 'punct_?']
Top most similar embeddings: want 0.01231	run 0.01216	wnat 0.01195	procrastinate 0.01188	agree/disagree 0.01171	need 0.01094	want/need 0.01090	cower 0.01076	agonise 0.01074	rememeber 0.01066

Generated lemmatized results
***************
GENERATED	run.v 300 ::: want;wnat;procrastinate;need;cower;agonise;rememeber;expect;think;raed

Filtered results
***************
RANKED	run.v 300	go 0.00989	flee 0.00890	operate 0.00844	rush 0.00822	proceed 0.00799	organise 0.00787	scurry 0.00782	use 0.00778	manage 0.00771	execute 0.00760	contradict 0.00759	appear 0.00755	handle 0.00754	fill 0.00724	extend 0.00718	include 0.00692	avoid 0.00684	govern 0.00668	cover 0.00652	stretch 0.00651	work 0.00610	sprint 0.00601	last 0.00591	flow 0.00578	complete 0.00576	chair 0.00530	control 0.00517	working 0.00513	total 0.00492	function 0.00481	functioning 0.00453	training 0.00335

Test context:
***************
side.n	301	29	on sunday at craven cottage , jose mourinho and his all stars exhibited all of the above symptoms and they were made to pay the price by a fulham __side__ that had in previous weeks woken up after matches with their heads kicked in .
Contexts for target side are: ['det_a', 'amod_fulham', 'prep:byI_pay', 'rcmod_had']
Contexts in vocabulary for target side are: ['det_a', 'prep:byI_pay', 'rcmod_had']
Top most similar embeddings: side 0.10500	sackful 0.08335	bucketload 0.08126	boatload 0.08092	frenchwoman 0.07957	motor-boat 0.07848	mix-up 0.07846	c-section 0.07834	bucketful 0.07685	raditech 0.07637

Generated lemmatized results
***************
GENERATED	side.n 301 ::: sackful;bucketload;boatload;frenchwoman;bucketful;raditech;fella;frenchman;halfpenny;passerby

Filtered results
***************
RANKED	side.n 301	team 0.06841	flank 0.06838	faction 0.06788	standpoint 0.06727	hand 0.06717	perspective 0.06680	bank 0.06674	edge 0.06659	position 0.06474	aspect 0.06451	area 0.06381	fringe 0.06305	facet 0.06217	contingent 0.06214	shore 0.06184	surface 0.06047	view 0.05810	boundary 0.05791	part 0.05406	ally 0.05247	divide 0.05155	responsibility 0.05144	conversely 0.04208	you 0.03748	instead 0.03652	against 0.03537

Test context:
***************
side.n	302	2	on our __side__ : provide more aid , untied to trade ; write off debt ; help with good governance and infrastructure ; training to the soldiers , with un blessing , in conflict resolution ; encouraging investment ; and access to our markets so that we practise the free trade we are so fond of preaching .
Contexts for target side are: ['poss_our', 'root:onI_*root*']
Contexts in vocabulary for target side are: ['poss_our', 'root:onI_*root*']
Top most similar embeddings: side 0.25494	otherhand 0.19011	right-hand-side 0.18937	sides 0.18929	handside 0.18782	hit-list 0.18594	death-bed 0.18573	doorsteps 0.18158	flank 0.17986	quarter-deck 0.17933

Generated lemmatized results
***************
GENERATED	side.n 302 ::: otherhand;handside;doorstep;flank;teamsheet;sufferance;backbench;matchdays;shore;mantlepiece

Filtered results
***************
RANKED	side.n 302	flank 0.17986	shore 0.17609	hand 0.16370	edge 0.15731	fringe 0.15286	team 0.15031	bank 0.14478	standpoint 0.14430	surface 0.14093	boundary 0.14035	perspective 0.13967	view 0.13855	position 0.13470	aspect 0.13396	ally 0.13252	contingent 0.12874	faction 0.12862	area 0.12852	facet 0.12727	part 0.12422	responsibility 0.12197	divide 0.11116	against 0.09469	conversely 0.08738	you 0.08452	instead 0.08238

Test context:
***************
side.n	303	11	if you want to find someone who can compose the biblical __side__ , write us .
Contexts for target side are: ['det_the', 'amod_biblical', 'dobjI_compose']
Contexts in vocabulary for target side are: ['det_the', 'amod_biblical', 'dobjI_compose']
Top most similar embeddings: side 0.11112	pericope 0.08971	pastorals 0.08715	martyrology 0.08700	kerygma 0.08564	story-line 0.08445	prayer-book 0.08443	sides 0.08436	eulogies 0.08428	recensions 0.08285

Generated lemmatized results
***************
GENERATED	side.n 303 ::: pericope;pastoral;martyrology;kerygma;eulogy;recensions;receptus;refutation;epic;targums

Filtered results
***************
RANKED	side.n 303	flank 0.07308	standpoint 0.07105	shore 0.07013	perspective 0.06916	fringe 0.06908	edge 0.06859	boundary 0.06777	aspect 0.06761	faction 0.06720	part 0.06703	surface 0.06695	team 0.06669	view 0.06446	position 0.06444	bank 0.06300	facet 0.06299	hand 0.06257	contingent 0.06102	area 0.06015	divide 0.06006	ally 0.05571	responsibility 0.05314	against 0.04160	instead 0.03752	conversely 0.03610	you 0.03301

Test context:
***************
side.n	304	6	this requires some action from your __side__ : if you get the message that a spy is reversed , remember the city where he came from , go directly to the empire map and send a spy to that city .
Contexts for target side are: ['poss_your', 'prep:fromI_action']
Contexts in vocabulary for target side are: ['poss_your', 'prep:fromI_action']
Top most similar embeddings: side 0.23728	sides 0.19075	right-hand-side 0.18668	handside 0.18045	backbenches 0.17405	nearside 0.17248	backside 0.17035	handstick 0.16902	left-side 0.16879	window-sill 0.16847

Generated lemmatized results
***************
GENERATED	side.n 304 ::: handside;backbench;nearside;backside;handstick;wingtip;earlobe;mantlepiece;sickbed;buttock

Filtered results
***************
RANKED	side.n 304	flank 0.16280	perspective 0.15720	team 0.15652	standpoint 0.15568	faction 0.15488	bank 0.14507	hand 0.14505	edge 0.14472	area 0.14334	position 0.14033	shore 0.13920	surface 0.13791	fringe 0.13660	ally 0.13588	view 0.12975	boundary 0.12850	part 0.12642	contingent 0.12561	responsibility 0.12406	aspect 0.12375	facet 0.11981	against 0.10370	divide 0.10057	you 0.09921	instead 0.09905	conversely 0.08310

Test context:
***************
side.n	305	8	then would that thou wert on the other __side__ of christ .
Contexts for target side are: ['det_the', 'amod_other', 'prep:onI_wert', 'prep:of_christ']
Contexts in vocabulary for target side are: ['det_the', 'amod_other', 'prep:of_christ']
Top most similar embeddings: side 0.13680	syde 0.09611	sides 0.09493	charisms 0.08979	hiri 0.08847	mercy-seat 0.08772	hand 0.08737	artifices 0.08607	perfections 0.08581	instrumentality 0.08568

Generated lemmatized results
***************
GENERATED	side.n 305 ::: syde;charisms;hiri;hand;artifice;perfection;instrumentality;gospell;apostle;solemnity

Filtered results
***************
RANKED	side.n 305	hand 0.08737	flank 0.07955	aspect 0.07898	facet 0.07696	shore 0.07640	part 0.07382	faction 0.07326	team 0.07270	edge 0.07243	standpoint 0.07151	fringe 0.07125	surface 0.07105	area 0.06979	bank 0.06849	contingent 0.06790	perspective 0.06737	boundary 0.06627	ally 0.06627	position 0.06452	responsibility 0.06229	view 0.06224	divide 0.05383	against 0.03980	conversely 0.03760	instead 0.03541	you 0.03221

Test context:
***************
side.n	306	9	12/31/04 - david magda says : on the flip __side__ , if you have a unix-y back-end ( e.g. , nis ) and would like the minority windows clients to log in you could try pgina : http://pgina.xpasystems.com / 1/1/05 - pete says : thanks for the great article .
Contexts for target side are: ['det_the', 'amod_flip', 'dep:onI_says']
Contexts in vocabulary for target side are: ['det_the', 'amod_flip']
Top most similar embeddings: side 0.28771	sides 0.20630	left-side 0.19508	handside 0.19456	right-hand-side 0.19281	winline 0.19210	doorframe 0.18935	sidewall 0.18569	nearside 0.18295	otherside 0.18144

Generated lemmatized results
***************
GENERATED	side.n 306 ::: handside;winline;doorframe;sidewall;nearside;otherside;wingtip;hypotenuse;touchline;upperside

Filtered results
***************
RANKED	side.n 306	flank 0.17239	edge 0.16925	shore 0.16741	surface 0.15502	fringe 0.15450	team 0.15164	hand 0.15023	standpoint 0.14803	aspect 0.14716	perspective 0.14421	position 0.14284	facet 0.14255	bank 0.14181	area 0.13961	part 0.13849	faction 0.13780	view 0.13550	boundary 0.13491	ally 0.12688	divide 0.12608	contingent 0.11826	responsibility 0.11282	instead 0.09384	against 0.09261	conversely 0.08475	you 0.07480

Test context:
***************
side.n	307	2	on which __side__ shall i be , when all these transitory things are done away with , when the dead have risen from their graves , when the great congregation shall stand upon the land , and upon the sea , when every valley , and every mountain , and every river , and every sea , shall be crowded with multitudes standing in thick array ?
Contexts for target side are: ['depI_on', 'dep_shall']
Contexts in vocabulary for target side are: ['depI_on', 'dep_shall']
Top most similar embeddings: side 0.17832	death-bed 0.15518	2la 0.15439	message 0.15145	plenary-admin@wsis-cs.org 0.15082	sufferance 0.15077	whereto 0.14957	doeth 0.14900	off-side 0.14716	turne 0.14709

Generated lemmatized results
***************
GENERATED	side.n 307 ::: message;sufferance;whereto;doeth;turne;wouldest;mouseover;soone;petitioner;wold

Filtered results
***************
RANKED	side.n 307	hand 0.13256	flank 0.12813	against 0.12789	edge 0.12625	fringe 0.12281	surface 0.12128	shore 0.12045	aspect 0.11985	boundary 0.11875	bank 0.11598	faction 0.11489	team 0.11336	position 0.11321	perspective 0.11280	standpoint 0.11271	facet 0.11214	divide 0.11130	contingent 0.11122	ally 0.11092	part 0.11008	instead 0.10982	conversely 0.10817	responsibility 0.10659	view 0.10649	you 0.10235	area 0.10171

Test context:
***************
side.n	308	18	this will help the younger generation to know and understand better its neighbors living just on the other __side__ of the mediterranean .
Contexts for target side are: ['det_the', 'amod_other', 'prep:onI_living', 'prep:of_mediterranean']
Contexts in vocabulary for target side are: ['det_the', 'amod_other', 'prep:onI_living', 'prep:of_mediterranean']
Top most similar embeddings: side 0.07134	sides 0.05219	shores 0.04803	peripheries 0.04787	sea-coast 0.04698	flank 0.04688	fringes 0.04600	shore 0.04510	otherside 0.04494	edge 0.04474

Generated lemmatized results
***************
GENERATED	side.n 308 ::: shore;periphery;flank;fringe;otherside;edge;hilltop;mountaintops;seaboard;archipelago

Filtered results
***************
RANKED	side.n 308	shore 0.04803	flank 0.04688	fringe 0.04600	edge 0.04474	hand 0.03992	part 0.03889	bank 0.03862	surface 0.03765	facet 0.03661	boundary 0.03653	aspect 0.03609	area 0.03586	faction 0.03282	contingent 0.03211	standpoint 0.03166	view 0.03111	ally 0.02989	team 0.02876	position 0.02732	perspective 0.02699	responsibility 0.02597	divide 0.02342	conversely 0.01594	instead 0.01382	against 0.01362	you 0.01276

Test context:
***************
side.n	309	16	under zeldman 's leadership , the group shifted its focus from browser makers to the other __side__ of the web standards equation--the developers and authoring tools responsible for the morass of nonstandard code found on the web today .
Contexts for target side are: ['det_the', 'amod_other', 'prep:toI_shifted', 'prep:of_equation']
Contexts in vocabulary for target side are: ['det_the', 'amod_other', 'prep:toI_shifted', 'prep:of_equation']
Top most similar embeddings: side 0.07675	sides 0.05114	right-hand-side 0.05038	left-side 0.04791	handside 0.04438	flank 0.04276	enantiomer 0.04265	syde 0.04263	supply-side 0.04261	c-terminus 0.04241

Generated lemmatized results
***************
GENERATED	side.n 309 ::: handside;flank;enantiomer;syde;nearside;end;extremity;quadrant;lh;periphery

Filtered results
***************
RANKED	side.n 309	flank 0.04276	fringe 0.04096	aspect 0.03920	part 0.03789	hand 0.03784	edge 0.03757	shore 0.03647	facet 0.03611	standpoint 0.03598	faction 0.03563	area 0.03303	boundary 0.03286	position 0.03249	perspective 0.03186	surface 0.03176	bank 0.03150	team 0.03125	contingent 0.03074	ally 0.02997	view 0.02644	responsibility 0.02543	divide 0.02417	against 0.01626	instead 0.01554	conversely 0.01528	you 0.01215

Test context:
***************
side.n	310	13	gattlinburg , tennessee is a touristy town to stay in on the north __side__ of the park .
Contexts for target side are: ['det_the', 'amod_north', 'pcomp:onI_in', 'prep:of_park']
Contexts in vocabulary for target side are: ['det_the', 'amod_north', 'pcomp:onI_in', 'prep:of_park']
Top most similar embeddings: side 0.07682	otherside 0.05355	sea-coast 0.05234	flank 0.05230	sides 0.05201	right-hand-side 0.04997	handside 0.04936	edge 0.04903	periphery 0.04868	corner 0.04830

Generated lemmatized results
***************
GENERATED	side.n 310 ::: otherside;flank;handside;edge;periphery;corner;perimeter;outskirt;ridgeline;shore

Filtered results
***************
RANKED	side.n 310	flank 0.05230	edge 0.04903	shore 0.04653	fringe 0.04629	boundary 0.04397	area 0.03840	surface 0.03722	aspect 0.03686	bank 0.03582	part 0.03503	hand 0.03209	team 0.03205	position 0.03163	facet 0.03130	view 0.03087	standpoint 0.03045	faction 0.03007	perspective 0.02890	divide 0.02645	contingent 0.02603	ally 0.02583	responsibility 0.02531	against 0.01551	conversely 0.01432	instead 0.01373	you 0.01309

Test context:
***************
tell.v	311	24	he held obi-wan loosely , gently stroking his back he knew now that it did n't matter what sampris said , or what yoda __told__ him .
Contexts for target told are: ['dobj_what', 'nsubj_yoda', 'conjI_said', 'dobj_him']
Contexts in vocabulary for target told are: ['dobj_what', 'nsubj_yoda', 'conjI_said', 'dobj_him']
Top most similar embeddings: told 0.06645	tells 0.05086	telling 0.04894	warned 0.04774	tell 0.04638	chides 0.04552	reminded 0.04481	chided 0.04419	telt 0.04374	upbraid 0.04371

Generated lemmatized results
***************
GENERATED	tell.v 311 ::: warn;chide;remind;telt;upbraid;implore;promise;know;blurt;accuse

Filtered results
***************
RANKED	tell.v 311	instruct 0.03843	assure 0.03719	order 0.03684	inform 0.03523	describe 0.03438	recount 0.03366	explain 0.03325	narrate 0.03215	impart 0.02896	notify 0.02834	communicate 0.02703

Test context:
***************
tell.v	312	3	our engineering department __tell__ me tests are now underway and they are hopeful of having the system up and running november/december .
Contexts for target tell are: ['nsubj_department', 'rootI_*root*', 'ccomp_underway', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target tell are: ['nsubj_department', 'rootI_*root*', 'ccomp_underway', 'punct_.']
Top most similar embeddings: tell 0.05415	said 0.05183	says 0.05087	told 0.04971	confirms 0.04904	tells 0.04902	recommends 0.04807	believes 0.04807	anticipates 0.04803	reckons 0.04775

Generated lemmatized results
***************
GENERATED	tell.v 312 ::: say;confirm;recommend;believe;anticipate;reckon;advise;inform;suggest;explain

Filtered results
***************
RANKED	tell.v 312	inform 0.04751	explain 0.04680	assure 0.04326	notify 0.04172	describe 0.04131	recount 0.04113	instruct 0.04032	order 0.03577	communicate 0.03548	narrate 0.03460	impart 0.02956

Test context:
***************
tell.v	313	47	i have n't found any negative side effects ... xp does n't seem to know the difference ( i can still log into xp using " john peterson " ) , but now vid and my servers realize i 'm me again without me having to continually __tell__ them !
Contexts for target tell are: ['aux_to', 'advmod_continually', 'xcompI_having', 'dobj_them']
Contexts in vocabulary for target tell are: ['aux_to', 'advmod_continually', 'xcompI_having', 'dobj_them']
Top most similar embeddings: tell 0.06245	disabuse 0.05572	remind 0.05524	berate 0.05504	re-adjust 0.05439	browbeat 0.05413	manhandle 0.05375	recalibrate 0.05318	re-train 0.05287	re-educate 0.05207

Generated lemmatized results
***************
GENERATED	tell.v 313 ::: disabuse;remind;berate;browbeat;manhandle;recalibrate;sanitise;dehumanise;cremate;embarass

Filtered results
***************
RANKED	tell.v 313	inform 0.04801	instruct 0.04515	explain 0.04391	notify 0.04243	narrate 0.04235	assure 0.04157	communicate 0.04127	recount 0.04076	impart 0.04041	describe 0.03955	order 0.02844

Test context:
***************
tell.v	314	4	" i used to __tell__ him , ' you 're beautiful , ' " says noonan , with a warm smile , " and he 'd look at me as if to say , ' i know. ' "
Contexts for target tell are: ['aux_to', 'xcompI_used', 'dobj_him']
Contexts in vocabulary for target tell are: ['aux_to', 'xcompI_used', 'dobj_him']
Top most similar embeddings: tell 0.13609	disabuse 0.12057	harrass 0.11563	idolise 0.11436	cremate 0.11377	unnerve 0.11264	re-assure 0.11249	baby-sit 0.11037	pressurize 0.11029	rile 0.10995

Generated lemmatized results
***************
GENERATED	tell.v 314 ::: disabuse;harrass;idolise;cremate;unnerve;pressurize;rile;bewitch;berate;overawe

Filtered results
***************
RANKED	tell.v 314	inform 0.10871	describe 0.10232	assure 0.09651	instruct 0.09515	notify 0.09162	explain 0.08951	narrate 0.08938	impart 0.08435	communicate 0.08359	recount 0.07876	order 0.05997

Test context:
***************
tell.v	315	13	so in 1986 i sent a resume over to mgm , and they __told__ me the next day that they wanted to hire me yet it took eight months before my first starting day .
Contexts for target told are: ['nsubj_they', 'conjI_sent', 'dobj_me', 'tmod_day', 'ccomp_wanted']
Contexts in vocabulary for target told are: ['nsubj_they', 'conjI_sent', 'dobj_me', 'tmod_day', 'ccomp_wanted']
Top most similar embeddings: told 0.03442	phoned 0.02484	asked 0.02408	telling 0.02385	knew 0.02229	begged 0.02222	nagged 0.02222	bethought 0.02204	reminded 0.02204	scolded 0.02190

Generated lemmatized results
***************
GENERATED	tell.v 315 ::: phone;ask;know;beg;nag;bethink;remind;scold;harangue;warn

Filtered results
***************
RANKED	tell.v 315	inform 0.02038	instruct 0.01924	assure 0.01916	order 0.01832	recount 0.01769	explain 0.01693	notify 0.01689	impart 0.01541	narrate 0.01524	describe 0.01496	communicate 0.01495

Test context:
***************
tell.v	316	11	very few people can as yet see that the lie we __tell__ ourselves about eternal life is directly related to war .
Contexts for target tell are: ['nsubj_we', 'rcmodI_lie', 'dobj_ourselves', 'prep:about_life']
Contexts in vocabulary for target tell are: ['nsubj_we', 'rcmodI_lie', 'dobj_ourselves', 'prep:about_life']
Top most similar embeddings: tell 0.06272	telling 0.05035	deluding 0.04609	disabuse 0.04527	remind 0.04523	told 0.04458	fantasize 0.04376	delude 0.04362	reassure 0.04209	lied 0.04170

Generated lemmatized results
***************
GENERATED	tell.v 316 ::: delude;disabuse;remind;fantasize;reassure;lie;ask;philosophise;brag;deceive

Filtered results
***************
RANKED	tell.v 316	inform 0.03896	assure 0.03755	explain 0.03569	narrate 0.03442	instruct 0.03401	recount 0.03337	describe 0.03237	communicate 0.03219	notify 0.03193	impart 0.03137	order 0.02430

Test context:
***************
tell.v	317	1	he __told__ me , " stay with your civilian clothes .
Contexts for target told are: ['nsubj_he', 'rootI_*root*', 'dobj_me', 'punct_,', "punct_''", 'dep_stay', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target told are: ['nsubj_he', 'rootI_*root*', 'dobj_me', 'punct_,', 'dep_stay', 'punct_.']
Top most similar embeddings: told 0.01930	tells 0.01557	chided 0.01458	implores 0.01452	implored 0.01412	quipped 0.01399	warned 0.01395	counseled 0.01382	panted 0.01381	scolded 0.01370

Generated lemmatized results
***************
GENERATED	tell.v 317 ::: chide;implore;quip;warn;counsel;pant;scold;drawl;smirk;bethink

Filtered results
***************
RANKED	tell.v 317	assure 0.01355	inform 0.01157	instruct 0.01094	recount 0.01086	narrate 0.01073	explain 0.01068	order 0.01042	describe 0.00977	notify 0.00916	impart 0.00764	communicate 0.00755

Test context:
***************
tell.v	318	5	j. reep wrote me and __told__ me the following about a heat shrink that would seal out water : " i noticed on your website you mentioned that heat shrink did not seal to the wire and water would by capillary action enter the splice .
Contexts for target told are: ['conjI_wrote', 'dobj_me', 'xcomp_seal']
Contexts in vocabulary for target told are: ['conjI_wrote', 'dobj_me', 'xcomp_seal']
Top most similar embeddings: told 0.13082	reminded 0.09820	asked 0.09571	telling 0.09538	begged 0.09387	instructed 0.09339	implored 0.09312	tells 0.09290	entreated 0.09228	persuaded 0.09134

Generated lemmatized results
***************
GENERATED	tell.v 318 ::: remind;ask;beg;instruct;implore;entreat;persuade;kiss;beseech;exhort

Filtered results
***************
RANKED	tell.v 318	instruct 0.09339	inform 0.08102	assure 0.07949	order 0.07808	narrate 0.07155	recount 0.07035	explain 0.06782	describe 0.06584	notify 0.06576	impart 0.06444	communicate 0.05845

Test context:
***************
tell.v	319	24	dear word detective : i am an orthopedic surgeon in los angeles and when our patients break a bone or something , we always __tell__ them that it will heal " like gangbusters " to denote that it will heal well .
Contexts for target tell are: ['advcl_break', 'punct_,', 'nsubj_we', 'advmod_always', 'conjI_surgeon', 'dobj_them', 'ccomp_heal']
Contexts in vocabulary for target tell are: ['advcl_break', 'punct_,', 'nsubj_we', 'advmod_always', 'conjI_surgeon', 'dobj_them', 'ccomp_heal']
Top most similar embeddings: tell 0.00580	admonish 0.00479	forgive 0.00467	ask 0.00467	warn 0.00455	prayed 0.00451	knew 0.00451	exhort 0.00446	pray 0.00445	recommend 0.00442

Generated lemmatized results
***************
GENERATED	tell.v 319 ::: admonish;forgive;ask;warn;pray;know;exhort;recommend;beseech;implore

Filtered results
***************
RANKED	tell.v 319	assure 0.00403	notify 0.00400	instruct 0.00398	explain 0.00386	inform 0.00373	narrate 0.00339	order 0.00331	recount 0.00323	impart 0.00323	describe 0.00318	communicate 0.00269

Test context:
***************
tell.v	320	9	robi damelin took part in this visit , and __tells__ the story this way : " we arrived at the roadblock and came face to face with the terrible and harsh reality of the day-to-day life of the palestinians living under cruel occupation .
Contexts for target tells are: ['conjI_took', 'dobj_story', 'dep_way']
Contexts in vocabulary for target tells are: ['conjI_took', 'dobj_story', 'dep_way']
Top most similar embeddings: tells 0.11065	told 0.09747	telling 0.09023	tell 0.08930	retells 0.08710	wove 0.08602	recounts 0.08271	re-told 0.08252	rewrote 0.08155	re-wrote 0.08034

Generated lemmatized results
***************
GENERATED	tell.v 320 ::: retell;weave;recount;rewrite;divulge;blurt;wiggle;resurrect;dramatise;write

Filtered results
***************
RANKED	tell.v 320	recount 0.08271	narrate 0.07756	inform 0.07752	explain 0.07353	assure 0.07275	describe 0.06729	instruct 0.06436	communicate 0.06365	order 0.06144	impart 0.05862	notify 0.05456

Test context:
***************
terrible.a	321	9	after going through a day and a half with __terrible__ sinus headaches , my wife , after watching your video , applied the techniques from the video and wham , my sinuses cleared .
Contexts for target terrible are: ['amodI_headaches']
Contexts in vocabulary for target terrible are: ['amodI_headaches']
Top most similar embeddings: terrible 0.53411	dreadful 0.46644	awful 0.46261	horrible 0.45036	horrendous 0.44689	tension-type 0.42974	appalling 0.42775	horrific 0.41620	near-fatal 0.41375	hideous 0.41311

Generated lemmatized results
***************
GENERATED	terrible.a 321 ::: dreadful;awful;horrible;horrendous;appalling;horrific;hideous;frightful;ghastly;niggly

Filtered results
***************
RANKED	terrible.a 321	dreadful 0.46644	awful 0.46261	horrible 0.45036	appalling 0.42775	horrific 0.41620	atrocious 0.39821	bad 0.39808	severe 0.39758	terrifying 0.37786	horrifying 0.36652	unpleasant 0.36415	fearsome 0.35684	deplorable 0.35453	shocking 0.35365	frightening 0.35145	formidable 0.32202	poignant 0.31770	abhorrent 0.31565	negative 0.30862

Test context:
***************
terrible.a	322	8	there were also pieces that would have been __terrible__ in any environment .
Contexts for target terrible are: ['nsubj_that', 'aux_would', 'aux_have', 'cop_been', 'rcmodI_pieces', 'prep:in_environment']
Contexts in vocabulary for target terrible are: ['nsubj_that', 'aux_would', 'aux_have', 'cop_been', 'rcmodI_pieces', 'prep:in_environment']
Top most similar embeddings: unimaginable 0.01145	unthinkable 0.01124	forgivable 0.01065	terrible 0.01025	unobtainable 0.01020	intolerable 0.01010	unbearable 0.01002	disastrous 0.00999	horrendous 0.00990	unsaleable 0.00978

Generated lemmatized results
***************
GENERATED	terrible.a 322 ::: unimaginable;unthinkable;forgivable;unobtainable;intolerable;unbearable;disastrous;horrendous;unsaleable;unheard

Filtered results
***************
RANKED	terrible.a 322	awful 0.00959	horrible 0.00919	dreadful 0.00918	terrifying 0.00918	appalling 0.00896	shocking 0.00862	deplorable 0.00855	horrific 0.00826	atrocious 0.00815	horrifying 0.00813	bad 0.00811	frightening 0.00807	abhorrent 0.00790	unpleasant 0.00783	poignant 0.00736	severe 0.00731	formidable 0.00690	fearsome 0.00630	negative 0.00628

Test context:
***************
terrible.a	323	7	the eu tax cartel would have a __terrible__ effect on the u.s. economy .
Contexts for target terrible are: ['amodI_effect']
Contexts in vocabulary for target terrible are: ['amodI_effect']
Top most similar embeddings: terrible 0.50867	dreadful 0.44342	awful 0.43596	horrible 0.43034	appalling 0.42402	baneful 0.41876	life-altering 0.41484	horrendous 0.41290	stomach-churning 0.41287	unwonted 0.41248

Generated lemmatized results
***************
GENERATED	terrible.a 323 ::: dreadful;awful;horrible;appalling;baneful;horrendous;unwonted;devastating;baleful;frightful

Filtered results
***************
RANKED	terrible.a 323	dreadful 0.44342	awful 0.43596	horrible 0.43034	appalling 0.42402	horrific 0.40527	terrifying 0.40304	horrifying 0.39463	atrocious 0.38970	bad 0.37947	shocking 0.37876	deplorable 0.37802	frightening 0.37531	severe 0.37313	unpleasant 0.37038	fearsome 0.35859	poignant 0.34922	negative 0.34678	formidable 0.34234	abhorrent 0.32582

Test context:
***************
terrible.a	324	4	this is clearly a __terrible__ and shameful blot on un peacekeeping .
Contexts for target terrible are: ['amodI_blot', 'cc_and', 'conj_shameful']
Contexts in vocabulary for target terrible are: ['amodI_blot', 'cc_and', 'conj_shameful']
Top most similar embeddings: terrible 0.13717	dreadful 0.12804	horrible 0.12485	appalling 0.12329	hideous 0.12162	awful 0.11967	horrendous 0.11721	horrific 0.11680	shameful 0.11566	frightful 0.11563

Generated lemmatized results
***************
GENERATED	terrible.a 324 ::: dreadful;horrible;appalling;hideous;awful;horrendous;horrific;shameful;frightful;disgusting

Filtered results
***************
RANKED	terrible.a 324	dreadful 0.12804	horrible 0.12485	appalling 0.12329	awful 0.11967	horrific 0.11680	horrifying 0.10728	atrocious 0.10682	deplorable 0.10624	shocking 0.10483	terrifying 0.10271	unpleasant 0.09661	abhorrent 0.09628	frightening 0.09342	poignant 0.08542	bad 0.08360	severe 0.08330	fearsome 0.08086	formidable 0.07878	negative 0.07593

Test context:
***************
terrible.a	325	56	the yells of the soldiers , the wild war-whoops of the indians , the screams of the terrified women and children , the rattle of rifle shots , shouts of command , the cursing of the maddened soldiers already firing the nearest teepees , contributed to the horrors of the battle , which was made more __terrible__ by the presence of mothers and babies in the blue rifle smoke that made the dawn more dim .
Contexts for target terrible are: ['advmod_more', 'acompI_made']
Contexts in vocabulary for target terrible are: ['advmod_more', 'acompI_made']
Top most similar embeddings: terrible 0.24867	awful 0.21497	horrible 0.21296	dreadful 0.20966	terrifying 0.20351	miserable 0.20073	bearable 0.20063	frightful 0.20052	livable 0.19866	horrendous 0.19701

Generated lemmatized results
***************
GENERATED	terrible.a 325 ::: awful;horrible;dreadful;terrifying;miserable;bearable;frightful;livable;horrendous;hideous

Filtered results
***************
RANKED	terrible.a 325	awful 0.21497	horrible 0.21296	dreadful 0.20966	terrifying 0.20351	appalling 0.19647	horrific 0.19616	frightening 0.19153	horrifying 0.19101	poignant 0.19055	shocking 0.18983	severe 0.18963	atrocious 0.18822	deplorable 0.18746	unpleasant 0.18477	fearsome 0.18337	formidable 0.18023	bad 0.17366	abhorrent 0.17015	negative 0.15696

Test context:
***************
terrible.a	326	3	i loved some __terrible__ way he lived in his mind and tried to be decent to others .
Contexts for target terrible are: ['amodI_way']
Contexts in vocabulary for target terrible are: ['amodI_way']
Top most similar embeddings: terrible 0.50358	awful 0.44825	dreadful 0.44289	horrible 0.43731	appalling 0.43470	cruelest 0.41383	god-awful 0.41309	horrendous 0.41214	horrific 0.40905	frightful 0.40685

Generated lemmatized results
***************
GENERATED	terrible.a 326 ::: awful;dreadful;horrible;appalling;cruel;horrendous;horrific;frightful;godawful;atrocious

Filtered results
***************
RANKED	terrible.a 326	awful 0.44825	dreadful 0.44289	horrible 0.43731	appalling 0.43470	horrific 0.40905	atrocious 0.40122	terrifying 0.39423	horrifying 0.39404	bad 0.38226	shocking 0.37674	deplorable 0.37188	unpleasant 0.36885	frightening 0.36709	severe 0.35530	fearsome 0.35010	poignant 0.34830	abhorrent 0.33900	formidable 0.33751	negative 0.33040

Test context:
***************
terrible.a	327	5	' ' the overcrowding is __terrible__ , it 's an undeniable reality.''(1 ) over the years , there has been a steady stream of allegations about physical punishments amounting to torture or cruel , inhuman or degrading treatment ; including boys being kicked , beaten , suspended upside down , having plastic bags put over their heads , being beaten on the back with a hammer or having their hands and feet scalded .
Contexts for target terrible are: ["punct_'", "punct_'", 'nsubj_overcrowding', 'cop_is', 'depI_stream', 'punct_,', 'ccomp_reality', 'punct_.', "punct_''", 'dep_1', 'prep:over_years', 'punct_,']
Contexts in vocabulary for target terrible are: ["punct_'", "punct_'", 'nsubj_overcrowding', 'cop_is', 'depI_stream', 'punct_,', 'ccomp_reality', 'punct_.', 'dep_1', 'prep:over_years', 'punct_,']
Top most similar embeddings: pronounced 0.00022	deplorable 0.00022	inexcusable 0.00022	rife 0.00022	unthinkable 0.00022	snowballing 0.00021	normalised 0.00021	appalling 0.00021	regrettable 0.00021	horrific 0.00021

Generated lemmatized results
***************
GENERATED	terrible.a 327 ::: pronounced;deplorable;inexcusable;rife;unthinkable;snowballing;normalised;appalling;regrettable;horrific

Filtered results
***************
RANKED	terrible.a 327	deplorable 0.00022	appalling 0.00021	horrific 0.00021	bad 0.00020	atrocious 0.00020	abhorrent 0.00019	shocking 0.00019	horrifying 0.00018	awful 0.00017	terrifying 0.00017	dreadful 0.00017	horrible 0.00016	frightening 0.00015	poignant 0.00015	severe 0.00014	unpleasant 0.00013	formidable 0.00012	negative 0.00012	fearsome 0.00011

Test context:
***************
terrible.a	328	16	they transformed edgar allan poe 's vertiginous short story of being swept into a huge and __terrible__ whirlpool by a raging hurricane that " the oldest seaman in norway never experienced " into a musical/dance/theatre extravganza .
Contexts for target terrible are: ['conjI_huge']
Contexts in vocabulary for target terrible are: ['conjI_huge']
Top most similar embeddings: terrible 0.50946	awful 0.44375	horrible 0.44159	appalling 0.42803	dreadful 0.42627	hideous 0.42577	horrendous 0.42385	terrifying 0.41954	frightful 0.40266	ghastly 0.39901

Generated lemmatized results
***************
GENERATED	terrible.a 328 ::: awful;horrible;appalling;dreadful;hideous;horrendous;terrifying;frightful;ghastly;atrocious

Filtered results
***************
RANKED	terrible.a 328	awful 0.44375	horrible 0.44159	appalling 0.42803	dreadful 0.42627	terrifying 0.41954	atrocious 0.39728	horrific 0.38910	horrifying 0.38895	fearsome 0.38269	frightening 0.37628	shocking 0.37089	unpleasant 0.35666	formidable 0.35613	bad 0.34929	deplorable 0.34114	poignant 0.33950	severe 0.33568	abhorrent 0.32957	negative 0.31885

Test context:
***************
terrible.a	329	10	and when you think about it , that 's pretty __terrible__ .
Contexts for target terrible are: ['cc_and', 'advcl_think', 'punct_,', 'nsubj_that', "cop_'s", 'advmod_pretty', 'rootI_*root*', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target terrible are: ['cc_and', 'advcl_think', 'punct_,', 'nsubj_that', "cop_'s", 'advmod_pretty', 'rootI_*root*', 'punct_.']
Top most similar embeddings: hillarious 0.00375	awful 0.00364	terrible 0.00346	forgivable 0.00343	mindblowing 0.00339	horrible 0.00339	scarey 0.00338	disgusting 0.00336	ridiculous 0.00336	unbelievable 0.00332

Generated lemmatized results
***************
GENERATED	terrible.a 329 ::: hillarious;awful;forgivable;mindblowing;horrible;scarey;disgusting;ridiculous;unbelievable;unbelieveable

Filtered results
***************
RANKED	terrible.a 329	awful 0.00364	horrible 0.00339	shocking 0.00323	appalling 0.00316	frightening 0.00314	dreadful 0.00314	atrocious 0.00310	terrifying 0.00301	bad 0.00282	deplorable 0.00278	horrifying 0.00274	abhorrent 0.00269	horrific 0.00261	unpleasant 0.00242	poignant 0.00238	formidable 0.00180	severe 0.00179	fearsome 0.00171	negative 0.00162

Test context:
***************
terrible.a	330	15	henry abramovitch : absolutely , and it 's very 'i mean besides being illegal and __terrible__ and immoral , but psychologically i think the great danger , as we know from the cold war , is that if you build a wall then you don 't know what 's going on in the other side of the wall .
Contexts for target terrible are: ['conjI_illegal']
Contexts in vocabulary for target terrible are: ['conjI_illegal']
Top most similar embeddings: terrible 0.46306	horrendous 0.41909	awful 0.41812	appalling 0.41580	horrible 0.41491	dreadful 0.40588	horrific 0.39667	atrocious 0.39653	disgraceful 0.39028	heinous 0.38897

Generated lemmatized results
***************
GENERATED	terrible.a 330 ::: horrendous;awful;appalling;horrible;dreadful;horrific;atrocious;disgraceful;heinous;unacceptable

Filtered results
***************
RANKED	terrible.a 330	awful 0.41812	appalling 0.41580	horrible 0.41491	dreadful 0.40588	horrific 0.39667	atrocious 0.39653	terrifying 0.38477	horrifying 0.37763	shocking 0.37706	abhorrent 0.37306	frightening 0.37000	deplorable 0.36223	bad 0.36152	unpleasant 0.36074	severe 0.34549	fearsome 0.33734	formidable 0.32001	negative 0.31841	poignant 0.29846

Test context:
***************
think.v	331	10	since there is never any shortage of darkness , i __think__ we should be allowed to pray for the grace to be victorious .
Contexts for target think are: ['advcl_is', 'punct_,', 'nsubj_i', 'rootI_*root*', 'ccomp_allowed', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target think are: ['advcl_is', 'punct_,', 'nsubj_i', 'rootI_*root*', 'ccomp_allowed', 'punct_.']
Top most similar embeddings: think 0.02371	forearmed 0.01896	says 0.01894	suppose 0.01864	gloats 0.01858	said 0.01849	believe 0.01843	contends 0.01793	avers 0.01790	daresay 0.01789

Generated lemmatized results
***************
GENERATED	think.v 331 ::: forearm;say;suppose;gloat;believe;contend;aver;daresay;debateable;know

Filtered results
***************
RANKED	think.v 331	suppose 0.01864	believe 0.01843	reckon 0.01746	assume 0.01671	recommend 0.01668	imagine 0.01642	consider 0.01585	feel 0.01577	guess 0.01550	anticipate 0.01480	suspect 0.01446	expect 0.01420	reason 0.01359	contemplate 0.01264	analyse 0.01031

Test context:
***************
think.v	332	1	shafer __thinks__ we 're going to cry , " he doesn 't get it! " in reply to his piece - " it " being the amazing world of the web and new media .
Contexts for target thinks are: ['nsubj_shafer', 'ccompI_get', 'ccomp_going']
Contexts in vocabulary for target thinks are: ['ccompI_get', 'ccomp_going']
Top most similar embeddings: thinks 0.26241	think 0.20586	knows 0.19834	reckons 0.18977	believes 0.18780	realizes 0.18773	realises 0.18515	says 0.18326	wants 0.18211	feels 0.18194

Generated lemmatized results
***************
GENERATED	think.v 332 ::: know;reckon;believe;realize;realise;say;want;feel;decide;gloat

Filtered results
***************
RANKED	think.v 332	reckon 0.18977	believe 0.18780	feel 0.18194	imagine 0.16564	consider 0.16485	expect 0.16197	suppose 0.15584	assume 0.15560	guess 0.15551	contemplate 0.15342	anticipate 0.15272	suspect 0.14563	recommend 0.14246	reason 0.13500	analyse 0.11671

Test context:
***************
think.v	333	4	isaac hayes seems to __think__ they 're heading too far to the right , though he certainly kept his mouth shut when they were going the hack on muslims , poofs and spastics. nicedream said ... the all important question : you can only watch one television show for the rest of your life .
Contexts for target think are: ['aux_to', 'xcompI_seems', 'ccomp_heading']
Contexts in vocabulary for target think are: ['aux_to', 'xcompI_seems', 'ccomp_heading']
Top most similar embeddings: think 0.12475	realize 0.09635	suggest 0.09442	know 0.09388	imply 0.09380	believe 0.09351	indicate 0.09341	anticipate 0.09287	assume 0.09263	insinuate 0.09198

Generated lemmatized results
***************
GENERATED	think.v 333 ::: realize;suggest;know;imply;believe;indicate;anticipate;assume;insinuate;say

Filtered results
***************
RANKED	think.v 333	believe 0.09351	anticipate 0.09287	assume 0.09263	reckon 0.08875	suppose 0.08526	imagine 0.08392	feel 0.08159	suspect 0.08123	guess 0.08057	contemplate 0.08021	consider 0.07862	expect 0.07552	recommend 0.06523	analyse 0.06330	reason 0.06212

Test context:
***************
think.v	334	4	i do n't ever __think__ it will be taken from us or destroyed .
Contexts for target think are: ['nsubj_i', 'aux_do', "neg_n't", 'advmod_ever', 'rootI_*root*', 'ccomp_taken', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target think are: ['nsubj_i', 'aux_do', "neg_n't", 'advmod_ever', 'rootI_*root*', 'ccomp_taken', 'punct_.']
Top most similar embeddings: think 0.01408	believe 0.01034	know 0.01020	forget 0.00994	thnk 0.00973	rememeber 0.00959	realize 0.00950	remember 0.00928	suppose 0.00906	imagine 0.00899

Generated lemmatized results
***************
GENERATED	think.v 334 ::: believe;know;forget;thnk;rememeber;realize;remember;suppose;imagine;reckon

Filtered results
***************
RANKED	think.v 334	believe 0.01034	suppose 0.00906	imagine 0.00899	reckon 0.00899	assume 0.00872	feel 0.00864	anticipate 0.00834	consider 0.00805	expect 0.00797	guess 0.00741	recommend 0.00740	suspect 0.00691	contemplate 0.00686	reason 0.00521	analyse 0.00461

Test context:
***************
think.v	335	13	the forms and buttons and stuff give the sense that every inch was __thought__ about and lovingly hand crafted .
Contexts for target thought are: ['mark_that', 'nsubjpass_inch', 'auxpass_was', 'ccompI_sense', 'ccomp_crafted']
Contexts in vocabulary for target thought are: ['mark_that', 'nsubjpass_inch', 'auxpass_was', 'ccompI_sense', 'ccomp_crafted']
Top most similar embeddings: thought 0.02224	believed 0.01957	pilfered 0.01905	wasted 0.01887	effaced 0.01846	rationalized 0.01841	understood 0.01836	concocted 0.01820	blunted 0.01815	realized 0.01811

Generated lemmatized results
***************
GENERATED	think.v 335 ::: believe;pilfer;waste;efface;rationalize;understand;concoct;blunt;realize;leaven

Filtered results
***************
RANKED	think.v 335	believe 0.01957	imagine 0.01750	reckon 0.01722	contemplate 0.01711	suppose 0.01710	assume 0.01671	anticipate 0.01615	suspect 0.01600	reason 0.01542	consider 0.01510	expect 0.01489	guess 0.01324	analyse 0.01217	recommend 0.01179	feel 0.01172

Test context:
***************
think.v	336	1	i __think__ there is a place in most investor 's portfolios to take speculative risks .
Contexts for target think are: ['nsubj_i', 'rootI_*root*', 'ccomp_is', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target think are: ['nsubj_i', 'rootI_*root*', 'ccomp_is', 'punct_.']
Top most similar embeddings: think 0.10932	2885557 0.10143	syph 0.08887	said 0.08612	ddarllen 0.08571	says 0.08508	believe 0.08423	gloats 0.08391	laur 0.08167	suppose 0.08126

Generated lemmatized results
***************
GENERATED	think.v 336 ::: syph;say;ddarllen;believe;gloat;laur;suppose;harpoole;fitsfile;suggest

Filtered results
***************
RANKED	think.v 336	believe 0.08423	suppose 0.08126	reckon 0.07895	assume 0.07482	imagine 0.07116	consider 0.07047	guess 0.06949	feel 0.06795	anticipate 0.06665	suspect 0.06485	recommend 0.06408	expect 0.06072	reason 0.05609	contemplate 0.05299	analyse 0.04847

Test context:
***************
think.v	337	16	in the process of searching for the right combination to bring out that flavor , we __think__ , we fail , we reflect , and hopefully , we succeed .
Contexts for target think are: ['punct_,', 'nsubj_we', 'parataxisI_fail', 'punct_,']
Contexts in vocabulary for target think are: ['punct_,', 'nsubj_we', 'parataxisI_fail', 'punct_,']
Top most similar embeddings: think 0.05555	believe 0.04811	opine 0.04784	hypothesize 0.04690	suppose 0.04650	know 0.04628	knaw 0.04567	assume 0.04556	reckon 0.04544	presume 0.04537

Generated lemmatized results
***************
GENERATED	think.v 337 ::: believe;opine;hypothesize;suppose;know;knaw;assume;reckon;presume;bewail

Filtered results
***************
RANKED	think.v 337	believe 0.04811	suppose 0.04650	assume 0.04556	reckon 0.04544	anticipate 0.04443	imagine 0.04242	expect 0.04212	suspect 0.04113	consider 0.04014	guess 0.03986	recommend 0.03961	reason 0.03941	contemplate 0.03912	feel 0.03815	analyse 0.03361

Test context:
***************
think.v	338	21	i discovered from the version number of setup.exe on my win 95 that it is the revision #1 , so i __think__ i might try installing win 98 instead .
Contexts for target think are: ['advmod_so', 'nsubj_i', 'depI_win', 'ccomp_try']
Contexts in vocabulary for target think are: ['advmod_so', 'nsubj_i', 'depI_win', 'ccomp_try']
Top most similar embeddings: think 0.08332	thnk 0.07006	hopefull 0.07003	supose 0.06644	reckon 0.06572	thinks 0.06140	let 0.06123	aslong 0.06064	unles 0.06063	thinkes 0.06043

Generated lemmatized results
***************
GENERATED	think.v 338 ::: thnk;hopefull;supose;reckon;let;aslong;unles;afraid;mabye;spose

Filtered results
***************
RANKED	think.v 338	reckon 0.06572	suppose 0.06024	guess 0.05776	believe 0.05651	feel 0.05353	assume 0.05298	imagine 0.05285	reason 0.05083	expect 0.05080	anticipate 0.04932	recommend 0.04821	suspect 0.04771	consider 0.04749	contemplate 0.04390	analyse 0.03597

Test context:
***************
think.v	339	18	in any case , when we look back , we can surely say that the great revolution modernism __thought__ it was bringing about simply failed .
Contexts for target thought are: ['mark_that', 'nsubj_modernism', 'ccompI_say', 'ccomp_bringing']
Contexts in vocabulary for target thought are: ['mark_that', 'nsubj_modernism', 'ccompI_say', 'ccomp_bringing']
Top most similar embeddings: thought 0.05461	believed 0.04478	thinks 0.04189	doubted 0.04065	meant 0.03938	felt 0.03934	understood 0.03927	beleived 0.03893	knew 0.03866	understands 0.03864

Generated lemmatized results
***************
GENERATED	think.v 339 ::: believe;doubt;mean;felt;understand;beleived;know;appreciate;belived;realize

Filtered results
***************
RANKED	think.v 339	believe 0.04478	feel 0.03513	suppose 0.03355	reckon 0.03307	imagine 0.03295	expect 0.03283	reason 0.03261	anticipate 0.03259	contemplate 0.03253	assume 0.03247	suspect 0.03241	consider 0.03169	guess 0.02970	recommend 0.02661	analyse 0.02209

Test context:
***************
think.v	340	2	you would __think__ that he would give paul the benefit of the doubt , and obey the scripture until such time as this explanation appeared .
Contexts for target think are: ['nsubj_you', 'aux_would', 'rootI_*root*', 'ccomp_give', 'punct_,', 'cc_and', 'conj_obey', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target think are: ['nsubj_you', 'aux_would', 'rootI_*root*', 'ccomp_give', 'punct_,', 'cc_and', 'conj_obey', 'punct_.']
Top most similar embeddings: think 0.00373	believe 0.00320	know 0.00291	acknowledge 0.00284	anticipate 0.00284	opine 0.00281	appreciate 0.00280	agree 0.00279	hearken 0.00276	sweare 0.00274

Generated lemmatized results
***************
GENERATED	think.v 340 ::: believe;know;acknowledge;anticipate;opine;appreciate;agree;hearken;sweare;pray

Filtered results
***************
RANKED	think.v 340	believe 0.00320	anticipate 0.00284	suppose 0.00271	imagine 0.00265	reckon 0.00264	consider 0.00262	expect 0.00260	feel 0.00256	recommend 0.00256	assume 0.00254	guess 0.00239	suspect 0.00236	contemplate 0.00210	reason 0.00207	analyse 0.00170

Test context:
***************
thus.r	341	19	it is relatively simple to find lenses which will maintain reasonably good central resolution the central resolution , but __thus__ far , i have not been able to achieve an edge resolution better than about 0.1 mm with " off the shelf " lenses .
Contexts for target thus are: ['advmodI_far']
Contexts in vocabulary for target thus are: ['advmodI_far']
Top most similar embeddings: thus 0.53967	so 0.40656	however 0.39923	proably 0.38699	indeed 0.38687	therefore 0.38432	nonetheless 0.38211	moreover 0.37714	certainly 0.37661	how 0.37509

Generated lemmatized results
***************
GENERATED	thus.r 341 ::: so;however;proably;indeed;therefore;nonetheless;moreover;certainly;how;still

Filtered results
***************
RANKED	thus.r 341	so 0.40656	therefore 0.38432	consequently 0.36106	hence 0.35504	accordingly 0.31896	there 0.28732	this 0.22667

Test context:
***************
thus.r	342	20	the calculation is based on the loan 's original principal , so fellows who are not recent graduates , and __thus__ have been making loan payments , are treated the same as new graduates .
Contexts for target thus are: ['advmodI_graduates']
Contexts in vocabulary for target thus are: ['advmodI_graduates']
Top most similar embeddings: thus 0.50509	dually 0.41935	therefore 0.41417	however 0.41366	indeed 0.40222	nonetheless 0.40115	moreover 0.39906	consequently 0.39854	additionally 0.39684	furthermore 0.39499

Generated lemmatized results
***************
GENERATED	thus.r 342 ::: dually;therefore;however;indeed;nonetheless;moreover;consequently;additionally;furthermore;finally

Filtered results
***************
RANKED	thus.r 342	therefore 0.41417	consequently 0.39854	hence 0.37991	so 0.35616	accordingly 0.34378	there 0.31212	this 0.21640

Test context:
***************
thus.r	343	0	__thus__ for example , ophthalmologists will need to know in a given population how many people of a particular age group and/or sex will suffer a retina detachment in the course of a year .
Contexts for target thus are: ['advmodI_for']
Contexts in vocabulary for target thus are: ['advmodI_for']
Top most similar embeddings: thus 0.52466	however 0.41613	indeed 0.41228	therefore 0.41086	also 0.40534	even 0.40363	perhaps 0.40217	unfortunately 0.39986	nonetheless 0.39952	certainly 0.39706

Generated lemmatized results
***************
GENERATED	thus.r 343 ::: however;indeed;therefore;also;even;perhaps;unfortunately;nonetheless;certainly;finally

Filtered results
***************
RANKED	thus.r 343	therefore 0.41086	consequently 0.38099	so 0.37212	hence 0.35424	accordingly 0.35418	there 0.29645	this 0.22586

Test context:
***************
thus.r	344	28	although he 's pitched 200 innings for the first time since mike had a girlfriend ( 200 innings being 6 more than any met has pitched this season __thus__ far ) , pedro has , again , seemed annoyingly off-balance lately .
Contexts for target thus are: ['advmodI_far']
Contexts in vocabulary for target thus are: ['advmodI_far']
Top most similar embeddings: thus 0.53967	so 0.40656	however 0.39923	proably 0.38699	indeed 0.38687	therefore 0.38432	nonetheless 0.38211	moreover 0.37714	certainly 0.37661	how 0.37509

Generated lemmatized results
***************
GENERATED	thus.r 344 ::: so;however;proably;indeed;therefore;nonetheless;moreover;certainly;how;still

Filtered results
***************
RANKED	thus.r 344	so 0.40656	therefore 0.38432	consequently 0.36106	hence 0.35504	accordingly 0.31896	there 0.28732	this 0.22667

Test context:
***************
thus.r	345	5	grey 's reformist doctrines can __thus__ be seen , not as an attempt to set out on the road to democracy , but as a means to strengthen the power of his own class , the aristocracy .
Contexts for target thus are: ['advmodI_seen']
Contexts in vocabulary for target thus are: ['advmodI_seen']
Top most similar embeddings: thus 0.52501	however 0.42596	therefore 0.42519	proably 0.42044	furthermore 0.41798	also 0.41463	moreover 0.41463	futhermore 0.41450	standardly 0.41443	indeed 0.41306

Generated lemmatized results
***************
GENERATED	thus.r 345 ::: however;therefore;proably;furthermore;also;moreover;futhermore;standardly;indeed;nonetheless

Filtered results
***************
RANKED	thus.r 345	therefore 0.42519	consequently 0.39754	hence 0.39119	so 0.36149	accordingly 0.34548	there 0.31495	this 0.22292

Test context:
***************
thus.r	346	3	a clear imperative __thus__ confronts american progressives -- that intricate ( and frequently fragile ) web of communities comprised of people of color , feminists , gays and lesbians , the poor and working class , as well as ethnic whites who value ethnicity , indeed all who have been systematically disenfrancised and dehumanized under the once ascendant " traditional values " of pre-civil rights america .
Contexts for target thus are: ['advmodI_confronts']
Contexts in vocabulary for target thus are: ['advmodI_confronts']
Top most similar embeddings: thus 0.52179	finally 0.42042	therefore 0.40867	however 0.40805	furthermore 0.40685	meanwhile 0.40570	nonetheless 0.40489	moreover 0.40488	spuriously 0.39904	ultimately 0.39280

Generated lemmatized results
***************
GENERATED	thus.r 346 ::: finally;therefore;however;furthermore;meanwhile;nonetheless;moreover;spuriously;ultimately;also

Filtered results
***************
RANKED	thus.r 346	therefore 0.40867	consequently 0.38213	hence 0.37189	so 0.34204	accordingly 0.33732	there 0.29813	this 0.22111

Test context:
***************
thus.r	347	42	we struggle to think of any other minority group in society who would be so easily and conveniently stereotyped and are saddened that law abiding , genuine football supporters of both sexes , all ages and backgrounds who want to stand are __thus__ thought of and portrayed as would be hooligans merely because they prefer to stand .
Contexts for target thus are: ['advmodI_thought']
Contexts in vocabulary for target thus are: ['advmodI_thought']
Top most similar embeddings: thus 0.51367	proably 0.43139	however 0.42255	therefore 0.41671	nonetheless 0.41546	furthermore 0.41217	indeed 0.40898	apprently 0.40781	moreover 0.40624	also 0.40525

Generated lemmatized results
***************
GENERATED	thus.r 347 ::: proably;however;therefore;nonetheless;furthermore;indeed;apprently;moreover;also;futhermore

Filtered results
***************
RANKED	thus.r 347	therefore 0.41671	consequently 0.39653	hence 0.38227	so 0.37447	accordingly 0.34714	there 0.31155	this 0.21628

Test context:
***************
thus.r	348	7	the kind of control he exercises is __thus__ likely to be limited to " passive " control such as inspection of produced goods and testing to insure that quality standards are being met .
Contexts for target thus are: ['advmodI_likely']
Contexts in vocabulary for target thus are: ['advmodI_likely']
Top most similar embeddings: thus 0.52432	therefore 0.43734	however 0.42563	furthermore 0.42042	moreover 0.41767	nonetheless 0.41233	indeed 0.41025	also 0.40719	consequently 0.40693	epistemically 0.40130

Generated lemmatized results
***************
GENERATED	thus.r 348 ::: therefore;however;furthermore;moreover;nonetheless;indeed;also;consequently;epistemically;nevertheless

Filtered results
***************
RANKED	thus.r 348	therefore 0.43734	consequently 0.40693	hence 0.39103	so 0.35827	accordingly 0.35232	there 0.29758	this 0.22430

Test context:
***************
thus.r	349	0	__thus__ they can connect with " who found them " .
Contexts for target thus are: ['advmodI_connect']
Contexts in vocabulary for target thus are: ['advmodI_connect']
Top most similar embeddings: thus 0.50616	however 0.40376	spuriously 0.40353	therefore 0.40318	feasibly 0.40276	then 0.39984	also 0.39782	futhermore 0.39705	reproducibly 0.39644	reciprocally 0.39589

Generated lemmatized results
***************
GENERATED	thus.r 349 ::: however;spuriously;therefore;feasibly;then;also;futhermore;reproducibly;reciprocally;furthermore

Filtered results
***************
RANKED	thus.r 349	therefore 0.40318	consequently 0.38035	hence 0.37264	so 0.35485	accordingly 0.33584	there 0.29755	this 0.22693

Test context:
***************
thus.r	350	13	the experiment also helps us in understanding the language of dreams , and __thus__ begins the process of interpretation .
Contexts for target thus are: ['advmodI_begins']
Contexts in vocabulary for target thus are: ['advmodI_begins']
Top most similar embeddings: thus 0.53669	however 0.41421	therefore 0.41360	spuriously 0.40958	moreover 0.40827	then 0.40605	furthermore 0.40566	futhermore 0.40519	indeed 0.40253	finally 0.40206

Generated lemmatized results
***************
GENERATED	thus.r 350 ::: however;therefore;spuriously;moreover;then;furthermore;futhermore;indeed;finally;bloodily

Filtered results
***************
RANKED	thus.r 350	therefore 0.41360	hence 0.39025	consequently 0.38398	so 0.37269	accordingly 0.35418	there 0.30813	this 0.22218

Test context:
***************
wind.n	351	2	because the __wind__ was going with us , we had to circle back behind the dog 's barking to come up from the rear .
Contexts for target wind are: ['det_the', 'nsubjI_going']
Contexts in vocabulary for target wind are: ['det_the', 'nsubjI_going']
Top most similar embeddings: wind 0.24373	winds 0.20179	breeze 0.18405	homesters 0.18264	grundys 0.18127	tide 0.17912	cloudbase 0.17835	sontarans 0.17656	clag 0.17608	kaptain 0.17589

Generated lemmatized results
***************
GENERATED	wind.n 351 ::: breeze;homesters;grundys;tide;cloudbase;sontarans;clag;kaptain;westerly;dwarfers

Filtered results
***************
RANKED	wind.n 351	breeze 0.18405	gust 0.17247	current 0.15709	blast 0.15023	whirlwind 0.14941	air 0.14765	gas 0.14265	vagary 0.13788	fart 0.12996	flatulence 0.12352

Test context:
***************
wind.n	352	28	it is particularly unfortunate for wind resources given the cost reductions wind has been able to achieve and the momentum that was building for the sustainable development of __wind__ in a number of states .
Contexts for target wind are: ['prep:ofI_development']
Contexts in vocabulary for target wind are: ['prep:ofI_development']
Top most similar embeddings: wind 0.47954	winds 0.38501	hydro-electricity 0.35546	satipatthana 0.35286	westerlies 0.34996	breeze 0.34946	windpower 0.34876	hydro-power 0.34864	windfarm 0.34693	magnetron 0.34545

Generated lemmatized results
***************
GENERATED	wind.n 352 ::: satipatthana;westerly;breeze;windpower;windfarm;magnetron;renewables;pbrs;bipv;turbine

Filtered results
***************
RANKED	wind.n 352	breeze 0.34946	current 0.32313	gust 0.32245	whirlwind 0.31312	blast 0.29390	gas 0.29308	air 0.29056	flatulence 0.28634	vagary 0.24268	fart 0.23915

Test context:
***************
wind.n	353	6	instead we read about fire , __wind__ , power , food , joy , unanimity and sharing - in short , a communism of love ( acts 2 and 4 ) .
Contexts for target wind are: ['conjI_fire']
Contexts in vocabulary for target wind are: ['conjI_fire']
Top most similar embeddings: wind 0.49861	winds 0.41706	breeze 0.37529	gusts 0.37377	gust 0.36322	sleet 0.36320	gales 0.36049	tempests 0.35945	rain 0.35781	storm 0.35671

Generated lemmatized results
***************
GENERATED	wind.n 353 ::: breeze;gust;sleet;gale;tempest;rain;storm;headwind;crosswind;hailstone

Filtered results
***************
RANKED	wind.n 353	breeze 0.37529	gust 0.37377	blast 0.34732	air 0.33176	gas 0.31914	whirlwind 0.31575	current 0.31379	flatulence 0.29232	fart 0.27543	vagary 0.25871

Test context:
***************
wind.n	354	30	driven by impulse and pure terror , jerome veered right... running across the street , right in front of the explorer. *ka-thump!* he made it with inches to spare.... the __wind__ from the passing truck nearly knocked him down .
Contexts for target wind are: ['det_the', 'nsubjI_knocked', 'prep:from_truck']
Contexts in vocabulary for target wind are: ['det_the', 'nsubjI_knocked', 'prep:from_truck']
Top most similar embeddings: wind 0.12011	winds 0.09309	breeze 0.08948	gusts 0.08526	gust 0.08421	headwind 0.08373	crosswind 0.08218	billows 0.08145	gales 0.08059	blast 0.08033

Generated lemmatized results
***************
GENERATED	wind.n 354 ::: breeze;gust;headwind;crosswind;billow;gale;blast;westerly;clag;squall

Filtered results
***************
RANKED	wind.n 354	breeze 0.08948	gust 0.08526	blast 0.08033	whirlwind 0.07059	air 0.06908	current 0.06411	gas 0.06210	fart 0.06103	flatulence 0.05618	vagary 0.05066

Test context:
***************
wind.n	355	0	__wind__ still produces less than 1 % of u.s. electricity , and a single nuclear power plant can generate 1,300 mw , more electricity than four of the world 's largest wind farms combined and more than one-quarter of all the electricity generated by wind in the u.s. that said , wind has a lot going for it .
Contexts for target wind are: ['nsubjI_produces']
Contexts in vocabulary for target wind are: ['nsubjI_produces']
Top most similar embeddings: wind 0.47196	winds 0.38036	breeze 0.36334	gust 0.35997	turbine 0.34977	westerlies 0.34957	e-ram 0.34868	nordex 0.34805	rpcgen 0.34565	spectron 0.34395

Generated lemmatized results
***************
GENERATED	wind.n 355 ::: breeze;gust;turbine;westerly;nordex;rpcgen;spectron;magnetron;airstream;tailwind

Filtered results
***************
RANKED	wind.n 355	breeze 0.36334	gust 0.35997	blast 0.31499	gas 0.30610	air 0.30220	flatulence 0.30091	current 0.29878	whirlwind 0.29055	fart 0.27374	vagary 0.26116

Test context:
***************
wind.n	356	13	use the links below to answer the following general questions : what causes __wind__ ?
Contexts for target wind are: ['dobjI_causes']
Contexts in vocabulary for target wind are: ['dobjI_causes']
Top most similar embeddings: wind 0.48051	winds 0.40666	westerlies 0.37360	breeze 0.36799	downdraught 0.36400	gusts 0.36358	windchill 0.36356	cloudiness 0.36007	swell 0.35659	sea-sickness 0.35634

Generated lemmatized results
***************
GENERATED	wind.n 356 ::: westerly;breeze;downdraught;gust;windchill;cloudiness;swell;rainstorm;headwind;gale

Filtered results
***************
RANKED	wind.n 356	breeze 0.36799	gust 0.36358	current 0.33928	flatulence 0.32907	blast 0.32454	whirlwind 0.31366	air 0.31226	gas 0.30324	fart 0.26669	vagary 0.26165

Test context:
***************
wind.n	357	2	in light __winds__ ( under 10 knots ) , course " o " ( triangle , windward , leeward ) can be substituted .
Contexts for target winds are: ['amod_light', 'prep:inI_o', 'prep:under_knots']
Contexts in vocabulary for target winds are: ['amod_light', 'prep:inI_o']
Top most similar embeddings: winds 0.25645	wind 0.19996	breezes 0.19748	westerlies 0.19153	breeze 0.19125	gusts 0.18419	gales 0.17852	zephyrs 0.17662	rain 0.17533	headwind 0.17440

Generated lemmatized results
***************
GENERATED	wind.n 357 ::: breeze;westerly;gust;gale;zephyr;rain;headwind;thermal;current;fog

Filtered results
***************
RANKED	wind.n 357	breeze 0.19748	gust 0.18419	current 0.17340	air 0.15546	gas 0.15424	blast 0.14820	whirlwind 0.14776	flatulence 0.12477	fart 0.12013	vagary 0.11183

Test context:
***************
wind.n	358	4	at the point where __wind__ is generating 10 % to 20 % of the electricity that the system is delivering in a given hour , it is an issue that needs to be addressed , but that can probably be resolved with wind forecasting ( which is fairly accurate in the time frame of interest to utility system operators ) , system software adjustments , and other changes .
Contexts for target wind are: ['nsubjI_generating']
Contexts in vocabulary for target wind are: ['nsubjI_generating']
Top most similar embeddings: wind 0.48292	winds 0.38988	breeze 0.36748	gust 0.35265	windfarm 0.34828	westerlies 0.34746	turbine 0.34424	windpower 0.34099	turbines 0.33934	gusts 0.33922

Generated lemmatized results
***************
GENERATED	wind.n 358 ::: breeze;gust;windfarm;westerly;turbine;windpower;windfarms;gale;nordex;photovoltaics

Filtered results
***************
RANKED	wind.n 358	breeze 0.36748	gust 0.35265	blast 0.30679	current 0.30392	whirlwind 0.29080	gas 0.28709	air 0.28488	flatulence 0.27062	fart 0.25580	vagary 0.25181

Test context:
***************
wind.n	359	27	the night is a good place ; sand and stone , the moon and the pale stars , the red glow of the fire and the cold __wind__ 's quiet whisper along the crest of the dune .
Contexts for target wind are: ['det_the', 'amod_cold', 'possI_whisper', "possessive_'s"]
Contexts in vocabulary for target wind are: ['det_the', 'amod_cold', "possessive_'s"]
Top most similar embeddings: wind 0.13202	winds 0.10058	winde 0.10021	breeze 0.09826	westerlies 0.09431	weather 0.09294	airstream 0.09160	tyde 0.08986	cloudbase 0.08949	headwind 0.08944

Generated lemmatized results
***************
GENERATED	wind.n 359 ::: winde;breeze;westerly;weather;airstream;tyde;cloudbase;headwind;lamplight;sun

Filtered results
***************
RANKED	wind.n 359	breeze 0.09826	gust 0.08532	air 0.08119	blast 0.07537	current 0.07407	gas 0.07043	whirlwind 0.06990	fart 0.06223	flatulence 0.06132	vagary 0.05886

Test context:
***************
wind.n	360	59	3/03 akenglish midnight wind creations ' where did they go those soft summer nights dancing in the moonlight. fleeting moments of bliss when all was right , my path so straight , heaven at my gate. then you were gone , as if you never were. now alone , with all those broken dreams. scattered forever , upon the __winds__ of life .
Contexts for target winds are: ['det_the', 'prep:uponI_scattered', 'prep:of_life']
Contexts in vocabulary for target winds are: ['det_the', 'prep:of_life']
Top most similar embeddings: winds 0.24614	hurly-burly 0.20371	wind 0.19614	tempests 0.19296	precariousness 0.19196	storms 0.19101	gales 0.19090	mundanity 0.19018	dreariness 0.19011	tides 0.19009

Generated lemmatized results
***************
GENERATED	wind.n 360 ::: tempest;precariousness;storm;gale;mundanity;dreariness;tide;gust;decency;breeze

Filtered results
***************
RANKED	wind.n 360	gust 0.18861	breeze 0.18827	current 0.18756	vagary 0.18325	whirlwind 0.16630	blast 0.15461	air 0.14977	gas 0.14011	fart 0.12948	flatulence 0.12385

Test context:
***************
charge.v	361	3	annual fees are __charged__ on a pro-rata basis to correspond with the standardised renewal date in december .
Contexts for target charged are: ['nsubjpass_fees', 'auxpass_are', 'rootI_*root*', 'prep:on_basis', 'xcomp_correspond', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target charged are: ['nsubjpass_fees', 'auxpass_are', 'rootI_*root*', 'prep:on_basis', 'xcomp_correspond', 'punct_.']
Top most similar embeddings: charged 0.01699	calculated 0.01413	recomputed 0.01259	recalculated 0.01235	re-calculated 0.01230	levied 0.01221	reimbursed 0.01217	invoiced 0.01199	assessed 0.01187	arranged 0.01187

Generated lemmatized results
***************
GENERATED	charge.v 361 ::: calculate;recomputed;recalculate;levy;reimburse;invoice;assess;arrange;bill;expense

Filtered results
***************
RANKED	charge.v 361	levy 0.01221	cost 0.01078	recharge 0.01072	require 0.01031	take 0.00987	impose 0.00931	ask 0.00931	indict 0.00878	demand 0.00838	accuse 0.00819	rush 0.00813	dash 0.00804	attack 0.00790	fly 0.00712	run 0.00709	storm 0.00567

Test context:
***************
charge.v	362	14	meanwhile , george begins obsessive plans for his funeral ... george , suspicious , __charges__ to her room to confront them .
Contexts for target charges are: ['apposI_george', 'prep:to_room', 'infmod_confront']
Contexts in vocabulary for target charges are: ['apposI_george', 'prep:to_room', 'infmod_confront']
Top most similar embeddings: charges 0.08020	returns 0.06746	charge 0.06710	downstairs 0.06710	summons 0.06688	heir 0.06624	goeth 0.06578	flees 0.06541	upstairs 0.06523	pleads 0.06480

Generated lemmatized results
***************
GENERATED	charge.v 362 ::: return;downstairs;summon;heir;goeth;flee;upstairs;plead;stairs;trot

Filtered results
***************
RANKED	charge.v 362	levy 0.06347	dash 0.06144	cost 0.05646	rush 0.05547	recharge 0.05487	storm 0.05256	take 0.05254	fly 0.05175	demand 0.05072	run 0.05071	attack 0.05052	accuse 0.04969	indict 0.04610	impose 0.04590	ask 0.04189	require 0.04065

Test context:
***************
charge.v	363	6	pauline gilmore , 32 , was __charged__ with possessing a blast bomb , 14 bullets and 21 explosive pipe darts in a field at drumcree on wednesday morning .
Contexts for target charged are: ['nsubjpass_gilmore', 'auxpass_was', 'rootI_*root*', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target charged are: ['auxpass_was', 'rootI_*root*', 'punct_.']
Top most similar embeddings: charged 0.13712	amerced 0.10741	respited 0.10191	surcharged 0.10185	rebolted 0.10184	re-arrested 0.10176	tasked 0.10173	laureated 0.10153	billed 0.10133	recompressed 0.10109

Generated lemmatized results
***************
GENERATED	charge.v 363 ::: amerce;respite;surcharge;rebolted;task;laureated;bill;recompressed;arrest;arraign

Filtered results
***************
RANKED	charge.v 363	indict 0.09985	levy 0.09722	ask 0.09522	accuse 0.09117	rush 0.09025	recharge 0.08949	attack 0.08937	take 0.08928	require 0.08779	demand 0.08665	dash 0.08323	cost 0.08234	impose 0.08109	storm 0.07943	fly 0.07897	run 0.07461

Test context:
***************
charge.v	364	12	plug in you h 10 in the usb outlet and it will __charge__ without the plug in adaptor .
Contexts for target charge are: ['nsubj_it', 'aux_will', 'conjI_h', 'prep:without_plug']
Contexts in vocabulary for target charge are: ['nsubj_it', 'aux_will', 'conjI_h']
Top most similar embeddings: charge 0.09837	non-cancellable 0.07615	appeare 0.07593	oxidise 0.07548	incur 0.07286	proue 0.07257	recurse 0.07247	apear 0.07227	recharged 0.07212	emit 0.07208

Generated lemmatized results
***************
GENERATED	charge.v 364 ::: appeare;oxidise;incur;proue;recurse;apear;recharge;emit;refund;surcharge

Filtered results
***************
RANKED	charge.v 364	recharge 0.07212	cost 0.06930	levy 0.06808	impose 0.06502	require 0.06233	run 0.06134	take 0.06040	fly 0.05848	rush 0.05848	attack 0.05768	ask 0.05737	dash 0.05729	accuse 0.05667	demand 0.05644	indict 0.05641	storm 0.04994

Test context:
***************
charge.v	365	13	u.s. nevada trooper charged with reckless driving , manslaughter a state trooper was __charged__ monday with nine felony counts of reckless driving and involuntary manslaughter in a crash that killed four people .
Contexts for target charged are: ['nsubjpass_trooper', 'auxpass_was', 'rcmodI_manslaughter', 'dobj_monday', 'prep:with_counts']
Contexts in vocabulary for target charged are: ['auxpass_was', 'dobj_monday', 'prep:with_counts']
Top most similar embeddings: charged 0.12708	billed 0.08712	levied 0.08240	credited 0.07694	surcharged 0.07675	despatched 0.07659	arraigned 0.07637	bombarded 0.07627	capped 0.07600	debited 0.07514

Generated lemmatized results
***************
GENERATED	charge.v 365 ::: bill;levy;credit;surcharge;despatch;arraign;bombard;cap;debit;issue

Filtered results
***************
RANKED	charge.v 365	levy 0.08240	recharge 0.07470	indict 0.07385	attack 0.06841	rush 0.06806	impose 0.06656	accuse 0.06649	dash 0.06436	demand 0.06390	cost 0.06242	run 0.06240	take 0.06121	fly 0.06116	ask 0.06075	storm 0.05891	require 0.05770

Test context:
***************
charge.v	366	34	in spite of this , unaware of the booby traps laid all around them , the entire power core of the bush administration jumped on the niger documents as on a battle horse and __charged__ off into in a massive public relations blitz .
Contexts for target charged are: ['conjI_this', 'prt_off']
Contexts in vocabulary for target charged are: ['conjI_this', 'prt_off']
Top most similar embeddings: charged 0.20032	paid 0.15816	fobbed 0.15745	charging 0.15555	payed 0.15297	hacked 0.15184	charge 0.15172	puked 0.15097	snipped 0.15057	paying 0.15024

Generated lemmatized results
***************
GENERATED	charge.v 366 ::: pay;fob;hack;puke;snip;bill;rip;hustle;cap;flog

Filtered results
***************
RANKED	charge.v 366	recharge 0.14329	rush 0.14228	dash 0.14073	levy 0.13812	storm 0.13793	indict 0.13728	take 0.13515	attack 0.13333	cost 0.13308	accuse 0.13219	run 0.13185	ask 0.12652	fly 0.12529	demand 0.12373	require 0.12101	impose 0.11560

Test context:
***************
charge.v	367	22	the question is not an issue of supply and demand because the claim under examination is not " we are going to __charge__ a lot because we can get that price .
Contexts for target charge are: ['aux_to', 'xcompI_going', 'dobj_lot']
Contexts in vocabulary for target charge are: ['aux_to', 'xcompI_going', 'dobj_lot']
Top most similar embeddings: charge 0.11375	baby-sit 0.09495	rile 0.09263	re-shoot 0.08987	spend 0.08861	guzzle 0.08729	wheedle 0.08703	disgorge 0.08698	harrass 0.08686	off-load 0.08679

Generated lemmatized results
***************
GENERATED	charge.v 367 ::: rile;spend;guzzle;wheedle;disgorge;harrass;manhandle;babysit;bamboozle;overpay

Filtered results
***************
RANKED	charge.v 367	recharge 0.08502	take 0.08076	ask 0.07854	impose 0.07641	cost 0.07609	indict 0.07372	demand 0.07220	accuse 0.07199	fly 0.07178	levy 0.07062	rush 0.07055	run 0.06968	require 0.06930	attack 0.06754	dash 0.05837	storm 0.05672

Test context:
***************
charge.v	368	6	so who are the people being __charged__ with stolen property? he asked .
Contexts for target charged are: ['auxpass_being', 'partmodI_people', 'prep:with_property']
Contexts in vocabulary for target charged are: ['auxpass_being', 'partmodI_people', 'prep:with_property']
Top most similar embeddings: charged 0.12302	saddled 0.09115	surcharged 0.08905	burdened 0.08876	involved 0.08861	endued 0.08842	arrested 0.08769	encumbered 0.08755	prosecuted 0.08578	swindled 0.08541

Generated lemmatized results
***************
GENERATED	charge.v 368 ::: saddle;surcharge;burden;involve;endue;arrest;encumber;prosecute;swindle;deal

Filtered results
***************
RANKED	charge.v 368	indict 0.08172	levy 0.07999	recharge 0.07602	accuse 0.07444	attack 0.07428	take 0.07337	require 0.06921	impose 0.06860	dash 0.06807	rush 0.06719	fly 0.06416	ask 0.06382	demand 0.06198	cost 0.06093	run 0.06058	storm 0.06032

Test context:
***************
charge.v	369	4	commission is the amount __charged__ to execute a trade .
Contexts for target charged are: ['partmodI_amount', 'xcomp_execute']
Contexts in vocabulary for target charged are: ['partmodI_amount', 'xcomp_execute']
Top most similar embeddings: charged 0.24182	required 0.17775	levied 0.17526	paid 0.17080	allowed 0.17016	requested 0.16517	assigned 0.16393	needed 0.16373	used 0.16353	attempting 0.16252

Generated lemmatized results
***************
GENERATED	charge.v 369 ::: require;levy;pay;allow;request;assign;need;use;attempt;authorize

Filtered results
***************
RANKED	charge.v 369	require 0.17775	levy 0.17526	take 0.15166	demand 0.15002	recharge 0.14965	impose 0.14936	ask 0.14268	indict 0.14193	rush 0.14032	cost 0.13508	accuse 0.13218	run 0.13129	dash 0.12895	attack 0.12673	fly 0.12669	storm 0.12456

Test context:
***************
charge.v	370	9	realizing immediately that strangers have come , the animals __charge__ them and the horses began to fight .
Contexts for target charge are: ['nsubj_animals', 'depI_realizing', 'dobj_them', 'cc_and', 'conj_began']
Contexts in vocabulary for target charge are: ['nsubj_animals', 'depI_realizing', 'dobj_them', 'cc_and', 'conj_began']
Top most similar embeddings: petted 0.01698	quieted 0.01689	undressed 0.01665	panicked 0.01633	suckled 0.01628	reared 0.01625	cuddled 0.01623	outgrew 0.01617	tormenting 0.01590	revolted 0.01585

Generated lemmatized results
***************
GENERATED	charge.v 370 ::: pet;quiet;undress;panic;suckle;rear;cuddle;outgrow;torment;revolt

Filtered results
***************
RANKED	charge.v 370	rush 0.01451	fly 0.01419	attack 0.01323	recharge 0.01318	dash 0.01293	accuse 0.01281	run 0.01280	take 0.01280	storm 0.01261	cost 0.01238	demand 0.01216	levy 0.01171	impose 0.01099	indict 0.01093	ask 0.01057	require 0.00969

Test context:
***************
civil.a	371	18	going to court : civil trial procedure this pamphlet explains what happens when you go to court about __civil__ cases involving negligence or damages .
Contexts for target civil are: ['amodI_cases']
Contexts in vocabulary for target civil are: ['amodI_cases']
Top most similar embeddings: civil 0.52299	non-criminal 0.41016	medicolegal 0.40838	anti-trust 0.39465	non-family 0.38784	construction-related 0.38434	obstetrical 0.37964	medico-legal 0.37664	asbestos-related 0.37623	court-based 0.37560

Generated lemmatized results
***************
GENERATED	civil.a 371 ::: medicolegal;obstetrical;antitrust;pupal;criminal;extraterritorial;extrajudicial;restitutionary;abovementioned;nonmilitary

Filtered results
***************
RANKED	civil.a 371	domestic 0.34158	private 0.33046	nongovernmental 0.32671	personal 0.32216	civic 0.32049	individual 0.31953	social 0.31903	internal 0.31813	public 0.31042	ordinary 0.30592	general 0.29475	benevolent 0.29462	polite 0.28416	thoughtful 0.27801	friendly 0.27323	inoffensive 0.27046	cordial 0.25927	courteous 0.25734	elected 0.25341	cultured 0.24391	state 0.24099	citizen 0.23957	community 0.23050

Test context:
***************
civil.a	372	6	with all due respect to our __civil__ authorities and lawmakers , we are called to testify by word and action , to the essential truths of our faith .
Contexts for target civil are: ['amodI_authorities']
Contexts in vocabulary for target civil are: ['amodI_authorities']
Top most similar embeddings: civil 0.51592	precepting 0.38800	anti-trust 0.38701	prosecutorial 0.38438	regional/local 0.38261	state-level 0.38173	national/local 0.37910	host-nation 0.37853	non-police 0.37682	non-devolved 0.37519

Generated lemmatized results
***************
GENERATED	civil.a 372 ::: precepting;prosecutorial;prefectural;senatorial;czarist;local;cantonal;synodical;adminstrative;nonmilitary

Filtered results
***************
RANKED	civil.a 372	civic 0.35052	nongovernmental 0.34679	public 0.33520	domestic 0.32931	social 0.32634	internal 0.31370	private 0.31105	individual 0.30794	benevolent 0.30715	personal 0.29071	polite 0.28473	elected 0.28416	general 0.28316	friendly 0.28123	ordinary 0.27983	courteous 0.27722	thoughtful 0.27183	inoffensive 0.26034	cordial 0.25060	citizen 0.24700	cultured 0.24029	community 0.23820	state 0.23469

Test context:
***************
civil.a	373	7	it is contrary to the spirit of __civil__ law , and to the natural working of economic law .
Contexts for target civil are: ['amodI_law']
Contexts in vocabulary for target civil are: ['amodI_law']
Top most similar embeddings: civil 0.53582	antiterrorist 0.41283	anti-trust 0.39868	sumptuary 0.39337	extraterritorial 0.38791	medicolegal 0.38725	anti-trade 0.38638	burghal 0.38575	non-criminal 0.38499	levitical 0.38456

Generated lemmatized results
***************
GENERATED	civil.a 373 ::: antiterrorist;sumptuary;extraterritorial;medicolegal;burghal;levitical;antitrust;synodical;monarchic;criminal

Filtered results
***************
RANKED	civil.a 373	domestic 0.35575	private 0.34256	social 0.33426	internal 0.33305	civic 0.33037	nongovernmental 0.32855	public 0.32548	personal 0.31921	general 0.31326	ordinary 0.30928	benevolent 0.30811	polite 0.29450	individual 0.28773	inoffensive 0.28522	courteous 0.28038	friendly 0.27726	thoughtful 0.26875	citizen 0.26093	cordial 0.25684	elected 0.25034	community 0.24510	state 0.24102	cultured 0.23877

Test context:
***************
civil.a	374	30	yes , we occasionally get into some heated discussions here , and the language can get a bit colorful at times , but in general , the posters are relatively __civil__ and well-behaved .
Contexts for target civil are: ['prep:in_general', 'punct_,', 'nsubj_posters', 'cop_are', 'advmod_relatively', 'conjI_get', 'cc_and', 'conj_well-behaved']
Contexts in vocabulary for target civil are: ['prep:in_general', 'punct_,', 'nsubj_posters', 'cop_are', 'advmod_relatively', 'conjI_get', 'cc_and', 'conj_well-behaved']
Top most similar embeddings: polite 0.00243	well-behaved 0.00238	docile 0.00226	self-controlled 0.00225	well-mannered 0.00223	courteous 0.00223	respectful 0.00212	considerate 0.00212	approachable 0.00210	apolitical 0.00208

Generated lemmatized results
***************
GENERATED	civil.a 374 ::: polite;docile;courteous;respectful;considerate;approachable;apolitical;inoffensive;abstemious;discreet

Filtered results
***************
RANKED	civil.a 374	polite 0.00243	courteous 0.00223	inoffensive 0.00208	friendly 0.00191	thoughtful 0.00172	cordial 0.00171	benevolent 0.00151	cultured 0.00138	ordinary 0.00116	private 0.00108	personal 0.00099	public 0.00097	domestic 0.00096	social 0.00092	internal 0.00090	elected 0.00088	individual 0.00088	citizen 0.00086	civic 0.00086	general 0.00083	state 0.00076	community 0.00062	nongovernmental 0.00041

Test context:
***************
civil.a	375	14	lionel , singapore lebanon has overcome all adversities in the past , ranging from __civil__ wars to israeli invasion .
Contexts for target civil are: ['amodI_wars']
Contexts in vocabulary for target civil are: ['amodI_wars']
Top most similar embeddings: civil 0.54734	peloponnesian 0.40375	spanish-american 0.40266	sino-japanese 0.39951	franco-prussian 0.39392	inter-imperialist 0.38787	pre-world 0.38692	inter-state 0.38677	iraq-iran 0.38406	centuries-long 0.38403

Generated lemmatized results
***************
GENERATED	civil.a 375 ::: peloponnesian;napoleonic;hussite;crimean;intercommunal;maccabean;punic;internecine;yugoslavian;czarist

Filtered results
***************
RANKED	civil.a 375	internal 0.33893	domestic 0.33283	civic 0.33013	private 0.32277	nongovernmental 0.32138	social 0.31544	polite 0.30977	personal 0.30579	benevolent 0.29864	public 0.29494	general 0.28602	friendly 0.28477	ordinary 0.28213	individual 0.28136	courteous 0.27345	thoughtful 0.26654	cordial 0.26000	inoffensive 0.25736	elected 0.24153	cultured 0.24053	citizen 0.24053	state 0.23297	community 0.22185

Test context:
***************
civil.a	376	26	this means combating corruption , building strong and accountable public sectors which have the necessary staff to deliver vital services , and ensuring that parliaments , __civil__ society , and the media can monitor public spending and act as watchdogs against corruption .
Contexts for target civil are: ['amodI_society']
Contexts in vocabulary for target civil are: ['amodI_society']
Top most similar embeddings: civil 0.54632	linnean 0.41261	rapidly-expanding 0.40868	linnaean 0.39589	newly-founded 0.39497	twenty-first-century 0.39048	multi-religious 0.38996	euro-american 0.38789	anglo-japanese 0.38771	newly-established 0.38509

Generated lemmatized results
***************
GENERATED	civil.a 376 ::: linnean;linnaean;phytopathological;communistic;antislavery;neighbourly;spelaeological;anthroposophical;silesian;gerontological

Filtered results
***************
RANKED	civil.a 376	civic 0.36147	nongovernmental 0.34420	polite 0.33885	benevolent 0.33746	domestic 0.32787	social 0.32401	private 0.32095	internal 0.31782	friendly 0.31404	personal 0.30614	ordinary 0.29816	public 0.29740	general 0.29622	courteous 0.29535	thoughtful 0.28970	individual 0.28798	inoffensive 0.27981	cordial 0.27871	cultured 0.27625	elected 0.25323	citizen 0.24586	community 0.23229	state 0.22739

Test context:
***************
civil.a	377	10	truly classy people find a way to be polite , __civil__ and courteous .
Contexts for target civil are: ['depI_polite', 'cc_and', 'conj_courteous']
Contexts in vocabulary for target civil are: ['depI_polite', 'cc_and', 'conj_courteous']
Top most similar embeddings: courteous 0.11854	civil 0.11273	polite 0.11096	tactful 0.09820	personable 0.09713	well-mannered 0.09568	punctual 0.09493	good-humoured 0.09403	considerate 0.09236	mannered 0.09215

Generated lemmatized results
***************
GENERATED	civil.a 377 ::: courteous;polite;tactful;personable;punctual;considerate;mannered;humoured;attentive;freindly

Filtered results
***************
RANKED	civil.a 377	courteous 0.11854	polite 0.11096	thoughtful 0.08476	friendly 0.08391	cordial 0.08193	benevolent 0.07492	inoffensive 0.07207	personal 0.06871	domestic 0.06781	social 0.06738	civic 0.06593	cultured 0.06505	private 0.06453	internal 0.06189	ordinary 0.06185	individual 0.05976	public 0.05847	general 0.05417	elected 0.05311	citizen 0.05155	community 0.04809	nongovernmental 0.04781	state 0.04571

Test context:
***************
civil.a	378	26	not just another period piece on germany 's disturbing past , this film should have deep resonance for today 's movie fans who are concerned about __civil__ and human rights .
Contexts for target civil are: ['amodI_rights', 'cc_and', 'conj_human']
Contexts in vocabulary for target civil are: ['amodI_rights', 'cc_and', 'conj_human']
Top most similar embeddings: civil 0.14116	constitutional 0.09440	juridical 0.09436	legal 0.09274	political 0.09270	social 0.09263	peace-making 0.09248	human 0.09194	economic 0.09182	corporate/commercial 0.09172

Generated lemmatized results
***************
GENERATED	civil.a 378 ::: constitutional;juridical;legal;political;social;human;economic;antitrust;matrimonial;moral

Filtered results
***************
RANKED	civil.a 378	social 0.09263	civic 0.08709	domestic 0.08301	personal 0.08006	private 0.07937	friendly 0.07572	internal 0.07534	public 0.07486	individual 0.07274	polite 0.07181	benevolent 0.07105	courteous 0.06996	thoughtful 0.06992	inoffensive 0.06798	ordinary 0.06769	nongovernmental 0.06737	cordial 0.06526	general 0.06488	citizen 0.05935	cultured 0.05531	elected 0.05485	community 0.05414	state 0.04871

Test context:
***************
civil.a	379	9	spontaneous gestures are a pie in the face of __civil__ society .
Contexts for target civil are: ['amodI_society']
Contexts in vocabulary for target civil are: ['amodI_society']
Top most similar embeddings: civil 0.54632	linnean 0.41261	rapidly-expanding 0.40868	linnaean 0.39589	newly-founded 0.39497	twenty-first-century 0.39048	multi-religious 0.38996	euro-american 0.38789	anglo-japanese 0.38771	newly-established 0.38509

Generated lemmatized results
***************
GENERATED	civil.a 379 ::: linnean;linnaean;phytopathological;communistic;antislavery;neighbourly;spelaeological;anthroposophical;silesian;gerontological

Filtered results
***************
RANKED	civil.a 379	civic 0.36147	nongovernmental 0.34420	polite 0.33885	benevolent 0.33746	domestic 0.32787	social 0.32401	private 0.32095	internal 0.31782	friendly 0.31404	personal 0.30614	ordinary 0.29816	public 0.29740	general 0.29622	courteous 0.29535	thoughtful 0.28970	individual 0.28798	inoffensive 0.27981	cordial 0.27871	cultured 0.27625	elected 0.25323	citizen 0.24586	community 0.23229	state 0.22739

Test context:
***************
civil.a	380	1	since __civil__ discourse in our country is increasingly lacking , and the word insanity in this context implies a lack of such civility , how can that be a good thing for anybody or the mark of a great president? " eh , one episode , wha-evuh .
Contexts for target civil are: ['amodI_discourse']
Contexts in vocabulary for target civil are: ['amodI_discourse']
Top most similar embeddings: civil 0.49776	political-economic 0.38282	sociopolitical 0.37894	sino-japanese 0.37886	ecclesiological 0.37565	interreligious 0.37546	chivalric 0.37374	political-military 0.37344	ufological 0.37334	medicolegal 0.37318

Generated lemmatized results
***************
GENERATED	civil.a 380 ::: sociopolitical;ecclesiological;interreligious;chivalric;ufological;medicolegal;juristic;historiographic;missiological;synodical

Filtered results
***************
RANKED	civil.a 380	civic 0.34695	social 0.34139	public 0.33355	polite 0.32816	internal 0.32662	nongovernmental 0.32510	private 0.32420	domestic 0.32274	ordinary 0.31059	personal 0.30862	thoughtful 0.30801	benevolent 0.30031	general 0.29743	courteous 0.29586	friendly 0.28691	individual 0.28603	inoffensive 0.28377	cordial 0.28192	cultured 0.26665	elected 0.25907	citizen 0.25258	state 0.23619	community 0.22815

Test context:
***************
clean.v	381	5	or i could have been __cleaning__ out closets , nursing a mono-stricken child , and playing santa .
Contexts for target cleaning are: ['nsubj_i', 'aux_could', 'aux_have', 'aux_been', 'rootI_*root*', 'prt_out', 'dobj_closets', 'punct_,', 'conj_nursing', 'punct_,', 'cc_and', 'conj_playing', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target cleaning are: ['nsubj_i', 'aux_could', 'aux_have', 'aux_been', 'rootI_*root*', 'prt_out', 'punct_,', 'conj_nursing', 'punct_,', 'cc_and', 'conj_playing', 'punct_.']
Top most similar embeddings: tutted 0.00022	trowelling 0.00020	umming 0.00020	cleaning 0.00020	leafletting 0.00020	fidgeted 0.00019	cleaned 0.00019	vacuuming 0.00019	lunching 0.00019	mucking 0.00019

Generated lemmatized results
***************
GENERATED	clean.v 381 ::: tutted;trowel;umming;leafletting;fidget;vacuum;lunch;muck;gutting;loiter

Filtered results
***************
RANKED	clean.v 381	tidy 0.00016	wash 0.00016	mend 0.00015	win 0.00015	wipe 0.00014	empty 0.00014	cleanse 0.00013	clear 0.00013	repair 0.00013	disinfect 0.00012	purge 0.00012	prosper 0.00012	accumulate 0.00012	purify 0.00012	restore 0.00012	finish 0.00011	remove 0.00011	scrape 0.00011	fix 0.00010	correct 0.00010	rectify 0.00009	complete 0.00009	remedy 0.00007

Test context:
***************
clean.v	382	9	4.2 dog and horse owners should be encouraged to __clean__ up after their animals .
Contexts for target clean are: ['aux_to', 'xcompI_encouraged', 'prt_up', 'prep:after_animals']
Contexts in vocabulary for target clean are: ['aux_to', 'xcompI_encouraged', 'prt_up', 'prep:after_animals']
Top most similar embeddings: clean 0.06137	tidy 0.04840	smarten 0.04644	look 0.04532	freshen 0.04177	dig 0.03927	cleanse 0.03918	limber 0.03853	wash 0.03823	re-stock 0.03812

Generated lemmatized results
***************
GENERATED	clean.v 382 ::: tidy;smarten;look;freshen;dig;cleanse;limber;wash;mop;poke

Filtered results
***************
RANKED	clean.v 382	tidy 0.04840	cleanse 0.03918	wash 0.03823	disinfect 0.03561	wipe 0.03559	purify 0.03347	scrape 0.03293	mend 0.03182	clear 0.03180	purge 0.03169	finish 0.03089	repair 0.03069	fix 0.03067	remove 0.03007	accumulate 0.02926	complete 0.02895	restore 0.02868	rectify 0.02840	empty 0.02778	win 0.02721	prosper 0.02607	remedy 0.02597	correct 0.02595

Test context:
***************
clean.v	383	18	on wednesday , democrats across america joined together to restore truth and trust to government , and to __clean__ up the republican culture of corruption that has pervaded our nations capital .
Contexts for target clean are: ['aux_to', 'conjI_joined', 'prt_up', 'dobj_culture']
Contexts in vocabulary for target clean are: ['aux_to', 'conjI_joined', 'prt_up', 'dobj_culture']
Top most similar embeddings: clean 0.05354	carve 0.04355	freshen 0.04346	smarten 0.04154	tidy 0.04024	cleaned 0.03987	liven 0.03930	soak 0.03925	re-invigorate 0.03906	brighten 0.03831

Generated lemmatized results
***************
GENERATED	clean.v 383 ::: carve;freshen;smarten;tidy;liven;soak;brighten;build;divvy;wipe

Filtered results
***************
RANKED	clean.v 383	tidy 0.04024	wipe 0.03783	purify 0.03710	cleanse 0.03605	wash 0.03409	purge 0.03386	mend 0.03313	disinfect 0.03285	restore 0.03269	scrape 0.03213	empty 0.03104	accumulate 0.03073	clear 0.03027	finish 0.03008	fix 0.02989	win 0.02894	complete 0.02880	prosper 0.02879	remove 0.02837	repair 0.02777	rectify 0.02744	correct 0.02656	remedy 0.02598

Test context:
***************
clean.v	384	9	" she looked up at crono , who was __cleaning__ the blood off his sword .
Contexts for target cleaning are: ['nsubj_who', 'aux_was', 'rcmodI_crono', 'dobj_blood', 'prep:off_sword']
Contexts in vocabulary for target cleaning are: ['nsubj_who', 'aux_was', 'dobj_blood']
Top most similar embeddings: cleaning 0.11561	mopping 0.09971	scrubbing 0.09640	disinfecting 0.09238	hoovering 0.09222	rinsing 0.09200	washing 0.09190	decontaminating 0.09095	swigging 0.09092	mistreating 0.09068

Generated lemmatized results
***************
GENERATED	clean.v 384 ::: mop;scrub;disinfect;hoover;rinse;wash;decontaminate;swig;mistreat;suck

Filtered results
***************
RANKED	clean.v 384	disinfect 0.09238	wash 0.09190	wipe 0.08944	purify 0.08642	mend 0.08627	purge 0.08445	clear 0.08329	tidy 0.08313	cleanse 0.08273	empty 0.08239	repair 0.07930	remove 0.07858	restore 0.07725	finish 0.07690	fix 0.07201	accumulate 0.07154	win 0.07117	scrape 0.06855	correct 0.06849	complete 0.06656	rectify 0.06631	remedy 0.06591	prosper 0.06025

Test context:
***************
clean.v	385	20	that 's good because we got a lot done , but now there is a definite and obvious need to __clean__ up .
Contexts for target clean are: ['aux_to', 'infmodI_need', 'prt_up']
Contexts in vocabulary for target clean are: ['aux_to', 'infmodI_need', 'prt_up']
Top most similar embeddings: clean 0.13330	smarten 0.11605	tidy 0.10303	freshen 0.10249	fumigate 0.10162	toughen 0.10117	decontaminate 0.10015	sanitise 0.09910	cleaned 0.09775	recondition 0.09645

Generated lemmatized results
***************
GENERATED	clean.v 385 ::: smarten;tidy;freshen;fumigate;toughen;decontaminate;sanitise;recondition;tighten;sterilise

Filtered results
***************
RANKED	clean.v 385	tidy 0.10303	disinfect 0.09285	cleanse 0.09231	wash 0.09061	wipe 0.08900	purify 0.08527	scrape 0.08247	purge 0.08184	remove 0.08154	fix 0.07961	clear 0.07868	mend 0.07868	repair 0.07733	accumulate 0.07730	restore 0.07689	finish 0.07479	complete 0.07409	rectify 0.07404	empty 0.07122	win 0.07084	correct 0.06888	remedy 0.06693	prosper 0.06587

Test context:
***************
clean.v	386	4	the first one to __clean__ their bowl completely wins .
Contexts for target clean are: ['aux_to', 'depI_wins', 'dobj_bowl']
Contexts in vocabulary for target clean are: ['aux_to', 'depI_wins', 'dobj_bowl']
Top most similar embeddings: clean 0.11031	cleaned 0.08627	scooped 0.08252	cleans 0.08171	disinfect 0.08150	sterilise 0.08126	tidy 0.08105	smarten 0.08081	scoop 0.07996	re-fill 0.07915

Generated lemmatized results
***************
GENERATED	clean.v 386 ::: scoop;disinfect;sterilise;tidy;smarten;decorate;carve;wipe;decontaminate;sieze

Filtered results
***************
RANKED	clean.v 386	disinfect 0.08150	tidy 0.08105	wipe 0.07772	win 0.07649	cleanse 0.07528	wash 0.07507	remove 0.07324	scrape 0.07237	empty 0.07075	purify 0.07055	finish 0.06775	restore 0.06642	complete 0.06637	mend 0.06635	fix 0.06628	purge 0.06496	clear 0.06392	repair 0.06130	rectify 0.06085	accumulate 0.06019	correct 0.05663	remedy 0.05623	prosper 0.05551

Test context:
***************
clean.v	387	20	i was always showing up late , having accidents on the way to work and having to go home , __clean__ up and change .
Contexts for target clean are: ['conjI_showing', 'advmod_up']
Contexts in vocabulary for target clean are: ['conjI_showing', 'advmod_up']
Top most similar embeddings: clean 0.21589	sprucing 0.18052	tidy 0.17877	grassing 0.17708	cleaned 0.17639	scrubbing 0.17057	brushing 0.16866	tidying 0.16792	mopping 0.16574	cleaning 0.16397

Generated lemmatized results
***************
GENERATED	clean.v 387 ::: spruce;tidy;grass;scrub;brush;mop;tot;warm;plonk;legging

Filtered results
***************
RANKED	clean.v 387	tidy 0.17877	wash 0.16058	disinfect 0.15107	clear 0.14869	wipe 0.14780	fix 0.14257	cleanse 0.14196	finish 0.14185	scrape 0.13947	mend 0.13789	remove 0.13643	repair 0.13269	correct 0.13175	win 0.13171	empty 0.13158	purify 0.12851	restore 0.12694	accumulate 0.12604	purge 0.12596	rectify 0.12375	prosper 0.12245	complete 0.12157	remedy 0.11869

Test context:
***************
clean.v	388	5	grace has the money to __clean__ up .
Contexts for target clean are: ['aux_to', 'xcompI_has', 'prt_up']
Contexts in vocabulary for target clean are: ['aux_to', 'xcompI_has', 'prt_up']
Top most similar embeddings: clean 0.12955	smarten 0.10740	cleaned 0.10285	tidy 0.10280	fumigate 0.09672	freshen 0.09572	toughen 0.09477	unbolt 0.09235	prussik 0.09207	manhandle 0.09149

Generated lemmatized results
***************
GENERATED	clean.v 388 ::: smarten;tidy;fumigate;freshen;toughen;unbolt;prussik;manhandle;carve;vacuum

Filtered results
***************
RANKED	clean.v 388	tidy 0.10280	wipe 0.08773	wash 0.08758	cleanse 0.08538	disinfect 0.08488	scrape 0.08265	purify 0.08185	mend 0.07910	fix 0.07889	clear 0.07853	purge 0.07795	remove 0.07639	finish 0.07600	empty 0.07570	accumulate 0.07519	repair 0.07307	complete 0.07235	win 0.07224	restore 0.07116	rectify 0.06921	correct 0.06729	prosper 0.06392	remedy 0.06356

Test context:
***************
clean.v	389	7	but mainly the wound had wanted to __clean__ itself .
Contexts for target clean are: ['aux_to', 'xcompI_wanted', 'dobj_itself']
Contexts in vocabulary for target clean are: ['aux_to', 'xcompI_wanted', 'dobj_itself']
Top most similar embeddings: clean 0.11809	fumigate 0.10536	smarten 0.10465	re-equip 0.10107	refashion 0.10076	rearm 0.10025	sanitise 0.10006	immortalise 0.09958	instal 0.09941	re-configure 0.09918

Generated lemmatized results
***************
GENERATED	clean.v 389 ::: fumigate;smarten;refashion;rearm;sanitise;immortalise;instal;unburden;decontaminate;disassociate

Filtered results
***************
RANKED	clean.v 389	cleanse 0.09727	purify 0.09286	disinfect 0.09250	tidy 0.09241	purge 0.09132	wipe 0.08948	remove 0.08548	wash 0.08491	mend 0.08283	rectify 0.08262	repair 0.08189	restore 0.08134	fix 0.07932	scrape 0.07623	correct 0.07447	finish 0.07405	empty 0.07348	clear 0.07283	win 0.07215	complete 0.07100	remedy 0.06959	accumulate 0.06883	prosper 0.06704

Test context:
***************
clean.v	390	5	do they want us to __clean__ up the mess while they take the no cost high road of publicly condemning our unilateral military action ?
Contexts for target clean are: ['nsubj_us', 'aux_to', 'xcompI_want', 'prt_up', 'dobj_mess', 'advcl_take']
Contexts in vocabulary for target clean are: ['nsubj_us', 'aux_to', 'xcompI_want', 'prt_up', 'dobj_mess', 'advcl_take']
Top most similar embeddings: clean 0.01568	smarten 0.01317	tidy 0.01282	freshen 0.01240	re-do 0.01094	toughen 0.01092	cleanse 0.01080	lighten 0.01075	wipe 0.01068	make 0.01067

Generated lemmatized results
***************
GENERATED	clean.v 390 ::: smarten;tidy;freshen;toughen;cleanse;lighten;wipe;make;straighten;sanitise

Filtered results
***************
RANKED	clean.v 390	tidy 0.01282	cleanse 0.01080	wipe 0.01068	purify 0.00990	fix 0.00975	disinfect 0.00975	clear 0.00948	wash 0.00920	scrape 0.00918	remove 0.00913	mend 0.00888	purge 0.00852	rectify 0.00838	finish 0.00820	accumulate 0.00815	restore 0.00810	win 0.00773	repair 0.00754	empty 0.00729	complete 0.00723	correct 0.00703	prosper 0.00698	remedy 0.00679

Test context:
***************
coach.n	391	35	it is interesting to note that when mr cleary inaugurated the motor rail service in 1911 it was on a three months trial with the postal authorities who insisted that this be followed by a __coach__ and five horses all the way to ensure its safe arrival .
Contexts for target coach are: ['det_a', 'prep:byI_followed', 'cc_and', 'conj_horses']
Contexts in vocabulary for target coach are: ['det_a', 'prep:byI_followed', 'cc_and', 'conj_horses']
Top most similar embeddings: coach 0.06219	hearse 0.04734	coaches 0.04600	waggon 0.04512	charabanc 0.04505	mini-bus 0.04501	tuk-tuk 0.04351	farrier 0.04224	lorry 0.04196	jeep 0.04183

Generated lemmatized results
***************
GENERATED	coach.n 391 ::: hearse;waggon;charabanc;farrier;lorry;jeep;bus;dram;motorboat;wagon

Filtered results
***************
RANKED	coach.n 391	bus 0.04149	carriage 0.04093	trainer 0.03975	instructor 0.03885	counsellor 0.03383	teacher 0.03370	car 0.03262	tutor 0.03218	transport 0.03014

Test context:
***************
coach.n	392	13	but the lack of 2004 success has the axe poised over rookie pigs __coach__ mark watkins .
Contexts for target coach are: ['nnI_watkins']
Contexts in vocabulary for target coach are: ['nnI_watkins']
Top most similar embeddings: coach 0.46032	player/coach 0.37274	wo2 0.35960	coaches 0.35857	clubmate 0.35817	guus 0.35624	csgt 0.35622	shiela 0.35102	f/o 0.35025	eilis 0.35015

Generated lemmatized results
***************
GENERATED	coach.n 392 ::: clubmate;guus;csgt;shiela;eilis;lcpl;sioned;profesor;conal;alethea

Filtered results
***************
RANKED	coach.n 392	trainer 0.33797	instructor 0.31552	bus 0.31457	tutor 0.30836	teacher 0.30681	counsellor 0.29910	carriage 0.29713	car 0.28957	transport 0.26442

Test context:
***************
coach.n	393	20	i invite you to become part of this community of commitment and to begin your journey toward becoming a masterful __coach__ .
Contexts for target coach are: ['det_a', 'amod_masterful', 'xcompI_becoming']
Contexts in vocabulary for target coach are: ['det_a', 'amod_masterful', 'xcompI_becoming']
Top most similar embeddings: coach 0.12110	song-writer 0.09756	tactician 0.09734	craftsperson 0.09706	skydiver 0.09537	horticulturalist 0.09479	storyteller 0.09424	rhetorician 0.09397	gunfighter 0.09347	player/coach 0.09309

Generated lemmatized results
***************
GENERATED	coach.n 393 ::: tactician;craftsperson;skydiver;horticulturalist;storyteller;rhetorician;gunfighter;portraitist;cabinetmaker;stylist

Filtered results
***************
RANKED	coach.n 393	trainer 0.08969	teacher 0.08862	instructor 0.08585	counsellor 0.07945	tutor 0.07438	bus 0.07178	carriage 0.07047	car 0.06825	transport 0.05355

Test context:
***************
coach.n	394	2	as a __coach__ , we speak and listen with the intent of helping people surface , question and reframe assumptions .
Contexts for target coach are: ['det_a', 'prep:asI_speak']
Contexts in vocabulary for target coach are: ['det_a', 'prep:asI_speak']
Top most similar embeddings: coach 0.24420	rhetorician 0.18452	player/coach 0.18382	reflexologist 0.18334	father-figure 0.18204	stammerer 0.18175	pedagogue 0.18137	non-jew 0.18109	disbeliever 0.18091	nightwatchman 0.18079

Generated lemmatized results
***************
GENERATED	coach.n 394 ::: rhetorician;reflexologist;stammerer;pedagogue;disbeliever;nightwatchman;lawmaker;phlebotomist;sideman;catechist

Filtered results
***************
RANKED	coach.n 394	trainer 0.17572	teacher 0.17471	counsellor 0.17314	bus 0.16977	instructor 0.16829	tutor 0.15527	carriage 0.15109	car 0.14786	transport 0.11555

Test context:
***************
coach.n	395	18	the championship by-law states that the sa will pay 100 % of travel , accommodation , uniform for __coaches__ and airfare too( ?
Contexts for target coaches are: ['prep:forI_uniform', 'cc_and', 'conj_airfare']
Contexts in vocabulary for target coaches are: ['prep:forI_uniform', 'cc_and', 'conj_airfare']
Top most similar embeddings: coaches 0.11245	mini-buses 0.08816	coach 0.08608	minibuses 0.08566	campervans 0.08230	carriages 0.08213	taxis 0.08158	buses 0.08157	chauffeurs 0.08135	limousines 0.08095

Generated lemmatized results
***************
GENERATED	coach.n 395 ::: minibus;campervans;carriage;taxi;bus;chauffeur;limousine;limo;valet;tuxedo

Filtered results
***************
RANKED	coach.n 395	carriage 0.08213	bus 0.08157	instructor 0.07749	trainer 0.07664	car 0.07047	teacher 0.06697	tutor 0.06451	counsellor 0.06189	transport 0.06183

Test context:
***************
coach.n	396	15	we have also proposed that they continue to encourage ways of giving greater priority to __coaches__ on the national road network following the successful introduction of a dedicated lane on the m4 spur to heathrow .
Contexts for target coaches are: ['prep:toI_giving', 'prep:on_network']
Contexts in vocabulary for target coaches are: ['prep:toI_giving', 'prep:on_network']
Top most similar embeddings: coaches 0.21532	buses 0.18363	trains 0.17819	coach 0.16795	hgvs 0.16673	trams 0.16375	passengers 0.16348	busses 0.16260	pedestrians 0.16246	ptws 0.16245

Generated lemmatized results
***************
GENERATED	coach.n 396 ::: bus;train;hgvs;tram;passenger;pedestrian;ptws;stagecoach;minibus;horseriders

Filtered results
***************
RANKED	coach.n 396	bus 0.18363	carriage 0.15790	trainer 0.14566	instructor 0.14244	car 0.14041	teacher 0.13926	tutor 0.13714	counsellor 0.13265	transport 0.13182

Test context:
***************
coach.n	397	2	" my __coach__ arrived very late last night and i have n't yet unpacked my belongings .
Contexts for target coach are: ['poss_my', 'nsubjI_arrived']
Contexts in vocabulary for target coach are: ['poss_my', 'nsubjI_arrived']
Top most similar embeddings: coach 0.24789	coaches 0.20074	hubbie 0.19322	stepdad 0.19240	chauffer 0.19126	mini-bus 0.18502	chauffeur 0.18409	g/f 0.18405	land-rover 0.18403	bus 0.18250

Generated lemmatized results
***************
GENERATED	coach.n 397 ::: hubbie;stepdad;chauffer;chauffeur;bus;charabanc;xantia;aerobed;collegue;missis

Filtered results
***************
RANKED	coach.n 397	bus 0.18250	car 0.16815	instructor 0.16763	carriage 0.16467	teacher 0.16314	trainer 0.16260	counsellor 0.15251	tutor 0.15155	transport 0.13707

Test context:
***************
coach.n	398	2	besides function __coaches__ for common activities , the train would have sleeping cars ( wagons lites ) with individual compartments .
Contexts for target coaches are: ['nn_function', 'prep:besidesI_have', 'prep:for_activities']
Contexts in vocabulary for target coaches are: ['nn_function', 'prep:besidesI_have', 'prep:for_activities']
Top most similar embeddings: coaches 0.09044	staterooms 0.07426	mini-buses 0.07305	carriages 0.07232	rooms 0.07193	minibuses 0.07178	accommodations 0.07070	coordinators 0.06984	coach 0.06953	helpers 0.06947

Generated lemmatized results
***************
GENERATED	coach.n 398 ::: stateroom;carriage;room;minibus;accommodation;coordinator;helper;invigilator;facilites;facility

Filtered results
***************
RANKED	coach.n 398	carriage 0.07232	instructor 0.06861	bus 0.06790	trainer 0.06590	tutor 0.06482	counsellor 0.06025	car 0.05912	teacher 0.05735	transport 0.05537

Test context:
***************
coach.n	399	5	we hopped back onto the __coach__ - now for the boulangerie !
Contexts for target coach are: ['det_the', 'prep:ontoI_hopped']
Contexts in vocabulary for target coach are: ['det_the']
Top most similar embeddings: coach 0.50471	coaches 0.41858	mini-bus 0.38144	bus 0.38105	coachee 0.37959	waterbus 0.37936	minibus 0.37302	charabanc 0.37182	x90 0.37069	ferryboat 0.36943

Generated lemmatized results
***************
GENERATED	coach.n 399 ::: bus;coachee;waterbus;minibus;charabanc;ferryboat;dustcart;scoutmaster;gondolier;snazzmattazz

Filtered results
***************
RANKED	coach.n 399	bus 0.38105	trainer 0.35187	teacher 0.34857	instructor 0.34411	carriage 0.34303	car 0.33929	counsellor 0.32933	tutor 0.32227	transport 0.28983

Test context:
***************
coach.n	400	12	this is also at the very essence or heart of being a __coach__ .
Contexts for target coach are: ['cop_being', 'det_a', 'pcompI_of']
Contexts in vocabulary for target coach are: ['cop_being', 'det_a', 'pcompI_of']
Top most similar embeddings: coach 0.11298	stammerer 0.09586	southerner 0.09159	home-owner 0.08996	workaholic 0.08861	francophile 0.08839	murderess 0.08730	also-ran 0.08713	non-entity 0.08700	moderniser 0.08671

Generated lemmatized results
***************
GENERATED	coach.n 400 ::: stammerer;southerner;workaholic;francophile;murderess;moderniser;mentor;skydiver;craftsperson;godparent

Filtered results
***************
RANKED	coach.n 400	teacher 0.07990	trainer 0.07877	counsellor 0.07595	instructor 0.07497	tutor 0.07018	carriage 0.06906	bus 0.06658	car 0.06172	transport 0.05171

Test context:
***************
dry.a	401	16	mowing the way that you mow your lawn will also affect how well it survives hot, __dry__ conditions .
Contexts for target dry are: ['amodI_conditions']
Contexts in vocabulary for target dry are: ['amodI_conditions']
Top most similar embeddings: dry 0.53184	wet 0.43620	anticyclonic 0.43438	moist 0.40821	desert-like 0.40428	humid 0.40172	frost-free 0.39768	windless 0.39623	wintery 0.39617	spring-like 0.39604

Generated lemmatized results
***************
GENERATED	dry.a 401 ::: wet;anticyclonic;moist;humid;windless;wintery;wintry;damp;thermic;insanitary

Filtered results
***************
RANKED	dry.a 401	arid 0.37379	parched 0.35789	dull 0.34538	waterless 0.34421	desiccated 0.33001	soulless 0.32889	stodgy 0.31978	empty 0.30703	flat 0.30349	evaporate 0.29910	boring 0.29760	teetotal 0.29583	out 0.29472	uninteresting 0.28995	deadpan 0.28832	impassive 0.28715	drought 0.28567	droll 0.28168	facetious 0.27597	unsympathetic 0.27392	wry 0.27009	understated 0.25864

Test context:
***************
dry.a	402	24	clinical trials burn money fast , putting companies in a precarious position if they do n't get definitive results before their bank accounts run __dry__ .
Contexts for target dry are: ['dobjI_run']
Contexts in vocabulary for target dry are: ['dobjI_run']
Top most similar embeddings: dry 0.50907	wet 0.38538	afoul 0.36648	msconfig 0.35998	scandisk 0.35868	sysprep 0.35347	chkdsk 0.35262	drier 0.35233	efit 0.34837	e2fsck 0.34817

Generated lemmatized results
***************
GENERATED	dry.a 402 ::: wet;afoul;msconfig;scandisk;sysprep;chkdsk;efit;dries;ldconfig;penult

Filtered results
***************
RANKED	dry.a 402	waterless 0.32249	parched 0.31900	arid 0.30723	evaporate 0.30532	empty 0.29386	desiccated 0.29383	flat 0.29372	dull 0.28830	deadpan 0.27643	droll 0.27530	stodgy 0.27452	soulless 0.27090	boring 0.26784	drought 0.26681	uninteresting 0.26415	impassive 0.26147	teetotal 0.25830	out 0.25783	facetious 0.25149	wry 0.24338	unsympathetic 0.23670	understated 0.23310

Test context:
***************
dry.a	403	4	surprisingly in such a __dry__ continent as australia , salt becomes a problem when there is too much water .
Contexts for target dry are: ['amodI_continent']
Contexts in vocabulary for target dry are: ['amodI_continent']
Top most similar embeddings: dry 0.50079	ice-covered 0.39667	wet 0.38552	water-logged 0.38167	desert-like 0.37935	wind-swept 0.37844	semi-tropical 0.37772	sun-baked 0.37588	snow-covered 0.37390	pathless 0.37184

Generated lemmatized results
***************
GENERATED	dry.a 403 ::: wet;pathless;semiarid;waterless;windy;barren;treeless;godforsaken;parched;arid

Filtered results
***************
RANKED	dry.a 403	waterless 0.36999	parched 0.36618	arid 0.36384	desiccated 0.34658	flat 0.33345	dull 0.32387	empty 0.32329	soulless 0.31619	stodgy 0.30548	impassive 0.30295	evaporate 0.29961	uninteresting 0.29765	boring 0.29010	out 0.28564	deadpan 0.28244	teetotal 0.28160	droll 0.28104	wry 0.27225	facetious 0.26441	drought 0.26431	unsympathetic 0.26209	understated 0.26020

Test context:
***************
dry.a	404	11	for people who knew him , it was typical of his __dry__ humor , but some in the audience thought he was tipsy .
Contexts for target dry are: ['amodI_humor']
Contexts in vocabulary for target dry are: ['amodI_humor']
Top most similar embeddings: dry 0.52689	wet 0.39184	vaporous 0.38486	pitch-black 0.37832	gloopy 0.37823	soupy 0.37655	self-deprecating 0.37590	moist 0.36843	self-mocking 0.36809	sludgy 0.36724

Generated lemmatized results
***************
GENERATED	dry.a 404 ::: wet;vaporous;gloopy;soupy;moist;sludgy;scabrous;cloying;campy;smutty

Filtered results
***************
RANKED	dry.a 404	waterless 0.35994	wry 0.34931	deadpan 0.34748	dull 0.34606	parched 0.33864	droll 0.33396	arid 0.33334	stodgy 0.33286	desiccated 0.32071	soulless 0.31126	facetious 0.31039	boring 0.30842	empty 0.30811	impassive 0.30292	evaporate 0.30277	teetotal 0.29850	understated 0.29481	flat 0.29394	uninteresting 0.29135	unsympathetic 0.26890	out 0.26457	drought 0.25046

Test context:
***************
dry.a	405	4	the romance is uninspiring...and __dry__ .
Contexts for target dry are: ['conjI_uninspiring']
Contexts in vocabulary for target dry are: ['conjI_uninspiring']
Top most similar embeddings: dry 0.47391	characterless 0.37199	wet 0.36562	dull 0.36415	doughy 0.36110	soggy 0.36039	uninspiring 0.36016	featureless 0.36004	uninviting 0.35857	dreary 0.35831

Generated lemmatized results
***************
GENERATED	dry.a 405 ::: characterless;wet;dull;doughy;soggy;uninspiring;featureless;uninviting;dreary;stodgy

Filtered results
***************
RANKED	dry.a 405	dull 0.36415	stodgy 0.35765	soulless 0.35003	boring 0.34348	arid 0.33430	uninteresting 0.33345	parched 0.32506	waterless 0.32150	desiccated 0.32095	empty 0.31752	droll 0.31341	deadpan 0.31243	facetious 0.30223	evaporate 0.30187	impassive 0.29724	flat 0.29550	wry 0.29318	unsympathetic 0.27857	teetotal 0.27812	understated 0.26589	out 0.25515	drought 0.23249

Test context:
***************
dry.a	406	9	part c ) all this has been a little __dry__ so far : now for some fun .
Contexts for target dry are: ['dep_c', 'nsubj_this', 'aux_has', 'cop_been', 'det_a', 'amod_little', 'depI_<eol>', 'advmod_far', 'punct_:', 'prep:for_fun', 'punct_.']
Contexts in vocabulary for target dry are: ['dep_c', 'nsubj_this', 'aux_has', 'cop_been', 'det_a', 'amod_little', 'advmod_far', 'punct_:', 'prep:for_fun', 'punct_.']
Top most similar embeddings: washout 0.00046	harsh 0.00045	dry 0.00045	scorcher 0.00044	digression 0.00044	ott 0.00044	kludge 0.00044	drier 0.00043	kinder 0.00043	warmer 0.00043

Generated lemmatized results
***************
GENERATED	dry.a 406 ::: washout;harsh;scorcher;digression;ott;kludge;kind;warm;wet;tricky

Filtered results
***************
RANKED	dry.a 406	dull 0.00037	stodgy 0.00035	empty 0.00035	facetious 0.00035	flat 0.00033	boring 0.00033	parched 0.00031	desiccated 0.00028	droll 0.00028	uninteresting 0.00028	understated 0.00026	drought 0.00025	unsympathetic 0.00025	soulless 0.00024	teetotal 0.00024	arid 0.00023	deadpan 0.00021	impassive 0.00020	wry 0.00020	evaporate 0.00020	waterless 0.00020	out 0.00015

Test context:
***************
dry.a	407	14	perhaps more than anything what one loves about this book is fowler 's incisive __dry__ wit .
Contexts for target dry are: ['amodI_wit']
Contexts in vocabulary for target dry are: ['amodI_wit']
Top most similar embeddings: dry 0.54065	wet 0.38812	vaporous 0.38355	self-deprecating 0.37873	self-mocking 0.37406	soupy 0.37391	caustic 0.37383	moist 0.37064	scabrous 0.36806	coruscating 0.36802

Generated lemmatized results
***************
GENERATED	dry.a 407 ::: wet;vaporous;soupy;caustic;moist;scabrous;coruscating;acerbic;breezy;zesty

Filtered results
***************
RANKED	dry.a 407	deadpan 0.35932	droll 0.35670	wry 0.35660	waterless 0.35431	arid 0.34475	parched 0.33955	desiccated 0.33667	stodgy 0.33476	dull 0.33431	impassive 0.31523	soulless 0.31358	empty 0.30489	facetious 0.30465	teetotal 0.30290	flat 0.30193	understated 0.30131	evaporate 0.29817	boring 0.29378	out 0.28178	uninteresting 0.27916	unsympathetic 0.27008	drought 0.25562

Test context:
***************
dry.a	408	16	the problem is , aari seems to have no memory of their love other than a __dry__ recitation as if he is reading a script of who he is supposed to be .
Contexts for target dry are: ['amodI_recitation']
Contexts in vocabulary for target dry are: ['amodI_recitation']
Top most similar embeddings: dry 0.50962	wet 0.38225	extemporaneous 0.36205	rock-hard 0.35934	languorous 0.35831	vaporous 0.35795	moist 0.35636	self-congratulatory 0.35635	syrupy 0.35205	pulpy 0.35126

Generated lemmatized results
***************
GENERATED	dry.a 408 ::: wet;extemporaneous;languorous;vaporous;moist;syrupy;pulpy;deadpan;soundless;wintry

Filtered results
***************
RANKED	dry.a 408	deadpan 0.35123	arid 0.34725	dull 0.34285	waterless 0.33768	stodgy 0.32330	droll 0.32072	soulless 0.31905	boring 0.31854	empty 0.31458	wry 0.31278	parched 0.31177	desiccated 0.30665	impassive 0.30570	facetious 0.30231	uninteresting 0.29951	teetotal 0.29543	understated 0.29178	evaporate 0.28586	flat 0.28498	out 0.26128	unsympathetic 0.25173	drought 0.24405

Test context:
***************
dry.a	409	29	she proved that in two years in illinois they had voted ninety-six towns dry , and that at that rate we would soon get over montana and have it __dry__ .
Contexts for target dry are: ['aux_have', 'nsubj_it', 'conjI_get']
Contexts in vocabulary for target dry are: ['aux_have', 'nsubj_it', 'conjI_get']
Top most similar embeddings: dry 0.10807	dried 0.08627	wet 0.08604	valeted 0.08357	rained 0.08347	snowed 0.08263	itched 0.08243	re-heated 0.08242	raining 0.08177	defrosted 0.08117

Generated lemmatized results
***************
GENERATED	dry.a 409 ::: dried;wet;valeted;rained;snowed;itched;raining;defrosted;dries;sumped

Filtered results
***************
RANKED	dry.a 409	dull 0.07567	boring 0.07365	empty 0.07332	parched 0.07049	evaporate 0.07009	uninteresting 0.06763	stodgy 0.06641	teetotal 0.06207	soulless 0.06122	flat 0.06113	arid 0.06083	desiccated 0.05916	facetious 0.05911	waterless 0.05882	understated 0.05730	droll 0.05727	unsympathetic 0.05547	deadpan 0.05359	impassive 0.05323	drought 0.05081	wry 0.04795	out 0.04650

Test context:
***************
dry.a	410	5	if the mixture is too __dry__ , add some water ; if it is too soft, add some flour .
Contexts for target dry are: ['mark_if', 'nsubj_mixture', 'cop_is', 'advmod_too', 'advclI_add']
Contexts in vocabulary for target dry are: ['mark_if', 'nsubj_mixture', 'cop_is', 'advmod_too', 'advclI_add']
Top most similar embeddings: dry 0.03405	crumbly 0.02959	wet 0.02744	moist 0.02693	runny 0.02591	salty 0.02433	syrupy 0.02409	thickened 0.02407	water-logged 0.02389	acidic 0.02382

Generated lemmatized results
***************
GENERATED	dry.a 410 ::: crumbly;wet;moist;runny;salty;syrupy;thickened;acidic;sticky;overfull

Filtered results
***************
RANKED	dry.a 410	parched 0.01973	dull 0.01917	stodgy 0.01890	empty 0.01833	evaporate 0.01716	uninteresting 0.01684	arid 0.01684	boring 0.01661	desiccated 0.01643	waterless 0.01620	teetotal 0.01569	flat 0.01564	understated 0.01452	deadpan 0.01409	droll 0.01377	unsympathetic 0.01337	soulless 0.01314	facetious 0.01311	impassive 0.01274	wry 0.01220	drought 0.01016	out 0.00936

Test context:
***************
full.a	411	49	dave chalmers : you can imagine that in 100 or 200 years there 's going to be sim universe , everyone 's going to have an entire simulated universe on the desk top , there will be virtual realities that people could interact with , that will provide the __full__ richness of an entire life .
Contexts for target full are: ['amodI_richness']
Contexts in vocabulary for target full are: ['amodI_richness']
Top most similar embeddings: full 0.51746	timbral 0.38275	fullest 0.37122	unwonted 0.37106	yeasty 0.36900	much-reduced 0.36694	fathomless 0.36444	kaleidoscopic 0.36405	unexampled 0.36297	limpid 0.36234

Generated lemmatized results
***************
GENERATED	full.a 411 ::: timbral;unwonted;yeasty;fathomless;kaleidoscopic;unexampled;limpid;unmatchable;biscuity;preternatural

Filtered results
***************
RANKED	full.a 411	overflowing 0.33729	abundant 0.31961	entire 0.31677	generous 0.30984	complete 0.30829	ample 0.30499	ruched 0.30223	voluminous 0.30099	whole 0.29656	total 0.29134	maximum 0.28975	highest 0.28935	big 0.28583	filled 0.27522	top 0.26623	gathered 0.24941

Test context:
***************
full.a	412	5	it 's a beatiful album __full__ of the type of songs that we 're rarely heard from the pumpkins .
Contexts for target full are: ['amodI_album', 'prep:of_type']
Contexts in vocabulary for target full are: ['amodI_album', 'prep:of_type']
Top most similar embeddings: full 0.23254	brimful 0.16893	catchiest 0.16758	fullest 0.16516	funkiest 0.16497	hugest 0.16493	first 0.16475	typical 0.16364	self-released 0.16161	devoid 0.15978

Generated lemmatized results
***************
GENERATED	full.a 412 ::: brimful;catchy;funky;huge;first;typical;devoid;evocative;hundredth;gay

Filtered results
***************
RANKED	full.a 412	big 0.15363	whole 0.14364	entire 0.14265	top 0.13840	overflowing 0.13562	highest 0.13451	total 0.13006	voluminous 0.12805	generous 0.12782	maximum 0.12646	complete 0.12609	abundant 0.12481	ample 0.12238	ruched 0.11421	filled 0.11420	gathered 0.09879

Test context:
***************
full.a	413	12	what we need is accountability ; we need offenders prosecuted with the __full__ weight of the law , so that this behaviour is eradicated .
Contexts for target full are: ['amodI_weight']
Contexts in vocabulary for target full are: ['amodI_weight']
Top most similar embeddings: full 0.51616	all-up 0.41548	much-reduced 0.41126	unsprung 0.38999	four-figure 0.38054	lowish 0.37711	ever-decreasing 0.37694	enourmous 0.36937	40kg 0.36698	unwonted 0.36369

Generated lemmatized results
***************
GENERATED	full.a 413 ::: unsprung;lowish;enourmous;unwonted;unfeasibly;resonable;submaximal;addtional;outsized;unladen

Filtered results
***************
RANKED	full.a 413	entire 0.33603	overflowing 0.32674	total 0.32383	ample 0.31837	ruched 0.31629	maximum 0.31514	whole 0.31250	generous 0.31241	big 0.31058	highest 0.30711	complete 0.30607	top 0.30152	voluminous 0.29638	abundant 0.28652	filled 0.28345	gathered 0.24585

Test context:
***************
full.a	414	7	the patent is granted in return for __full__ disclosure of the details of the invention .
Contexts for target full are: ['amodI_disclosure']
Contexts in vocabulary for target full are: ['amodI_disclosure']
Top most similar embeddings: full 0.53080	timeous 0.37721	fullest 0.37346	in-principle 0.36344	non-consensual 0.35831	unexpurgated 0.35486	once-only 0.35383	publicly-available 0.35374	10-page 0.35344	court-ordered 0.35252

Generated lemmatized results
***************
GENERATED	full.a 414 ::: timeous;unexpurgated;brimful;widescale;inital;addtional;partial;wrongful;extraterritorial;injudicious

Filtered results
***************
RANKED	full.a 414	complete 0.32379	ample 0.30843	entire 0.30669	overflowing 0.30513	generous 0.30448	voluminous 0.29733	total 0.29602	top 0.29489	big 0.29175	ruched 0.28929	maximum 0.28917	whole 0.28489	abundant 0.27371	highest 0.27246	filled 0.26476	gathered 0.24197

Test context:
***************
full.a	415	18	because of the intermittency and variability of the wind , conventional power plants must be kept running at __full__ capacity to meet the actual demand for electricity .
Contexts for target full are: ['amodI_capacity']
Contexts in vocabulary for target full are: ['amodI_capacity']
Top most similar embeddings: full 0.52010	much-reduced 0.40403	unutilised 0.37942	fullest 0.37479	single-stage 0.37283	isokinetic 0.37023	class-leading 0.36614	in-principle 0.36431	second-stage 0.36326	ever-decreasing 0.36252

Generated lemmatized results
***************
GENERATED	full.a 415 ::: unutilised;isokinetic;addtional;enourmous;replicative;brimful;absorptive;sufficent;submaximal;ohmic

Filtered results
***************
RANKED	full.a 415	ample 0.33255	overflowing 0.32834	entire 0.32385	total 0.32285	generous 0.32001	maximum 0.31835	big 0.31088	abundant 0.30878	highest 0.30335	voluminous 0.30099	complete 0.29913	whole 0.29839	ruched 0.28653	top 0.28600	filled 0.27949	gathered 0.24676

Test context:
***************
full.a	416	10	he tends to wear a doublet , a shirt with __full__ gentlemanly blousing sleeves , kneelength trousers , and slippers .
Contexts for target full are: ['amodI_sleeves']
Contexts in vocabulary for target full are: ['amodI_sleeves']
Top most similar embeddings: full 0.50653	extra-long 0.38836	re-sealable 0.38677	knee-length 0.38294	close-fitting 0.38198	tight-fitting 0.38022	well-fitting 0.37807	well-filled 0.37782	resealable 0.37618	low-cut 0.37469

Generated lemmatized results
***************
GENERATED	full.a 416 ::: resealable;sequined;sequinned;overfull;zippered;sealable;tasselled;childproof;jeweled;rimless

Filtered results
***************
RANKED	full.a 416	ruched 0.34870	voluminous 0.33189	overflowing 0.32189	entire 0.31824	generous 0.31778	ample 0.30807	complete 0.30677	big 0.30504	filled 0.29271	top 0.28958	abundant 0.28260	whole 0.28069	total 0.27800	maximum 0.27471	highest 0.27351	gathered 0.25189

Test context:
***************
full.a	417	6	however , once i got a __full__ load of clients , i realized that my income potential was being limited .
Contexts for target full are: ['amodI_load']
Contexts in vocabulary for target full are: ['amodI_load']
Top most similar embeddings: full 0.52309	much-reduced 0.39300	lowish 0.37173	ever-decreasing 0.36920	extra-long 0.36823	submaximal 0.36195	single-stage 0.36160	continous 0.36000	isokinetic 0.35993	overfull 0.35798

Generated lemmatized results
***************
GENERATED	full.a 417 ::: lowish;submaximal;continous;isokinetic;overfull;ohmic;inital;unwonted;biaxial;addtional

Filtered results
***************
RANKED	full.a 417	entire 0.33808	whole 0.32923	complete 0.32747	big 0.32511	overflowing 0.32287	generous 0.32024	total 0.31698	maximum 0.31012	ample 0.30945	voluminous 0.29550	highest 0.29494	ruched 0.29337	filled 0.28981	abundant 0.28693	top 0.28584	gathered 0.23923

Test context:
***************
full.a	418	16	of course , seeing how much fun he has finger feeding himself a high chair tray __full__ of mashed banana ( some will actually go in his mouth ) is worth just about anything .
Contexts for target full are: ['amodI_tray', 'prep:of_mashed']
Contexts in vocabulary for target full are: ['amodI_tray']
Top most similar embeddings: full 0.50666	slide-out 0.40189	well-filled 0.40065	re-sealable 0.39988	fold-down 0.39404	resealable 0.39088	height-adjustable 0.38808	overfull 0.38352	straight-sided 0.38236	heatproof 0.38140

Generated lemmatized results
***************
GENERATED	full.a 418 ::: resealable;overfull;heatproof;lidded;sealable;microwaveable;childproof;rubberized;zippered;floured

Filtered results
***************
RANKED	full.a 418	overflowing 0.35197	ruched 0.33322	generous 0.33322	entire 0.32999	ample 0.32353	big 0.31481	complete 0.31366	voluminous 0.31085	whole 0.30888	filled 0.30462	top 0.30428	total 0.28291	abundant 0.28030	highest 0.27254	maximum 0.27048	gathered 0.23855

Test context:
***************
full.a	419	5	be sure to read the __full__ story .
Contexts for target full are: ['amodI_story']
Contexts in vocabulary for target full are: ['amodI_story']
Top most similar embeddings: full 0.54758	well-told 0.40553	five-page 0.39610	spine-chilling 0.39566	heartrending 0.39511	tragi-comic 0.39068	rags-to-riches 0.39058	10-page 0.38974	six-page 0.38457	3-page 0.38387

Generated lemmatized results
***************
GENERATED	full.a 419 ::: heartrending;unexpurgated;tragical;brimful;scabrous;orignal;tragicomic;neverending;wondeful;goddamned

Filtered results
***************
RANKED	full.a 419	entire 0.34147	complete 0.33433	whole 0.32800	big 0.32364	overflowing 0.31729	voluminous 0.30060	top 0.30016	ruched 0.30003	ample 0.29963	filled 0.29097	generous 0.28776	total 0.28471	abundant 0.28396	highest 0.28276	maximum 0.26309	gathered 0.22765

Test context:
***************
full.a	420	29	any podium , fax , phone , or mail bids that do not conform to a full or half increment will be rounded up or down to the nearest __full__ or half increment .
Contexts for target full are: ['amodI_increment', 'cc_or', 'conj_half']
Contexts in vocabulary for target full are: ['amodI_increment', 'cc_or', 'conj_half']
Top most similar embeddings: full 0.12183	25ml 0.08968	7kg 0.08915	1/12th 0.08727	1/60th 0.08592	1/8th 0.08537	8kg 0.08501	108.85 0.08415	30kg 0.08394	25kg 0.08393

Generated lemmatized results
***************
GENERATED	full.a 420 ::: hkd;hourly;partial;centimeter;millisecond;termly;foure;yearly;empty;nonparity

Filtered results
***************
RANKED	full.a 420	whole 0.07118	maximum 0.06843	big 0.06663	overflowing 0.06400	generous 0.06318	total 0.06284	highest 0.06155	ample 0.06112	complete 0.06106	ruched 0.05996	entire 0.05965	top 0.05865	abundant 0.05600	voluminous 0.05530	filled 0.05266	gathered 0.04365

Test context:
***************
heap.n	421	23	the wind is testing its strength , blowing down to the ants ' path with its tiny pebbles , down to the tiny __heaps__ of gravel , down to all the heaps of gravel .
Contexts for target heaps are: ['det_the', 'amod_tiny', 'prep:toI_down', 'prep:of_gravel']
Contexts in vocabulary for target heaps are: ['det_the', 'amod_tiny', 'prep:toI_down', 'prep:of_gravel']
Top most similar embeddings: heaps 0.06285	heap 0.05341	mounds 0.05128	piles 0.04978	specks 0.04839	clods 0.04735	lochans 0.04726	hillocks 0.04696	rivulets 0.04693	mound 0.04690

Generated lemmatized results
***************
GENERATED	heap.n 421 ::: mound;pile;speck;clod;lochans;hillock;rivulet;puddle;fleck;corrugation

Filtered results
***************
RANKED	heap.n 421	mound 0.05128	pile 0.04978	lump 0.04592	bundle 0.03859	bin 0.03635	loads 0.03586	tons 0.03580	mess 0.03498	wreck 0.03430	assortment 0.03367	lots 0.03202	state 0.02941	collection 0.02798	category 0.02566

Test context:
***************
heap.n	422	7	regards george melky hey guys , thanks __heaps__ for the fabulously run race today .
Contexts for target heaps are: ['depI_thanks', 'prep:for_race', 'tmod_today']
Contexts in vocabulary for target heaps are: ['depI_thanks', 'prep:for_race', 'tmod_today']
Top most similar embeddings: heaps 0.09785	alot 0.07936	thankyou 0.07223	congrats 0.07197	delievered 0.07185	gearing 0.07175	allot 0.07105	lots 0.07061	heap 0.07015	gunning 0.07010

Generated lemmatized results
***************
GENERATED	heap.n 422 ::: alot;thankyou;congrats;delievered;gearing;allot;lot;gunning;djn;antmat

Filtered results
***************
RANKED	heap.n 422	lots 0.07061	loads 0.06957	pile 0.06777	tons 0.05859	mound 0.05797	mess 0.05666	bin 0.05604	bundle 0.05377	lump 0.05338	wreck 0.05325	assortment 0.05103	category 0.04586	state 0.04450	collection 0.04331

Test context:
***************
heap.n	423	15	by the time you 've finished your dinner you 've got nothing but a garbage __heap__ on your plate .
Contexts for target heap are: ['det_a', 'nn_garbage', 'conjI_nothing', 'prep:on_plate']
Contexts in vocabulary for target heap are: ['det_a', 'nn_garbage', 'conjI_nothing', 'prep:on_plate']
Top most similar embeddings: heap 0.07064	pile 0.05239	heaps 0.04486	crock 0.04383	blob 0.04359	wheelbarrow 0.04286	piles 0.04275	dump 0.04247	clod 0.04229	garbage 0.04162

Generated lemmatized results
***************
GENERATED	heap.n 423 ::: pile;crock;blob;wheelbarrow;dump;clod;garbage;dollop;splattering;speck

Filtered results
***************
RANKED	heap.n 423	pile 0.05239	bin 0.04048	mound 0.03924	lump 0.03857	mess 0.03774	bundle 0.03587	assortment 0.03384	collection 0.03324	loads 0.03120	tons 0.03002	wreck 0.02989	lots 0.02891	state 0.02647	category 0.02264

Test context:
***************
heap.n	424	18	if it is a good category system there should not be too many left over in the miscellaneous __heap__ , and there should not be too many that you want to assign to more than one category .
Contexts for target heap are: ['det_the', 'amod_miscellaneous', 'prep:inI_left']
Contexts in vocabulary for target heap are: ['det_the', 'amod_miscellaneous', 'prep:inI_left']
Top most similar embeddings: heap 0.12358	heaps 0.09651	pile 0.09571	piles 0.09398	wreckage 0.08932	wastebasket 0.08929	rubble 0.08853	worklist 0.08587	morass 0.08585	mire 0.08582

Generated lemmatized results
***************
GENERATED	heap.n 424 ::: pile;wreckage;wastebasket;rubble;worklist;morass;mire;midden;detritus;trashcan

Filtered results
***************
RANKED	heap.n 424	pile 0.09571	mess 0.08038	mound 0.07920	bin 0.07846	collection 0.07484	wreck 0.07481	bundle 0.07221	assortment 0.07125	lump 0.07050	category 0.07034	state 0.06719	loads 0.06214	tons 0.05876	lots 0.05506

Test context:
***************
heap.n	425	14	composting is carried out by accumulating dung , domestic and other wastes in a __heap__ or pit .
Contexts for target heap are: ['det_a', 'prep:inI_accumulating', 'cc_or', 'conj_pit']
Contexts in vocabulary for target heap are: ['det_a', 'prep:inI_accumulating', 'cc_or', 'conj_pit']
Top most similar embeddings: heap 0.06326	cesspool 0.04856	midden 0.04744	coldframe 0.04620	wormery 0.04586	flowerpot 0.04580	soakaway 0.04545	cesspit 0.04534	borehole 0.04433	ploughsoil 0.04414

Generated lemmatized results
***************
GENERATED	heap.n 425 ::: cesspool;midden;coldframe;wormery;flowerpot;soakaway;cesspit;borehole;ploughsoil;gulley

Filtered results
***************
RANKED	heap.n 425	pile 0.04369	mound 0.04223	bin 0.04098	lump 0.03962	mess 0.03744	wreck 0.03228	bundle 0.03105	state 0.02855	tons 0.02801	loads 0.02653	collection 0.02596	assortment 0.02573	category 0.02567	lots 0.02282

Test context:
***************
heap.n	426	24	it took along time to get to the point where i could smile at the thought of her rather then collapse into an emotional __heap__ .
Contexts for target heap are: ['det_an', 'amod_emotional', 'prep:intoI_smile']
Contexts in vocabulary for target heap are: ['det_an', 'amod_emotional']
Top most similar embeddings: heap 0.22938	wringer 0.17769	armful 0.17756	overabundance 0.17631	tailspin 0.17514	outburst 0.17432	outpouring 0.17348	excrescence 0.17302	anticlimax 0.17268	earful 0.17247

Generated lemmatized results
***************
GENERATED	heap.n 426 ::: wringer;armful;overabundance;tailspin;outburst;outpouring;excrescence;anticlimax;earful;anthill

Filtered results
***************
RANKED	heap.n 426	pile 0.17032	mess 0.16082	mound 0.15738	wreck 0.15717	assortment 0.15298	state 0.14934	bundle 0.14898	lump 0.14768	bin 0.14763	collection 0.13937	loads 0.12826	tons 0.12739	category 0.12718	lots 0.11171

Test context:
***************
heap.n	427	18	in 1978 , a ford mustang ii ( my first car , and trust me it was a __heap__ , but it was cheap ) cost about $ 3,500 brand new .
Contexts for target heap are: ['nsubj_it', 'cop_was', 'det_a', 'rcmodI_me']
Contexts in vocabulary for target heap are: ['nsubj_it', 'cop_was', 'det_a', 'rcmodI_me']
Top most similar embeddings: heap 0.05360	goner 0.05029	toughie 0.04938	pisser 0.04692	god-send 0.04569	larf 0.04565	hoot 0.04487	beaut 0.04486	laff 0.04447	stinker 0.04441

Generated lemmatized results
***************
GENERATED	heap.n 427 ::: goner;toughie;pisser;larf;hoot;beaut;laff;stinker;doddle;longshot

Filtered results
***************
RANKED	heap.n 427	pile 0.04179	mess 0.03906	lump 0.03560	wreck 0.03502	bundle 0.03310	mound 0.03221	bin 0.03087	loads 0.02829	assortment 0.02649	state 0.02622	collection 0.02542	category 0.02489	tons 0.02483	lots 0.02272

Test context:
***************
heap.n	428	7	it 's a hodgepodge , a humongous __heap__ of tips & tricks , hortations with no underlying concepts .
Contexts for target heap are: ['det_a', 'amod_humongous', 'apposI_hodgepodge', 'prep:of_tips']
Contexts in vocabulary for target heap are: ['det_a', 'amod_humongous', 'prep:of_tips']
Top most similar embeddings: heap 0.13227	pile 0.10597	sackful 0.10009	bagful 0.09792	wodge 0.09707	heaps 0.09370	shedload 0.09239	plateful 0.09239	bucketful 0.09175	stack 0.09044

Generated lemmatized results
***************
GENERATED	heap.n 428 ::: pile;sackful;bagful;wodge;shedload;plateful;bucketful;stack;truckload;fistful

Filtered results
***************
RANKED	heap.n 428	pile 0.10597	bundle 0.08575	mound 0.08227	assortment 0.08216	lump 0.07971	collection 0.07967	mess 0.07895	bin 0.07663	tons 0.07376	loads 0.07016	wreck 0.06609	lots 0.06360	category 0.05664	state 0.05487

Test context:
***************
heap.n	429	17	some years ago several key chefs from fore street had been snatched up to make this cantankerous __heap__ on the water a destination .
Contexts for target heap are: ['det_this', 'amod_cantankerous', 'dobjI_make']
Contexts in vocabulary for target heap are: ['det_this', 'amod_cantankerous', 'dobjI_make']
Top most similar embeddings: heap 0.10944	contraption 0.08023	buffoon 0.07999	mess 0.07948	pile 0.07936	clod 0.07850	threesome 0.07753	wretch 0.07743	creature 0.07725	stew 0.07632

Generated lemmatized results
***************
GENERATED	heap.n 429 ::: contraption;buffoon;mess;pile;clod;threesome;wretch;creature;stew;eejit

Filtered results
***************
RANKED	heap.n 429	mess 0.07948	pile 0.07936	lump 0.06879	bundle 0.06849	mound 0.06710	bin 0.06572	wreck 0.06525	assortment 0.06155	category 0.06121	collection 0.06090	state 0.05544	loads 0.05520	lots 0.05226	tons 0.05065

Test context:
***************
heap.n	430	6	by putting them in your compost __heap__ , she says , " they break everything down fast and beautifully .
Contexts for target heap are: ['poss_your', 'nn_compost', 'prep:inI_putting']
Contexts in vocabulary for target heap are: ['poss_your', 'nn_compost', 'prep:inI_putting']
Top most similar embeddings: heap 0.14303	bin 0.10755	heaps 0.10245	pile 0.10183	wormery 0.10163	dustbin 0.10061	composter 0.09902	compost 0.09673	bins 0.09598	piles 0.09043

Generated lemmatized results
***************
GENERATED	heap.n 430 ::: bin;pile;wormery;dustbin;composter;compost;bucket;compactor;trashcan;leafmould

Filtered results
***************
RANKED	heap.n 430	bin 0.10755	pile 0.10183	mess 0.07380	mound 0.07262	bundle 0.07160	lump 0.06851	collection 0.06735	category 0.06558	assortment 0.06378	loads 0.06287	lots 0.06106	tons 0.05917	state 0.05834	wreck 0.05349

Test context:
***************
job.n	431	6	it had to do a better __job__ of managing the key global issues that would determine the future .
Contexts for target job are: ['det_a', 'amod_better', 'dobjI_do']
Contexts in vocabulary for target job are: ['det_a', 'amod_better', 'dobjI_do']
Top most similar embeddings: job 0.14866	handstand 0.09788	double-take 0.09550	jobs 0.09082	once-over 0.09042	headstand 0.08952	deede 0.08819	work-out 0.08787	fundo 0.08637	payrise 0.08629

Generated lemmatized results
***************
GENERATED	job.n 431 ::: handstand;headstand;deede;fundo;payrise;laff;traineeship;gig;lot;thing

Filtered results
***************
RANKED	job.n 431	task 0.08251	career 0.07982	business 0.07902	duty 0.07663	bit 0.07648	position 0.07420	role 0.07352	place 0.07099	assignment 0.07005	contract 0.06847	work 0.06735	employment 0.06505	matter 0.06484	post 0.06464	function 0.06346	responsibility 0.05970	functional 0.04375

Test context:
***************
job.n	432	1	his __job__ was unpaid , but he was working just to keep himself fit .
Contexts for target job are: ['poss_his', 'nsubjI_unpaid']
Contexts in vocabulary for target job are: ['poss_his', 'nsubjI_unpaid']
Top most similar embeddings: job 0.25705	internship 0.17829	life-work 0.17615	jobs 0.16976	duties 0.16974	role 0.16912	come-uppance 0.16901	workrate 0.16809	secondment 0.16785	position 0.16779

Generated lemmatized results
***************
GENERATED	job.n 432 ::: internship;duty;role;workrate;secondment;position;sickbed;pupillage;placement;dutie

Filtered results
***************
RANKED	job.n 432	duty 0.16974	role 0.16912	position 0.16779	task 0.16580	career 0.16461	employment 0.16213	work 0.15903	post 0.15393	responsibility 0.15083	assignment 0.14992	contract 0.14654	business 0.13982	place 0.13136	matter 0.12127	function 0.11821	bit 0.11812	functional 0.09495

Test context:
***************
job.n	433	7	if this government had been doing its __job__ they would have total confidence .
Contexts for target job are: ['poss_its', 'dobjI_doing', 'rcmod_have']
Contexts in vocabulary for target job are: ['poss_its', 'dobjI_doing', 'rcmod_have']
Top most similar embeddings: job 0.12731	jobs 0.08821	damnedest 0.08646	chores 0.08486	task 0.08464	tasks 0.08403	shtick 0.08342	errands 0.08154	duties 0.08124	homework 0.08056

Generated lemmatized results
***************
GENERATED	job.n 433 ::: damnedest;chore;task;shtick;errand;duty;homework;thing;internship;business

Filtered results
***************
RANKED	job.n 433	task 0.08464	duty 0.08124	business 0.07688	role 0.07672	responsibility 0.07534	employment 0.07201	assignment 0.07146	work 0.07042	career 0.06938	position 0.06920	bit 0.06698	contract 0.06605	function 0.06496	matter 0.06017	place 0.05954	post 0.05739	functional 0.04354

Test context:
***************
job.n	434	28	when it 's dark. ' ' she had no idea how she was going to accomplish this , but she knew that as the eldest it was her __job__ to look after her two younger sisters .
Contexts for target job are: ['nsubj_it', 'cop_was', 'nsubj_her', 'rcmodI_eldest', 'infmod_look']
Contexts in vocabulary for target job are: ['nsubj_it', 'cop_was', 'nsubj_her', 'infmod_look']
Top most similar embeddings: job 0.05966	toughie 0.04236	oppertunity 0.04185	chore 0.04132	priviledge 0.04022	eye-opener 0.04004	pleasure 0.03984	likey 0.03980	larf 0.03949	task 0.03937

Generated lemmatized results
***************
GENERATED	job.n 434 ::: toughie;oppertunity;chore;priviledge;pleasure;likey;larf;task;enuf;dificult

Filtered results
***************
RANKED	job.n 434	task 0.03937	duty 0.03909	place 0.03512	responsibility 0.03441	bit 0.03237	matter 0.03148	career 0.03103	position 0.03037	role 0.02956	work 0.02860	contract 0.02771	assignment 0.02698	function 0.02580	business 0.02539	employment 0.02516	functional 0.02495	post 0.02470

Test context:
***************
job.n	435	10	martin amis : i think he did a very good __job__ .
Contexts for target job are: ['det_a', 'amod_good', 'dobjI_did']
Contexts in vocabulary for target job are: ['det_a', 'amod_good', 'dobjI_did']
Top most similar embeddings: job 0.15012	handstand 0.10282	once-over 0.10190	double-take 0.10014	headstand 0.09723	deede 0.09531	work-out 0.09474	laff 0.09358	read-through 0.09299	plateful 0.09116

Generated lemmatized results
***************
GENERATED	job.n 435 ::: handstand;headstand;deede;laff;plateful;thing;wodge;backflip;larf;gig

Filtered results
***************
RANKED	job.n 435	career 0.08089	task 0.08038	bit 0.08010	duty 0.07629	business 0.07559	work 0.07301	role 0.07264	position 0.07143	contract 0.06995	place 0.06883	assignment 0.06821	post 0.06679	matter 0.06408	employment 0.06384	function 0.06179	responsibility 0.05846	functional 0.04225

Test context:
***************
job.n	436	13	we need far better government , and we should get on with the __job__ of finding it .
Contexts for target job are: ['det_the', 'prep:withI_get']
Contexts in vocabulary for target job are: ['det_the', 'prep:withI_get']
Top most similar embeddings: job 0.26719	af360 0.18574	jobs 0.18549	task 0.18548	footbrake 0.18157	tejon 0.18055	chillow 0.17965	lifedrive 0.17768	w550i 0.17605	chores 0.17534

Generated lemmatized results
***************
GENERATED	job.n 436 ::: task;footbrake;tejon;chillow;lifedrive;chore;mooncup;beemer;hastle;legwork

Filtered results
***************
RANKED	job.n 436	task 0.18548	assignment 0.15736	role 0.15687	business 0.15512	duty 0.15423	contract 0.15062	career 0.15003	work 0.14942	responsibility 0.14555	position 0.14500	bit 0.14450	employment 0.14412	post 0.13676	matter 0.13158	function 0.13076	place 0.12886	functional 0.10171

Test context:
***************
job.n	437	7	human resources professionals plan and organize their __job__ tasks at complexity level 4. explanation of the complexity levels level 1 level 2 level 3 level 4 little variety in work activities ; similar repetitive tasks .
Contexts for target job are: ['nnI_tasks']
Contexts in vocabulary for target job are: ['nnI_tasks']
Top most similar embeddings: job 0.49874	xronos 0.36812	task 0.36537	fsmo 0.35452	oh&s 0.34334	post-installation 0.34236	homework 0.33929	risk-assessment 0.33920	route-finding 0.33815	defragmentation 0.33803

Generated lemmatized results
***************
GENERATED	job.n 437 ::: xronos;task;fsmo;homework;defragmentation;assignment;ooda;csar;voms;backoffice

Filtered results
***************
RANKED	job.n 437	task 0.36537	assignment 0.33431	business 0.32000	employment 0.31954	career 0.31694	work 0.31298	role 0.30698	duty 0.29784	post 0.29156	responsibility 0.28932	position 0.28593	contract 0.27978	function 0.26998	place 0.26386	matter 0.24860	bit 0.24757	functional 0.24083

Test context:
***************
job.n	438	8	within days you can apply for that unreachable __job__ , or show your degree to your employer and demand the raise and promotion that your knowledge and skills deserve .
Contexts for target job are: ['det_that', 'amod_unreachable', 'prep:forI_apply']
Contexts in vocabulary for target job are: ['det_that', 'amod_unreachable', 'prep:forI_apply']
Top most similar embeddings: job 0.10786	jobs 0.08107	positon 0.08048	vacancy 0.07652	task 0.07504	postion 0.07487	goal 0.07480	position 0.07366	errand 0.07216	mesage 0.07163

Generated lemmatized results
***************
GENERATED	job.n 438 ::: positon;vacancy;task;postion;goal;position;errand;mesage;purpose;dispensation

Filtered results
***************
RANKED	job.n 438	task 0.07504	position 0.07366	post 0.06737	place 0.06732	employment 0.06691	role 0.06667	duty 0.06565	career 0.06313	assignment 0.06136	matter 0.06059	contract 0.05805	responsibility 0.05692	function 0.05649	bit 0.05638	business 0.05611	work 0.05331	functional 0.03948

Test context:
***************
job.n	439	0	__job__ creation is critical to attracting new residents and giving renters the confidence to become homeowners .
Contexts for target job are: ['nnI_creation']
Contexts in vocabulary for target job are: ['nnI_creation']
Top most similar embeddings: job 0.53837	jobs 0.37979	task 0.36077	employment 0.35178	vacancy 0.34656	toolpath 0.34489	voms 0.34257	buildspec 0.33938	searchengine 0.33678	installshield 0.33462

Generated lemmatized results
***************
GENERATED	job.n 439 ::: task;employment;vacancy;toolpath;voms;buildspec;searchengine;installshield;gtld;business

Filtered results
***************
RANKED	job.n 439	task 0.36077	employment 0.35178	business 0.33331	career 0.32558	role 0.31156	contract 0.30262	assignment 0.30191	duty 0.29428	post 0.29134	position 0.28129	work 0.27936	function 0.27050	responsibility 0.26819	matter 0.26406	place 0.25330	bit 0.25156	functional 0.24328

Test context:
***************
job.n	440	30	people are thinking of something they can take home , that in some way , affirms what they believe , or how they think-and boy , it 's not the __job__ description of the artist to do that .
Contexts for target job are: ['det_the', 'depI_not', 'amod_description']
Contexts in vocabulary for target job are: ['det_the', 'depI_not', 'amod_description']
Top most similar embeddings: job 0.12084	task 0.08178	jobs 0.07800	vacancy 0.07540	renter 0.07319	doer 0.07206	product 0.07198	pastorate 0.07174	chargee 0.07160	payee 0.07114

Generated lemmatized results
***************
GENERATED	job.n 440 ::: task;vacancy;renter;doer;product;pastorate;chargee;payee;cra;salesman

Filtered results
***************
RANKED	job.n 440	task 0.08178	role 0.06871	position 0.06835	duty 0.06689	assignment 0.06646	contract 0.06643	responsibility 0.06468	career 0.06337	employment 0.06334	business 0.06238	post 0.05878	function 0.05830	place 0.05755	matter 0.05731	work 0.05662	bit 0.05489	functional 0.04847

Test context:
***************
late.r	441	31	she was to be waiting with the other virgins - her bridesmaids and companions - who would all have oil in their lamps in case the groom should choose to come __late__ in the night .
Contexts for target late are: ['advmodI_in']
Contexts in vocabulary for target late are: ['advmodI_in']
Top most similar embeddings: late 0.52738	early 0.41119	later 0.36872	especially 0.34539	proably 0.34445	even 0.34365	only 0.34221	particularly 0.34155	mainly 0.33791	already 0.33766

Generated lemmatized results
***************
GENERATED	late.r 441 ::: early;later;especially;proably;even;only;particularly;mainly;already;precipitously

Filtered results
***************
RANKED	late.r 441	recently 0.32775	lately 0.30607	behind 0.27861	tardy 0.27617	latterly 0.26936	overdue 0.26224	recent 0.26004	older 0.25625	delayed 0.25294	current 0.24658

Test context:
***************
late.r	442	8	this fits with alot of my thinking of __late__ when it comes to church .
Contexts for target late are: ['pcompI_of', 'advcl_comes']
Contexts in vocabulary for target late are: ['pcompI_of', 'advcl_comes']
Top most similar embeddings: late 0.21739	oversimplifying 0.17118	closed-minded 0.16952	inconveniencing 0.16554	unpatriotic 0.16433	shirking 0.16337	empathising 0.16199	unloving 0.16088	stingy 0.16077	appeasing 0.16035

Generated lemmatized results
***************
GENERATED	late.r 442 ::: oversimplifying;inconveniencing;unpatriotic;shirking;empathising;unloving;stingy;appeasing;abating;cashing

Filtered results
***************
RANKED	late.r 442	tardy 0.15891	delayed 0.14419	overdue 0.13630	behind 0.13427	lately 0.12283	older 0.12019	recently 0.10932	recent 0.10277	current 0.10005	latterly 0.09422

Test context:
***************
late.r	443	5	" he would come home __late__ from work , put his earpieces in and listen to his favourite sports show on the radio , read the paper and fall asleep , " tilly says .
Contexts for target late are: ['advmodI_come', 'prep:from_work']
Contexts in vocabulary for target late are: ['advmodI_come', 'prep:from_work']
Top most similar embeddings: late 0.23750	early 0.18834	later 0.16725	back 0.16549	ignominiously 0.16532	away 0.16501	unstuck 0.16445	tamely 0.16296	eventualy 0.16203	hither 0.16189

Generated lemmatized results
***************
GENERATED	late.r 443 ::: early;later;back;ignominiously;away;unstuck;tamely;eventualy;hither;thither

Filtered results
***************
RANKED	late.r 443	recently 0.14565	lately 0.14225	overdue 0.13394	latterly 0.12896	older 0.12634	behind 0.12630	tardy 0.12351	delayed 0.11702	recent 0.10961	current 0.10834

Test context:
***************
late.r	444	2	we were __late__ doing this since i refused to use someone else 's " shopping cart " system that i did n't write and could n't trust .
Contexts for target late are: ['nsubj_we', 'cop_were', 'rootI_*root*', 'xcomp_doing', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target late are: ['nsubj_we', 'cop_were', 'rootI_*root*', 'xcomp_doing', 'punct_.']
Top most similar embeddings: lucky 0.02198	fortunate 0.02183	delighted 0.02168	late 0.02165	keen 0.02158	busy 0.02158	short-handed 0.02132	glad 0.02122	desparate 0.02113	happy 0.02094

Generated lemmatized results
***************
GENERATED	late.r 444 ::: lucky;fortunate;delighted;keen;busy;glad;desparate;happy;pleased;anxious

Filtered results
***************
RANKED	late.r 444	tardy 0.01916	overdue 0.01650	delayed 0.01501	older 0.01237	behind 0.01193	latterly 0.00953	lately 0.00915	recently 0.00845	recent 0.00797	current 0.00794

Test context:
***************
late.r	445	1	very __late__ in the movie , he finally does marry scarlett .
Contexts for target late are: ['advmod_very', 'advmodI_in']
Contexts in vocabulary for target late are: ['advmod_very', 'advmodI_in']
Top most similar embeddings: late 0.26849	early 0.21435	dexterously 0.18672	ineffectually 0.17647	cheaply 0.17542	cannily 0.17470	often 0.17451	sportingly 0.17435	conservatively 0.17357	sparingly 0.17259

Generated lemmatized results
***************
GENERATED	late.r 445 ::: early;dexterously;ineffectually;cheaply;cannily;often;sportingly;conservatively;sparingly;easilly

Filtered results
***************
RANKED	late.r 445	recently 0.16737	lately 0.15406	tardy 0.14371	behind 0.13112	recent 0.13011	overdue 0.12740	latterly 0.12159	delayed 0.11776	older 0.11463	current 0.11234

Test context:
***************
late.r	446	9	' there were only 10 golf clubs in the __late__ 1700s .
Contexts for target late are: ['amodI_1700s']
Contexts in vocabulary for target late are: ['amodI_1700s']
Top most similar embeddings: late 0.57535	early 0.43365	mid-late 0.41703	mid-to-late 0.41483	early/mid 0.39832	mid/late 0.38677	early-mid 0.38637	mid 0.35582	later 0.33773	mid-19th 0.32356

Generated lemmatized results
***************
GENERATED	late.r 446 ::: early;mid;later;earlier;successional;tardy;drizzly;belatedly;seaven;premature

Filtered results
***************
RANKED	late.r 446	tardy 0.29347	recently 0.26714	older 0.26113	delayed 0.25959	overdue 0.25408	lately 0.24950	behind 0.24898	recent 0.24861	current 0.22927	latterly 0.22796

Test context:
***************
late.r	447	7	t his fear of being slow or __late__ is an older and more dangerous problem than it seems .
Contexts for target late are: ['conjI_slow']
Contexts in vocabulary for target late are: ['conjI_slow']
Top most similar embeddings: late 0.46737	slow 0.37824	erratic 0.36624	sluggish 0.35631	hung-over 0.35270	slowish 0.35158	laborious 0.35121	fitful 0.34882	ponderous 0.34789	unreliable 0.34658

Generated lemmatized results
***************
GENERATED	late.r 447 ::: slow;erratic;sluggish;slowish;laborious;fitful;ponderous;unreliable;clumsy;drizzly

Filtered results
***************
RANKED	late.r 447	tardy 0.33892	delayed 0.31553	overdue 0.30616	recently 0.28369	lately 0.27283	behind 0.27267	recent 0.26773	older 0.26704	latterly 0.24864	current 0.24416

Test context:
***************
late.r	448	1	as __late__ as 1918 , they elected 32 state legislators .
Contexts for target late are: ['prep:asI_elected', 'prep:as_1918']
Contexts in vocabulary for target late are: ['prep:asI_elected']
Top most similar embeddings: late 0.44954	early 0.35607	vice-convener 0.32385	ex-president 0.32316	heretofore 0.32221	president-elect 0.32116	myp 0.32050	sub-warden 0.32047	bishop-elect 0.31999	coadjutor 0.31932

Generated lemmatized results
***************
GENERATED	late.r 448 ::: early;heretofore;myp;coadjutor;scrutineers;backbencher;bencher;commissar;pursuivant;sidesmen

Filtered results
***************
RANKED	late.r 448	recently 0.29489	tardy 0.28975	overdue 0.27522	lately 0.27117	recent 0.26734	older 0.26498	latterly 0.25298	delayed 0.25161	current 0.24995	behind 0.24607

Test context:
***************
late.r	449	2	in the __late__ 60s , he moved to california , got bored and moved to nashville where he began working on his first album titled " old no.1 " .
Contexts for target late are: ['amodI_60s']
Contexts in vocabulary for target late are: ['amodI_60s']
Top most similar embeddings: late 0.55148	mid-to-late 0.43450	mid-late 0.42602	early 0.42347	early/mid 0.42133	early-mid 0.39975	mid/late 0.38562	mid-twentieth 0.36261	mid-19th 0.36204	mid-20th 0.35942

Generated lemmatized results
***************
GENERATED	late.r 449 ::: early;mid;later;seaven;lugubrious;monkish;luckless;fusty;somnolent;bygone

Filtered results
***************
RANKED	late.r 449	tardy 0.31595	overdue 0.29288	older 0.28521	delayed 0.27900	recent 0.27388	behind 0.27102	recently 0.27008	lately 0.26252	current 0.25732	latterly 0.24880

Test context:
***************
late.r	450	2	i married __late__ and had children later and in retrospect my self absorption in my own career cheated my sons of knowing this man who taught me so much .
Contexts for target late are: ['dep_i', 'amod_married', 'depI_<eol>', 'cc_and', 'conj_had', 'dep_later', 'punct_.']
Contexts in vocabulary for target late are: ['dep_i', 'amod_married', 'cc_and', 'conj_had', 'dep_later', 'punct_.']
Top most similar embeddings: late 0.00944	remarried 0.00941	re-married 0.00903	coh 0.00881	hereupon 0.00864	2dly 0.00863	married 0.00832	nowe 0.00808	bapt 0.00802	orn 0.00801

Generated lemmatized results
***************
GENERATED	late.r 450 ::: remarried;coh;hereupon;married;nowe;bapt;orn;googled;relented;twas

Filtered results
***************
RANKED	late.r 450	tardy 0.00712	overdue 0.00602	older 0.00597	delayed 0.00592	behind 0.00584	lately 0.00533	latterly 0.00493	recently 0.00381	current 0.00367	recent 0.00318

Test context:
***************
new.a	451	9	my interest in europe 's defence policy is nothing __new__ .
Contexts for target new are: ['amodI_nothing']
Contexts in vocabulary for target new are: ['amodI_nothing']
Top most similar embeddings: new 0.52362	newish 0.39133	newfangled 0.38657	out-of-the-ordinary 0.38457	brand-new 0.37880	earth-shattering 0.37382	origional 0.37344	certian 0.37237	world-changing 0.37137	newer 0.37121

Generated lemmatized results
***************
GENERATED	new.a 451 ::: newish;newfangled;origional;certian;comtemporary;fangled;lilliputian;geniune;cultish;untoward

Filtered results
***************
RANKED	new.a 451	original 0.34207	different 0.33285	extra 0.33258	modern 0.33249	additional 0.33063	fresh 0.33041	other 0.31363	recent 0.31310	current 0.31118	novel 0.30838	further 0.30175	latest 0.30172	younger 0.29318	distinct 0.29205	succeeding 0.28048	another 0.23063

Test context:
***************
new.a	452	7	do not start a new page for __new__ sections ( chapters ) or subsections .
Contexts for target new are: ['amodI_sections']
Contexts in vocabulary for target new are: ['amodI_sections']
Top most similar embeddings: new 0.50818	then-new 0.40759	newly-released 0.40532	newly-developed 0.40485	public-facing 0.40447	upper-level 0.40328	addtional 0.40188	non-music 0.40035	theme-based 0.39852	60-page 0.39798

Generated lemmatized results
***************
GENERATED	new.a 452 ::: addtional;newish;certian;dockable;preambular;ancilliary;additonal;aspheric;specfic;pervious

Filtered results
***************
RANKED	new.a 452	additional 0.35922	different 0.35418	extra 0.33138	original 0.33046	fresh 0.32911	modern 0.32673	distinct 0.32667	current 0.32616	other 0.32589	recent 0.31797	succeeding 0.31687	further 0.31390	latest 0.30983	younger 0.30858	novel 0.28567	another 0.22608

Test context:
***************
new.a	453	34	while there she also received a visit from the holy carmelite maria de yepes , who had just returned from rome with permission to establish a reformed convent and who provided teresa with a __new__ light on the question of the type of poverty to be adopted by her own community .
Contexts for target new are: ['amodI_light']
Contexts in vocabulary for target new are: ['amodI_light']
Top most similar embeddings: new 0.51641	trefoil-headed 0.40739	super-duper 0.40477	ogee-headed 0.40449	flourescent 0.40438	multicolored 0.39684	supernal 0.39608	uranian 0.39489	solar-powered 0.39476	colour-changing 0.39469

Generated lemmatized results
***************
GENERATED	new.a 453 ::: flourescent;multicolored;supernal;uranian;electroluminescent;addtional;newfangled;zodiacal;thermoelectric;newish

Filtered results
***************
RANKED	new.a 453	additional 0.35323	fresh 0.35311	different 0.34482	modern 0.33861	original 0.33321	extra 0.33281	current 0.31712	latest 0.31419	recent 0.31359	further 0.31284	other 0.29975	novel 0.29853	distinct 0.29476	succeeding 0.28509	younger 0.27625	another 0.22742

Test context:
***************
new.a	454	40	tea hybrid climbing mme caroline testout damask rose york and lancaster with pink and white flowers all these roses flower only on one-year old branches , which is why they have only a short flowering period followed by development of __new__ branches for next year 's flowers ( some damask roses , though , show a second short bloom in fall ) .
Contexts for target new are: ['amodI_branches']
Contexts in vocabulary for target new are: ['amodI_branches']
Top most similar embeddings: new 0.50307	newly-established 0.40871	top-performing 0.39921	similar-sized 0.39609	then-new 0.39437	newly-created 0.39419	upper-level 0.39412	non-united 0.38981	non-council 0.38848	national/local 0.38815

Generated lemmatized results
***************
GENERATED	new.a 454 ::: petaid;hyphal;dockable;addtional;ocal;exsisting;conidial;prefectural;ancilliary;newfangled

Filtered results
***************
RANKED	new.a 454	additional 0.35450	different 0.35189	fresh 0.33744	modern 0.32708	other 0.32551	original 0.32346	extra 0.32237	current 0.32066	younger 0.31767	distinct 0.31228	latest 0.31169	recent 0.31073	further 0.30887	succeeding 0.29648	novel 0.27104	another 0.23408

Test context:
***************
new.a	455	4	our proposals will unlock __new__ ways of raising the finance needed to develop businesses , be they big or small .
Contexts for target new are: ['amodI_ways']
Contexts in vocabulary for target new are: ['amodI_ways']
Top most similar embeddings: new 0.53386	newfangled 0.40166	certian 0.39577	nontraditional 0.39500	non-complex 0.39484	newish 0.39436	surefire 0.39260	untraditional 0.39183	differnt 0.38921	tried-and-tested 0.38891

Generated lemmatized results
***************
GENERATED	new.a 455 ::: newfangled;certian;nontraditional;newish;surefire;untraditional;differnt;differnet;fangled;specfic

Filtered results
***************
RANKED	new.a 455	different 0.37304	additional 0.34760	fresh 0.34294	modern 0.34147	original 0.33429	current 0.32860	other 0.32792	novel 0.32124	recent 0.31801	distinct 0.31668	extra 0.31065	latest 0.30934	further 0.30653	younger 0.28475	succeeding 0.27341	another 0.22850

Test context:
***************
new.a	456	23	in her welcome address to delegates , she will be announcing the publication of updated hse guidelines on lifting and the outcome of __new__ research by the institute of occupational medicine , that validates the current manual handling advice .
Contexts for target new are: ['amodI_research']
Contexts in vocabulary for target new are: ['amodI_research']
Top most similar embeddings: new 0.51847	trust-funded 0.44269	patient-oriented 0.44132	prosopographical 0.43696	near-market 0.43230	phenomenographic 0.42989	industry-sponsored 0.42651	late-breaking 0.42139	externally-funded 0.42080	pre-competitive 0.42010

Generated lemmatized results
***************
GENERATED	new.a 456 ::: prosopographical;phenomenographic;gerontological;largescale;ethnobotanical;neuroscientific;pharmacogenetic;geoscientific;geoarchaeological;goethean

Filtered results
***************
RANKED	new.a 456	recent 0.36499	current 0.36480	original 0.35949	additional 0.35796	modern 0.35178	latest 0.34677	fresh 0.33458	further 0.33283	extra 0.31924	other 0.31356	different 0.31055	novel 0.30641	younger 0.28765	distinct 0.28455	succeeding 0.26828	another 0.22790

Test context:
***************
new.a	457	16	i love this saddle and hate to sell it , but just does n't fit the __new__ horse .
Contexts for target new are: ['amodI_horse']
Contexts in vocabulary for target new are: ['amodI_horse']
Top most similar embeddings: new 0.49246	one-trick 0.42617	then-new 0.41047	150-year-old 0.40378	super-duper 0.40329	one-horse 0.40188	jet-powered 0.40099	newish 0.40084	brand-new 0.40011	much-acclaimed 0.39998

Generated lemmatized results
***************
GENERATED	new.a 457 ::: newish;newfangled;traditonal;majorcan;prizewinning;wizarding;agreat;geniune;homebred;beleagured

Filtered results
***************
RANKED	new.a 457	original 0.33896	modern 0.33860	fresh 0.33783	additional 0.33000	current 0.32472	different 0.32438	extra 0.31720	latest 0.31543	recent 0.31496	younger 0.31189	other 0.30523	succeeding 0.29531	distinct 0.28743	further 0.28694	novel 0.28086	another 0.24136

Test context:
***************
new.a	458	8	the lecture itself went well , but a __new__ problem arose .
Contexts for target new are: ['amodI_problem']
Contexts in vocabulary for target new are: ['amodI_problem']
Top most similar embeddings: new 0.48743	three-body 0.41085	much-discussed 0.40829	decades-old 0.40727	n-body 0.40214	israeli/palestinian 0.39894	researchable 0.39659	now-familiar 0.39635	two-bit 0.39499	multibillion-dollar 0.39423

Generated lemmatized results
***************
GENERATED	new.a 458 ::: researchable;addtional;specfic;geniune;newish;socalled;pharmacotherapeutic;curent;finacial;multibillion

Filtered results
***************
RANKED	new.a 458	additional 0.35750	original 0.34777	current 0.34521	modern 0.33688	recent 0.33180	different 0.33156	fresh 0.32787	latest 0.31859	extra 0.31835	further 0.31572	other 0.31425	distinct 0.30955	novel 0.29746	younger 0.28500	succeeding 0.27479	another 0.22664

Test context:
***************
new.a	459	16	the announcement came just hours before a planned press conference to reveal the name of the __new__ director .
Contexts for target new are: ['amodI_director']
Contexts in vocabulary for target new are: ['amodI_director']
Top most similar embeddings: new 0.51752	newly-appointed 0.41656	toronto-based 0.41602	norwich-based 0.41539	board-level 0.41446	longest-serving 0.40955	swansea-based 0.40834	highest-paid 0.40755	then-new 0.40724	surrey-based 0.40563

Generated lemmatized results
***************
GENERATED	new.a 459 ::: newish;corporative;onetime;finacial;inaugral;erstwhile;prestigeous;beleagured;upstate;guinean

Filtered results
***************
RANKED	new.a 459	current 0.34704	additional 0.34624	original 0.34069	recent 0.32430	modern 0.32318	fresh 0.32154	different 0.31866	latest 0.31348	extra 0.31039	other 0.30317	further 0.29760	succeeding 0.29041	younger 0.29032	novel 0.28394	distinct 0.27932	another 0.21906

Test context:
***************
new.a	460	18	these empires , with names like ghana , mali , and songhay , established caravan routes that brought __new__ peoples and the religion of islam to the areas of west africa .
Contexts for target new are: ['amodI_peoples']
Contexts in vocabulary for target new are: ['amodI_peoples']
Top most similar embeddings: new 0.47086	indiginous 0.41262	ex-colonial 0.41070	non-english-speaking 0.40873	arabic-speaking 0.40406	greek-speaking 0.39489	pre-hispanic 0.39291	newly-arrived 0.39291	non-arab 0.39278	non-indigenous 0.39164

Generated lemmatized results
***************
GENERATED	new.a 460 ::: indiginous;melanesian;illyrian;autochthonous;karelian;mesoamerican;gaulish;azerbaijani;salvadoran;micronesian

Filtered results
***************
RANKED	new.a 460	different 0.34396	modern 0.34035	original 0.33030	other 0.32806	additional 0.32530	recent 0.31566	distinct 0.31402	current 0.31127	younger 0.31078	fresh 0.30523	latest 0.29931	extra 0.29746	succeeding 0.28767	further 0.28276	novel 0.27718	another 0.23383

Test context:
***************
often.r	461	12	beazley : i 'm a confident traveller because i do it so __often__ and my experience has always been good .
Contexts for target often are: ['advmod_so', 'advmodI_do', 'cc_and', 'conj_experience']
Contexts in vocabulary for target often are: ['advmod_so', 'advmodI_do', 'cc_and', 'conj_experience']
Top most similar embeddings: knowledgeably 0.04794	prosperously 0.04763	experientially 0.04758	pervasively 0.04751	often 0.04693	articulately 0.04684	enjoyably 0.04676	prayerfully 0.04665	eloquently 0.04642	maturely 0.04616

Generated lemmatized results
***************
GENERATED	often.r 461 ::: knowledgeably;prosperously;experientially;pervasively;articulately;enjoyably;prayerfully;eloquently;maturely;lucidly

Filtered results
***************
RANKED	often.r 461	frequently 0.03823	much 0.03719	habitually 0.03584	recurrently 0.03526	sometimes 0.03510	regularly 0.03447	occasionally 0.03402	generally 0.03304	commonly 0.03092	usually 0.02506

Test context:
***************
often.r	462	13	when archaeologists think of alternative ( or ' cult ' ) archaeology we __often__ think of those patterns of argument that imitate conventional archaeological process and language but arrive at outlandish conclusions .
Contexts for target often are: ['advmodI_think']
Contexts in vocabulary for target often are: ['advmodI_think']
Top most similar embeddings: often 0.52462	sometimes 0.44773	proably 0.42953	actaully 0.41880	apprently 0.41850	presumptuously 0.41460	even 0.41379	usally 0.41319	ocassionally 0.41155	probally 0.40968

Generated lemmatized results
***************
GENERATED	often.r 462 ::: sometimes;proably;actaully;apprently;presumptuously;even;usally;ocassionally;probally;unconventionally

Filtered results
***************
RANKED	often.r 462	sometimes 0.44773	frequently 0.40117	usually 0.39638	generally 0.38760	recurrently 0.37588	occasionally 0.36593	commonly 0.36258	habitually 0.35766	regularly 0.34387	much 0.33627

Test context:
***************
often.r	463	9	the bonnet has a coloured cord and tassels which __often__ identify the institution they represent .
Contexts for target often are: ['advmodI_identify']
Contexts in vocabulary for target often are: ['advmodI_identify']
Top most similar embeddings: often 0.50885	sometimes 0.42319	affectively 0.41760	reproducibly 0.41625	clearly 0.41343	frequently 0.41131	feasibly 0.41047	intelligibly 0.40930	mechanistically 0.40676	adeptly 0.40613

Generated lemmatized results
***************
GENERATED	often.r 463 ::: sometimes;affectively;reproducibly;clearly;frequently;feasibly;intelligibly;mechanistically;adeptly;unproblematically

Filtered results
***************
RANKED	often.r 463	sometimes 0.42319	frequently 0.41131	usually 0.39576	generally 0.37865	recurrently 0.37726	commonly 0.36537	occasionally 0.36241	regularly 0.35540	habitually 0.35244	much 0.31392

Test context:
***************
often.r	464	4	tiny droplets of dew __often__ form at night on cold surfaces such as grass and leaves .
Contexts for target often are: ['advmodI_form']
Contexts in vocabulary for target often are: ['advmodI_form']
Top most similar embeddings: often 0.52620	sometimes 0.43351	frequently 0.42193	mechanistically 0.41305	reproducibly 0.41297	affectively 0.41108	usually 0.40959	dually 0.40752	adeptly 0.40650	dexterously 0.40463

Generated lemmatized results
***************
GENERATED	often.r 464 ::: sometimes;frequently;mechanistically;reproducibly;affectively;usually;dually;adeptly;dexterously;ocassionally

Filtered results
***************
RANKED	often.r 464	sometimes 0.43351	frequently 0.42193	usually 0.40959	generally 0.39082	recurrently 0.38713	commonly 0.37959	occasionally 0.36971	regularly 0.35648	habitually 0.35185	much 0.32247

Test context:
***************
often.r	465	8	the full balance is paid on completion , __often__ giving you more than 12 months to organise your financial affairs .
Contexts for target often are: ['advmodI_giving']
Contexts in vocabulary for target often are: ['advmodI_giving']
Top most similar embeddings: often 0.51465	sometimes 0.42886	dexterously 0.41411	good-naturedly 0.41011	frequently 0.40819	proably 0.40783	adeptly 0.40433	publickly 0.40348	regularily 0.40226	thus 0.40218

Generated lemmatized results
***************
GENERATED	often.r 465 ::: sometimes;dexterously;frequently;proably;adeptly;publickly;regularily;thus;deviously;presumptuously

Filtered results
***************
RANKED	often.r 465	sometimes 0.42886	frequently 0.40819	usually 0.39251	generally 0.38223	occasionally 0.37631	recurrently 0.37538	regularly 0.36918	habitually 0.35275	commonly 0.34783	much 0.32754

Test context:
***************
often.r	466	15	we frequently add both new and old articles to the site , so check back __often__ !
Contexts for target often are: ['advmodI_check']
Contexts in vocabulary for target often are: ['advmodI_check']
Top most similar embeddings: often 0.51740	frequently 0.42728	regularily 0.42203	sometimes 0.41121	proably 0.40705	reguarly 0.40701	ususally 0.40230	always 0.40154	ocassionally 0.40141	defintely 0.39984

Generated lemmatized results
***************
GENERATED	often.r 466 ::: frequently;regularily;sometimes;proably;reguarly;ususally;always;ocassionally;defintely;routinely

Filtered results
***************
RANKED	often.r 466	frequently 0.42728	sometimes 0.41121	regularly 0.38884	usually 0.38767	occasionally 0.37762	generally 0.37067	recurrently 0.35698	habitually 0.35356	commonly 0.34714	much 0.30995

Test context:
***************
often.r	467	5	they are pinker and most __often__ darker than their mothers unexposed skin .
Contexts for target often are: ['advmod_most', 'advmodI_darker']
Contexts in vocabulary for target often are: ['advmod_most', 'advmodI_darker']
Top most similar embeddings: often 0.26974	noticably 0.22692	pervasively 0.22141	frequently 0.22048	egregiously 0.21891	potently 0.21859	damagingly 0.21251	unpleasantly 0.20539	viscerally 0.20420	plentifully 0.20392

Generated lemmatized results
***************
GENERATED	often.r 467 ::: noticably;pervasively;frequently;egregiously;potently;damagingly;unpleasantly;viscerally;plentifully;mystically

Filtered results
***************
RANKED	often.r 467	frequently 0.22048	usually 0.19355	generally 0.18804	commonly 0.18685	sometimes 0.18025	occasionally 0.17069	habitually 0.16703	regularly 0.16423	recurrently 0.16335	much 0.15718

Test context:
***************
often.r	468	11	they shall wash their hands thoroughly before starting work and as __often__ as necessary while working to remove soil and contaminants .
Contexts for target often are: ['advmod_as', 'conjI_starting', 'dep_necessary']
Contexts in vocabulary for target often are: ['advmod_as', 'conjI_starting', 'dep_necessary']
Top most similar embeddings: often 0.10242	soon 0.08919	long 0.08200	infrequently 0.08119	far 0.08074	quickly 0.08072	frequently 0.08010	expeditiously 0.07972	insofar 0.07724	efficiently 0.07712

Generated lemmatized results
***************
GENERATED	often.r 468 ::: soon;long;infrequently;far;quickly;frequently;expeditiously;insofar;efficiently;expediently

Filtered results
***************
RANKED	often.r 468	frequently 0.08010	much 0.07258	sometimes 0.07090	regularly 0.06816	commonly 0.06372	occasionally 0.06354	recurrently 0.06169	usually 0.05959	generally 0.05835	habitually 0.05522

Test context:
***************
often.r	469	9	but the great irony is that those articles are __often__ sandwiched between misleading ads funded by an even more brazenly corrupt lobbyist who has evaded the law for decades .
Contexts for target often are: ['advmodI_sandwiched']
Contexts in vocabulary for target often are: ['advmodI_sandwiched']
Top most similar embeddings: often 0.50220	sometimes 0.42184	adeptly 0.41209	frequently 0.40866	inconspicuously 0.40372	promiscuously 0.40152	picturesquely 0.40106	usually 0.39974	plentifully 0.39914	dexterously 0.39797

Generated lemmatized results
***************
GENERATED	often.r 469 ::: sometimes;adeptly;frequently;inconspicuously;promiscuously;picturesquely;usually;plentifully;dexterously;unconventionally

Filtered results
***************
RANKED	often.r 469	sometimes 0.42184	frequently 0.40866	usually 0.39974	generally 0.38082	recurrently 0.37218	occasionally 0.37061	commonly 0.35447	habitually 0.34913	regularly 0.34299	much 0.31395

Test context:
***************
often.r	470	15	this is something that most civilians never think about -and maybe do n't understand how __often__ it happens and what profound impact it has on the letter recipient .
Contexts for target often are: ['advmod_how', 'advmodI_happens']
Contexts in vocabulary for target often are: ['advmod_how', 'advmodI_happens']
Top most similar embeddings: often 0.28772	frequently 0.22376	sometimes 0.20919	quickly 0.20374	adeptly 0.20326	pervasively 0.20044	affectively 0.20029	egregiously 0.19730	easilly 0.19658	rarely 0.19509

Generated lemmatized results
***************
GENERATED	often.r 470 ::: frequently;sometimes;quickly;adeptly;pervasively;affectively;egregiously;easilly;rarely;dexterously

Filtered results
***************
RANKED	often.r 470	frequently 0.22376	sometimes 0.20919	commonly 0.17937	recurrently 0.17885	much 0.17847	regularly 0.17695	usually 0.17230	occasionally 0.17095	generally 0.16572	habitually 0.16479

Test context:
***************
only.r	471	3	cattle bones were __only__ present in small numbers .
Contexts for target only are: ['advmodI_present']
Contexts in vocabulary for target only are: ['advmodI_present']
Top most similar embeddings: only 0.51415	dually 0.40567	also 0.40233	atypically 0.40137	existentially 0.40118	legislatively 0.39982	probabilistically 0.39871	usally 0.39711	intially 0.39634	kinetically 0.39586

Generated lemmatized results
***************
GENERATED	only.r 471 ::: dually;also;atypically;existentially;legislatively;probabilistically;usally;intially;kinetically;catalytically

Filtered results
***************
RANKED	only.r 471	just 0.39504	merely 0.39424	solely 0.35057	barely 0.34718	uniquely 0.34239	singularly 0.34238	exclusively 0.33948	hardly 0.33848	purely 0.33673	recently 0.31392

Test context:
***************
only.r	472	1	that __only__ gives 200 transactions per second , a massive drop in performance .
Contexts for target only are: ['advmodI_gives']
Contexts in vocabulary for target only are: ['advmodI_gives']
Top most similar embeddings: only 0.51975	also 0.41379	futhermore 0.40911	just 0.40799	bascially 0.40237	dually 0.40040	intially 0.39787	merely 0.39739	proably 0.39651	cryptographically 0.39608

Generated lemmatized results
***************
GENERATED	only.r 472 ::: also;futhermore;just;bascially;dually;intially;merely;proably;cryptographically;defintely

Filtered results
***************
RANKED	only.r 472	just 0.40799	merely 0.39739	hardly 0.34293	barely 0.33843	uniquely 0.33794	solely 0.33495	exclusively 0.33446	singularly 0.33308	purely 0.32892	recently 0.30553

Test context:
***************
only.r	473	10	the argument has been set out elsewhere(24 ) and needs __only__ be summarised here .
Contexts for target only are: ['advmodI_summarised']
Contexts in vocabulary for target only are: ['advmodI_summarised']
Top most similar embeddings: only 0.48090	probabilistically 0.38780	legislatively 0.38558	algebraically 0.38464	just 0.38460	diagrammatically 0.38236	dually 0.37959	purposively 0.37915	also 0.37881	irrefutably 0.37780

Generated lemmatized results
***************
GENERATED	only.r 473 ::: probabilistically;legislatively;algebraically;just;diagrammatically;dually;purposively;also;irrefutably;spuriously

Filtered results
***************
RANKED	only.r 473	just 0.38460	merely 0.37737	hardly 0.33085	recently 0.32998	purely 0.32705	solely 0.32428	uniquely 0.31714	singularly 0.31489	barely 0.31300	exclusively 0.30840

Test context:
***************
only.r	474	4	truth can be reached __only__ through the comprehension of opposites .
Contexts for target only are: ['advmodI_through']
Contexts in vocabulary for target only are: ['advmodI_through']
Top most similar embeddings: only 0.53988	just 0.41068	even 0.40143	primarily 0.39776	mainly 0.38912	merely 0.38750	usually 0.38509	particularly 0.38413	perhaps 0.37854	especially 0.37623

Generated lemmatized results
***************
GENERATED	only.r 474 ::: just;even;primarily;mainly;merely;usually;particularly;perhaps;especially;also

Filtered results
***************
RANKED	only.r 474	just 0.41068	merely 0.38750	solely 0.36785	barely 0.34074	purely 0.32760	exclusively 0.32744	hardly 0.32465	recently 0.32236	singularly 0.31888	uniquely 0.30478

Test context:
***************
only.r	475	5	true beauty could be discovered __only__ by one who mentally completed the incomplete .
Contexts for target only are: ['advmodI_by']
Contexts in vocabulary for target only are: ['advmodI_by']
Top most similar embeddings: only 0.55265	just 0.43003	even 0.41253	merely 0.40473	primarily 0.39903	mainly 0.39310	usually 0.39295	simply 0.39037	also 0.38448	especially 0.38058

Generated lemmatized results
***************
GENERATED	only.r 475 ::: just;even;merely;primarily;mainly;usually;simply;also;especially;futhermore

Filtered results
***************
RANKED	only.r 475	just 0.43003	merely 0.40473	solely 0.37394	exclusively 0.33827	barely 0.32742	recently 0.32473	hardly 0.32332	purely 0.31899	singularly 0.31889	uniquely 0.31183

Test context:
***************
only.r	476	32	if this practice is to be guillotined and we are not to be permittedto give notice of amendments as we proceed clause by clause,it will not be fair for those who have __only__ just now joinedthe assembly .
Contexts for target only are: ['advmodI_now']
Contexts in vocabulary for target only are: ['advmodI_now']
Top most similar embeddings: only 0.52453	just 0.42647	even 0.41334	proably 0.39525	bascially 0.39409	probaly 0.38989	usally 0.38960	probally 0.38934	doubtlessly 0.38818	genuinly 0.38761

Generated lemmatized results
***************
GENERATED	only.r 476 ::: just;even;proably;bascially;probaly;usally;probally;doubtlessly;genuinly;neccesarily

Filtered results
***************
RANKED	only.r 476	just 0.42647	merely 0.36739	barely 0.33286	solely 0.32943	hardly 0.32847	exclusively 0.32778	singularly 0.31755	purely 0.31106	recently 0.30693	uniquely 0.30191

Test context:
***************
only.r	477	4	u.s. citizens should hire __only__ an authorized guide and be cautious when visiting libanona beach , peak saint louis , or other isolated areas .
Contexts for target only are: ['advmodI_guide']
Contexts in vocabulary for target only are: ['advmodI_guide']
Top most similar embeddings: only 0.53992	just 0.40814	defintely 0.39939	proably 0.39483	doubtlessly 0.39437	merely 0.39384	bascially 0.39191	futhermore 0.38961	dually 0.38908	kinetically 0.38715

Generated lemmatized results
***************
GENERATED	only.r 477 ::: just;defintely;proably;doubtlessly;merely;bascially;futhermore;dually;kinetically;epistemically

Filtered results
***************
RANKED	only.r 477	just 0.40814	merely 0.39384	purely 0.34786	solely 0.34268	barely 0.33642	uniquely 0.33579	hardly 0.33535	singularly 0.32978	exclusively 0.32616	recently 0.31251

Test context:
***************
only.r	478	0	__only__ when the planks are inserted in the correct order , do the pictures appear proper .
Contexts for target only are: ['advmodI_when']
Contexts in vocabulary for target only are: ['advmodI_when']
Top most similar embeddings: only 0.54570	even 0.42447	just 0.42336	especially 0.39181	particularly 0.38687	usually 0.36849	mainly 0.36277	exactly 0.35954	too 0.35593	merely 0.35491

Generated lemmatized results
***************
GENERATED	only.r 478 ::: even;just;especially;particularly;usually;mainly;exactly;too;merely;mostly

Filtered results
***************
RANKED	only.r 478	just 0.42336	merely 0.35491	solely 0.32950	barely 0.31718	singularly 0.31029	hardly 0.30769	purely 0.30742	exclusively 0.29838	recently 0.29792	uniquely 0.29438

Test context:
***************
only.r	479	3	if there was __only__ a way where i could take just a few minutes out my busy schedule , part-time , to grab my share of the huge internet pie , this can literally mean thousands of dollars in extra yearly income !
Contexts for target only are: ['advmodI_way']
Contexts in vocabulary for target only are: ['advmodI_way']
Top most similar embeddings: only 0.51076	just 0.42734	proably 0.40978	defintely 0.40310	bascially 0.39960	merely 0.39788	futhermore 0.39271	usally 0.39060	probaly 0.39020	acutally 0.38950

Generated lemmatized results
***************
GENERATED	only.r 479 ::: just;proably;defintely;bascially;merely;futhermore;usally;probaly;acutally;apprently

Filtered results
***************
RANKED	only.r 479	just 0.42734	merely 0.39788	hardly 0.34861	purely 0.34062	solely 0.33487	barely 0.33051	singularly 0.32928	uniquely 0.32405	exclusively 0.31979	recently 0.31192

Test context:
***************
only.r	480	14	know the conventions of the form you 're working in , and break them __only__ when you have a good reason to .
Contexts for target only are: ['dep_have']
Contexts in vocabulary for target only are: ['dep_have']
Top most similar embeddings: only 0.45177	neccessarily 0.38764	neccesarily 0.37879	ususally 0.37389	actully 0.37342	aslong 0.37320	usally 0.37015	therfore 0.36517	futhermore 0.36465	http://www.windmill.co.uk 0.36417

Generated lemmatized results
***************
GENERATED	only.r 480 ::: neccessarily;neccesarily;ususally;actully;aslong;usally;therfore;futhermore;especailly;particularily

Filtered results
***************
RANKED	only.r 480	just 0.32715	merely 0.32489	purely 0.32230	solely 0.31035	singularly 0.30418	exclusively 0.29904	barely 0.29828	uniquely 0.29703	hardly 0.29428	recently 0.26032

Test context:
***************
pulse.n	481	1	the __pulses__ were either short or long , representing the dots and dashes of morse code .
Contexts for target pulses are: ['det_the', 'nsubjI_short']
Contexts in vocabulary for target pulses are: ['det_the', 'nsubjI_short']
Top most similar embeddings: pulses 0.25417	pulse 0.20196	internodes 0.18729	tendrils 0.18408	corrugations 0.18367	petioles 0.18291	telomeres 0.18248	cotyledons 0.18125	forelimbs 0.18095	cilia 0.18003

Generated lemmatized results
***************
GENERATED	pulse.n 481 ::: internode;tendril;corrugation;petiole;telomere;cotyledon;forelimb;cilium;pistil;ureter

Filtered results
***************
RANKED	pulse.n 481	wave 0.17046	heartbeat 0.16939	beep 0.16543	vibration 0.16441	rhythm 0.15765	energy 0.15089	stimulus 0.15039	throb 0.14831	emanation 0.14788	beat 0.14288	force 0.14232	reflex 0.14103	lifeblood 0.13708	heart 0.13631	sound 0.13158	legume 0.13031	throbbing 0.12872	centre 0.12474

Test context:
***************
pulse.n	482	6	the river has always been the __pulse__ of the town , although the reasons have changed slightly over the years .
Contexts for target pulse are: ['nsubj_river', 'aux_has', 'advmod_always', 'cop_been', 'det_the', 'rootI_*root*', 'prep:of_town', 'punct_,', 'advcl_changed', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target pulse are: ['nsubj_river', 'aux_has', 'advmod_always', 'cop_been', 'det_the', 'rootI_*root*', 'prep:of_town', 'punct_,', 'advcl_changed', 'punct_.']
Top most similar embeddings: mainstay 0.00057	watchword 0.00052	epitome 0.00050	lifeblood 0.00049	lynchpin 0.00047	buzzing 0.00047	hallmark 0.00046	reawakening 0.00046	byword 0.00046	by-word 0.00046

Generated lemmatized results
***************
GENERATED	pulse.n 482 ::: mainstay;watchword;epitome;lifeblood;lynchpin;buzzing;hallmark;reawakening;byword;overflowed

Filtered results
***************
RANKED	pulse.n 482	lifeblood 0.00049	heartbeat 0.00043	throb 0.00038	throbbing 0.00037	beep 0.00036	beat 0.00035	sound 0.00035	emanation 0.00033	wave 0.00030	force 0.00028	stimulus 0.00027	reflex 0.00024	heart 0.00022	centre 0.00022	rhythm 0.00021	vibration 0.00021	energy 0.00017	legume 0.00015

Test context:
***************
pulse.n	483	21	non alcohol related questions & answers q. i take a fair amount of exercise on a training machine , and my __pulse__ is 110 at the end of the session .
Contexts for target pulse are: ['poss_my', 'nsubjI_110']
Contexts in vocabulary for target pulse are: ['poss_my', 'nsubjI_110']
Top most similar embeddings: pulse 0.23046	b/p 0.17861	pulses 0.16899	creatinine 0.16299	inr 0.16133	saturations 0.15968	i.q. 0.15696	heartbeat 0.15642	esr 0.15560	g/f 0.15454

Generated lemmatized results
***************
GENERATED	pulse.n 483 ::: creatinine;inr;saturation;heartbeat;esr;rmr;bmr;voltage;pcv;milage

Filtered results
***************
RANKED	pulse.n 483	heartbeat 0.15642	beep 0.13886	heart 0.13779	rhythm 0.13770	energy 0.13721	beat 0.13629	throb 0.13403	wave 0.13276	reflex 0.12409	vibration 0.12299	throbbing 0.12184	stimulus 0.11666	sound 0.11420	lifeblood 0.11043	force 0.10994	legume 0.10229	emanation 0.10029	centre 0.09368

Test context:
***************
pulse.n	484	20	most of the time , it lies hidden beneath the noise and confusion of our everyday lives , a quiet __pulse__ that almost unconsciously drives us forward to this day and the next .
Contexts for target pulse are: ['det_a', 'amod_quiet', 'depI_lies', 'rcmod_drives']
Contexts in vocabulary for target pulse are: ['det_a', 'amod_quiet', 'depI_lies', 'rcmod_drives']
Top most similar embeddings: pulse 0.05377	pulsation 0.04083	heartbeat 0.04083	life-force 0.03972	melody 0.03953	impulse 0.03948	throb 0.03930	miasma 0.03881	footstep 0.03869	rhythm 0.03861

Generated lemmatized results
***************
GENERATED	pulse.n 484 ::: pulsation;heartbeat;melody;impulse;throb;miasma;footstep;rhythm;bassline;drumbeat

Filtered results
***************
RANKED	pulse.n 484	heartbeat 0.04083	throb 0.03930	rhythm 0.03861	throbbing 0.03565	wave 0.03527	heart 0.03397	vibration 0.03346	beep 0.03208	reflex 0.03187	sound 0.03146	stimulus 0.03085	force 0.03078	beat 0.03003	energy 0.02988	emanation 0.02919	lifeblood 0.02848	legume 0.02530	centre 0.02314

Test context:
***************
pulse.n	485	13	on examination the knee was found to be swollen , and distal limb __pulses__ were absent .
Contexts for target pulses are: ['amod_distal', 'nn_limb', 'conjI_on']
Contexts in vocabulary for target pulses are: ['amod_distal', 'nn_limb', 'conjI_on']
Top most similar embeddings: pulses 0.10341	posteriorly 0.08321	kinking 0.08272	angulation 0.08156	extensors 0.08138	lobes 0.08048	dislocations 0.08042	lymphatics 0.08000	flexure 0.07980	contractures 0.07975

Generated lemmatized results
***************
GENERATED	pulse.n 485 ::: posteriorly;kinking;angulation;extensor;lobe;dislocation;lymphatics;flexure;contracture;flexor

Filtered results
***************
RANKED	pulse.n 485	reflex 0.07665	vibration 0.07623	heartbeat 0.06760	beep 0.06497	wave 0.06373	stimulus 0.06202	throbbing 0.06138	energy 0.05999	rhythm 0.05856	throb 0.05813	legume 0.05715	beat 0.05644	emanation 0.05597	sound 0.05210	centre 0.04799	force 0.04725	heart 0.04512	lifeblood 0.03922

Test context:
***************
pulse.n	486	5	sustained bass notes and ambient __pulses__ keep things gently swirling .
Contexts for target pulses are: ['amod_ambient', 'conjI_notes']
Contexts in vocabulary for target pulses are: ['amod_ambient', 'conjI_notes']
Top most similar embeddings: pulses 0.24137	pulse 0.18638	arpeggios 0.18354	harmonics 0.18186	soundscapes 0.17822	transients 0.17790	pulsations 0.17698	vibrations 0.17634	waveforms 0.17548	atmospherics 0.17535

Generated lemmatized results
***************
GENERATED	pulse.n 486 ::: arpeggio;harmonic;soundscapes;transient;pulsation;vibration;waveform;atmospherics;drumbeat;chord

Filtered results
***************
RANKED	pulse.n 486	vibration 0.17634	rhythm 0.17261	emanation 0.16422	wave 0.16402	beep 0.15982	stimulus 0.15841	beat 0.15741	sound 0.15374	heartbeat 0.15020	energy 0.14776	throb 0.14336	legume 0.13835	reflex 0.13423	throbbing 0.12301	force 0.12097	heart 0.11940	centre 0.10901	lifeblood 0.10605

Test context:
***************
pulse.n	487	39	prevalence of different agro-ecological tracts has made it possible to grow a multitude of over 60 crops ranging from typical tropical ones to moderate temperate varieties including cereals such as rice , wheat. maize , millet , beans , __pulses__ and oilseeds : industrial crops such as cotton , jute , rubber , sugar cane , toddy palm , tobacco and spices , and many others both edible and non-edible .
Contexts for target pulses are: ['conjI_maize']
Contexts in vocabulary for target pulses are: ['conjI_maize']
Top most similar embeddings: pulses 0.51346	sorghum 0.39673	sugarbeet 0.39659	groundnuts 0.39006	manioc 0.38954	triticale 0.38825	yams 0.38478	beans 0.38331	plantains 0.38061	pulse 0.37857

Generated lemmatized results
***************
GENERATED	pulse.n 487 ::: sorghum;sugarbeet;groundnut;manioc;triticale;yam;bean;plantain;linseed;maize

Filtered results
***************
RANKED	pulse.n 487	legume 0.35883	heartbeat 0.30994	vibration 0.30038	beat 0.29618	rhythm 0.29574	wave 0.29491	energy 0.29271	emanation 0.28988	beep 0.28447	stimulus 0.28281	throbbing 0.28074	heart 0.27617	throb 0.27598	reflex 0.26245	centre 0.26196	lifeblood 0.25989	sound 0.25378	force 0.25088

Test context:
***************
pulse.n	488	24	it 's also present in adequate quantities in dairy products , eggs and nuts , as well as in combinations of foods such as __pulses__ and grains .
Contexts for target pulses are: ['prep:asI_foods', 'cc_and', 'conj_grains']
Contexts in vocabulary for target pulses are: ['prep:asI_foods', 'cc_and', 'conj_grains']
Top most similar embeddings: pulses 0.14485	wholegrains 0.12968	plantains 0.11535	linseeds 0.11511	manioc 0.11288	beansprouts 0.11155	flours 0.11148	grains 0.11120	yams 0.11098	wheatgerm 0.10978

Generated lemmatized results
***************
GENERATED	pulse.n 488 ::: wholegrains;plantain;linseed;manioc;beansprouts;flour;grain;yam;wheatgerm;bilberry

Filtered results
***************
RANKED	pulse.n 488	legume 0.10220	wave 0.07019	heartbeat 0.06919	heart 0.06690	vibration 0.06684	energy 0.06630	beat 0.06600	emanation 0.06313	rhythm 0.06307	throb 0.06293	beep 0.05885	stimulus 0.05776	lifeblood 0.05515	reflex 0.05508	throbbing 0.05453	centre 0.05072	sound 0.04970	force 0.04879

Test context:
***************
pulse.n	489	11	but he could feel the whale was sensing him with sound __pulses__ .
Contexts for target pulses are: ['amod_sound', 'prep:withI_sensing']
Contexts in vocabulary for target pulses are: ['amod_sound']
Top most similar embeddings: pulses 0.51938	pulse 0.41463	vibrations 0.37918	waves 0.37882	waveforms 0.36960	signals 0.36719	waveform 0.36378	scatterers 0.35976	pulsations 0.35927	spectrograms 0.35734

Generated lemmatized results
***************
GENERATED	pulse.n 489 ::: vibration;wave;waveform;signal;scatterers;pulsation;spectrogram;transient;scaler;impulse

Filtered results
***************
RANKED	pulse.n 489	vibration 0.37918	wave 0.37882	beep 0.33664	stimulus 0.33339	heartbeat 0.33200	beat 0.32480	energy 0.31943	rhythm 0.31795	emanation 0.31781	throb 0.31280	reflex 0.30134	sound 0.29016	throbbing 0.28955	legume 0.28391	heart 0.27648	force 0.27579	centre 0.25889	lifeblood 0.24982

Test context:
***************
pulse.n	490	13	she drank a great deal of coffee and had a rapid , thin __pulse__ .
Contexts for target pulse are: ['det_a', 'amod_rapid', 'punct_,', 'amod_thin', 'dobjI_had']
Contexts in vocabulary for target pulse are: ['det_a', 'amod_rapid', 'punct_,', 'amod_thin', 'dobjI_had']
Top most similar embeddings: pulse 0.02863	lumpectomy 0.02175	tracheotomy 0.02160	taproot 0.02157	heartbeat 0.02141	bradycardia 0.02093	nosebleed 0.02091	heartbeats 0.02075	exhalation 0.02068	pulsation 0.02068

Generated lemmatized results
***************
GENERATED	pulse.n 490 ::: lumpectomy;tracheotomy;taproot;heartbeat;bradycardia;nosebleed;exhalation;pulsation;laceration;facemask

Filtered results
***************
RANKED	pulse.n 490	heartbeat 0.02141	throb 0.01963	rhythm 0.01826	wave 0.01792	beep 0.01727	reflex 0.01702	beat 0.01681	throbbing 0.01605	stimulus 0.01568	vibration 0.01548	sound 0.01495	force 0.01481	heart 0.01442	emanation 0.01375	legume 0.01326	energy 0.01316	lifeblood 0.01109	centre 0.01066

Test context:
***************
put.v	491	7	it was amazing how you managed to __put__ together so many facts and present in such a hilarious manner .
Contexts for target put are: ['aux_to', 'xcompI_managed', 'advmod_together', 'dobj_facts']
Contexts in vocabulary for target put are: ['aux_to', 'xcompI_managed', 'advmod_together', 'dobj_facts']
Top most similar embeddings: put 0.06877	get 0.05473	wheedle 0.05452	shoehorn 0.05212	bring 0.05207	cobble 0.05187	distill 0.05075	concoct 0.05074	distil 0.04989	assemble 0.04905

Generated lemmatized results
***************
GENERATED	put.v 491 ::: get;wheedle;shoehorn;bring;cobble;distill;concoct;distil;assemble;condense

Filtered results
***************
RANKED	put.v 491	get 0.05473	assemble 0.04905	gather 0.04856	collate 0.04587	collect 0.04449	propound 0.04394	fasten 0.04388	give 0.04243	provide 0.04081	make 0.04026	settle 0.03992	fix 0.03866	lay 0.03822	leave 0.03804	stick 0.03803	dismiss 0.03785	join 0.03772	send 0.03748	remove 0.03692	nullify 0.03644	present 0.03505	set 0.03454	place 0.03447	allay 0.03358	advance 0.03115	allow 0.03110	express 0.03105	propose 0.03098	position 0.02934	state 0.02875	phrase 0.02798

Test context:
***************
put.v	492	5	it is best not to __put__ babies to sleep with a bottle .
Contexts for target put are: ['neg_not', 'aux_to', 'xcompI_best', 'dobj_babies', 'xcomp_sleep']
Contexts in vocabulary for target put are: ['neg_not', 'aux_to', 'xcompI_best', 'dobj_babies', 'xcomp_sleep']
Top most similar embeddings: put 0.03083	breast-feed 0.02397	resuscitate 0.02369	circumcise 0.02357	manhandle 0.02351	breastfeed 0.02350	immunise 0.02338	pressurize 0.02327	reprogramme 0.02322	vaccinate 0.02320

Generated lemmatized results
***************
GENERATED	put.v 492 ::: resuscitate;circumcise;manhandle;breastfeed;immunise;pressurize;reprogramme;vaccinate;anaesthetise;disturb

Filtered results
***************
RANKED	put.v 492	get 0.02246	settle 0.02200	leave 0.02115	allow 0.02079	give 0.02077	make 0.02055	send 0.02033	remove 0.02003	dismiss 0.01961	fasten 0.01943	collect 0.01874	lay 0.01835	provide 0.01756	assemble 0.01750	propose 0.01747	gather 0.01746	propound 0.01742	join 0.01715	allay 0.01683	fix 0.01628	stick 0.01626	place 0.01537	nullify 0.01528	present 0.01522	collate 0.01470	express 0.01398	phrase 0.01352	set 0.01333	position 0.01315	advance 0.01280	state 0.01065

Test context:
***************
put.v	493	0	__put__ some more crushed paper on top of the component and place the next piece on top , put paper between the component and the wall of the carton .
Contexts for target put are: ['rootI_*root*', 'dobj_paper', 'prep:on_top', 'dobj_piece', 'punct_,', 'dep_put', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target put are: ['rootI_*root*', 'dobj_paper', 'prep:on_top', 'dobj_piece', 'punct_,', 'dep_put', 'punct_.']
Top most similar embeddings: put 0.00735	unroll 0.00646	puts 0.00621	plopped 0.00611	scrunch 0.00582	sewed 0.00561	putting 0.00551	scrounged 0.00548	sprinkle 0.00544	rustled 0.00542

Generated lemmatized results
***************
GENERATED	put.v 493 ::: unroll;plop;scrunch;sew;scrounge;sprinkle;rustle;undo;unbolt;liquidise

Filtered results
***************
RANKED	put.v 493	lay 0.00505	place 0.00481	fasten 0.00472	get 0.00466	give 0.00462	remove 0.00448	stick 0.00448	collect 0.00428	assemble 0.00416	gather 0.00410	dismiss 0.00406	propound 0.00402	send 0.00402	present 0.00402	leave 0.00397	settle 0.00396	phrase 0.00386	position 0.00383	join 0.00380	collate 0.00375	propose 0.00374	provide 0.00369	make 0.00357	nullify 0.00353	fix 0.00352	allow 0.00330	set 0.00326	express 0.00324	state 0.00318	allay 0.00282	advance 0.00277

Test context:
***************
put.v	494	13	barnes : mr. speaker , it is strange that when i try to __put__ some perspective on my question , the members opposite ask me to get to the question .
Contexts for target put are: ['aux_to', 'xcompI_try', 'dobj_perspective', 'prep:on_question']
Contexts in vocabulary for target put are: ['aux_to', 'xcompI_try', 'dobj_perspective', 'prep:on_question']
Top most similar embeddings: put 0.05790	counterpose 0.05161	re-state 0.05000	conciliate 0.04908	enunciate 0.04802	reorient 0.04794	economize 0.04761	reformulate 0.04737	foist 0.04716	give 0.04701

Generated lemmatized results
***************
GENERATED	put.v 494 ::: counterpose;conciliate;enunciate;reorient;economize;reformulate;foist;give;fixate;moralise

Filtered results
***************
RANKED	put.v 494	give 0.04701	propound 0.04657	get 0.04360	provide 0.04143	dismiss 0.03894	assemble 0.03842	allay 0.03824	settle 0.03763	make 0.03762	remove 0.03691	gather 0.03647	nullify 0.03638	present 0.03580	collate 0.03571	fasten 0.03552	lay 0.03548	propose 0.03529	fix 0.03512	stick 0.03426	express 0.03387	leave 0.03358	collect 0.03326	place 0.03304	send 0.03269	allow 0.03246	join 0.03155	advance 0.03149	phrase 0.03128	set 0.03007	state 0.02906	position 0.02571

Test context:
***************
put.v	495	26	however , i 'll reserve my decision on your motion without prejudicing your position , and determine as quickly as possible the motion as it was __put__ to the house and see if it does qualify , hon. member .
Contexts for target put are: ['mark_as', 'nsubjpass_it', 'auxpass_was', 'depI_motion', 'prep:to_house', 'cc_and', 'conj_see']
Contexts in vocabulary for target put are: ['mark_as', 'nsubjpass_it', 'auxpass_was', 'depI_motion', 'prep:to_house', 'cc_and', 'conj_see']
Top most similar embeddings: put 0.00559	floated 0.00511	moved 0.00510	dragged 0.00505	taxied 0.00489	opposed 0.00489	passed 0.00480	carted 0.00478	rushed 0.00477	jerked 0.00475

Generated lemmatized results
***************
GENERATED	put.v 495 ::: float;move;drag;taxi;oppose;pass;cart;rush;jerk;whisk

Filtered results
***************
RANKED	put.v 495	propound 0.00428	fix 0.00419	present 0.00415	propose 0.00413	remove 0.00410	settle 0.00404	phrase 0.00400	state 0.00393	lay 0.00392	stick 0.00385	gather 0.00383	leave 0.00382	fasten 0.00381	place 0.00381	assemble 0.00377	position 0.00377	send 0.00374	nullify 0.00354	give 0.00354	dismiss 0.00352	express 0.00350	make 0.00350	get 0.00347	set 0.00347	collate 0.00325	advance 0.00318	collect 0.00315	allow 0.00314	join 0.00310	provide 0.00303	allay 0.00299

Test context:
***************
put.v	496	1	simply __put__ , the frequent claim that conventional research is essential to good teaching has no basis in fact .
Contexts for target put are: ['advmod_simply', 'advclI_has']
Contexts in vocabulary for target put are: ['advmod_simply', 'advclI_has']
Top most similar embeddings: put 0.23707	puts 0.20472	putting 0.18869	re-insert 0.17637	regurgitate 0.17567	tacked 0.17215	steamrollered 0.17113	misspell 0.17104	encase 0.17084	unclip 0.17025

Generated lemmatized results
***************
GENERATED	put.v 496 ::: regurgitate;tack;steamroller;misspell;encase;unclip;rephrase;ignore;phrase;dunk

Filtered results
***************
RANKED	put.v 496	phrase 0.16916	place 0.16248	stick 0.16125	dismiss 0.16100	state 0.15599	lay 0.15501	remove 0.15476	nullify 0.15434	settle 0.15341	get 0.15315	express 0.15126	propound 0.15082	give 0.14980	send 0.14962	fasten 0.14844	allow 0.14758	make 0.14748	gather 0.14676	assemble 0.14511	position 0.14471	leave 0.14449	present 0.14339	provide 0.14339	allay 0.14280	fix 0.14266	propose 0.14074	set 0.14049	collect 0.13907	collate 0.13617	join 0.13401	advance 0.12654

Test context:
***************
put.v	497	16	administrators are people too ; are they going to make a decision that 's going to __put__ people with families and children out of jobs , or are they going to make a decision that will keep those jobs safe ?
Contexts for target put are: ['aux_to', 'xcompI_going', 'dobj_people', 'prep:with_families']
Contexts in vocabulary for target put are: ['aux_to', 'xcompI_going', 'dobj_people', 'prep:with_families']
Top most similar embeddings: put 0.05665	rehouse 0.05208	re-integrate 0.05138	re-house 0.05126	socialize 0.05087	baby-sit 0.05079	rile 0.05049	re-unite 0.05021	ingratiate 0.05004	re-assure 0.04950

Generated lemmatized results
***************
GENERATED	put.v 497 ::: rehouse;socialize;rile;ingratiate;reacquaint;reintegrate;evangelize;impale;embarass;enfranchise

Filtered results
***************
RANKED	put.v 497	get 0.04382	settle 0.04083	assemble 0.04043	leave 0.03913	make 0.03899	give 0.03874	join 0.03865	gather 0.03796	lay 0.03753	dismiss 0.03716	remove 0.03638	provide 0.03633	send 0.03587	stick 0.03580	place 0.03560	fasten 0.03555	collect 0.03424	propound 0.03376	allow 0.03374	fix 0.03248	propose 0.03229	collate 0.03198	nullify 0.03169	present 0.03097	allay 0.03014	express 0.02946	set 0.02897	phrase 0.02699	advance 0.02668	position 0.02662	state 0.02318

Test context:
***************
put.v	498	12	if you have a special poem you are doing with the children __put__ it on the wall and everyone can practice it while waiting for the doors to open .
Contexts for target put are: ['depI_have', 'dobj_it', 'prep:on_wall']
Contexts in vocabulary for target put are: ['depI_have', 'dobj_it', 'prep:on_wall']
Top most similar embeddings: put 0.11856	putting 0.09869	puts 0.09320	nailed 0.08981	bunged 0.08816	reseal 0.08724	shoved 0.08616	bodged 0.08579	banged 0.08562	plonked 0.08537

Generated lemmatized results
***************
GENERATED	put.v 498 ::: nail;bung;reseal;shove;bodge;bang;plonk;scrawl;prop;plop

Filtered results
***************
RANKED	put.v 498	stick 0.08455	place 0.08167	lay 0.08107	fasten 0.07642	get 0.07586	position 0.07476	fix 0.07428	phrase 0.07265	settle 0.07235	leave 0.07174	send 0.07139	nullify 0.07075	remove 0.06968	dismiss 0.06931	assemble 0.06714	make 0.06567	express 0.06491	propound 0.06374	present 0.06353	give 0.06352	provide 0.06349	set 0.06325	allay 0.06301	gather 0.06212	collect 0.06101	collate 0.05959	advance 0.05896	join 0.05834	state 0.05770	allow 0.05681	propose 0.05284

Test context:
***************
put.v	499	9	getting your problems out in the open can really __put__ things in perspective .
Contexts for target put are: ['nsubj_getting', 'aux_can', 'advmod_really', 'rootI_*root*', 'dobj_things', 'prep:in_perspective', 'punct_.', 'dobj_<eol>']
Contexts in vocabulary for target put are: ['nsubj_getting', 'aux_can', 'advmod_really', 'rootI_*root*', 'dobj_things', 'prep:in_perspective', 'punct_.']
Top most similar embeddings: put 0.00736	puts 0.00588	changed 0.00508	stuck 0.00477	appreciate 0.00477	summed 0.00477	cheapen 0.00476	pushed 0.00475	perked 0.00468	overemphasise 0.00468

Generated lemmatized results
***************
GENERATED	put.v 499 ::: change;stick;appreciate;sum;cheapen;push;perk;overemphasise;ease;complicate

Filtered results
***************
RANKED	put.v 499	stick 0.00477	get 0.00419	settle 0.00417	make 0.00415	place 0.00414	lay 0.00395	phrase 0.00394	leave 0.00376	dismiss 0.00371	fix 0.00369	fasten 0.00369	nullify 0.00364	propound 0.00358	give 0.00354	express 0.00354	position 0.00351	gather 0.00350	propose 0.00349	collect 0.00349	present 0.00347	remove 0.00347	set 0.00347	send 0.00344	allay 0.00341	state 0.00326	provide 0.00326	join 0.00325	assemble 0.00323	allow 0.00315	advance 0.00305	collate 0.00300

Test context:
***************
put.v	500	11	if you have a report from your mechanic , this might __put__ their doubts to rest .
Contexts for target put are: ['advcl_have', 'punct_,', 'nsubj_this', 'aux_might', 'rootI_*root*', 'dobj_doubts', 'prep:to_rest', 'punct_.', 'dobj_<eol>']
Contexts in vocabulary for target put are: ['advcl_have', 'punct_,', 'nsubj_this', 'aux_might', 'rootI_*root*', 'dobj_doubts', 'prep:to_rest', 'punct_.']
Top most similar embeddings: put 0.00302	suggest 0.00258	puts 0.00254	explain 0.00245	reignited 0.00242	indicate 0.00240	dispelled 0.00238	obviated 0.00238	eased 0.00234	understate 0.00233

Generated lemmatized results
***************
GENERATED	put.v 500 ::: suggest;explain;reignite;indicate;dispel;obviate;ease;understate;spark;digress

Filtered results
***************
RANKED	put.v 500	allay 0.00231	leave 0.00213	give 0.00212	lay 0.00211	nullify 0.00208	remove 0.00207	send 0.00203	express 0.00203	allow 0.00199	place 0.00197	settle 0.00196	dismiss 0.00195	propose 0.00190	get 0.00187	present 0.00187	phrase 0.00186	propound 0.00185	make 0.00180	fasten 0.00176	provide 0.00174	state 0.00173	fix 0.00173	stick 0.00171	gather 0.00169	position 0.00166	set 0.00161	join 0.00153	collect 0.00152	assemble 0.00147	collate 0.00147	advance 0.00141

Test context:
***************
really.r	501	10	he used to - he was interested - he was __really__ ... he always wanted to be a politician .
Contexts for target really are: ['nsubj_he', 'cop_was', 'depI_interested']
Contexts in vocabulary for target really are: ['nsubj_he', 'cop_was', 'depI_interested']
Top most similar embeddings: soooooooo 0.08792	extreamly 0.08652	sooo 0.08567	definitly 0.08566	really 0.08564	sooooooo 0.08522	realy 0.08471	soooo 0.08463	soooooo 0.08455	kinda 0.08405

Generated lemmatized results
***************
GENERATED	really.r 501 ::: soooooooo;extreamly;sooo;definitly;sooooooo;realy;soooo;soooooo;kinda;sooooo

Filtered results
***************
RANKED	really.r 501	genuinely 0.07623	honestly 0.06985	definitely 0.06827	unquestionably 0.06769	totally 0.06757	absolutely 0.06145	unreservedly 0.06022	exceptionally 0.05922	truly 0.05854	actually 0.05666	completely 0.05660	indeed 0.05608	effectively 0.05050	properly 0.04994	extremely 0.04761	very 0.04319

Test context:
***************
really.r	502	17	he 's passionate about it - it is his passion - and to be denied that is __really__ hard .
Contexts for target really are: ['advmodI_hard']
Contexts in vocabulary for target really are: ['advmodI_hard']
Top most similar embeddings: really 0.54987	extemely 0.43694	extremly 0.43140	trully 0.42417	numbingly 0.42116	freakishly 0.42034	extrememly 0.41906	horrifyingly 0.41738	diabolically 0.41657	too 0.41579

Generated lemmatized results
***************
GENERATED	really.r 502 ::: extemely;extremly;trully;numbingly;freakishly;extrememly;horrifyingly;diabolically;too;realy

Filtered results
***************
RANKED	really.r 502	actually 0.40622	very 0.40337	extremely 0.38884	truly 0.37875	genuinely 0.37700	indeed 0.37682	definitely 0.37169	exceptionally 0.35576	honestly 0.34965	unquestionably 0.34245	absolutely 0.34233	totally 0.33826	completely 0.33004	properly 0.32442	effectively 0.30681	unreservedly 0.29460

Test context:
***************
really.r	503	4	some of them were __really__ good but some , especially the older ones , were really apathetic .
Contexts for target really are: ['advmodI_good']
Contexts in vocabulary for target really are: ['advmodI_good']
Top most similar embeddings: really 0.55786	realy 0.43817	extemely 0.43738	trully 0.43588	extremly 0.43213	extrememly 0.43164	proably 0.42889	probaly 0.42738	freakishly 0.42702	numbingly 0.42624

Generated lemmatized results
***************
GENERATED	really.r 503 ::: realy;extemely;trully;extremly;extrememly;proably;probaly;freakishly;numbingly;actually

Filtered results
***************
RANKED	really.r 503	actually 0.42585	very 0.40944	definitely 0.38597	truly 0.38519	extremely 0.38102	indeed 0.37725	genuinely 0.37714	unquestionably 0.36714	absolutely 0.35435	exceptionally 0.35136	honestly 0.34373	totally 0.34010	completely 0.32999	properly 0.32087	unreservedly 0.31190	effectively 0.30795

Test context:
***************
really.r	504	14	so the puzzle is that the brain seems to be getting ready to move __really__ some time before we are aware that we are going to move and that we have the intention .
Contexts for target really are: ['advmodI_time']
Contexts in vocabulary for target really are: ['advmodI_time']
Top most similar embeddings: really 0.51964	proably 0.43482	probaly 0.42412	defintely 0.42237	actaully 0.41701	apprently 0.41559	actually 0.41167	freakishly 0.40891	quite 0.40838	acutally 0.40748

Generated lemmatized results
***************
GENERATED	really.r 504 ::: proably;probaly;defintely;actaully;apprently;actually;freakishly;quite;acutally;trully

Filtered results
***************
RANKED	really.r 504	actually 0.41167	definitely 0.39580	indeed 0.37754	truly 0.37722	very 0.37130	genuinely 0.36620	extremely 0.36179	absolutely 0.35677	unquestionably 0.35306	properly 0.34408	honestly 0.34397	effectively 0.33896	completely 0.33735	totally 0.33727	exceptionally 0.32880	unreservedly 0.30269

Test context:
***************
really.r	505	10	you can sort of challenge them well , did you __really__ know the time when you said yes ?
Contexts for target really are: ['advmodI_know']
Contexts in vocabulary for target really are: ['advmodI_know']
Top most similar embeddings: really 0.55089	proably 0.44739	trully 0.44052	acutally 0.44022	actaully 0.43969	probaly 0.43481	proberly 0.43328	actually 0.42931	defintely 0.42857	actully 0.42774

Generated lemmatized results
***************
GENERATED	really.r 505 ::: proably;trully;acutally;actaully;probaly;proberly;actually;defintely;actully;usally

Filtered results
***************
RANKED	really.r 505	actually 0.42931	truly 0.39061	definitely 0.38917	genuinely 0.38648	honestly 0.37635	indeed 0.37166	absolutely 0.35344	unquestionably 0.34045	totally 0.33940	very 0.33861	properly 0.33786	completely 0.33771	extremely 0.32168	effectively 0.31369	exceptionally 0.31160	unreservedly 0.29957

Test context:
***************
really.r	506	4	is this what we __really__ want for our daughters , granddaughters , sisters , and friends ?
Contexts for target really are: ['advmodI_want']
Contexts in vocabulary for target really are: ['advmodI_want']
Top most similar embeddings: really 0.56384	trully 0.43892	actaully 0.43859	defintely 0.43243	reelly 0.43229	actually 0.43225	proably 0.42920	probaly 0.42766	realy 0.42750	acutally 0.42737

Generated lemmatized results
***************
GENERATED	really.r 506 ::: trully;actaully;defintely;reelly;actually;proably;probaly;realy;acutally;apprently

Filtered results
***************
RANKED	really.r 506	actually 0.43225	definitely 0.40553	genuinely 0.39698	truly 0.39022	indeed 0.36965	honestly 0.36484	absolutely 0.35929	unquestionably 0.33456	very 0.33324	totally 0.33238	properly 0.33214	extremely 0.32836	completely 0.32699	exceptionally 0.31615	effectively 0.31568	unreservedly 0.31077

Test context:
***************
really.r	507	3	and if you __really__ want a town like that ( just not awmish ) come visit tehachapi , ca. its paradise in the middle of the mountains , where nobody is in a hurry and everyone gets along !
Contexts for target really are: ['advmodI_want']
Contexts in vocabulary for target really are: ['advmodI_want']
Top most similar embeddings: really 0.56384	trully 0.43892	actaully 0.43859	defintely 0.43243	reelly 0.43229	actually 0.43225	proably 0.42920	probaly 0.42766	realy 0.42750	acutally 0.42737

Generated lemmatized results
***************
GENERATED	really.r 507 ::: trully;actaully;defintely;reelly;actually;proably;probaly;realy;acutally;apprently

Filtered results
***************
RANKED	really.r 507	actually 0.43225	definitely 0.40553	genuinely 0.39698	truly 0.39022	indeed 0.36965	honestly 0.36484	absolutely 0.35929	unquestionably 0.33456	very 0.33324	totally 0.33238	properly 0.33214	extremely 0.32836	completely 0.32699	exceptionally 0.31615	effectively 0.31568	unreservedly 0.31077

Test context:
***************
really.r	508	1	we __really__ pushed it for " nv " .
Contexts for target really are: ['advmodI_pushed']
Contexts in vocabulary for target really are: ['advmodI_pushed']
Top most similar embeddings: really 0.52749	actaully 0.41718	proably 0.41504	actually 0.41225	acutally 0.40704	defintely 0.40385	apprently 0.39741	majorly 0.39711	ever-so-slightly 0.39661	probaly 0.39564

Generated lemmatized results
***************
GENERATED	really.r 508 ::: actaully;proably;actually;acutally;defintely;apprently;majorly;probaly;trully;dexterously

Filtered results
***************
RANKED	really.r 508	actually 0.41225	definitely 0.37582	truly 0.37580	genuinely 0.36433	indeed 0.35947	completely 0.34378	honestly 0.34183	totally 0.34067	unquestionably 0.33978	properly 0.33676	very 0.33649	absolutely 0.33605	extremely 0.32833	effectively 0.32539	exceptionally 0.31721	unreservedly 0.31150

Test context:
***************
really.r	509	11	it 's not even something that i tolerate - it 's __really__ something i demand of people .
Contexts for target really are: ['advmodI_something']
Contexts in vocabulary for target really are: ['advmodI_something']
Top most similar embeddings: really 0.52561	actaully 0.43106	proably 0.43000	defintely 0.42687	apprently 0.42497	trully 0.42289	acutally 0.42282	definetely 0.41994	definitly 0.41844	actually 0.41743

Generated lemmatized results
***************
GENERATED	really.r 509 ::: actaully;proably;defintely;apprently;trully;acutally;definetely;definitly;actually;probaly

Filtered results
***************
RANKED	really.r 509	actually 0.41743	definitely 0.40281	truly 0.38824	genuinely 0.37768	indeed 0.37517	unquestionably 0.36567	absolutely 0.35243	honestly 0.35147	very 0.34216	properly 0.34102	completely 0.34087	totally 0.33686	extremely 0.31802	effectively 0.31548	exceptionally 0.31375	unreservedly 0.30341

Test context:
***************
really.r	510	20	the teacher had yelled at her when she 'd used the inhaler in class , claiming that she did n't __really__ need it .
Contexts for target really are: ['advmodI_need']
Contexts in vocabulary for target really are: ['advmodI_need']
Top most similar embeddings: really 0.55343	defintely 0.44250	proably 0.43272	apprently 0.42917	probaly 0.42854	actaully 0.42648	trully 0.42631	actually 0.42598	acutally 0.42410	usally 0.42384

Generated lemmatized results
***************
GENERATED	really.r 510 ::: defintely;proably;apprently;probaly;actaully;trully;actually;acutally;usally;desperatly

Filtered results
***************
RANKED	really.r 510	actually 0.42598	definitely 0.40405	genuinely 0.38193	truly 0.37923	indeed 0.37417	absolutely 0.36617	honestly 0.35369	properly 0.35100	unquestionably 0.34704	very 0.33527	completely 0.33267	effectively 0.33148	totally 0.33148	exceptionally 0.32530	extremely 0.32231	unreservedly 0.30706

Test context:
***************
return.v	511	11	after a fire extinguisher is used , it must always be __returned__ for recharging and its use recorded .
Contexts for target returned are: ['advcl_used', 'punct_,', 'nsubjpass_it', 'aux_must', 'advmod_always', 'auxpass_be', 'rootI_*root*', 'prep:for_recharging', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target returned are: ['advcl_used', 'punct_,', 'nsubjpass_it', 'aux_must', 'advmod_always', 'auxpass_be', 'rootI_*root*', 'punct_.']
Top most similar embeddings: returned 0.00423	dereferenced 0.00341	recomputed 0.00328	emphasized 0.00326	deallocated 0.00322	remembered 0.00321	recalled 0.00317	decremented 0.00316	assumed 0.00315	prepended 0.00311

Generated lemmatized results
***************
GENERATED	return.v 511 ::: dereferenced;recomputed;emphasize;deallocated;remember;recall;decremented;assume;prepended;rescale

Filtered results
***************
RANKED	return.v 511	retrieve 0.00279	make 0.00262	realize 0.00258	repeat 0.00254	resume 0.00249	revert 0.00245	produce 0.00230	get 0.00228	yield 0.00228	earn 0.00219	revisit 0.00219	retrace 0.00212	go 0.00210	regress 0.00203

Test context:
***************
return.v	512	1	we __return__ to the young woman who is reading the wrigley 's wrapping paper .
Contexts for target return are: ['nsubj_we', 'rootI_*root*', 'prep:to_woman', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target return are: ['nsubj_we', 'rootI_*root*', 'prep:to_woman', 'punct_.']
Top most similar embeddings: return 0.05722	returned 0.04735	blathered 0.04427	apologize 0.04380	apologise 0.04379	talked 0.04302	detoured 0.04272	allude 0.04267	spoke 0.04251	refer 0.04248

Generated lemmatized results
***************
GENERATED	return.v 512 ::: blather;apologize;apologise;talk;detour;allude;speak;refer;doff;revert

Filtered results
***************
RANKED	return.v 512	revert 0.04194	go 0.04149	retrace 0.03872	repeat 0.03829	yield 0.03730	make 0.03552	regress 0.03551	resume 0.03478	realize 0.03445	revisit 0.03444	get 0.03326	retrieve 0.03293	produce 0.03131	earn 0.03090

Test context:
***************
return.v	513	2	they always __returned__ the phonecalls and were more than helpful with advice as so with the showroom and sarah 's advice .
Contexts for target returned are: ['nsubj_they', 'advmod_always', 'rootI_*root*', 'dobj_phonecalls', 'cc_and', 'conj_were', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target returned are: ['nsubj_they', 'advmod_always', 'rootI_*root*', 'dobj_phonecalls', 'cc_and', 'conj_were', 'punct_.']
Top most similar embeddings: returned 0.00697	doffed 0.00563	wore 0.00539	quarreled 0.00537	fielded 0.00528	recalled 0.00522	tutted 0.00520	rallied 0.00520	received 0.00516	recived 0.00516

Generated lemmatized results
***************
GENERATED	return.v 513 ::: doff;wear;quarrel;field;recall;tutted;rally;receive;recived;take

Filtered results
***************
RANKED	return.v 513	go 0.00502	yield 0.00482	retrace 0.00480	resume 0.00476	get 0.00473	revert 0.00472	make 0.00470	earn 0.00427	repeat 0.00420	retrieve 0.00405	regress 0.00404	realize 0.00385	produce 0.00374	revisit 0.00331

Test context:
***************
return.v	514	3	click here to __return__ to the booklist
Contexts for target return are: ['aux_to', 'xcompI_click', 'prep:to_<eol>']
Contexts in vocabulary for target return are: ['aux_to', 'xcompI_click']
Top most similar embeddings: return 0.27289	re-send 0.18760	down-load 0.18286	retreive 0.18201	re-load 0.18110	enlarge 0.18073	reenter 0.17994	resend 0.17910	re-submit 0.17907	deallocate 0.17755

Generated lemmatized results
***************
GENERATED	return.v 514 ::: retreive;enlarge;reenter;resend;deallocate;reselect;go;rebook;regrade;redisplay

Filtered results
***************
RANKED	return.v 514	go 0.17724	revert 0.17402	retrieve 0.17338	revisit 0.16628	get 0.16590	resume 0.16032	make 0.15854	retrace 0.15787	repeat 0.15534	yield 0.15087	produce 0.14571	earn 0.14252	realize 0.14236	regress 0.14180

Test context:
***************
return.v	515	28	specific vacancy search if you know the reference of a vacancy you found previously on londonjobs , you may enter it in the specific vacancy search box to __return__ the vacancy .
Contexts for target return are: ['aux_to', 'xcompI_enter', 'dobj_vacancy']
Contexts in vocabulary for target return are: ['aux_to', 'xcompI_enter', 'dobj_vacancy']
Top most similar embeddings: return 0.12418	re-submit 0.08750	re-book 0.08712	submit 0.08661	re-send 0.08608	reselect 0.08595	re-activate 0.08566	resubmit 0.08554	repossess 0.08548	vacate 0.08522

Generated lemmatized results
***************
GENERATED	return.v 515 ::: submit;reselect;resubmit;repossess;vacate;retreive;fill;deregister;reenter;retrieve

Filtered results
***************
RANKED	return.v 515	retrieve 0.08344	revisit 0.07947	revert 0.07924	resume 0.07584	produce 0.07235	get 0.07195	retrace 0.07011	repeat 0.06977	make 0.06791	yield 0.06752	go 0.06682	earn 0.06670	regress 0.06335	realize 0.06286

Test context:
***************
return.v	516	12	tea tree a tea bush or plant which has been allowed to __return__ to its wild state and grow back into a tree .
Contexts for target return are: ['aux_to', 'xcompI_allowed', 'prep:to_state', 'cc_and', 'conj_grow']
Contexts in vocabulary for target return are: ['aux_to', 'xcompI_allowed', 'prep:to_state', 'cc_and', 'conj_grow']
Top most similar embeddings: return 0.02761	acclimatize 0.02436	pupate 0.02324	readjust 0.02311	habituate 0.02296	ripen 0.02262	acclimatise 0.02224	regrow 0.02208	overreact 0.02200	downsize 0.02198

Generated lemmatized results
***************
GENERATED	return.v 516 ::: acclimatize;pupate;readjust;habituate;ripen;acclimatise;regrow;overreact;downsize;revert

Filtered results
***************
RANKED	return.v 516	revert 0.02192	regress 0.02120	go 0.01855	revisit 0.01846	retrace 0.01846	yield 0.01834	resume 0.01727	retrieve 0.01631	produce 0.01627	get 0.01611	repeat 0.01507	earn 0.01505	realize 0.01425	make 0.01422

Test context:
***************
return.v	517	17	you will still be responsible for the shipping and handling fees , and for the cost of __returning__ the merchandise .
Contexts for target returning are: ['pcompI_of', 'dobj_merchandise']
Contexts in vocabulary for target returning are: ['pcompI_of', 'dobj_merchandise']
Top most similar embeddings: returning 0.26840	repatriating 0.20512	aquiring 0.19752	despatching 0.19351	transporting 0.19288	confiscating 0.19274	producing 0.18767	donating 0.18763	transfering 0.18750	withdrawing 0.18677

Generated lemmatized results
***************
GENERATED	return.v 517 ::: repatriate;aquiring;despatch;transport;confiscate;produce;donate;transfer;withdraw;immigrate

Filtered results
***************
RANKED	return.v 517	produce 0.18767	get 0.18286	retrieve 0.17671	resume 0.17586	make 0.16279	revisit 0.15834	regress 0.15784	earn 0.15336	yield 0.15317	revert 0.15083	retrace 0.14843	repeat 0.14748	realize 0.14372	go 0.14041

Test context:
***************
return.v	518	4	he is tireless in __returning__ to the point and relentless in challenging the popular view of aristotle that he places aristocracy ahead of democracy as the best regime .
Contexts for target returning are: ['pcompI_in', 'prep:to_point', 'cc_and', 'conj_relentless']
Contexts in vocabulary for target returning are: ['pcompI_in', 'prep:to_point', 'cc_and', 'conj_relentless']
Top most similar embeddings: returning 0.05557	decelerating 0.04386	retreating 0.04343	unrelenting 0.04342	relenting 0.04219	gravitating 0.04199	rehabilitating 0.04160	penetrating 0.04135	disengaging 0.04105	acclimatising 0.04103

Generated lemmatized results
***************
GENERATED	return.v 518 ::: decelerate;retreat;unrelenting;relent;gravitate;rehabilitate;penetrate;disengage;acclimatise;redouble

Filtered results
***************
RANKED	return.v 518	regress 0.04007	revert 0.04006	get 0.03914	retrace 0.03862	retrieve 0.03630	yield 0.03500	resume 0.03390	repeat 0.03293	revisit 0.03196	produce 0.03162	realize 0.03151	earn 0.03030	go 0.02951	make 0.02942

Test context:
***************
return.v	519	12	according to street stories market wizards index , zweig 's top-rated stocks __returned__ 25 % , on average , over the 19-year period from may 1976 to march 1995 .
Contexts for target returned are: ['mark_according', 'mark_to', 'nsubj_index', 'rootI_*root*', 'dobj_%', 'punct_,', 'prep:on_average', 'punct_,', 'prep:over_period', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target returned are: ['mark_according', 'mark_to', 'nsubj_index', 'rootI_*root*', 'dobj_%', 'punct_,', 'prep:on_average', 'punct_,', 'prep:over_period', 'punct_.']
Top most similar embeddings: averaged 0.00093	totaled 0.00088	plummeted 0.00085	returned 0.00082	outperformed 0.00081	soared 0.00079	declined 0.00076	decreased 0.00074	fluctuated 0.00074	risen 0.00074

Generated lemmatized results
***************
GENERATED	return.v 519 ::: average;total;plummet;outperform;soar;decline;decrease;fluctuate;rise;shrink

Filtered results
***************
RANKED	return.v 519	yield 0.00065	revert 0.00058	produce 0.00057	earn 0.00054	regress 0.00053	resume 0.00051	retrieve 0.00050	go 0.00046	make 0.00044	realize 0.00043	revisit 0.00040	repeat 0.00040	retrace 0.00038	get 0.00038

Test context:
***************
return.v	520	8	by safely storing food , the mechanical refrigerator __returns__ a stream of savings-income that exceeds the expenditure , even including time-payments and credit costs , to buy the refrigerator .
Contexts for target returns are: ['punct_,', 'nsubj_refrigerator', 'rootI_*root*', 'dobj_stream', 'punct_,', 'prep:including_costs', 'punct_,', 'xcomp_buy', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target returns are: ['punct_,', 'nsubj_refrigerator', 'rootI_*root*', 'dobj_stream', 'punct_,', 'prep:including_costs', 'punct_,', 'xcomp_buy', 'punct_.']
Top most similar embeddings: returns 0.00135	subtracts 0.00118	borrows 0.00117	recalculates 0.00114	allocates 0.00113	fetches 0.00111	backtracks 0.00111	calculates 0.00109	consumes 0.00108	creates 0.00108

Generated lemmatized results
***************
GENERATED	return.v 520 ::: subtract;borrow;recalculate;allocate;fetch;backtrack;calculate;consume;create;exact

Filtered results
***************
RANKED	return.v 520	produce 0.00098	revisit 0.00098	retrieve 0.00098	revert 0.00095	retrace 0.00093	earn 0.00089	make 0.00088	resume 0.00085	yield 0.00085	get 0.00084	go 0.00083	realize 0.00079	repeat 0.00073	regress 0.00067

Test context:
***************
shed.v	521	14	two reasons -- first , since ripley has no hair , she does n't __shed__ .
Contexts for target shed are: ['advmod_first', 'punct_,', 'advcl_has', 'punct_,', 'nsubj_she', 'aux_does', "neg_n't", 'depI_reasons']
Contexts in vocabulary for target shed are: ['advmod_first', 'punct_,', 'advcl_has', 'punct_,', 'nsubj_she', 'aux_does', "neg_n't", 'depI_reasons']
Top most similar embeddings: flinch 0.00238	shed 0.00216	scold 0.00215	ovulate 0.00204	demur 0.00203	snore 0.00203	relent 0.00197	balk 0.00197	budge 0.00197	urinate 0.00195

Generated lemmatized results
***************
GENERATED	shed.v 521 ::: flinch;scold;ovulate;demur;snore;relent;balk;budge;urinate;reappear

Filtered results
***************
RANKED	shed.v 521	lose 0.00180	emit 0.00174	moult 0.00172	throw 0.00166	radiate 0.00163	shine 0.00163	reveal 0.00161	pass 0.00155	discard 0.00153	spread 0.00147	spill 0.00145	disperse 0.00143	transmit 0.00141	relinquish 0.00140	give 0.00139	drop 0.00133	scatter 0.00131	discarding 0.00112

Test context:
***************
shed.v	522	13	feeding an overweight dog [ offsite link ] to help your overweight dog __shed__ some pounds , you might need to change his eating habits - either what or how much he consumes .
Contexts for target shed are: ['nsubj_dog', 'ccompI_help', 'dobj_pounds']
Contexts in vocabulary for target shed are: ['nsubj_dog', 'ccompI_help', 'dobj_pounds']
Top most similar embeddings: shed 0.13132	sheds 0.09015	shedding 0.08376	aquire 0.08101	weigh 0.08083	lose 0.07761	launder 0.07598	wheedle 0.07591	claw 0.07536	wean 0.07534

Generated lemmatized results
***************
GENERATED	shed.v 522 ::: aquire;weigh;lose;launder;wheedle;claw;wean;excrete;plough;chew

Filtered results
***************
RANKED	shed.v 522	lose 0.07761	throw 0.07144	emit 0.06843	shine 0.06675	spill 0.06604	disperse 0.06511	give 0.06373	moult 0.06358	spread 0.06308	pass 0.06277	reveal 0.06207	drop 0.06114	scatter 0.06019	relinquish 0.05748	discard 0.05650	radiate 0.05611	transmit 0.05528	discarding 0.05349

Test context:
***************
shed.v	523	3	a mouse study __sheds__ light on the mixed results coming from investigations into the cognitive effects of hormone replacement therapy .
Contexts for target sheds are: ['partmodI_study', 'dobj_light', 'prep:on_results']
Contexts in vocabulary for target sheds are: ['partmodI_study', 'dobj_light', 'prep:on_results']
Top most similar embeddings: sheds 0.13976	shed 0.10883	shedding 0.09417	casts 0.08705	focussing 0.08544	focusing 0.08333	reflecting 0.08290	focusses 0.08269	centring 0.08201	focuses 0.08092

Generated lemmatized results
***************
GENERATED	shed.v 523 ::: cast;focus;reflect;centre;impinge;center;capitalise;concentrate;illuminate;hinge

Filtered results
***************
RANKED	shed.v 523	throw 0.07339	scatter 0.07268	reveal 0.07216	shine 0.07058	emit 0.07039	give 0.06782	discarding 0.06687	discard 0.06687	radiate 0.06518	disperse 0.06506	transmit 0.06427	spill 0.06325	pass 0.06231	spread 0.06201	lose 0.05901	drop 0.05527	moult 0.05526	relinquish 0.05133

Test context:
***************
shed.v	524	6	what is it that in youth __sheds__ a dewy light round the evening star ?
Contexts for target sheds are: ['mark_that', 'prep:in_youth', 'depI_it', 'dobj_round']
Contexts in vocabulary for target sheds are: ['mark_that', 'prep:in_youth', 'depI_it', 'dobj_round']
Top most similar embeddings: sheds 0.04354	shed 0.03845	shined 0.03757	slumbered 0.03601	twirled 0.03560	trod 0.03533	shone 0.03497	flings 0.03441	bloomed 0.03440	flowered 0.03431

Generated lemmatized results
***************
GENERATED	shed.v 524 ::: shin;slumber;twirl;tread;shine;fling;bloom;flower;spin;flit

Filtered results
***************
RANKED	shed.v 524	shine 0.03497	radiate 0.03141	throw 0.03011	scatter 0.03007	spill 0.02983	emit 0.02948	moult 0.02886	lose 0.02881	discard 0.02867	disperse 0.02798	pass 0.02774	spread 0.02675	discarding 0.02634	transmit 0.02626	reveal 0.02603	drop 0.02599	relinquish 0.02558	give 0.02494

Test context:
***************
shed.v	525	17	the economy may have produced jobs sluggishly during december , but the economy also seems to be __shedding__ fewer jobs when clinton turned the economy over to bush .
Contexts for target shedding are: ['aux_to', 'aux_be', 'xcompI_seems', 'dobj_jobs', 'advcl_turned']
Contexts in vocabulary for target shedding are: ['aux_to', 'aux_be', 'xcompI_seems', 'dobj_jobs', 'advcl_turned']
Top most similar embeddings: shedding 0.02777	losing 0.02049	shirking 0.02039	loosing 0.02015	monopolising 0.01970	bottoming 0.01917	hogging 0.01909	shed 0.01908	waning 0.01900	lose 0.01891

Generated lemmatized results
***************
GENERATED	shed.v 525 ::: lose;shirk;loose;monopolise;bottom;hog;wan;mellow;buck;shrink

Filtered results
***************
RANKED	shed.v 525	lose 0.02049	shine 0.01805	relinquish 0.01754	discarding 0.01711	discard 0.01711	spread 0.01687	emit 0.01672	disperse 0.01661	throw 0.01644	reveal 0.01607	drop 0.01603	radiate 0.01574	give 0.01512	moult 0.01510	pass 0.01479	transmit 0.01467	scatter 0.01465	spill 0.01460

Test context:
***************
shed.v	526	6	but over the years it gradually __shed__ its religious affiliation and became a secular institution , as did the other ivies .
Contexts for target shed are: ['cc_but', 'prep:over_years', 'nsubj_it', 'advmod_gradually', 'rootI_*root*', 'dobj_affiliation', 'cc_and', 'conj_institution', 'punct_,', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target shed are: ['cc_but', 'prep:over_years', 'nsubj_it', 'advmod_gradually', 'rootI_*root*', 'dobj_affiliation', 'cc_and', 'conj_institution', 'punct_,', 'punct_.']
Top most similar embeddings: evolved 0.00058	shed 0.00057	deepened 0.00057	dwindled 0.00054	waned 0.00054	wavered 0.00054	snowballed 0.00054	emerged 0.00054	stagnated 0.00053	hardens 0.00053

Generated lemmatized results
***************
GENERATED	shed.v 526 ::: evolve;deepen;dwindle;wan;waver;snowball;emerge;stagnate;harden;prosper

Filtered results
***************
RANKED	shed.v 526	lose 0.00047	reveal 0.00047	disperse 0.00044	relinquish 0.00043	give 0.00041	radiate 0.00041	spread 0.00040	drop 0.00040	shine 0.00039	moult 0.00038	emit 0.00037	pass 0.00036	spill 0.00035	discard 0.00035	scatter 0.00034	throw 0.00034	transmit 0.00034	discarding 0.00028

Test context:
***************
shed.v	527	17	cats in the latent phase only have the virus internally , but feel normal and do not __shed__ the virus to other cats and the environment .
Contexts for target shed are: ['aux_do', 'neg_not', 'conjI_have', 'dobj_virus', 'prep:to_cats']
Contexts in vocabulary for target shed are: ['aux_do', 'neg_not', 'conjI_have', 'dobj_virus', 'prep:to_cats']
Top most similar embeddings: shed 0.02341	excrete 0.02033	tolerate 0.01933	contaminate 0.01856	transmit 0.01855	overdo 0.01846	over-react 0.01835	succumb 0.01834	pollinate 0.01831	ovulate 0.01827

Generated lemmatized results
***************
GENERATED	shed.v 527 ::: excrete;tolerate;contaminate;transmit;overdo;succumb;pollinate;ovulate;habituate;inactivate

Filtered results
***************
RANKED	shed.v 527	transmit 0.01855	emit 0.01777	pass 0.01692	spread 0.01653	give 0.01627	lose 0.01572	disperse 0.01561	throw 0.01558	reveal 0.01555	spill 0.01518	moult 0.01513	discard 0.01509	radiate 0.01474	relinquish 0.01465	drop 0.01384	scatter 0.01325	shine 0.01319	discarding 0.01097

Test context:
***************
shed.v	528	16	vacuuming the lawn we used to have a large yellow tree in our front lawn which __shed__ a blanket of bright yellow leaves each year .
Contexts for target shed are: ['nsubj_which', 'rcmodI_lawn', 'dobj_blanket']
Contexts in vocabulary for target shed are: ['nsubj_which', 'rcmodI_lawn', 'dobj_blanket']
Top most similar embeddings: shed 0.10344	sheds 0.09187	abutted 0.08478	overlies 0.08414	billowed 0.08162	protruded 0.08121	dangles 0.08119	adorns 0.08066	encloses 0.07996	abuts 0.07995

Generated lemmatized results
***************
GENERATED	shed.v 528 ::: abut;overlie;billow;protrude;dangle;adorn;enclose;suffocate;glint;seperates

Filtered results
***************
RANKED	shed.v 528	radiate 0.07601	throw 0.07455	emit 0.07359	spread 0.07312	scatter 0.07237	spill 0.07175	moult 0.07066	shine 0.07008	disperse 0.06933	discard 0.06711	give 0.06504	lose 0.06449	transmit 0.06418	drop 0.06349	pass 0.06128	reveal 0.06001	discarding 0.05904	relinquish 0.05894

Test context:
***************
shed.v	529	2	you have __shed__ blood for us and we thank you .
Contexts for target shed are: ['nsubj_you', 'aux_have', 'rootI_*root*', 'dobj_blood', 'prep:for_us', 'cc_and', 'conj_thank', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target shed are: ['nsubj_you', 'aux_have', 'rootI_*root*', 'dobj_blood', 'prep:for_us', 'cc_and', 'conj_thank', 'punct_.']
Top most similar embeddings: shed 0.00314	recived 0.00239	wept 0.00237	fundraised 0.00231	prayed 0.00227	swooned 0.00227	blushed 0.00225	pined 0.00224	poured 0.00221	shined 0.00218

Generated lemmatized results
***************
GENERATED	shed.v 529 ::: recived;weep;fundraise;pray;swoon;blush;pin;pour;shin;donate

Filtered results
***************
RANKED	shed.v 529	spill 0.00215	lose 0.00204	shine 0.00203	spread 0.00176	give 0.00175	pass 0.00175	throw 0.00174	drop 0.00170	reveal 0.00167	discard 0.00165	moult 0.00162	scatter 0.00159	relinquish 0.00158	radiate 0.00155	emit 0.00147	transmit 0.00144	disperse 0.00141	discarding 0.00130

Test context:
***************
shed.v	530	2	they have __shed__ much more heat than light .
Contexts for target shed are: ['nsubj_they', 'aux_have', 'rootI_*root*', 'dobj_heat', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target shed are: ['nsubj_they', 'aux_have', 'rootI_*root*', 'dobj_heat', 'punct_.']
Top most similar embeddings: shed 0.02809	felt 0.02186	withstood 0.02181	chorused 0.02167	dowsed 0.02159	won 0.02131	waffled 0.02124	endured 0.02102	speculated 0.02087	pooh-poohed 0.02085

Generated lemmatized results
***************
GENERATED	shed.v 530 ::: felt;withstand;chorus;dowse;win;waffle;endure;speculate;hoard;survive

Filtered results
***************
RANKED	shed.v 530	lose 0.02001	spill 0.01954	shine 0.01936	reveal 0.01918	moult 0.01810	radiate 0.01807	emit 0.01802	discard 0.01781	drop 0.01749	relinquish 0.01748	disperse 0.01747	give 0.01734	spread 0.01718	throw 0.01715	pass 0.01699	scatter 0.01639	transmit 0.01555	discarding 0.01335

Test context:
***************
softly.r	531	18	go " he leaves and she sits down in the chair , looks over the figures and mutters __softly__ to herself as she reaches for the mouse .
Contexts for target softly are: ['advmodI_to']
Contexts in vocabulary for target softly are: ['advmodI_to']
Top most similar embeddings: softly 0.52881	loudly 0.39297	precariously 0.39066	tenaciously 0.39004	solemnly 0.38980	soothingly 0.38594	ceaselessly 0.38270	merrily 0.38156	quietly 0.37993	nicely 0.37528

Generated lemmatized results
***************
GENERATED	softly.r 531 ::: loudly;precariously;tenaciously;solemnly;soothingly;ceaselessly;merrily;quietly;nicely;dexterously

Filtered results
***************
RANKED	softly.r 531	quietly 0.37993	lightly 0.36056	tenderly 0.34991	daintily 0.34972	gently 0.34948	indifferently 0.34397	carefully 0.33996	delicately 0.33376	slightly 0.33285	faintly 0.32491	subtly 0.30879	finely 0.29565

Test context:
***************
softly.r	532	17	the best small cars ride smoothly , even over uneven road surfaces , but are not so __softly__ sprung that they wallow when turning , braking or accelerating .
Contexts for target softly are: ['advmod_so', 'advmodI_sprung']
Contexts in vocabulary for target softly are: ['advmod_so', 'advmodI_sprung']
Top most similar embeddings: softly 0.27040	dexterously 0.22402	ponderously 0.21169	jauntily 0.21116	stiffly 0.21090	shallowly 0.21013	sweetly 0.21009	imperiously 0.20956	lustily 0.20942	insistently 0.20937

Generated lemmatized results
***************
GENERATED	softly.r 532 ::: dexterously;ponderously;jauntily;stiffly;shallowly;sweetly;imperiously;lustily;insistently;grandly

Filtered results
***************
RANKED	softly.r 532	daintily 0.20717	tenderly 0.20241	delicately 0.19694	indifferently 0.19482	quietly 0.19266	lightly 0.19229	gently 0.19175	faintly 0.18186	subtly 0.17988	finely 0.17333	slightly 0.16420	carefully 0.16384

Test context:
***************
softly.r	533	18	it was falling on every part of the dark central plain , on the treeless hills , falling __softly__ upon the bog of allen and , farther westward , softly falling into the dark mutinous shannon waves .
Contexts for target softly are: ['advmodI_falling']
Contexts in vocabulary for target softly are: ['advmodI_falling']
Top most similar embeddings: softly 0.52667	sleepily 0.41540	absent-mindedly 0.40851	ponderously 0.40724	moodily 0.40690	precipitously 0.40433	limply 0.40230	soothingly 0.40185	helplessly 0.40039	wordlessly 0.40007

Generated lemmatized results
***************
GENERATED	softly.r 533 ::: sleepily;ponderously;moodily;precipitously;limply;soothingly;helplessly;wordlessly;jauntily;demurely

Filtered results
***************
RANKED	softly.r 533	gently 0.39047	daintily 0.38003	tenderly 0.37833	quietly 0.37567	lightly 0.36860	delicately 0.36518	indifferently 0.36055	faintly 0.35955	subtly 0.34231	slightly 0.33341	carefully 0.32549	finely 0.30448

Test context:
***************
softly.r	534	21	it should not be that a son should remember his father for having tapped the table after a meal ... smiling __softly__ , he touched his knuckles to his lips .
Contexts for target softly are: ['advmodI_smiling']
Contexts in vocabulary for target softly are: ['advmodI_smiling']
Top most similar embeddings: softly 0.55120	soothingly 0.44870	mournfully 0.44350	sleepily 0.44220	demurely 0.43731	sorrowfully 0.43386	shyly 0.43348	moodily 0.43046	absently 0.42995	amiably 0.42815

Generated lemmatized results
***************
GENERATED	softly.r 534 ::: soothingly;mournfully;sleepily;demurely;sorrowfully;shyly;moodily;absently;amiably;evilly

Filtered results
***************
RANKED	softly.r 534	tenderly 0.41370	daintily 0.40318	gently 0.40305	quietly 0.40303	faintly 0.39406	indifferently 0.38458	delicately 0.38456	lightly 0.37182	subtly 0.35999	slightly 0.33663	carefully 0.32000	finely 0.30556

Test context:
***************
softly.r	535	3	finally she smiled __softly__ and told him , " as a matter of fact i did .
Contexts for target softly are: ['advmodI_smiled']
Contexts in vocabulary for target softly are: ['advmodI_smiled']
Top most similar embeddings: softly 0.55854	soothingly 0.45803	mournfully 0.45375	shyly 0.44956	absently 0.44882	sleepily 0.44859	demurely 0.44537	guiltily 0.44496	airily 0.44486	hoarsely 0.44366

Generated lemmatized results
***************
GENERATED	softly.r 535 ::: soothingly;mournfully;shyly;absently;sleepily;demurely;guiltily;airily;hoarsely;delightedly

Filtered results
***************
RANKED	softly.r 535	tenderly 0.41452	indifferently 0.40312	daintily 0.40195	quietly 0.39980	gently 0.39615	faintly 0.39503	delicately 0.37492	lightly 0.36819	subtly 0.34712	slightly 0.32962	carefully 0.32435	finely 0.32353

Test context:
***************
softly.r	536	3	the wood was __softly__ polished , the bronze had a beautiful green
Contexts for target softly are: ['advmodI_polished']
Contexts in vocabulary for target softly are: ['advmodI_polished']
Top most similar embeddings: softly 0.51273	soothingly 0.41568	seductively 0.39778	crisply 0.39767	mournfully 0.39529	invitingly 0.39523	airily 0.39322	jauntily 0.39307	nastily 0.39307	coldly 0.39173

Generated lemmatized results
***************
GENERATED	softly.r 536 ::: soothingly;seductively;crisply;mournfully;invitingly;airily;jauntily;nastily;coldly;comically

Filtered results
***************
RANKED	softly.r 536	delicately 0.39094	daintily 0.38543	gently 0.38172	quietly 0.37853	tenderly 0.37116	indifferently 0.37080	lightly 0.36775	faintly 0.36548	carefully 0.34944	finely 0.34611	subtly 0.33939	slightly 0.32935

Test context:
***************
softly.r	537	6	that day , said the father __softly__ with tears now rolling down his face , the boys from both teams helped bring a piece of true love and humanity into this world .
Contexts for target softly are: ['advmodI_with']
Contexts in vocabulary for target softly are: ['advmodI_with']
Top most similar embeddings: softly 0.53228	loudly 0.39652	precariously 0.39211	nicely 0.39083	ceaselessly 0.38902	incessantly 0.38523	ferociously 0.38493	conservatively 0.38435	merrily 0.38298	lightly 0.38232

Generated lemmatized results
***************
GENERATED	softly.r 537 ::: loudly;precariously;nicely;ceaselessly;incessantly;ferociously;conservatively;merrily;lightly;derisively

Filtered results
***************
RANKED	softly.r 537	lightly 0.38232	quietly 0.37686	daintily 0.35849	tenderly 0.35626	indifferently 0.35375	gently 0.35213	delicately 0.34819	carefully 0.34498	faintly 0.32704	subtly 0.32365	slightly 0.32093	finely 0.30490

Test context:
***************
softly.r	538	3	and , hissing __softly__ with the voice of fire , and brightening to a wrathful , terrible gold , the demon leapt forward to do battle with the beast, even as it had promised me , in return for its freedom after cycles of captivity .
Contexts for target softly are: ['advmodI_with']
Contexts in vocabulary for target softly are: ['advmodI_with']
Top most similar embeddings: softly 0.53228	loudly 0.39652	precariously 0.39211	nicely 0.39083	ceaselessly 0.38902	incessantly 0.38523	ferociously 0.38493	conservatively 0.38435	merrily 0.38298	lightly 0.38232

Generated lemmatized results
***************
GENERATED	softly.r 538 ::: loudly;precariously;nicely;ceaselessly;incessantly;ferociously;conservatively;merrily;lightly;derisively

Filtered results
***************
RANKED	softly.r 538	lightly 0.38232	quietly 0.37686	daintily 0.35849	tenderly 0.35626	indifferently 0.35375	gently 0.35213	delicately 0.34819	carefully 0.34498	faintly 0.32704	subtly 0.32365	slightly 0.32093	finely 0.30490

Test context:
***************
softly.r	539	8	nia steps beside rafe , her hands gripping __softly__ on the straps of her backpack .
Contexts for target softly are: ['advmodI_gripping']
Contexts in vocabulary for target softly are: ['advmodI_gripping']
Top most similar embeddings: softly 0.50291	soothingly 0.41524	tensely 0.41028	ferociously 0.40429	seductively 0.40305	mournfully 0.40193	icily 0.39953	dreamily 0.39717	ineffably 0.39661	comically 0.39644

Generated lemmatized results
***************
GENERATED	softly.r 539 ::: soothingly;tensely;ferociously;seductively;mournfully;icily;dreamily;ineffably;comically;moodily

Filtered results
***************
RANKED	softly.r 539	quietly 0.39272	gently 0.38965	tenderly 0.38782	delicately 0.37808	daintily 0.37609	faintly 0.37403	lightly 0.35636	subtly 0.35182	indifferently 0.34437	finely 0.32407	slightly 0.31635	carefully 0.31209

Test context:
***************
softly.r	540	9	in the front seat stel and dominic are chuckling __softly__ at us and dominic slides in a tape of sky-noise .
Contexts for target softly are: ['advmodI_chuckling']
Contexts in vocabulary for target softly are: ['advmodI_chuckling']
Top most similar embeddings: softly 0.54195	soothingly 0.43187	mournfully 0.42113	absently 0.42031	lustily 0.42011	shyly 0.41717	hoarsely 0.41597	absent-mindedly 0.41396	loudly 0.41235	quietly 0.41197

Generated lemmatized results
***************
GENERATED	softly.r 540 ::: soothingly;mournfully;absently;lustily;shyly;hoarsely;loudly;quietly;moodily;ecstatically

Filtered results
***************
RANKED	softly.r 540	quietly 0.41197	tenderly 0.38866	gently 0.38772	daintily 0.38125	faintly 0.37662	indifferently 0.36810	delicately 0.36536	lightly 0.35803	subtly 0.33459	slightly 0.31842	carefully 0.31767	finely 0.30568

Test context:
***************
special.a	541	4	the raceboard has a __special__ covering which is resistant to size build-up and wear .
Contexts for target special are: ['amodI_covering']
Contexts in vocabulary for target special are: ['amodI_covering']
Top most similar embeddings: special 0.47746	extra-special 0.37826	shock-absorbing 0.36664	heat-resistant 0.36628	sumptious 0.36524	weather-resistant 0.36462	extra-wide 0.35857	anti-vandal 0.35804	end-of-season 0.35616	well-fitting 0.35595

Generated lemmatized results
***************
GENERATED	special.a 541 ::: sumptious;heatproof;rubberized;crinkly;protective;antistatic;filmy;metalic;diaphanous;additonal

Filtered results
***************
RANKED	special.a 541	additional 0.33431	exceptional 0.33390	extra 0.33308	unique 0.32553	exclusive 0.31852	magical 0.31799	lovely 0.31223	memorable 0.31055	wonderful 0.30919	particular 0.30859	extraordinary 0.30691	peculiar 0.30552	remarkable 0.29523	abnormal 0.29438	outstanding 0.29223	eminent 0.29146	treasured 0.29061	anomalous 0.28988	kind 0.28739	atypical 0.28442	important 0.27888	tailored 0.27295	valued 0.26953	premium 0.26781	distinguished 0.26044	selected 0.25381	quality 0.25172

Test context:
***************
special.a	542	1	a __special__ case of this is where a person collects a privacy-sensitive document ( such as medical information ) , or a token intended to serve as evidence of identity ( such as a passport ) .
Contexts for target special are: ['amodI_case']
Contexts in vocabulary for target special are: ['amodI_case']
Top most similar embeddings: special 0.53127	extra-special 0.41149	pupal 0.37777	lian-li 0.37766	cial 0.37262	top-of-the-line 0.37209	well-publicized 0.37001	2000th 0.36731	slim-line 0.36708	shock-absorbing 0.36546

Generated lemmatized results
***************
GENERATED	special.a 542 ::: pupal;cial;particular;exceptional;specific;snazzy;medicolegal;rimless;noreve;archetypical

Filtered results
***************
RANKED	special.a 542	particular 0.36414	exceptional 0.36289	extraordinary 0.34914	unique 0.34469	peculiar 0.33868	magical 0.33256	additional 0.33023	memorable 0.32481	wonderful 0.32166	extra 0.32003	atypical 0.31835	anomalous 0.31826	lovely 0.31756	remarkable 0.31489	exclusive 0.31413	important 0.31228	abnormal 0.31113	outstanding 0.30800	eminent 0.28893	kind 0.28355	treasured 0.28272	selected 0.27663	tailored 0.27489	distinguished 0.27207	valued 0.26546	quality 0.26043	premium 0.25633

Test context:
***************
special.a	543	27	i have rarely if ever seen a film from brazil , but if you miss city of god , you really have missed out on something very __special__ indeed .
Contexts for target special are: ['advmod_very', 'amodI_something', 'advmod_indeed']
Contexts in vocabulary for target special are: ['advmod_very', 'amodI_something', 'advmod_indeed']
Top most similar embeddings: special 0.13184	un-english 0.10332	extra-special 0.10183	tarty 0.09794	uncomplimentary 0.09753	strange 0.09625	hush-hush 0.09488	un-pc 0.09472	appetizing 0.09437	contraversial 0.09433

Generated lemmatized results
***************
GENERATED	special.a 543 ::: tarty;uncomplimentary;strange;appetizing;contraversial;eery;ceremonious;untraditional;unsual;unmeaning

Filtered results
***************
RANKED	special.a 543	peculiar 0.09244	magical 0.09031	remarkable 0.08989	extraordinary 0.08857	memorable 0.08797	unique 0.08692	exceptional 0.08565	wonderful 0.08241	important 0.08148	anomalous 0.08089	lovely 0.07669	abnormal 0.07302	eminent 0.07113	exclusive 0.07041	atypical 0.07023	particular 0.06824	treasured 0.06773	outstanding 0.06514	kind 0.06496	distinguished 0.06404	valued 0.06362	extra 0.06338	additional 0.05286	tailored 0.05000	premium 0.04947	selected 0.04593	quality 0.04370

Test context:
***************
special.a	544	3	the need for __special__ regions to ensure representation for sparsely populated outlying areas is acknowledged and will be accommodated .
Contexts for target special are: ['amodI_regions']
Contexts in vocabulary for target special are: ['amodI_regions']
Top most similar embeddings: special 0.49060	wine-producing 0.39129	tsunami-affected 0.38861	star-forming 0.38430	wine-growing 0.37920	oil-producing 0.37508	malarious 0.37384	epileptogenic 0.37311	randomly-selected 0.37286	intergenic 0.37277

Generated lemmatized results
***************
GENERATED	special.a 544 ::: malarious;epileptogenic;intergenic;biogeographic;karstic;semiarid;cial;orthologous;specific;different

Filtered results
***************
RANKED	special.a 544	particular 0.34610	magical 0.33789	unique 0.33239	extra 0.32857	extraordinary 0.32846	additional 0.32803	peculiar 0.32534	abnormal 0.32121	exceptional 0.31940	wonderful 0.31858	anomalous 0.31748	memorable 0.30939	important 0.30845	lovely 0.30632	exclusive 0.30561	remarkable 0.30354	treasured 0.29783	outstanding 0.29751	selected 0.29713	atypical 0.29683	eminent 0.28807	premium 0.28109	kind 0.27601	valued 0.26992	distinguished 0.26718	tailored 0.26035	quality 0.25440

Test context:
***************
special.a	545	13	you 're invited to enjoy live demonstrations , a children 's corner , __special__ visitors and exhibits , musical entertainment , and cake .
Contexts for target special are: ['amodI_visitors']
Contexts in vocabulary for target special are: ['amodI_visitors']
Top most similar embeddings: special 0.50215	non-paying 0.38075	extra-special 0.38052	non-skiing 0.37640	randomly-selected 0.37543	outward-bound 0.37471	non-regular 0.37305	non-birding 0.37229	fare-paying 0.37211	non-scottish 0.36900

Generated lemmatized results
***************
GENERATED	special.a 545 ::: unique;regular;geniune;homebound;addtional;indiginous;prestigeous;noteable;undermentioned;enthusiatic

Filtered results
***************
RANKED	special.a 545	unique 0.36543	additional 0.34175	magical 0.34016	extra 0.33938	exceptional 0.33355	memorable 0.33221	extraordinary 0.32848	wonderful 0.32133	peculiar 0.32099	exclusive 0.31504	particular 0.31471	lovely 0.31354	eminent 0.31037	important 0.30995	anomalous 0.30646	treasured 0.30518	distinguished 0.30066	outstanding 0.29818	remarkable 0.29803	abnormal 0.28866	valued 0.28758	atypical 0.28523	premium 0.28119	selected 0.27469	tailored 0.27440	kind 0.27008	quality 0.25872

Test context:
***************
special.a	546	19	his poignant lyrics and powerful delivery backed by a tight band co-led by brian jackson , make these songs __special__ .
Contexts for target special are: ['nsubj_songs', 'xcompI_make']
Contexts in vocabulary for target special are: ['nsubj_songs', 'xcompI_make']
Top most similar embeddings: special 0.24216	extra-special 0.20963	unforgetable 0.19050	memorable 0.18521	believeable 0.18221	singable 0.18189	irresistable 0.17524	punchier 0.17433	unforgettable 0.17369	snappier 0.17348

Generated lemmatized results
***************
GENERATED	special.a 546 ::: unforgetable;memorable;believeable;singable;irresistable;punchier;unforgettable;snappy;appetizing;standouts

Filtered results
***************
RANKED	special.a 546	memorable 0.18521	magical 0.16830	unique 0.16547	wonderful 0.15892	lovely 0.15778	extraordinary 0.15741	exceptional 0.15601	peculiar 0.15165	treasured 0.14460	remarkable 0.14355	kind 0.13982	exclusive 0.13974	outstanding 0.13893	extra 0.13827	anomalous 0.13587	important 0.13397	abnormal 0.13216	particular 0.13097	atypical 0.12908	tailored 0.12478	eminent 0.12460	additional 0.11623	valued 0.11545	distinguished 0.11512	premium 0.11386	quality 0.11130	selected 0.11126

Test context:
***************
special.a	547	1	take __special__ note of the following : swimming pools do not dive into the pool .
Contexts for target special are: ['amodI_note']
Contexts in vocabulary for target special are: ['amodI_note']
Top most similar embeddings: special 0.52352	post-meeting 0.43908	extra-special 0.40915	onfirmed 0.40479	promissory 0.38959	five-page 0.38066	six-page 0.38030	3-page 0.37874	congratulatory 0.37801	12-page 0.37689

Generated lemmatized results
***************
GENERATED	special.a 547 ::: onfirmed;promissory;congratulatory;cial;prefatory;additonal;valedictory;cautionary;especial;wondeful

Filtered results
***************
RANKED	special.a 547	particular 0.35330	additional 0.34644	magical 0.34065	important 0.33486	unique 0.33459	exceptional 0.33166	extraordinary 0.32959	extra 0.32679	peculiar 0.32623	wonderful 0.32018	memorable 0.31983	lovely 0.31255	remarkable 0.31201	exclusive 0.31077	kind 0.30325	anomalous 0.30240	outstanding 0.29758	abnormal 0.29474	atypical 0.29205	treasured 0.29114	premium 0.27962	tailored 0.27693	eminent 0.27572	distinguished 0.27229	valued 0.26897	selected 0.26453	quality 0.25762

Test context:
***************
special.a	548	11	remember to factor in staff training time in addition to any __special__ equipment or software you might need .
Contexts for target special are: ['amodI_equipment']
Contexts in vocabulary for target special are: ['amodI_equipment']
Top most similar embeddings: special 0.52945	anti-vandal 0.39314	earth-moving 0.39253	mains-powered 0.39079	top-of-the-line 0.38948	extra-special 0.38760	single-purpose 0.37957	in-water 0.37886	audio/visual 0.37867	the-art 0.37834

Generated lemmatized results
***************
GENERATED	special.a 548 ::: additonal;addtional;cial;audiometric;antistatic;benchtop;ancilliary;unsafeguarded;bariatric;specialised

Filtered results
***************
RANKED	special.a 548	additional 0.35414	extra 0.34172	magical 0.33643	particular 0.33343	exceptional 0.33166	unique 0.33117	extraordinary 0.32203	wonderful 0.31752	exclusive 0.31525	peculiar 0.31154	treasured 0.30860	anomalous 0.29783	important 0.29733	memorable 0.29575	lovely 0.29523	abnormal 0.29491	outstanding 0.29357	remarkable 0.29129	tailored 0.28623	atypical 0.28167	valued 0.27951	selected 0.27762	premium 0.27710	quality 0.27173	eminent 0.26882	kind 0.26350	distinguished 0.25163

Test context:
***************
special.a	549	23	the meeting would have to wait till september 4. no one understood better the importance of taking a break to spend a little __special__ time with the wife and dog than president george w. bush .
Contexts for target special are: ['amodI_time']
Contexts in vocabulary for target special are: ['amodI_time']
Top most similar embeddings: special 0.49782	extra-special 0.40692	double-quick 0.38836	5-hour 0.37887	40-hour 0.37761	addtional 0.37745	6-hour 0.37327	full/part 0.37073	wondeful 0.37062	40-day 0.36809

Generated lemmatized results
***************
GENERATED	special.a 549 ::: addtional;wondeful;psychokinetic;umpteenth;unforgetable;troublous;certian;resonable;agreat;interaural

Filtered results
***************
RANKED	special.a 549	extra 0.35192	magical 0.35100	wonderful 0.34851	particular 0.34684	additional 0.34552	memorable 0.33066	extraordinary 0.33053	lovely 0.33050	exceptional 0.32923	unique 0.32656	peculiar 0.31659	remarkable 0.30721	important 0.30505	exclusive 0.30385	treasured 0.30195	outstanding 0.29559	abnormal 0.29514	atypical 0.29152	anomalous 0.28947	kind 0.28306	eminent 0.27530	valued 0.27498	quality 0.27146	premium 0.26731	tailored 0.26685	selected 0.26510	distinguished 0.25584

Test context:
***************
special.a	550	5	thank you for being so __special__ , and filling my life with such joy and love .
Contexts for target special are: ['cop_being', 'advmod_so', 'pcompI_for', 'punct_,', 'cc_and', 'conj_filling']
Contexts in vocabulary for target special are: ['cop_being', 'advmod_so', 'pcompI_for', 'punct_,', 'cc_and', 'conj_filling']
Top most similar embeddings: nourishing 0.01064	appetising 0.01020	over-weight 0.01015	accomodating 0.01012	dressy 0.01008	garrulous 0.01008	short-tempered 0.01005	chatty 0.01005	stuffy 0.01001	hot-headed 0.00997

Generated lemmatized results
***************
GENERATED	special.a 550 ::: nourishing;appetising;accomodating;dressy;garrulous;chatty;stuffy;cocky;snobby;ornery

Filtered results
***************
RANKED	special.a 550	memorable 0.00827	lovely 0.00769	unique 0.00763	kind 0.00745	peculiar 0.00744	magical 0.00731	exceptional 0.00721	wonderful 0.00701	atypical 0.00699	eminent 0.00682	treasured 0.00678	extraordinary 0.00669	abnormal 0.00667	exclusive 0.00664	remarkable 0.00661	anomalous 0.00637	outstanding 0.00635	important 0.00624	valued 0.00588	distinguished 0.00587	extra 0.00532	tailored 0.00517	selected 0.00479	quality 0.00467	premium 0.00461	particular 0.00373	additional 0.00335

Test context:
***************
way.n	551	40	they lunched on cutlets - stripped the cutlets to the bone - and little crisp brown potatoes , and they drank between them a whole half bottle of - some white wine or other , lewisham selected in an off-hand __way__ from the list .
Contexts for target way are: ['det_an', 'amod_off-hand', 'prep:inI_selected', 'prep:from_list']
Contexts in vocabulary for target way are: ['det_an', 'amod_off-hand', 'prep:inI_selected', 'prep:from_list']
Top most similar embeddings: way 0.05287	manner 0.04767	epigraph 0.03807	epigram 0.03713	response 0.03641	accent 0.03605	fashion 0.03567	exclamation 0.03544	eagerness 0.03507	interjection 0.03496

Generated lemmatized results
***************
GENERATED	way.n 551 ::: manner;epigraph;epigram;response;accent;fashion;exclamation;eagerness;interjection;absence

Filtered results
***************
RANKED	way.n 551	manner 0.04767	fashion 0.03567	method 0.03261	direction 0.03120	aspect 0.02961	respect 0.02913	technique 0.02896	sense 0.02886	passage 0.02876	route 0.02861	practice 0.02576	journey 0.02456	characteristic 0.02361	means 0.02305	so 0.02252	far 0.02131	incidentally 0.01916	some 0.01540	how 0.01371	by 0.01273

Test context:
***************
way.n	552	4	so that in one __way__ things in the distressed areas are not as bad as they might be .
Contexts for target way are: ['num_one', 'dep:inI_that', 'rcmod_bad']
Contexts in vocabulary for target way are: ['num_one', 'dep:inI_that', 'rcmod_bad']
Top most similar embeddings: way 0.11770	everyway 0.08575	deede 0.08410	contry 0.08239	houre 0.08034	someway 0.08028	maner 0.07999	inning 0.07976	afternoone 0.07883	retrospect 0.07881

Generated lemmatized results
***************
GENERATED	way.n 552 ::: everyway;deede;contry;houre;someway;maner;inning;afternoone;retrospect;consequence

Filtered results
***************
RANKED	way.n 552	manner 0.07522	respect 0.07474	sense 0.07200	direction 0.07029	aspect 0.06745	passage 0.06586	fashion 0.06155	method 0.06142	journey 0.06079	practice 0.05660	route 0.05612	technique 0.05565	characteristic 0.05201	incidentally 0.04947	means 0.04928	far 0.04793	some 0.04375	so 0.04221	how 0.03271	by 0.02902

Test context:
***************
way.n	553	6	as well , he needs quick __ways__ of getting across routine messages such as lunch orders on days when his speech lets him down .
Contexts for target ways are: ['amod_quick', 'dobjI_needs']
Contexts in vocabulary for target ways are: ['amod_quick', 'dobjI_needs']
Top most similar embeddings: ways 0.22789	work-arounds 0.18763	work-around 0.17031	palliatives 0.16933	short-cuts 0.16895	way 0.16888	tune-up 0.16848	explainations 0.16828	takedowns 0.16630	pick-me-up 0.16420

Generated lemmatized results
***************
GENERATED	way.n 553 ::: palliative;explainations;takedown;clarification;footwork;inhalation;turnaround;reassurance;takeoff;workarounds

Filtered results
***************
RANKED	way.n 553	method 0.15473	manner 0.15115	direction 0.14508	route 0.14324	technique 0.14252	sense 0.13973	passage 0.13773	respect 0.13605	means 0.13560	practice 0.13013	fashion 0.12851	aspect 0.12353	journey 0.12310	characteristic 0.11910	so 0.11557	some 0.11447	incidentally 0.10354	how 0.09955	by 0.09771	far 0.09369

Test context:
***************
way.n	554	24	no single model formulation will ever be a complete representation of how worlds work : all representations are partial , but partial in different __ways__ .
Contexts for target ways are: ['amod_different', 'prep:inI_partial']
Contexts in vocabulary for target ways are: ['amod_different', 'prep:inI_partial']
Top most similar embeddings: ways 0.25831	guises 0.17869	callings 0.17774	interpretations 0.17454	senses 0.17275	conceptualisations 0.17147	recensions 0.17124	calibres 0.17006	contexts 0.16981	world-views 0.16924

Generated lemmatized results
***************
GENERATED	way.n 554 ::: guise;calling;interpretation;sens;conceptualisation;recensions;calibre;context;temperament;situation

Filtered results
***************
RANKED	way.n 554	manner 0.16466	aspect 0.16107	respect 0.16088	method 0.15765	sense 0.15344	direction 0.15016	passage 0.14944	technique 0.14175	characteristic 0.13909	fashion 0.13799	route 0.13574	practice 0.13435	means 0.12478	journey 0.11773	so 0.10660	far 0.10328	some 0.10072	how 0.09088	incidentally 0.08347	by 0.08063

Test context:
***************
way.n	555	2	by the __way__ , outcomes are more than the check you get like clockwork .
Contexts for target way are: ['det_the', 'prep:byI_<eol>']
Contexts in vocabulary for target way are: ['det_the']
Top most similar embeddings: way 0.52273	otherhand 0.40273	d666 0.39213	afternoone 0.38965	bucketload 0.38714	erlle 0.38321	minerva-press 0.38105	a696 0.38066	off-chance 0.38027	winline 0.37700

Generated lemmatized results
***************
GENERATED	way.n 555 ::: otherhand;afternoone;bucketload;erlle;winline;snazzmattazz;waye;plughole;heavenlies;bridlepath

Filtered results
***************
RANKED	way.n 555	manner 0.36659	method 0.34203	route 0.34049	direction 0.33505	technique 0.32470	journey 0.32440	sense 0.32413	passage 0.32217	aspect 0.31452	fashion 0.30946	characteristic 0.30834	means 0.30793	practice 0.28768	respect 0.28115	far 0.27267	so 0.27080	incidentally 0.23479	how 0.22090	some 0.20880	by 0.19888

Test context:
***************
way.n	556	17	i now wonder whether this same syndrome , much disguised and domesticated , is what underpins the __way__ we shop for chicken or frozen fish-fingers without a thought to the deaths of individual animals .
Contexts for target way are: ['det_the', 'dobjI_underpins', 'rcmod_shop']
Contexts in vocabulary for target way are: ['det_the', 'dobjI_underpins', 'rcmod_shop']
Top most similar embeddings: way 0.11908	ways 0.08336	manner 0.07994	direction 0.07779	marketplace 0.07634	enviroment 0.07515	itms 0.07504	economy 0.07405	fundamentals 0.07372	mountainside 0.07344

Generated lemmatized results
***************
GENERATED	way.n 556 ::: manner;direction;marketplace;enviroment;itms;economy;fundamental;mountainside;sense;path

Filtered results
***************
RANKED	way.n 556	manner 0.07994	direction 0.07779	sense 0.07277	fashion 0.07083	method 0.06748	passage 0.06458	aspect 0.06443	route 0.06407	journey 0.06228	technique 0.06143	practice 0.05996	characteristic 0.05834	respect 0.05828	means 0.05409	so 0.05359	far 0.04589	incidentally 0.04175	some 0.03998	how 0.03915	by 0.02962

Test context:
***************
way.n	557	27	m.schumacher : yeah , it did n't look like it in the beginning stages but then he pitted so much earlier and it was pretty clear which __way__ it would go .
Contexts for target way are: ['det_which', 'depI_clear', 'rcmod_go']
Contexts in vocabulary for target way are: ['det_which', 'depI_clear', 'rcmod_go']
Top most similar embeddings: way 0.11569	ways 0.07786	whithersoever 0.07665	ones 0.07604	direction 0.07585	becouse 0.07583	someway 0.07563	whither 0.07560	wheresoever 0.07513	manner 0.07450

Generated lemmatized results
***************
GENERATED	way.n 557 ::: whithersoever;one;direction;becouse;someway;whither;wheresoever;manner;becuase;eventhough

Filtered results
***************
RANKED	way.n 557	direction 0.07585	manner 0.07450	route 0.06872	passage 0.06598	sense 0.06409	respect 0.06277	method 0.06212	fashion 0.05837	aspect 0.05749	journey 0.05720	technique 0.05556	practice 0.05503	means 0.05304	characteristic 0.05222	incidentally 0.04997	so 0.04872	some 0.04571	far 0.04421	how 0.04218	by 0.03566

Test context:
***************
way.n	558	2	on the __way__ out of the parking lot johnny felt a thump .
Contexts for target way are: ['det_the', 'prep:onI_felt']
Contexts in vocabulary for target way are: ['det_the', 'prep:onI_felt']
Top most similar embeddings: way 0.24829	otherhand 0.22735	off-chance 0.20500	quarter-deck 0.20001	backburner 0.19700	winline 0.19586	highroad 0.19243	otherside 0.18945	sea-coast 0.18867	tow-path 0.18804

Generated lemmatized results
***************
GENERATED	way.n 558 ::: otherhand;backburner;winline;highroad;otherside;goalline;foredeck;warpath;startline;doorframe

Filtered results
***************
RANKED	way.n 558	route 0.16273	journey 0.16051	manner 0.15746	direction 0.14852	passage 0.14822	method 0.14769	aspect 0.14696	technique 0.13961	sense 0.13726	means 0.13450	fashion 0.13418	characteristic 0.13138	so 0.12213	respect 0.12093	practice 0.11821	far 0.10807	incidentally 0.09430	some 0.09122	how 0.08837	by 0.07851

Test context:
***************
way.n	559	31	the proposed definition has outraged many scientists , who are frustrated that students could be discussing supernatural explanations for natural phenomena in their science classes. " it 's a completely unscientific __way__ of looking at the world, " said keith miller , a kansas state university geologist .
Contexts for target way are: ['nsubj_it', "cop_'s", 'det_a', 'amod_unscientific', 'ccompI_outraged']
Contexts in vocabulary for target way are: ['nsubj_it', "cop_'s", 'det_a', 'amod_unscientific', 'ccompI_outraged']
Top most similar embeddings: way 0.02586	platitude 0.02216	ploy 0.02178	travesty 0.02148	cop-out 0.02147	co-incidence 0.02094	sacrilege 0.02083	ruse 0.02039	exaggeration 0.02017	coincidence 0.01998

Generated lemmatized results
***************
GENERATED	way.n 559 ::: platitude;ploy;travesty;sacrilege;ruse;exaggeration;coincidence;truism;toughie;ripoff

Filtered results
***************
RANKED	way.n 559	manner 0.01632	means 0.01486	method 0.01465	fashion 0.01418	aspect 0.01359	characteristic 0.01350	technique 0.01338	sense 0.01282	direction 0.01225	route 0.01219	journey 0.01213	respect 0.01181	passage 0.01166	practice 0.01126	far 0.01029	so 0.00851	incidentally 0.00765	some 0.00534	how 0.00500	by 0.00447

Test context:
***************
way.n	560	5	gabe says : i read __way__ , way ahead .
Contexts for target way are: ['dobjI_read']
Contexts in vocabulary for target way are: ['dobjI_read']
Top most similar embeddings: way 0.45827	artical 0.36351	ways 0.34688	freakonomics 0.34493	longhand 0.34382	hadeeth 0.34356	writeup 0.34314	entirity 0.34033	someway 0.34012	one-pager 0.33840

Generated lemmatized results
***************
GENERATED	way.n 560 ::: artical;freakonomics;longhand;hadeeth;writeup;entirity;someway;fleshmarket;starseeker;coments

Filtered results
***************
RANKED	way.n 560	manner 0.33107	passage 0.32154	fashion 0.29829	direction 0.29340	sense 0.29264	journey 0.28959	some 0.28814	aspect 0.28806	route 0.28434	method 0.28283	technique 0.27729	respect 0.27461	means 0.27330	characteristic 0.27000	practice 0.26642	far 0.25316	so 0.25284	how 0.25003	incidentally 0.24516	by 0.21646

Test context:
***************
about.r	561	3	we 've talked __about__ that a little before on the program but let 's just remind people what that is and what sort of challenge you think it poses to science .
Contexts for target about are: ['pcomp_that']
Contexts in vocabulary for target about are: ['pcomp_that']
Top most similar embeddings: about 0.51374	of 0.36327	so 0.35350	except 0.35062	than 0.34946	around 0.34723	like 0.34462	besides 0.34455	after 0.34188	before 0.33825

Generated lemmatized results
***************
GENERATED	about.r 561 ::: of;so;except;than;around;like;besides;after;before;over

Filtered results
***************
RANKED	about.r 561	of 0.36327	around 0.34723	concerning 0.28708	regarding 0.28609	roughly 0.27603	approximately 0.27301	nearly 0.26931	happen 0.24865	somewhat 0.24689	discussed 0.24242	arise 0.23728	occur 0.22876	consider 0.22353	round 0.22224

Test context:
***************
about.r	562	1	by __about__ six months of age , a baby 's iron stores are low and extra foods will be needed to prevent later nutritional problems such as iron deficiency .
Contexts for target about are: ['quantmodI_six']
Contexts in vocabulary for target about are: ['quantmodI_six']
Top most similar embeddings: about 0.54021	around 0.38297	than 0.37231	over 0.36331	at 0.36312	just 0.36247	aproximately 0.35993	only 0.35385	approximately 0.35362	of 0.34538

Generated lemmatized results
***************
GENERATED	about.r 562 ::: around;than;over;at;just;aproximately;only;approximately;of;exactly

Filtered results
***************
RANKED	about.r 562	around 0.38297	approximately 0.35362	of 0.34538	roughly 0.34047	nearly 0.33980	somewhat 0.28308	regarding 0.25717	concerning 0.25032	occur 0.23623	happen 0.23302	round 0.23089	discussed 0.22826	arise 0.22332	consider 0.21952

Test context:
***************
about.r	563	14	this website is for use mainly by public sector and industry professionals and is __about__ victorian state government policy , information and programs .
Contexts for target about are: []
Contexts in vocabulary for target about are: []
Top most similar embeddings: about 1.00000	around 0.72754	bascially 0.71125	of 0.70916	proably 0.70872	over 0.69910	staff-related 0.69773	presumptuously 0.69740	usally 0.69654	proberly 0.69471

Generated lemmatized results
***************
GENERATED	about.r 563 ::: around;bascially;of;proably;over;presumptuously;usally;proberly;than;actaully

Filtered results
***************
RANKED	about.r 563	around 0.72754	of 0.70916	approximately 0.65764	roughly 0.64649	nearly 0.63244	concerning 0.61277	regarding 0.61155	happen 0.60787	somewhat 0.60099	discussed 0.59603	consider 0.59309	arise 0.59200	occur 0.58866	round 0.54348

Test context:
***************
about.r	564	2	it went __about__ as well as you can imagine .
Contexts for target about are: ['advmodI_well']
Contexts in vocabulary for target about are: ['advmodI_well']
Top most similar embeddings: about 0.46816	as 0.39329	extemely 0.36726	extremly 0.35788	ineffably 0.35499	comparitively 0.35147	crushingly 0.34989	really 0.34987	jaw-droppingly 0.34812	proably 0.34797

Generated lemmatized results
***************
GENERATED	about.r 564 ::: as;extemely;extremly;ineffably;comparitively;crushingly;really;proably;averagely;numbingly

Filtered results
***************
RANKED	about.r 564	around 0.34205	nearly 0.31408	roughly 0.30544	approximately 0.30052	somewhat 0.28609	of 0.27915	concerning 0.24349	regarding 0.24294	happen 0.24215	occur 0.23150	discussed 0.22824	arise 0.22468	round 0.22251	consider 0.21231

Test context:
***************
about.r	565	6	but how has this situation come __about__ ?
Contexts for target about are: ['advmodI_come']
Contexts in vocabulary for target about are: ['advmodI_come']
Top most similar embeddings: about 0.51403	proably 0.39329	actaully 0.38091	bascially 0.37844	usally 0.37481	eventualy 0.37272	presumptuously 0.37191	acutally 0.37171	around 0.37164	ocassionally 0.37132

Generated lemmatized results
***************
GENERATED	about.r 565 ::: proably;actaully;bascially;usally;eventualy;presumptuously;acutally;around;ocassionally;defintely

Filtered results
***************
RANKED	about.r 565	around 0.37164	roughly 0.31534	approximately 0.31534	nearly 0.31127	of 0.30073	somewhat 0.29613	happen 0.24774	concerning 0.24413	regarding 0.24138	round 0.23768	occur 0.22972	arise 0.22356	discussed 0.22211	consider 0.21841

Test context:
***************
about.r	566	13	when i used linux in 1994 , i found that my system crashed __about__ once a week due to hard disk problems ; however , linux has matured a great deal since then , and that was probably the fault of my system setup , not linux .
Contexts for target about are: []
Contexts in vocabulary for target about are: []
Top most similar embeddings: about 1.00000	around 0.72754	bascially 0.71125	of 0.70916	proably 0.70872	over 0.69910	staff-related 0.69773	presumptuously 0.69740	usally 0.69654	proberly 0.69471

Generated lemmatized results
***************
GENERATED	about.r 566 ::: around;bascially;of;proably;over;presumptuously;usally;proberly;than;actaully

Filtered results
***************
RANKED	about.r 566	around 0.72754	of 0.70916	approximately 0.65764	roughly 0.64649	nearly 0.63244	concerning 0.61277	regarding 0.61155	happen 0.60787	somewhat 0.60099	discussed 0.59603	consider 0.59309	arise 0.59200	occur 0.58866	round 0.54348

Test context:
***************
about.r	567	3	you 're just __about__ to start coding when wendy points out that you 're not done yet .
Contexts for target about are: ['nsubj_you', "cop_'re", 'advmod_just', 'rootI_*root*', 'xcomp_start', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target about are: ['nsubj_you', "cop_'re", 'advmod_just', 'rootI_*root*', 'xcomp_start', 'punct_.']
Top most similar embeddings: about 0.01385	gwyne 0.01180	like 0.01175	kiddin 0.01155	desparate 0.01150	gots 0.01145	goign 0.01144	wonderin 0.01115	unlucky 0.01085	kidding 0.01075

Generated lemmatized results
***************
GENERATED	about.r 567 ::: gwyne;like;kiddin;desparate;gots;goign;wonderin;unlucky;kidding;ready

Filtered results
***************
RANKED	about.r 567	around 0.00721	happen 0.00660	consider 0.00640	round 0.00534	discussed 0.00519	arise 0.00464	occur 0.00461	regarding 0.00437	roughly 0.00427	approximately 0.00406	of 0.00397	somewhat 0.00393	concerning 0.00376	nearly 0.00286

Test context:
***************
about.r	568	13	as you said about neurons working in waves , i 'd never thought __about__ that before .
Contexts for target about are: []
Contexts in vocabulary for target about are: []
Top most similar embeddings: about 1.00000	around 0.72754	bascially 0.71125	of 0.70916	proably 0.70872	over 0.69910	staff-related 0.69773	presumptuously 0.69740	usally 0.69654	proberly 0.69471

Generated lemmatized results
***************
GENERATED	about.r 568 ::: around;bascially;of;proably;over;presumptuously;usally;proberly;than;actaully

Filtered results
***************
RANKED	about.r 568	around 0.72754	of 0.70916	approximately 0.65764	roughly 0.64649	nearly 0.63244	concerning 0.61277	regarding 0.61155	happen 0.60787	somewhat 0.60099	discussed 0.59603	consider 0.59309	arise 0.59200	occur 0.58866	round 0.54348

Test context:
***************
about.r	569	4	they are all running __about__ in their bullet proof vests .
Contexts for target about are: ['advmodI_in']
Contexts in vocabulary for target about are: ['advmodI_in']
Top most similar embeddings: about 0.50595	just 0.36563	even 0.36551	proably 0.36492	only 0.36072	particularly 0.35975	especially 0.35826	bascially 0.35713	at 0.35382	actaully 0.34791

Generated lemmatized results
***************
GENERATED	about.r 569 ::: just;even;proably;only;particularly;especially;bascially;at;actaully;still

Filtered results
***************
RANKED	about.r 569	roughly 0.34238	around 0.34230	approximately 0.33151	nearly 0.32530	somewhat 0.30913	of 0.29143	occur 0.23959	regarding 0.23818	concerning 0.23736	happen 0.23626	arise 0.22788	discussed 0.21863	round 0.21845	consider 0.21830

Test context:
***************
about.r	570	18	the ss , however , is very happy at the moment , & has significantly more to think __about__ than me .
Contexts for target about are: ['advmodI_think', 'prep:than_me']
Contexts in vocabulary for target about are: ['advmodI_think', 'prep:than_me']
Top most similar embeddings: about 0.23493	proberly 0.17550	actaully 0.17252	presumptuously 0.17208	probally 0.17146	guardedly 0.17034	flippantly 0.17023	defintely 0.16869	smarter 0.16786	insultingly 0.16761

Generated lemmatized results
***************
GENERATED	about.r 570 ::: proberly;actaully;presumptuously;probally;guardedly;flippantly;defintely;smarter;insultingly;intelligibly

Filtered results
***************
RANKED	about.r 570	around 0.15333	roughly 0.14742	of 0.13334	nearly 0.13225	approximately 0.12917	somewhat 0.12810	happen 0.11040	regarding 0.10721	concerning 0.10599	round 0.10232	arise 0.10223	occur 0.09482	discussed 0.08900	consider 0.08634

Test context:
***************
bug.n	571	15	in any case , it deems the us president to have the power to authorise __bugs__ on any person and any organisation .
Contexts for target bugs are: ['dobjI_authorise']
Contexts in vocabulary for target bugs are: ['dobjI_authorise']
Top most similar embeddings: bugs 0.44087	bug 0.35194	underspends 0.32996	redirections 0.32842	breakages 0.32826	modifications 0.32823	infringers 0.32677	oversights 0.32673	modification 0.32635	errors 0.32560

Generated lemmatized results
***************
GENERATED	bug.n 571 ::: underspends;redirections;breakage;modification;infringers;oversight;error;virements;enforcement;chargebacks

Filtered results
***************
RANKED	bug.n 571	error 0.32560	fault 0.31323	insect 0.30942	virus 0.30532	defect 0.30419	infection 0.29720	gremlin 0.29692	germ 0.29529	problem 0.29252	surveillance 0.27489	tap 0.27449	craze 0.27119	fever 0.26567	obsession 0.25885	addiction 0.25814

Test context:
***************
bug.n	572	2	combining this __bug__ with the key recovery attack would allow an attacker to obtain the private keys of anyone who viewed a web page containing the code .
Contexts for target bug are: ['det_this', 'dobjI_combining']
Contexts in vocabulary for target bug are: ['det_this', 'dobjI_combining']
Top most similar embeddings: bug 0.22025	flaw 0.17130	bugs 0.16830	malware 0.16085	technique 0.15973	virus 0.15967	functionality 0.15916	story-line 0.15907	niceness 0.15813	glitch 0.15810

Generated lemmatized results
***************
GENERATED	bug.n 572 ::: flaw;malware;technique;virus;functionality;niceness;glitch;fungus;error;bacterium

Filtered results
***************
RANKED	bug.n 572	virus 0.15967	error 0.15771	defect 0.15162	craze 0.14510	problem 0.14446	fault 0.14427	insect 0.14193	germ 0.14123	obsession 0.14029	gremlin 0.13613	infection 0.13488	addiction 0.13305	fever 0.12991	surveillance 0.12924	tap 0.12625

Test context:
***************
bug.n	573	17	the bravest of the immune cells invade the area in a kamikaze act and the majority of __bugs__ will be killed off in the ensuing battle .
Contexts for target bugs are: ['prep:ofI_majority']
Contexts in vocabulary for target bugs are: ['prep:ofI_majority']
Top most similar embeddings: bugs 0.49408	glitches 0.36237	bug 0.35690	ciliates 0.35609	millipedes 0.35529	typos 0.35437	vulnerabilities 0.35426	hacks 0.35401	sandflies 0.35396	virii 0.35372

Generated lemmatized results
***************
GENERATED	bug.n 573 ::: glitch;ciliate;millipede;typo;vulnerability;hack;sandfly;virii;bacteraemias;synaesthetes

Filtered results
***************
RANKED	bug.n 573	error 0.35204	fault 0.35040	infection 0.34961	defect 0.34281	insect 0.34213	virus 0.34048	germ 0.33796	gremlin 0.32969	problem 0.32295	fever 0.30327	craze 0.29688	tap 0.28650	obsession 0.27543	addiction 0.27040	surveillance 0.25884

Test context:
***************
bug.n	574	7	to get on this list , a __bug__ has to be able to cause at least half a day of futile head scratching , and has to be aggravated by the poor design of the " c " language .
Contexts for target bug are: ['det_a', 'nsubjI_has']
Contexts in vocabulary for target bug are: ['det_a', 'nsubjI_has']
Top most similar embeddings: bug 0.24708	drawingarea 0.19321	detailsview 0.18717	sandbar 0.18537	rotifer 0.18501	flaw 0.18460	woodlouse 0.18438	millipede 0.18294	flatworm 0.18286	collectpoint 0.18240

Generated lemmatized results
***************
GENERATED	bug.n 574 ::: drawingarea;detailsview;sandbar;rotifer;flaw;woodlouse;millipede;flatworm;collectpoint;vizsla

Filtered results
***************
RANKED	bug.n 574	virus 0.17585	gremlin 0.17428	problem 0.16498	error 0.15942	defect 0.15621	insect 0.15527	fault 0.15514	germ 0.15259	infection 0.15014	craze 0.14933	fever 0.14539	tap 0.14236	obsession 0.14021	addiction 0.13978	surveillance 0.11475

Test context:
***************
bug.n	575	15	if temperatures are warm enough for the virus to mature inside the mosquito , the __bug__ can pass along the virus the next time it bites , berner and bradley explained .
Contexts for target bug are: ['det_the', 'nsubjI_pass']
Contexts in vocabulary for target bug are: ['det_the', 'nsubjI_pass']
Top most similar embeddings: bug 0.23367	bugs 0.19118	virus 0.18301	dwarfers 0.18291	winnats 0.18127	skaarj 0.18084	colonoscope 0.17619	cercaria 0.17567	superbug 0.17523	spambots 0.17442

Generated lemmatized results
***************
GENERATED	bug.n 575 ::: virus;dwarfers;winnats;skaarj;colonoscope;cercaria;superbug;spambots;grundys;cylons

Filtered results
***************
RANKED	bug.n 575	virus 0.18301	gremlin 0.17257	germ 0.16447	problem 0.15624	fault 0.15544	defect 0.15425	infection 0.15344	craze 0.15190	error 0.14829	insect 0.14808	fever 0.14342	obsession 0.12967	tap 0.12872	addiction 0.12388	surveillance 0.11489

Test context:
***************
bug.n	576	5	let your child pick one __bug__ to glue on the lid .
Contexts for target bug are: ['num_one', 'dobjI_pick']
Contexts in vocabulary for target bug are: ['num_one', 'dobjI_pick']
Top most similar embeddings: bug 0.24525	bugs 0.19392	flaw 0.19263	drumstick 0.18273	glitch 0.18188	titbit 0.18090	niggle 0.17998	band/artist 0.17975	plectrum 0.17602	lifebuoy 0.17521

Generated lemmatized results
***************
GENERATED	bug.n 576 ::: flaw;drumstick;glitch;titbit;niggle;plectrum;lifebuoy;headshot;minigame;niggles

Filtered results
***************
RANKED	bug.n 576	gremlin 0.16987	virus 0.16960	problem 0.16023	error 0.15996	fault 0.15948	defect 0.15542	germ 0.15328	infection 0.15010	insect 0.14588	craze 0.13595	tap 0.13514	fever 0.13329	obsession 0.13259	addiction 0.12857	surveillance 0.10802

Test context:
***************
bug.n	577	3	later she made __bug__ soup in the birdbath .
Contexts for target bug are: ['nnI_soup']
Contexts in vocabulary for target bug are: ['nnI_soup']
Top most similar embeddings: bug 0.49034	bugs 0.38610	tattie 0.36304	skink 0.35878	whelk 0.35630	fajita 0.35134	udon 0.35025	lasagna 0.35013	chipolata 0.34981	potatoe 0.34795

Generated lemmatized results
***************
GENERATED	bug.n 577 ::: tattie;skink;whelk;fajita;udon;lasagna;chipolata;potatoe;butternut;brocolli

Filtered results
***************
RANKED	bug.n 577	virus 0.34355	germ 0.32667	insect 0.31781	gremlin 0.31346	defect 0.31264	error 0.30609	fault 0.30024	craze 0.29938	problem 0.29213	infection 0.28739	addiction 0.28427	fever 0.28417	tap 0.27325	surveillance 0.26606	obsession 0.25824

Test context:
***************
bug.n	578	26	the formerly empty area under the staircase is now filled with big pots of water covered with trays and mismatching pot covers to keep out stray __bugs__ and dust .
Contexts for target bugs are: ['amod_stray', 'dobjI_keep', 'cc_and', 'conj_dust']
Contexts in vocabulary for target bugs are: ['amod_stray', 'dobjI_keep', 'cc_and', 'conj_dust']
Top most similar embeddings: bugs 0.06237	slugs 0.05313	mosquitos 0.05062	swarf 0.05020	germs 0.04947	cockroaches 0.04943	fleas 0.04915	gnats 0.04887	mites 0.04884	midges 0.04870

Generated lemmatized results
***************
GENERATED	bug.n 578 ::: slug;mosquito;swarf;germ;cockroach;flea;gnat;mite;midge;insect

Filtered results
***************
RANKED	bug.n 578	germ 0.04947	insect 0.04819	gremlin 0.04111	virus 0.04099	error 0.03821	fever 0.03810	infection 0.03515	tap 0.03410	defect 0.03390	fault 0.03323	obsession 0.03006	addiction 0.02878	problem 0.02841	surveillance 0.02802	craze 0.02580

Test context:
***************
bug.n	579	12	we wanted to give our client more than just a list of __bugs__ and an invoice-- we wanted to provide an audit trail of our work along with meaningful productivity metrics .
Contexts for target bugs are: ['prep:ofI_list', 'cc_and', 'conj_invoice']
Contexts in vocabulary for target bugs are: ['prep:ofI_list', 'cc_and', 'conj_invoice']
Top most similar embeddings: bugs 0.10760	misspellings 0.08905	p14s 0.08573	prefixes 0.08386	errors 0.08315	invoices 0.08301	saes 0.08232	bug-fixes 0.08130	comparables 0.08098	howtos 0.08088

Generated lemmatized results
***************
GENERATED	bug.n 579 ::: misspelling;prefix;error;invoice;saes;comparables;howtos;wishlists;bugfixes;timesheets

Filtered results
***************
RANKED	bug.n 579	error 0.08315	fault 0.07659	defect 0.07484	virus 0.07432	germ 0.06898	insect 0.06875	fever 0.06651	gremlin 0.06639	infection 0.06394	problem 0.06296	obsession 0.05931	tap 0.05907	addiction 0.05807	craze 0.05609	surveillance 0.05141

Test context:
***************
bug.n	580	12	after being at nths for two years , she caught the networking __bug__ and since then has concentrated all her efforts to provide networking education to her students .
Contexts for target bug are: ['det_the', 'nn_networking', 'dobjI_caught']
Contexts in vocabulary for target bug are: ['det_the', 'nn_networking', 'dobjI_caught']
Top most similar embeddings: bug 0.13364	bugs 0.09983	virus 0.08686	glitch 0.08581	flaw 0.08556	worm 0.08338	millipede 0.08120	glitches 0.08096	nightbus 0.08042	craze 0.07930

Generated lemmatized results
***************
GENERATED	bug.n 580 ::: virus;glitch;flaw;worm;millipede;nightbus;craze;superbug;snag;rootkit

Filtered results
***************
RANKED	bug.n 580	virus 0.08686	craze 0.07930	problem 0.07790	error 0.07784	gremlin 0.07541	fault 0.07173	germ 0.07007	infection 0.06925	insect 0.06720	fever 0.06671	defect 0.06550	tap 0.06227	obsession 0.06039	addiction 0.05765	surveillance 0.05040

Test context:
***************
bull.n	581	14	to fight each other is not a natural state for that dog or that __bull__ to be in .
Contexts for target bull are: ['depI_that', 'infmod_be', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target bull are: ['depI_that', 'infmod_be', 'punct_.']
Top most similar embeddings: bull 0.09715	seemes 0.08194	reson 0.08088	pandarus 0.08078	arcite 0.08039	tchiowa 0.07978	desireth 0.07970	beginneth 0.07965	proceedeth 0.07942	seeketh 0.07887

Generated lemmatized results
***************
GENERATED	bull.n 581 ::: seemes;reson;pandarus;arcite;tchiowa;desireth;beginneth;proceedeth;seeketh;locrine

Filtered results
***************
RANKED	bull.n 581	cow 0.07033	nonsense 0.06838	warrant 0.06814	crap 0.06660	stag 0.06323	rubbish 0.06139	suitor 0.06098	edict 0.06078	animal 0.05949	target 0.05742	male 0.05688	stud 0.05524	document 0.05314	rising 0.05276	booming 0.04703	centre 0.04654	growing 0.04646

Test context:
***************
bull.n	582	1	the __bull__ market is n't the only thing that makes short-selling perilous .
Contexts for target bull are: ['nnI_market']
Contexts in vocabulary for target bull are: ['nnI_market']
Top most similar embeddings: bull 0.52086	leadenhall 0.39717	eurobond 0.39197	elmstead 0.38036	chrisp 0.37915	helmshore 0.37408	texcoco 0.36943	cattle 0.36402	watney 0.36221	bulls 0.36095

Generated lemmatized results
***************
GENERATED	bull.n 582 ::: leadenhall;eurobond;elmstead;chrisp;helmshore;texcoco;cattle;watney;thainstone;pig

Filtered results
***************
RANKED	bull.n 582	cow 0.33278	animal 0.31592	stag 0.30657	target 0.29237	warrant 0.28143	stud 0.27846	crap 0.27697	suitor 0.27445	male 0.27362	centre 0.27283	nonsense 0.26617	growing 0.26612	document 0.26234	booming 0.25983	rising 0.25763	edict 0.25453	rubbish 0.24596

Test context:
***************
bull.n	583	12	we werent two miles into the park when we saw a huge __bull__ elephant standing in the middle of the road in front of us , his ears out , his trunk up , and bellowing .
Contexts for target bull are: ['nnI_standing']
Contexts in vocabulary for target bull are: ['nnI_standing']
Top most similar embeddings: bull 0.49117	cow 0.37543	heifer 0.37270	bulls 0.36713	ox 0.36408	lion 0.36351	dandie 0.36306	cockerel 0.36261	donkey 0.36166	vanir 0.35985

Generated lemmatized results
***************
GENERATED	bull.n 583 ::: cow;heifer;ox;lion;dandie;cockerel;donkey;vanir;pugilist;tup

Filtered results
***************
RANKED	bull.n 583	cow 0.37543	stag 0.33068	animal 0.31705	suitor 0.29453	stud 0.28975	crap 0.28882	male 0.28238	nonsense 0.27864	warrant 0.26363	centre 0.26032	target 0.25630	rising 0.25411	rubbish 0.25383	edict 0.25352	growing 0.24115	document 0.23921	booming 0.22895

Test context:
***************
bull.n	584	22	and i dont care how skinny you are or how much of a hard gainer you think you are ( that is __bull__ once you discover these secrets ) .
Contexts for target bull are: ['nsubj_you', 'cop_are', 'punct_-lrb-', 'nsubj_that', 'cop_is', 'ccompI_think', 'advcl_discover']
Contexts in vocabulary for target bull are: ['nsubj_you', 'cop_are', 'nsubj_that', 'cop_is', 'ccompI_think', 'advcl_discover']
Top most similar embeddings: creditworthy 0.01025	unforgiveable 0.01012	unlovable 0.00969	teachable 0.00955	stupider 0.00955	goign 0.00945	cleverer 0.00942	salvageable 0.00936	pre-disposed 0.00933	fixable 0.00933

Generated lemmatized results
***************
GENERATED	bull.n 584 ::: creditworthy;unforgiveable;unlovable;teachable;stupider;goign;cleverer;salvageable;fixable;stupid

Filtered results
***************
RANKED	bull.n 584	crap 0.00838	rubbish 0.00773	nonsense 0.00753	warrant 0.00698	booming 0.00691	cow 0.00610	target 0.00565	male 0.00558	growing 0.00523	animal 0.00505	suitor 0.00495	rising 0.00483	stud 0.00476	stag 0.00429	edict 0.00398	document 0.00392	centre 0.00289

Test context:
***************
bull.n	585	5	walter barlow absolutely took the __bull__ by the horns and soon there was a bike , then an attempt at raising funds .
Contexts for target bull are: ['det_the', 'dobjI_took']
Contexts in vocabulary for target bull are: ['det_the', 'dobjI_took']
Top most similar embeddings: bull 0.25489	holeshot 0.20989	hindmost 0.20101	cudgels 0.19994	hastle 0.19560	sawhorse 0.19214	bulls 0.18756	mini-pill 0.18641	saw-horse 0.18583	rowboat 0.18544

Generated lemmatized results
***************
GENERATED	bull.n 585 ::: holeshot;hindmost;cudgel;hastle;sawhorse;rowboat;lioness;sudetenland;hogg;backseat

Filtered results
***************
RANKED	bull.n 585	cow 0.17316	stag 0.16261	animal 0.14675	stud 0.14617	edict 0.14616	suitor 0.14510	crap 0.13881	rising 0.13695	warrant 0.13386	rubbish 0.13375	male 0.13360	nonsense 0.13187	document 0.12929	centre 0.12910	target 0.12516	growing 0.10712	booming 0.10268

Test context:
***************
bull.n	586	6	treaty of tordesillas under a papal __bull__ issued in 1493 , spain was awarded lands west and south of the line of demarcation , and portugal received lands east and south .
Contexts for target bull are: ['det_a', 'amod_papal', 'prep:underI_treaty', 'partmod_issued']
Contexts in vocabulary for target bull are: ['det_a', 'amod_papal', 'partmod_issued']
Top most similar embeddings: bull 0.13003	proclamation 0.09092	fatwa 0.08983	ukase 0.08888	summons 0.08865	recantation 0.08838	edict 0.08806	bulls 0.08647	crosier 0.08602	counter-notice 0.08532

Generated lemmatized results
***************
GENERATED	bull.n 586 ::: proclamation;fatwa;ukase;summons;recantation;edict;crosier;decree;writ;fpn

Filtered results
***************
RANKED	bull.n 586	edict 0.08806	warrant 0.08144	cow 0.07701	document 0.07629	suitor 0.06887	stag 0.06628	stud 0.06077	animal 0.06060	male 0.05766	nonsense 0.05608	target 0.05581	crap 0.05214	rubbish 0.05149	centre 0.05040	rising 0.05026	booming 0.04297	growing 0.04126

Test context:
***************
bull.n	587	2	hit the __bulls__ eye with your marketing when you have limited capital and have only one shot left .
Contexts for target bulls are: ['nnI_eye']
Contexts in vocabulary for target bulls are: ['nnI_eye']
Top most similar embeddings: bulls 0.52032	sheeps 0.37243	grafik 0.37021	rams 0.36789	tigers 0.36517	bullocks 0.36113	bull 0.35860	lions 0.35329	boars 0.35262	wolves 0.35243

Generated lemmatized results
***************
GENERATED	bull.n 587 ::: sheep;grafik;ram;tiger;bullock;lion;boar;wolf;galloway;cow

Filtered results
***************
RANKED	bull.n 587	cow 0.35125	stag 0.34284	animal 0.31462	male 0.29702	stud 0.29090	suitor 0.28462	edict 0.27643	crap 0.27118	nonsense 0.27014	warrant 0.26296	booming 0.25487	rising 0.25395	target 0.25054	centre 0.24830	document 0.24729	growing 0.23583	rubbish 0.23516

Test context:
***************
bull.n	588	4	hunky bill paxton plays __bull__ to three women in big love .
Contexts for target bull are: ['dobjI_plays']
Contexts in vocabulary for target bull are: ['dobjI_plays']
Top most similar embeddings: bull 0.47380	malvolio 0.36503	petruchio 0.36147	dooku 0.36056	rothbart 0.35798	saxaphone 0.35777	niobe 0.35656	sejanus 0.35461	merrin 0.35458	x-court 0.35429

Generated lemmatized results
***************
GENERATED	bull.n 588 ::: malvolio;petruchio;dooku;rothbart;saxaphone;niobe;sejanus;merrin;wino;mathilda

Filtered results
***************
RANKED	bull.n 588	cow 0.33508	stag 0.30536	crap 0.30075	suitor 0.29927	stud 0.29093	male 0.28466	nonsense 0.28139	animal 0.28011	rubbish 0.26865	rising 0.25935	centre 0.25526	edict 0.25301	target 0.25205	warrant 0.24874	booming 0.24862	document 0.24141	growing 0.23459

Test context:
***************
bull.n	589	28	" some darting terms originated outside the sport , such as " hat trick " meaning all three darts of a player 's round landing in the " __bull__ .
Contexts for target bull are: ['det_the', "punct_''", 'prep:inI_landing']
Contexts in vocabulary for target bull are: ['det_the', 'prep:inI_landing']
Top most similar embeddings: bull 0.22635	fiord 0.18242	endzone 0.17913	hellespont 0.17635	berkshires 0.17579	shetlands 0.17539	antartic 0.17511	henhouse 0.17510	bulrushes 0.17500	rowboat 0.17497

Generated lemmatized results
***************
GENERATED	bull.n 589 ::: fiord;endzone;hellespont;berkshire;shetland;antartic;henhouse;bulrush;rowboat;feild

Filtered results
***************
RANKED	bull.n 589	stag 0.15003	cow 0.14954	centre 0.14227	rising 0.14075	stud 0.13711	suitor 0.13590	animal 0.13370	edict 0.13163	crap 0.12773	rubbish 0.12732	male 0.12672	warrant 0.12370	nonsense 0.12317	target 0.12256	document 0.12222	booming 0.10559	growing 0.10407

Test context:
***************
bull.n	590	5	" what a bunch of __bull__ .
Contexts for target bull are: ['prep:ofI_bunch']
Contexts in vocabulary for target bull are: ['prep:ofI_bunch']
Top most similar embeddings: bull 0.47204	wallies 0.38066	bulls 0.37922	deers 0.36776	crazies 0.36699	dickheads 0.36570	trendies 0.36387	hoodlums 0.36367	scallies 0.36366	gringos 0.36217

Generated lemmatized results
***************
GENERATED	bull.n 590 ::: wally;deer;crazy;dickhead;trendies;hoodlum;scallies;gringo;ewoks;towny

Filtered results
***************
RANKED	bull.n 590	stag 0.33715	cow 0.33486	crap 0.31926	animal 0.30748	nonsense 0.30350	suitor 0.30094	rubbish 0.29957	male 0.29739	stud 0.29417	edict 0.28199	document 0.26289	rising 0.25831	warrant 0.25754	target 0.25552	centre 0.24866	growing 0.24754	booming 0.24155

Test context:
***************
education.n	591	7	increase the percentage of adults taking up __education__ and training and so increase the overall level of educational attainment and literacy levels in victoria .
Contexts for target education are: ['dobjI_taking', 'cc_and', 'conj_training']
Contexts in vocabulary for target education are: ['dobjI_taking', 'cc_and', 'conj_training']
Top most similar embeddings: education 0.13178	eduction 0.10584	avces 0.10070	educations 0.09731	re-skilling 0.09668	self-education 0.09633	skillseekers 0.09562	hncs 0.09518	schooling 0.09488	throughcare 0.09486

Generated lemmatized results
***************
GENERATED	education.n 591 ::: eduction;avces;skillseekers;hncs;schooling;throughcare;gamekeeping;employment;sabbatical;tvei

Filtered results
***************
RANKED	education.n 591	schooling 0.09488	training 0.09031	teaching 0.08234	instruction 0.08233	tuition 0.08197	learning 0.08115	college 0.07808	knowledge 0.07362	study 0.07102	intellect 0.06226	erudition 0.06217	educated 0.06040	place 0.05698

Test context:
***************
education.n	592	25	persons convicted of a criminal offense and considering a teaching career should write to the bcct for clarification of their status before undertaking a teacher __education__ program .
Contexts for target education are: ['nnI_program']
Contexts in vocabulary for target education are: ['nnI_program']
Top most similar embeddings: education 0.50345	eduction 0.43140	studies/area 0.42608	biodefense 0.39968	training/education 0.39675	bubblemaker 0.39345	itet 0.39272	educations 0.39266	educare 0.39018	tm-sidhi 0.38784

Generated lemmatized results
***************
GENERATED	education.n 592 ::: eduction;biodefense;bubblemaker;itet;educare;apiculture;microenterprise;training;preservice;skillseekers

Filtered results
***************
RANKED	education.n 592	training 0.37566	schooling 0.37173	learning 0.32646	teaching 0.31950	study 0.31893	instruction 0.31883	tuition 0.31238	college 0.30069	knowledge 0.28932	intellect 0.27525	educated 0.26695	erudition 0.26083	place 0.24935

Test context:
***************
education.n	593	24	i do n't know anyone who does n't work hard , who has n't made a success of themselves , whatever their level of __education__ .
Contexts for target education are: ['prep:ofI_level']
Contexts in vocabulary for target education are: ['prep:ofI_level']
Top most similar embeddings: education 0.50202	eduction 0.42756	schooling 0.39203	owner-occupation 0.38389	educations 0.38360	training/education 0.37809	literacy/numeracy 0.37739	self-education 0.36897	self-actualisation 0.36773	literacy 0.36763

Generated lemmatized results
***************
GENERATED	education.n 593 ::: eduction;schooling;literacy;lipspeaking;licensure;neuroticism;oracy;unionisation;joblessness;innovativeness

Filtered results
***************
RANKED	education.n 593	schooling 0.39203	training 0.35586	tuition 0.33613	instruction 0.33031	knowledge 0.32465	learning 0.32027	teaching 0.31738	study 0.30466	intellect 0.30402	erudition 0.30182	college 0.29343	educated 0.27411	place 0.25090

Test context:
***************
education.n	594	21	the children hope to use the area in all aspects of their school work , to benefit not only their environmental __education__ , but also the birds , bugs and wild flowers of llandinam .
Contexts for target education are: ['preconj_only', 'poss_their', 'amod_environmental', 'dobjI_benefit']
Contexts in vocabulary for target education are: ['preconj_only', 'poss_their', 'amod_environmental', 'dobjI_benefit']
Top most similar embeddings: education 0.05016	educations 0.04143	microenterprises 0.04126	eduction 0.03985	well-being 0.03922	profession 0.03907	entitlements 0.03830	dependents 0.03818	livelihood 0.03795	communities 0.03783

Generated lemmatized results
***************
GENERATED	education.n 594 ::: microenterprises;eduction;profession;entitlement;dependent;livelihood;community;wellbeing;health;career

Filtered results
***************
RANKED	education.n 594	schooling 0.03691	knowledge 0.03605	training 0.03276	teaching 0.03259	learning 0.03239	study 0.03186	intellect 0.03175	college 0.03093	instruction 0.02780	erudition 0.02643	tuition 0.02591	place 0.02444	educated 0.02241

Test context:
***************
education.n	595	5	the education , education , __education__ mantra has moved on to standards , standards , standards .
Contexts for target education are: ['nnI_mantra']
Contexts in vocabulary for target education are: ['nnI_mantra']
Top most similar embeddings: education 0.44610	eduction 0.36955	schooling 0.36465	educations 0.35493	foreign-policy 0.35381	clil 0.34683	gayatri 0.34345	itet 0.34337	fe/he 0.34164	managerialist 0.33932

Generated lemmatized results
***************
GENERATED	education.n 595 ::: eduction;schooling;clil;gayatri;itet;managerialist;sivananda;vastu;intercessory;vipassana

Filtered results
***************
RANKED	education.n 595	schooling 0.36465	training 0.32290	learning 0.30824	instruction 0.29869	tuition 0.29379	teaching 0.28546	knowledge 0.28412	college 0.28020	study 0.27523	erudition 0.26863	intellect 0.26363	educated 0.25933	place 0.23681

Test context:
***************
education.n	596	27	there is no thought in them that implies a habit of deep and refined reflection ( more than we are accustomed ordinarily to find in people of __education__ ) ; there is no knowledge that does not lie within the reach of obvious and mechanical search ; and as to the powers of language , the chief miracle is , that a source of words so apt , forcible and well-arranged , so copious and unfailing , should have been found constantly open to express their ideas without any previous preparation .
Contexts for target education are: ['prep:ofI_people']
Contexts in vocabulary for target education are: ['prep:ofI_people']
Top most similar embeddings: education 0.45179	eduction 0.38205	abarnahara 0.38021	apiapum 0.37111	madinah 0.36992	semipalatinsk 0.36768	lefke 0.36619	najran 0.36275	tillydrone 0.36226	creggan 0.35992

Generated lemmatized results
***************
GENERATED	education.n 596 ::: eduction;abarnahara;apiapum;madinah;semipalatinsk;lefke;najran;tillydrone;creggan;ashkhabad

Filtered results
***************
RANKED	education.n 596	schooling 0.34683	training 0.30937	learning 0.30275	intellect 0.30069	college 0.29568	knowledge 0.29140	teaching 0.28809	erudition 0.28752	instruction 0.28010	tuition 0.27862	study 0.27614	educated 0.27602	place 0.27337

Test context:
***************
education.n	597	17	johnson assured lavena that he would make sure she and her younger sister would receive a college __education__ , even if it meant that he had to work two jobs .
Contexts for target education are: ['det_a', 'nn_college', 'dobjI_receive']
Contexts in vocabulary for target education are: ['det_a', 'nn_college', 'dobjI_receive']
Top most similar embeddings: education 0.11555	eduction 0.09163	educations 0.08922	prospectus 0.08905	bursary 0.08824	certhe 0.08731	clerkship 0.08666	schooling 0.08619	doctorate 0.08592	lecturership 0.08591

Generated lemmatized results
***************
GENERATED	education.n 597 ::: eduction;prospectus;bursary;certhe;clerkship;schooling;doctorate;lecturership;scholarship;traineeship

Filtered results
***************
RANKED	education.n 597	schooling 0.08619	training 0.08083	tuition 0.07773	instruction 0.07671	teaching 0.07107	college 0.06883	study 0.06617	knowledge 0.06343	learning 0.06324	place 0.06075	intellect 0.05567	erudition 0.05336	educated 0.04961

Test context:
***************
education.n	598	3	it takes an __education__ ( hard work for most ) and an examination by people who have already proven themselves as skilled and trustworthy .
Contexts for target education are: ['det_an', 'dobjI_takes', 'dep_work']
Contexts in vocabulary for target education are: ['det_an', 'dobjI_takes', 'dep_work']
Top most similar embeddings: education 0.09464	apprenticeship 0.07808	internship 0.07731	assistantship 0.07581	eduction 0.07531	epistemology 0.07447	sabbatical 0.07428	educator 0.07405	hour 0.07358	ex-offender 0.07351

Generated lemmatized results
***************
GENERATED	education.n 598 ::: apprenticeship;internship;assistantship;eduction;epistemology;sabbatical;educator;hour;insite;aupair

Filtered results
***************
RANKED	education.n 598	schooling 0.07039	instruction 0.06731	place 0.06591	training 0.06407	intellect 0.06332	learning 0.06065	teaching 0.06049	knowledge 0.05927	study 0.05872	erudition 0.05730	tuition 0.05725	college 0.05146	educated 0.05020

Test context:
***************
education.n	599	10	in a time of widespread pressure for improvement in public __education__ , this is the way the teacher unions put their power to most effective use .
Contexts for target education are: ['amod_public', 'prep:inI_improvement']
Contexts in vocabulary for target education are: ['amod_public', 'prep:inI_improvement']
Top most similar embeddings: education 0.24325	eduction 0.20583	schooling 0.19085	health 0.18278	services 0.18193	servcies 0.18059	awarness 0.17976	life-chances 0.17959	decisionmaking 0.17818	educations 0.17778

Generated lemmatized results
***************
GENERATED	education.n 599 ::: eduction;schooling;health;service;servcies;awarness;decisionmaking;sector;healthcare;socialcare

Filtered results
***************
RANKED	education.n 599	schooling 0.19085	training 0.15443	knowledge 0.14944	instruction 0.14909	teaching 0.14686	learning 0.14524	college 0.14425	place 0.13869	intellect 0.13729	tuition 0.13528	study 0.13106	erudition 0.11873	educated 0.11146

Test context:
***************
education.n	600	12	a wide gap existed between europe and the united states in the __education__ of youth .
Contexts for target education are: ['det_the', 'prep:inI_existed', 'prep:of_youth']
Contexts in vocabulary for target education are: ['det_the', 'prep:inI_existed', 'prep:of_youth']
Top most similar embeddings: education 0.10047	eduction 0.08804	interstices 0.08712	after-life 0.08659	here-and-now 0.08606	1590s 0.08568	mid-fifties 0.08509	netherworld 0.08400	imagination 0.08397	gdr 0.08374

Generated lemmatized results
***************
GENERATED	education.n 600 ::: eduction;interstice;netherworld;imagination;gdr;womb;antipode;realm;lifeworld;novitiate

Filtered results
***************
RANKED	education.n 600	schooling 0.07750	teaching 0.07390	intellect 0.06936	college 0.06791	training 0.06657	instruction 0.06570	study 0.06474	knowledge 0.06356	place 0.06255	erudition 0.06123	learning 0.06075	tuition 0.05513	educated 0.05058

Test context:
***************
girl.n	601	14	martin amis : yes , there 's that line in the film where the __girl__ asks the guy what he does .
Contexts for target girl are: ['det_the', 'nsubjI_asks']
Contexts in vocabulary for target girl are: ['det_the', 'nsubjI_asks']
Top most similar embeddings: girl 0.25475	boy 0.21273	pfy 0.21225	woman 0.20807	lycosa 0.20258	stewardess 0.19921	lilim 0.19819	scammer 0.19717	gondolier 0.19615	barmaid 0.19559

Generated lemmatized results
***************
GENERATED	girl.n 601 ::: boy;pfy;woman;lycosa;stewardess;lilim;scammer;gondolier;barmaid;lad

Filtered results
***************
RANKED	girl.n 601	woman 0.20807	lass 0.18794	child 0.17151	gal 0.15734	female 0.14704	she 0.11746	miss 0.10768

Test context:
***************
girl.n	602	11	narrator : in 1957 he married margot budd , a local __girl__ who never imagined her new husband would one day be deputy prime minister .
Contexts for target girl are: ['det_a', 'amod_local', 'nsubjI_minister', 'rcmod_imagined']
Contexts in vocabulary for target girl are: ['det_a', 'amod_local', 'nsubjI_minister', 'rcmod_imagined']
Top most similar embeddings: girl 0.05535	boy 0.04818	woman 0.04738	lad 0.04594	businesswoman 0.04402	schoolgirl 0.04362	yokel 0.04357	dignitary 0.04318	woodcutter 0.04315	busybody 0.04299

Generated lemmatized results
***************
GENERATED	girl.n 602 ::: boy;woman;lad;businesswoman;schoolgirl;yokel;dignitary;woodcutter;busybody;barmaid

Filtered results
***************
RANKED	girl.n 602	woman 0.04738	lass 0.04145	child 0.03483	gal 0.03433	female 0.02898	she 0.01959	miss 0.01837

Test context:
***************
girl.n	603	4	media reports stating that __girls__ are now topping more subjects than boys and that boys are being left behind are now replicated in most australian states each january .
Contexts for target girls are: ['nsubjI_topping']
Contexts in vocabulary for target girls are: ['nsubjI_topping']
Top most similar embeddings: girls 0.46663	boys 0.41420	lads 0.37153	girlies 0.36140	ladies 0.35959	girl 0.35630	schoolgirls 0.35621	sugababes 0.35239	lasses 0.35130	kelis 0.34889

Generated lemmatized results
***************
GENERATED	girl.n 603 ::: boy;lad;girlies;lady;schoolgirl;sugababes;lass;kelis;doughboy;kid

Filtered results
***************
RANKED	girl.n 603	lass 0.35130	gal 0.34060	female 0.32710	woman 0.32027	child 0.31505	she 0.28510	miss 0.25966

Test context:
***************
girl.n	604	7	he responded , ' good god , __girl__ , ca n't you understand english !
Contexts for target girl are: ['apposI_god']
Contexts in vocabulary for target girl are: ['apposI_god']
Top most similar embeddings: girl 0.45657	boy 0.41699	bartimaeus 0.39247	woman 0.38790	lad 0.37974	elymas 0.37892	ninurta 0.37504	wench 0.37335	hephaestus 0.37330	missis 0.37307

Generated lemmatized results
***************
GENERATED	girl.n 604 ::: boy;bartimaeus;woman;lad;elymas;ninurta;wench;hephaestus;missis;gal

Filtered results
***************
RANKED	girl.n 604	woman 0.38790	gal 0.37281	lass 0.36681	child 0.31614	female 0.29737	she 0.26523	miss 0.25791

Test context:
***************
girl.n	605	9	but one day the little spider died and the __girl__ was very , very sad .
Contexts for target girl are: ['det_the', 'nsubjI_sad']
Contexts in vocabulary for target girl are: ['det_the', 'nsubjI_sad']
Top most similar embeddings: girl 0.24217	boy 0.20540	gopis 0.19463	woman 0.19245	girls 0.19094	signora 0.18849	lioness 0.18734	lad 0.18699	mother-to-be 0.18569	giantess 0.18558

Generated lemmatized results
***************
GENERATED	girl.n 605 ::: boy;gopis;woman;signora;lioness;lad;giantess;lycosa;deil;blighter

Filtered results
***************
RANKED	girl.n 605	woman 0.19245	lass 0.18035	child 0.16644	gal 0.15651	female 0.14286	she 0.11327	miss 0.11152

Test context:
***************
girl.n	606	8	she was said to have been an attractive __girl__ .
Contexts for target girl are: ['aux_to', 'aux_have', 'cop_been', 'det_an', 'amod_attractive', 'xcompI_said']
Contexts in vocabulary for target girl are: ['aux_to', 'aux_have', 'cop_been', 'det_an', 'amod_attractive', 'xcompI_said']
Top most similar embeddings: churchgoer 0.01007	abductee 0.01004	girl 0.00995	prostitute 0.00992	horsewoman 0.00990	gentlewoman 0.00985	anorexic 0.00969	lady-in-waiting 0.00968	also-ran 0.00967	coeval 0.00963

Generated lemmatized results
***************
GENERATED	girl.n 606 ::: churchgoer;abductee;prostitute;horsewoman;gentlewoman;anorexic;coeval;attender;admirer;playmate

Filtered results
***************
RANKED	girl.n 606	woman 0.00871	lass 0.00789	female 0.00708	gal 0.00615	child 0.00568	miss 0.00441	she 0.00219

Test context:
***************
girl.n	607	4	if you were a __girl__ what do you think you would like to do when you grew up ?
Contexts for target girl are: ['mark_if', 'nsubj_you', 'cop_were', 'det_a', 'rootI_*root*', 'rcmod_think', 'punct_?', 'dep_<eol>']
Contexts in vocabulary for target girl are: ['mark_if', 'nsubj_you', 'cop_were', 'det_a', 'rootI_*root*', 'rcmod_think', 'punct_?']
Top most similar embeddings: masochist 0.00611	shopworker 0.00572	dolt 0.00557	prude 0.00548	backslider 0.00547	noob 0.00546	chocoholic 0.00542	dickhead 0.00541	plonker 0.00540	girl 0.00538

Generated lemmatized results
***************
GENERATED	girl.n 607 ::: masochist;shopworker;dolt;prude;backslider;noob;chocoholic;dickhead;plonker;cheapskate

Filtered results
***************
RANKED	girl.n 607	woman 0.00427	lass 0.00420	gal 0.00377	female 0.00347	child 0.00303	miss 0.00299	she 0.00074

Test context:
***************
girl.n	608	16	the two kittens above are 5 months old , a boy ( left ) and a __girl__ .
Contexts for target girl are: ['det_a', 'conjI_old']
Contexts in vocabulary for target girl are: ['det_a', 'conjI_old']
Top most similar embeddings: girl 0.25505	boy 0.22349	woman 0.20343	stripling 0.20146	brunette 0.19606	schoolgirl 0.19472	lad 0.19405	teenager 0.19281	haemophiliac 0.19270	divorcee 0.19224

Generated lemmatized results
***************
GENERATED	girl.n 608 ::: boy;woman;stripling;brunette;schoolgirl;lad;teenager;haemophiliac;divorcee;choirboy

Filtered results
***************
RANKED	girl.n 608	woman 0.20343	lass 0.18299	gal 0.16626	female 0.16597	child 0.16467	miss 0.12771	she 0.10179

Test context:
***************
girl.n	609	8	in discussing world war ii , the three __girls__ try to use what they have learned at school about world war i. their knowledge points in two dif- ferent directions .
Contexts for target girls are: ['det_the', 'num_three', 'nsubjI_try']
Contexts in vocabulary for target girls are: ['det_the', 'num_three', 'nsubjI_try']
Top most similar embeddings: girls 0.12692	boys 0.11332	dwarfers 0.10053	lads 0.09933	julies 0.09777	ladies 0.09748	kids 0.09697	schoolgirls 0.09623	girlies 0.09591	kenyans 0.09556

Generated lemmatized results
***************
GENERATED	girl.n 609 ::: boy;dwarfers;lad;july;lady;kid;schoolgirl;girlies;kenyan;kitty

Filtered results
***************
RANKED	girl.n 609	lass 0.09289	gal 0.08843	woman 0.08696	female 0.08645	child 0.08642	miss 0.05093	she 0.04174

Test context:
***************
girl.n	610	40	by the early ' 70s in victoria , the role of church welfare agencies , such as the mission of st james and st john , the mission to streets and lanes and st john 's homes for boys and __girls__ , began to review their role and purpose in both church and community .
Contexts for target girls are: ['conjI_boys']
Contexts in vocabulary for target girls are: ['conjI_boys']
Top most similar embeddings: girls 0.59218	boys 0.49973	girl 0.41212	ladies 0.41190	schoolgirls 0.40577	lads 0.39360	oiks 0.38563	men 0.38512	lasses 0.38500	babes 0.38446

Generated lemmatized results
***************
GENERATED	girl.n 610 ::: boy;lady;schoolgirl;lad;oiks;men;lass;babe;teenager;gran

Filtered results
***************
RANKED	girl.n 610	lass 0.38500	gal 0.38102	woman 0.36614	female 0.35384	child 0.33024	she 0.25835	miss 0.25578

Test context:
***************
good.a	611	5	indeed , he had a __good__ forty years left in him .
Contexts for target good are: ['amodI_years']
Contexts in vocabulary for target good are: ['amodI_years']
Top most similar embeddings: good 0.48264	ten-to-fifteen 0.42478	20-odd 0.40349	30-plus 0.40233	40-odd 0.39371	30-odd 0.39024	not-so-good 0.38494	intercalary 0.38383	record-setting 0.38302	goal-den 0.38248

Generated lemmatized results
***************
GENERATED	good.a 611 ::: intercalary;troublous;wondeful;seaven;plenteous;bad;excellent;excellant;wonderful;regnal

Filtered results
***************
RANKED	good.a 611	excellent 0.36112	decent 0.34488	pleasant 0.33531	enjoyable 0.33404	healthy 0.32667	respectable 0.32657	happy 0.32475	satisfactory 0.32374	reasonable 0.32282	commendable 0.32170	nice 0.32096	full 0.31041	amiable 0.30584	favourable 0.30168	significant 0.30136	effective 0.29918	substantial 0.29756	considerable 0.29493	easy 0.29450	beneficial 0.29115	comfortable 0.29084	minimum 0.29055	thorough 0.28742	large 0.28517	competent 0.28482	fun 0.27815	happiness 0.27452	standing 0.27318	friendliness 0.25239	esteem 0.24814	reputation 0.24556	cordiality 0.23270	character 0.21953

Test context:
***************
good.a	612	4	eventually , calm and __good__ humour was restored , and lt. e. dixon-child became the first pilot to land an aircraft on wide-awake airfield .
Contexts for target good are: ['conjI_calm']
Contexts in vocabulary for target good are: ['conjI_calm']
Top most similar embeddings: good 0.47079	calm 0.40218	clear-headed 0.38257	good-tempered 0.38018	well-mannered 0.37792	good-humoured 0.37692	businesslike 0.37501	imperturbable 0.37249	self-possessed 0.37236	clear-eyed 0.37110

Generated lemmatized results
***************
GENERATED	good.a 612 ::: calm;businesslike;imperturbable;soldierly;companionable;ladylike;crotchety;equable;unemotional;artless

Filtered results
***************
RANKED	good.a 612	pleasant 0.36389	decent 0.36292	reasonable 0.35641	amiable 0.34960	excellent 0.34867	respectable 0.34682	nice 0.34558	healthy 0.34112	commendable 0.33846	comfortable 0.33545	satisfactory 0.33375	happy 0.33224	enjoyable 0.33057	thorough 0.32270	happiness 0.32101	competent 0.31887	effective 0.31726	easy 0.31192	friendliness 0.30122	favourable 0.30037	beneficial 0.29932	fun 0.29904	full 0.29874	cordiality 0.29643	substantial 0.29264	large 0.28381	significant 0.27452	considerable 0.27185	esteem 0.26408	standing 0.25945	minimum 0.25348	character 0.25340	reputation 0.24831

Test context:
***************
good.a	613	10	in fact , my european counterparts and i spend a __good__ part of every day talking to one other , staying in touch , in constant touch , and there is no european leader that i spend more time talking to , and whose advice i value more highly than that of javier .
Contexts for target good are: ['amodI_part']
Contexts in vocabulary for target good are: ['amodI_part']
Top most similar embeddings: good 0.49016	not-so-good 0.39374	long-neglected 0.39273	southern-most 0.38261	wondeful 0.38037	fine-looking 0.38015	certian 0.37947	god-awful 0.37769	close-run 0.37634	geat 0.37359

Generated lemmatized results
***************
GENERATED	good.a 613 ::: wondeful;certian;geat;resonable;bad;godforsaken;signficant;geniune;great;pleasant

Filtered results
***************
RANKED	good.a 613	pleasant 0.36840	excellent 0.36545	decent 0.35541	significant 0.35224	large 0.35169	substantial 0.34736	enjoyable 0.34640	nice 0.34536	respectable 0.33864	satisfactory 0.33635	reasonable 0.33553	commendable 0.33448	considerable 0.33144	healthy 0.32869	effective 0.32407	easy 0.32350	full 0.32270	happy 0.31700	beneficial 0.31538	amiable 0.30870	comfortable 0.30681	fun 0.30504	competent 0.30433	favourable 0.29954	thorough 0.29607	standing 0.27780	minimum 0.27394	friendliness 0.26608	happiness 0.26006	esteem 0.25215	character 0.23901	cordiality 0.23553	reputation 0.22932

Test context:
***************
good.a	614	1	a __good__ way to see who collects what is to look at exhibition wall labels and see who owns the loaned work that fits with yours best .
Contexts for target good are: ['amodI_way']
Contexts in vocabulary for target good are: ['amodI_way']
Top most similar embeddings: good 0.51883	half-assed 0.41008	rough-and-ready 0.40839	excellent 0.40817	resonable 0.40715	wondeful 0.40490	not-so-good 0.40305	non-adversarial 0.40075	time-efficient 0.39902	certian 0.39705

Generated lemmatized results
***************
GENERATED	good.a 614 ::: excellent;resonable;wondeful;certian;fantasic;excellant;sound;bad;cretinous;godawful

Filtered results
***************
RANKED	good.a 614	excellent 0.40817	pleasant 0.37732	decent 0.37357	nice 0.36070	satisfactory 0.35927	effective 0.35833	enjoyable 0.35255	reasonable 0.35170	easy 0.34987	commendable 0.34202	healthy 0.34029	respectable 0.33888	amiable 0.33289	beneficial 0.33184	significant 0.32806	thorough 0.32656	comfortable 0.32286	fun 0.32197	substantial 0.32052	favourable 0.31927	considerable 0.31670	happy 0.31483	competent 0.31208	large 0.30696	full 0.30644	minimum 0.26998	standing 0.26834	friendliness 0.26265	happiness 0.26048	esteem 0.24334	cordiality 0.23724	character 0.22760	reputation 0.22702

Test context:
***************
good.a	615	3	we have a __good__ time making coloured tissue paper tear-outs to be in front of candles , but we get very sticky gluing the tissue paper to black card .
Contexts for target good are: ['amodI_time']
Contexts in vocabulary for target good are: ['amodI_time']
Top most similar embeddings: good 0.52138	double-quick 0.41941	resonable 0.40763	wondeful 0.40306	troublous 0.39935	certian 0.39092	fantasic 0.39058	ever-decreasing 0.38940	tenseless 0.38805	not-so-good 0.38773

Generated lemmatized results
***************
GENERATED	good.a 615 ::: resonable;wondeful;troublous;certian;fantasic;tenseless;sufficent;excellent;bad;agreat

Filtered results
***************
RANKED	good.a 615	excellent 0.38599	decent 0.36987	reasonable 0.36771	pleasant 0.35556	nice 0.35414	respectable 0.34874	enjoyable 0.34846	considerable 0.33910	commendable 0.33781	full 0.33447	significant 0.32822	satisfactory 0.32790	substantial 0.32371	happy 0.32200	easy 0.32073	effective 0.31879	favourable 0.31519	healthy 0.31489	comfortable 0.31105	beneficial 0.30699	amiable 0.30677	thorough 0.30474	fun 0.30469	large 0.30172	competent 0.29804	minimum 0.29304	happiness 0.27750	standing 0.27685	friendliness 0.24638	esteem 0.24293	reputation 0.23999	cordiality 0.23587	character 0.22458

Test context:
***************
good.a	616	4	norah had been a __good__ , docile baby and then she became a good, obedient little girl .
Contexts for target good are: ['amodI_baby']
Contexts in vocabulary for target good are: ['amodI_baby']
Top most similar embeddings: good 0.46876	six-month-old 0.40140	longed-for 0.39208	fine-looking 0.38543	drop-dead 0.38537	wondeful 0.38305	not-so-good 0.38278	nice-looking 0.38016	pre-verbal 0.37968	purr-fect 0.37940

Generated lemmatized results
***************
GENERATED	good.a 616 ::: wondeful;best;fantasic;geat;goddamned;fiesty;sucky;bad;cute;rambunctious

Filtered results
***************
RANKED	good.a 616	excellent 0.36118	healthy 0.35829	decent 0.34898	nice 0.34274	pleasant 0.33587	happy 0.33337	large 0.32685	reasonable 0.32262	respectable 0.32027	amiable 0.31733	comfortable 0.31668	satisfactory 0.31440	easy 0.31296	commendable 0.31114	full 0.30243	enjoyable 0.30214	competent 0.29538	significant 0.29332	effective 0.29328	substantial 0.29063	beneficial 0.28994	favourable 0.28482	considerable 0.28362	fun 0.28208	thorough 0.28168	standing 0.28073	happiness 0.26909	minimum 0.26679	friendliness 0.25053	esteem 0.24419	reputation 0.24163	character 0.23556	cordiality 0.23322

Test context:
***************
good.a	617	3	we have seen __good__ growth in revenue in the year , largely as a result of more complex procedures being undertaken in our hospitals .
Contexts for target good are: ['amodI_growth']
Contexts in vocabulary for target good are: ['amodI_growth']
Top most similar embeddings: good 0.49370	export-led 0.41597	below-average 0.41288	sub-par 0.39321	top-line 0.39093	single-digit 0.38777	double-digit 0.38592	economy-wide 0.38551	excellent 0.38294	pubertal 0.38272

Generated lemmatized results
***************
GENERATED	good.a 617 ::: excellent;pubertal;phenominal;strong;geniune;ohmic;tremendous;vigourous;lowish;resonable

Filtered results
***************
RANKED	good.a 617	excellent 0.38294	decent 0.36423	healthy 0.35481	significant 0.34841	satisfactory 0.34222	substantial 0.34204	considerable 0.33485	reasonable 0.33476	respectable 0.33375	nice 0.32682	commendable 0.32620	pleasant 0.32466	large 0.31956	effective 0.31635	favourable 0.31560	beneficial 0.31471	full 0.30455	thorough 0.29984	easy 0.29960	comfortable 0.29893	amiable 0.29628	enjoyable 0.29449	happy 0.29217	competent 0.28777	minimum 0.27702	standing 0.27652	happiness 0.26624	fun 0.26366	reputation 0.25621	friendliness 0.25000	character 0.24825	esteem 0.24448	cordiality 0.23411

Test context:
***************
good.a	618	3	it 's a __good__ examining into the evil dead mythos and gives us an insight into the people on and off screen .
Contexts for target good are: ['amodI_examining']
Contexts in vocabulary for target good are: ['amodI_examining']
Top most similar embeddings: good 0.41080	half-decent 0.34787	decent 0.34509	highly-successful 0.34500	not-so-good 0.34257	external 0.34223	much-improved 0.33960	high-scoring 0.33914	top-class 0.33906	reserve-team 0.33901

Generated lemmatized results
***************
GENERATED	good.a 618 ::: decent;external;brutal;yearlong;excellent;unaccredited;rigourous;unpublicised;desultory;bad

Filtered results
***************
RANKED	good.a 618	decent 0.34509	excellent 0.33408	thorough 0.31780	pleasant 0.30479	amiable 0.30476	substantial 0.30406	significant 0.29993	respectable 0.29948	enjoyable 0.29931	satisfactory 0.29924	commendable 0.29864	nice 0.29587	effective 0.29564	large 0.29418	reasonable 0.29395	considerable 0.29284	favourable 0.28931	competent 0.28652	full 0.28567	healthy 0.28340	happy 0.27353	beneficial 0.27339	comfortable 0.26785	easy 0.25898	minimum 0.25726	standing 0.25437	fun 0.25402	friendliness 0.24194	happiness 0.23258	cordiality 0.22534	reputation 0.22329	esteem 0.22097	character 0.20464

Test context:
***************
good.a	619	4	good jobs begin with __good__ schools , and here we 've made a fine start .
Contexts for target good are: ['amodI_schools']
Contexts in vocabulary for target good are: ['amodI_schools']
Top most similar embeddings: good 0.50015	state-sector 0.42904	research-engaged 0.42572	lea-maintained 0.42079	top-performing 0.40174	non-faith 0.39823	low-achieving 0.39716	primary-school 0.39087	mono-cultural 0.39084	not-so-good 0.39039

Generated lemmatized results
***************
GENERATED	good.a 619 ::: excellent;decent;bad;certian;postsecondary;mediocre;wondeful;unaccredited;japenese;lousy

Filtered results
***************
RANKED	good.a 619	excellent 0.38827	decent 0.37413	healthy 0.34839	respectable 0.34718	effective 0.33403	satisfactory 0.33384	pleasant 0.33165	commendable 0.33021	large 0.32642	nice 0.32537	reasonable 0.32194	enjoyable 0.31188	substantial 0.30683	happy 0.30192	full 0.30013	significant 0.29747	beneficial 0.29664	comfortable 0.29371	competent 0.29259	favourable 0.29109	amiable 0.28938	thorough 0.28850	considerable 0.28689	easy 0.28680	fun 0.27008	minimum 0.26467	standing 0.26237	friendliness 0.24780	happiness 0.24690	reputation 0.23915	esteem 0.23807	cordiality 0.22302	character 0.22029

Test context:
***************
good.a	620	35	but her brother 's foolish and expensive antics are getting completely out of hand , and would , probably , not only land them both in the poor house , but also destroy her own __good__ name as well .
Contexts for target good are: ['amodI_name']
Contexts in vocabulary for target good are: ['amodI_name']
Top most similar embeddings: good 0.50914	bad 0.40183	half-decent 0.39473	double-barrelled 0.39411	godawful 0.39336	wondeful 0.39113	certian 0.38982	now-familiar 0.38798	high-sounding 0.38731	tiptop 0.38687

Generated lemmatized results
***************
GENERATED	good.a 620 ::: bad;godawful;wondeful;certian;tiptop;definative;fantasic;latinized;excellant;excellent

Filtered results
***************
RANKED	good.a 620	excellent 0.37490	decent 0.36590	nice 0.35353	respectable 0.33869	full 0.33848	pleasant 0.33326	reasonable 0.32942	satisfactory 0.32684	amiable 0.32469	commendable 0.32309	significant 0.31787	effective 0.31683	large 0.31053	healthy 0.30852	favourable 0.30600	substantial 0.30525	enjoyable 0.30386	beneficial 0.30036	considerable 0.30000	competent 0.29947	easy 0.29896	comfortable 0.29667	happy 0.29594	thorough 0.29460	fun 0.28839	standing 0.27612	happiness 0.27089	minimum 0.27047	friendliness 0.25691	cordiality 0.23738	reputation 0.23320	esteem 0.22998	character 0.22846

Test context:
***************
hard.r	621	3	if you look __hard__ you might just catch him smile .
Contexts for target hard are: ['advmodI_look']
Contexts in vocabulary for target hard are: ['advmodI_look']
Top most similar embeddings: hard 0.49850	harder 0.39946	ineffectually 0.37277	proably 0.37237	actaully 0.37230	unconventionally 0.37057	defintely 0.36545	industriously 0.36401	eventualy 0.36240	proberly 0.36147

Generated lemmatized results
***************
GENERATED	hard.r 621 ::: ineffectually;proably;actaully;unconventionally;defintely;industriously;eventualy;proberly;personnally;acutally

Filtered results
***************
RANKED	hard.r 621	intently 0.35087	closely 0.34190	earnestly 0.33797	strenuously 0.33100	diligently 0.32859	carefully 0.32563	determinedly 0.32480	keenly 0.32064	seriously 0.31860	fiercely 0.31841	intensively 0.31815	intensely 0.30970	harshly 0.30634	badly 0.30222	firmly 0.30197	persistently 0.30049	forcefully 0.29956	tightly 0.29861	heavily 0.29572	strongly 0.29509	severely 0.29301	violently 0.28728	sufficiently 0.28255	aggressive 0.27587

Test context:
***************
hard.r	622	37	if i write a book that becomes popular , i want to get as much out of it as i can , and i figure that i can best do that by accepting no advance and pushing __hard__ on royalty rates .
Contexts for target hard are: ['advmodI_pushing']
Contexts in vocabulary for target hard are: ['advmodI_pushing']
Top most similar embeddings: hard 0.53987	harder 0.43326	ineffectually 0.39020	hardest 0.38247	ceaselessly 0.37223	feverishly 0.37161	gamely 0.37089	industriously 0.36771	frantically 0.36744	aggressively 0.36731

Generated lemmatized results
***************
GENERATED	hard.r 622 ::: ineffectually;ceaselessly;feverishly;gamely;industriously;frantically;aggressively;strenuously;dexterously;tenaciously

Filtered results
***************
RANKED	hard.r 622	strenuously 0.36512	determinedly 0.34222	fiercely 0.33534	diligently 0.32962	forcefully 0.32676	earnestly 0.32514	firmly 0.32373	intently 0.32063	violently 0.31766	strongly 0.31565	heavily 0.31524	persistently 0.31384	intensely 0.31082	tightly 0.30894	keenly 0.30562	harshly 0.30531	severely 0.30529	seriously 0.30510	closely 0.30402	intensively 0.30293	badly 0.30273	carefully 0.30073	sufficiently 0.27914	aggressive 0.27052

Test context:
***************
hard.r	623	4	although jacob had worked __hard__ and faithfully for his father-in-law , he continually defrauded him .
Contexts for target hard are: ['advmodI_worked']
Contexts in vocabulary for target hard are: ['advmodI_worked']
Top most similar embeddings: hard 0.55345	harder 0.42128	industriously 0.39194	hardest 0.38553	feverishly 0.38383	tirelessly 0.37751	eventualy 0.37251	ineffectually 0.37245	unceasingly 0.37232	assiduously 0.37208

Generated lemmatized results
***************
GENERATED	hard.r 623 ::: industriously;feverishly;tirelessly;eventualy;ineffectually;unceasingly;assiduously;valiantly;actaully;unconventionally

Filtered results
***************
RANKED	hard.r 623	diligently 0.35894	strenuously 0.35783	closely 0.34768	intensively 0.34714	determinedly 0.33264	intently 0.33007	intensely 0.32519	earnestly 0.32453	carefully 0.31503	heavily 0.31435	fiercely 0.31132	badly 0.30860	keenly 0.30812	tightly 0.30691	persistently 0.30602	forcefully 0.29865	strongly 0.29707	violently 0.29672	harshly 0.29656	firmly 0.29641	seriously 0.29571	severely 0.29068	sufficiently 0.28289	aggressive 0.25325

Test context:
***************
hard.r	624	17	it 's printed matter , i bet you&gt; could get sued for duplicating it if you tried __hard__ enough .
Contexts for target hard are: ['advmodI_enough']
Contexts in vocabulary for target hard are: ['advmodI_enough']
Top most similar embeddings: hard 0.52745	harder 0.37330	ineffectually 0.36989	good-naturedly 0.36663	easilly 0.36393	difficult 0.36300	dexterously 0.36261	tough 0.35940	shallowly 0.35561	nastily 0.35511

Generated lemmatized results
***************
GENERATED	hard.r 624 ::: ineffectually;easilly;difficult;dexterously;tough;shallowly;nastily;cannily;unrelentingly;unconventionally

Filtered results
***************
RANKED	hard.r 624	diligently 0.33448	intently 0.33039	strenuously 0.33015	closely 0.32539	fiercely 0.32391	seriously 0.32288	badly 0.32192	intensively 0.32120	earnestly 0.32097	forcefully 0.32076	strongly 0.31915	tightly 0.31664	firmly 0.31485	intensely 0.31306	violently 0.31303	heavily 0.31010	severely 0.30747	keenly 0.30692	harshly 0.30670	determinedly 0.30651	carefully 0.30637	persistently 0.30519	sufficiently 0.29666	aggressive 0.28211

Test context:
***************
hard.r	625	21	it 's a lot of fun as you are carrying on two conversations at once and you are required to listen __hard__ .
Contexts for target hard are: ['advmodI_listen']
Contexts in vocabulary for target hard are: ['advmodI_listen']
Top most similar embeddings: hard 0.50189	harder 0.39604	actaully 0.36994	ineffectually 0.36886	hardest 0.36334	unceasingly 0.36295	attentively 0.36196	defintely 0.36045	proably 0.36018	personnally 0.35883

Generated lemmatized results
***************
GENERATED	hard.r 625 ::: actaully;ineffectually;unceasingly;attentively;defintely;proably;personnally;intently;proberly;regularily

Filtered results
***************
RANKED	hard.r 625	intently 0.35691	diligently 0.33834	carefully 0.33632	intensively 0.33469	closely 0.33469	strenuously 0.32965	keenly 0.32803	earnestly 0.32771	determinedly 0.32257	intensely 0.32109	fiercely 0.31786	seriously 0.31676	persistently 0.31374	heavily 0.29967	badly 0.29965	harshly 0.29957	forcefully 0.29689	tightly 0.29626	firmly 0.29483	strongly 0.28941	severely 0.28802	violently 0.28575	sufficiently 0.27859	aggressive 0.26765

Test context:
***************
hard.r	626	7	one event in particular hits the platoon __hard__ : the death of its platoon leader , 2lt ben colgan .
Contexts for target hard are: ['advmodI_platoon']
Contexts in vocabulary for target hard are: []
Top most similar embeddings: hard 1.00000	harder 0.80858	difficult 0.79622	backbreaking 0.75002	hardest 0.74102	tough 0.74049	back-breaking 0.73233	dificult 0.72342	wide-brimmed 0.72321	troublous 0.72174

Generated lemmatized results
***************
GENERATED	hard.r 626 ::: difficult;backbreaking;tough;dificult;troublous;easy;ineffectually;impossible;swingy;stressfull

Filtered results
***************
RANKED	hard.r 626	strenuously 0.67449	intently 0.65117	diligently 0.64805	earnestly 0.64513	fiercely 0.64050	determinedly 0.63717	closely 0.63514	intensively 0.63213	intensely 0.62489	heavily 0.62344	aggressive 0.62117	keenly 0.62114	firmly 0.62101	violently 0.61708	tightly 0.61640	harshly 0.61551	persistently 0.61535	strongly 0.61297	badly 0.61281	severely 0.61156	seriously 0.61149	forcefully 0.61118	carefully 0.60491	sufficiently 0.58467

Test context:
***************
hard.r	627	24	chase manhattan bank chairman david rockefeller , founder of the development association , and his brother , new york governor nelson rockefeller , pushed __hard__ for the project , insisting it would benefit the entire city .
Contexts for target hard are: ['advmodI_pushed']
Contexts in vocabulary for target hard are: ['advmodI_pushed']
Top most similar embeddings: hard 0.53590	harder 0.42576	ineffectually 0.38988	hardest 0.38055	gamely 0.37410	feverishly 0.37240	industriously 0.37218	acrobatically 0.36887	eventualy 0.36858	manfully 0.36846

Generated lemmatized results
***************
GENERATED	hard.r 627 ::: ineffectually;gamely;feverishly;industriously;acrobatically;eventualy;manfully;dexterously;aggressively;convulsively

Filtered results
***************
RANKED	hard.r 627	strenuously 0.36017	determinedly 0.34716	fiercely 0.33846	diligently 0.33094	forcefully 0.32800	firmly 0.32764	violently 0.32715	intently 0.32559	persistently 0.32441	heavily 0.32382	earnestly 0.32276	strongly 0.31765	tightly 0.31657	harshly 0.31611	keenly 0.31542	closely 0.31513	intensely 0.30964	badly 0.30773	carefully 0.30699	severely 0.30593	intensively 0.30391	seriously 0.30312	sufficiently 0.28855	aggressive 0.26870

Test context:
***************
hard.r	628	6	she has told friends she thought __hard__ about going to the police , aware that her story might not be believed , but she decided to do so because she thought her status as a french citizen with close links to the consulate 's business section would carry some weight .
Contexts for target hard are: ['advmodI_thought']
Contexts in vocabulary for target hard are: ['advmodI_thought']
Top most similar embeddings: hard 0.48661	harder 0.38689	actaully 0.37767	proably 0.37670	ineffectually 0.36778	proberly 0.36673	personnally 0.36519	alledgedly 0.36405	unconventionally 0.36183	inexcusably 0.36105

Generated lemmatized results
***************
GENERATED	hard.r 628 ::: actaully;proably;ineffectually;proberly;personnally;alledgedly;unconventionally;inexcusably;misguidedly;industriously

Filtered results
***************
RANKED	hard.r 628	strenuously 0.33622	earnestly 0.33259	diligently 0.32587	carefully 0.32209	fiercely 0.32182	intently 0.32166	keenly 0.32112	seriously 0.32108	badly 0.31942	determinedly 0.31811	intensely 0.31683	intensively 0.31631	closely 0.30852	persistently 0.30421	strongly 0.30118	firmly 0.30082	heavily 0.29990	forcefully 0.29880	harshly 0.29879	tightly 0.29725	severely 0.29674	violently 0.29571	sufficiently 0.29066	aggressive 0.27006

Test context:
***************
hard.r	629	11	he was so pleased , he was squeezing my hand very __hard__ because it had such a " ceremonial " feel to it .
Contexts for target hard are: ['advmod_very', 'advmodI_hand']
Contexts in vocabulary for target hard are: ['advmod_very', 'advmodI_hand']
Top most similar embeddings: hard 0.24440	dexterously 0.20515	ineffectually 0.20174	cannily 0.19474	easilly 0.19012	shabbily 0.18994	industriously 0.18829	good-naturedly 0.18697	nastily 0.18575	tenaciously 0.18560

Generated lemmatized results
***************
GENERATED	hard.r 629 ::: dexterously;ineffectually;cannily;easilly;shabbily;industriously;nastily;tenaciously;sloppily;shallowly

Filtered results
***************
RANKED	hard.r 629	determinedly 0.17581	strenuously 0.17342	tightly 0.16942	intently 0.16890	earnestly 0.16886	carefully 0.16828	diligently 0.16635	firmly 0.16444	closely 0.16356	fiercely 0.16230	keenly 0.16057	intensely 0.15992	heavily 0.15951	harshly 0.15894	intensively 0.15891	forcefully 0.15881	badly 0.15442	violently 0.15360	strongly 0.15300	seriously 0.15298	severely 0.15283	persistently 0.15196	aggressive 0.13594	sufficiently 0.13205

Test context:
***************
hard.r	630	10	they cornered me on the playing field and kicked me __hard__ enough to draw blood .
Contexts for target hard are: ['advmodI_enough']
Contexts in vocabulary for target hard are: ['advmodI_enough']
Top most similar embeddings: hard 0.52745	harder 0.37330	ineffectually 0.36989	good-naturedly 0.36663	easilly 0.36393	difficult 0.36300	dexterously 0.36261	tough 0.35940	shallowly 0.35561	nastily 0.35511

Generated lemmatized results
***************
GENERATED	hard.r 630 ::: ineffectually;easilly;difficult;dexterously;tough;shallowly;nastily;cannily;unrelentingly;unconventionally

Filtered results
***************
RANKED	hard.r 630	diligently 0.33448	intently 0.33039	strenuously 0.33015	closely 0.32539	fiercely 0.32391	seriously 0.32288	badly 0.32192	intensively 0.32120	earnestly 0.32097	forcefully 0.32076	strongly 0.31915	tightly 0.31664	firmly 0.31485	intensely 0.31306	violently 0.31303	heavily 0.31010	severely 0.30747	keenly 0.30692	harshly 0.30670	determinedly 0.30651	carefully 0.30637	persistently 0.30519	sufficiently 0.29666	aggressive 0.28211

Test context:
***************
heavy.a	631	3	the engines were __heavy__ , immovable , and needed a big , continuous supply of water to boil .
Contexts for target heavy are: ['nsubj_engines', 'cop_were', 'rootI_*root*', 'punct_,', 'conj_immovable', 'punct_,', 'cc_and', 'conj_needed', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target heavy are: ['nsubj_engines', 'cop_were', 'rootI_*root*', 'punct_,', 'conj_immovable', 'punct_,', 'cc_and', 'conj_needed', 'punct_.']
Top most similar embeddings: unbolted 0.00146	unpaved 0.00146	over-engineered 0.00145	heavy 0.00142	sparser 0.00141	indestructable 0.00135	heavier 0.00135	unperturbed 0.00133	odorless 0.00132	underpowered 0.00132

Generated lemmatized results
***************
GENERATED	heavy.a 631 ::: unbolted;unpaved;sparse;indestructable;unperturbed;odorless;underpowered;fixable;bombproof;unfastened

Filtered results
***************
RANKED	heavy.a 631	costly 0.00119	tough 0.00111	weighty 0.00107	harsh 0.00104	onerous 0.00103	laboured 0.00101	tedious 0.00101	strong 0.00098	big 0.00096	fat 0.00096	abundant 0.00094	hard 0.00092	difficult 0.00092	stout 0.00091	profuse 0.00091	dark 0.00090	overweight 0.00089	frequent 0.00083	severe 0.00082	strongest 0.00078	constant 0.00076	serious 0.00076	excessive 0.00075	wild 0.00071	massive 0.00065	extensive 0.00061	substantial 0.00061	worst 0.00058	considerable 0.00056	ample 0.00056	regular 0.00046

Test context:
***************
heavy.a	632	1	some __heavy__ users develop a psychological dependence on cannabis .
Contexts for target heavy are: ['amodI_users']
Contexts in vocabulary for target heavy are: ['amodI_users']
Top most similar embeddings: heavy 0.53118	heavier 0.42437	heaviest 0.39916	non-windows 0.38472	non-computer 0.38169	non-unix 0.37774	heavy-duty 0.37695	high-mileage 0.37562	budget-conscious 0.37323	non-regular 0.37270

Generated lemmatized results
***************
GENERATED	heavy.a 632 ::: inexpert;hefty;infrequent;mucronate;nonessential;bulky;light;voracious;unseasoned;motorised

Filtered results
***************
RANKED	heavy.a 632	regular 0.34803	excessive 0.33493	weighty 0.33450	big 0.33021	severe 0.32937	massive 0.32928	frequent 0.32890	costly 0.32567	serious 0.32358	overweight 0.31624	harsh 0.31229	extensive 0.31014	substantial 0.30894	tedious 0.30860	profuse 0.30806	tough 0.30744	strong 0.30693	hard 0.30520	onerous 0.30244	fat 0.30144	dark 0.29193	stout 0.29162	difficult 0.28916	considerable 0.28639	strongest 0.28142	worst 0.28130	abundant 0.27918	constant 0.27895	ample 0.27323	wild 0.26959	laboured 0.25484

Test context:
***************
heavy.a	633	5	offences against the act carry __heavy__ penalties , and may also invalidate professional indemnity insurance .
Contexts for target heavy are: ['amodI_penalties']
Contexts in vocabulary for target heavy are: ['amodI_penalties']
Top most similar embeddings: heavy 0.53705	heavier 0.42738	hefty 0.41350	heaviest 0.39601	stiff 0.38585	government-imposed 0.38392	stiffer 0.37537	severe 0.37384	severer 0.37078	punitive 0.36461

Generated lemmatized results
***************
GENERATED	heavy.a 633 ::: hefty;stiff;severe;punitive;harsh;outsized;weighty;horrendous;swingeing;light

Filtered results
***************
RANKED	heavy.a 633	severe 0.37384	harsh 0.36437	weighty 0.36331	onerous 0.35301	massive 0.35167	substantial 0.35090	excessive 0.34977	tough 0.34951	costly 0.34204	serious 0.33402	strong 0.33262	big 0.32993	profuse 0.32554	considerable 0.32346	tedious 0.31070	frequent 0.30897	strongest 0.30875	regular 0.30559	hard 0.30482	stout 0.30202	overweight 0.30113	extensive 0.30054	dark 0.29885	fat 0.29567	worst 0.29566	ample 0.29354	difficult 0.29000	abundant 0.28415	constant 0.27652	wild 0.27422	laboured 0.27258

Test context:
***************
heavy.a	634	7	i was very happy to see the __heavy__ burden of social welfare costs to our municipalities reduced .
Contexts for target heavy are: ['amodI_burden']
Contexts in vocabulary for target heavy are: ['amodI_burden']
Top most similar embeddings: heavy 0.54701	heavier 0.43899	heaviest 0.41453	hefty 0.40970	government-imposed 0.38587	weighty 0.38310	ever-rising 0.37864	much-reduced 0.37850	back-breaking 0.37206	lighter 0.37160

Generated lemmatized results
***************
GENERATED	heavy.a 634 ::: hefty;weighty;light;backbreaking;enourmous;outsized;unwonted;unrelieved;unneccessary;massive

Filtered results
***************
RANKED	heavy.a 634	weighty 0.38310	massive 0.36579	onerous 0.36565	excessive 0.36214	substantial 0.34766	severe 0.34695	harsh 0.34284	considerable 0.34127	big 0.33870	costly 0.33799	tedious 0.33479	profuse 0.32438	serious 0.32385	strong 0.31576	tough 0.31282	hard 0.31211	stout 0.31110	overweight 0.30871	extensive 0.30743	regular 0.30344	difficult 0.30286	constant 0.29745	dark 0.29357	fat 0.29356	frequent 0.29202	strongest 0.28752	abundant 0.28705	worst 0.28364	ample 0.27889	wild 0.27737	laboured 0.26535

Test context:
***************
heavy.a	635	5	this material , with its __heavy__ social and political overtones , will be of particular interest to students and scholars of popular culture and history .
Contexts for target heavy are: ['amodI_social']
Contexts in vocabulary for target heavy are: ['amodI_social']
Top most similar embeddings: heavy 0.48623	heavier 0.36585	hefty 0.35876	massive 0.35397	severe 0.35267	weighty 0.35187	centuries-long 0.34941	huge 0.34918	intense 0.34780	heaviest 0.34513

Generated lemmatized results
***************
GENERATED	heavy.a 635 ::: hefty;massive;severe;weighty;huge;intense;enormous;outsized;torrential;tempestuous

Filtered results
***************
RANKED	heavy.a 635	massive 0.35397	severe 0.35267	weighty 0.35187	harsh 0.32897	strong 0.32802	excessive 0.32748	onerous 0.32570	substantial 0.32447	regular 0.32311	big 0.32169	serious 0.32058	extensive 0.31721	frequent 0.31698	tough 0.31618	costly 0.31081	dark 0.30906	tedious 0.30797	profuse 0.30749	considerable 0.30218	strongest 0.29838	stout 0.29359	worst 0.28837	constant 0.28784	ample 0.28720	hard 0.28639	overweight 0.28373	difficult 0.28049	abundant 0.27837	fat 0.27433	laboured 0.27213	wild 0.27095

Test context:
***************
heavy.a	636	19	at 11,000 feet and in heavy clouds and light precipitation , our radar showed that we would skirt the __heaviest__ of the thunderstorms by only about 2 miles .
Contexts for target heaviest are: ['det_the', 'dobjI_skirt', 'prep:of_thunderstorms']
Contexts in vocabulary for target heaviest are: ['det_the', 'dobjI_skirt', 'prep:of_thunderstorms']
Top most similar embeddings: heaviest 0.10352	mountaintops 0.08443	roughest 0.08356	ice-cap 0.08204	tree-tops 0.08131	lightest 0.08102	worst 0.08095	gentlest 0.07999	mountainsides 0.07889	fiercest 0.07864

Generated lemmatized results
***************
GENERATED	heavy.a 636 ::: mountaintops;rough;light;bad;gentle;mountainsides;fierce;thick;mild;treeline

Filtered results
***************
RANKED	heavy.a 636	worst 0.08095	tough 0.07444	harsh 0.07395	severe 0.07254	dark 0.06869	strongest 0.06837	strong 0.06837	hard 0.06830	wild 0.06790	fat 0.06570	big 0.06115	costly 0.05945	stout 0.05660	abundant 0.05185	constant 0.05045	profuse 0.04919	overweight 0.04858	frequent 0.04802	onerous 0.04632	weighty 0.04626	massive 0.04505	excessive 0.04415	ample 0.04377	extensive 0.04291	serious 0.04182	regular 0.04107	tedious 0.04044	substantial 0.04022	considerable 0.03880	laboured 0.03425	difficult 0.03359

Test context:
***************
heavy.a	637	4	she is short and __heavy__ but she has a heart of gold .
Contexts for target heavy are: ['conjI_short']
Contexts in vocabulary for target heavy are: ['conjI_short']
Top most similar embeddings: heavy 0.52250	heavier 0.39691	wiry 0.38945	weighty 0.38436	to-the-point 0.38282	well-shaped 0.37897	hefty 0.37710	over-long 0.37474	ponderous 0.37440	sharp-edged 0.37313

Generated lemmatized results
***************
GENERATED	heavy.a 637 ::: wiry;weighty;hefty;ponderous;grippy;stubby;curvy;stocky;stiff;unchallenging

Filtered results
***************
RANKED	heavy.a 637	weighty 0.38436	tedious 0.34783	harsh 0.34167	severe 0.34146	stout 0.34035	profuse 0.33890	massive 0.33200	tough 0.33198	onerous 0.32990	dark 0.32840	excessive 0.32695	strong 0.32548	frequent 0.32218	big 0.32155	substantial 0.32107	hard 0.31790	regular 0.31649	costly 0.31628	fat 0.31247	extensive 0.30570	difficult 0.30192	overweight 0.29913	laboured 0.29892	serious 0.29467	abundant 0.29268	ample 0.29146	considerable 0.29122	constant 0.28304	wild 0.27935	strongest 0.27093	worst 0.26024

Test context:
***************
heavy.a	638	3	this story is __heavy__ and complex on the one hand , yet compelling and enlightening on the other .
Contexts for target heavy are: ['nsubj_story', 'cop_is', 'rootI_*root*', 'cc_and', 'conj_complex', 'prep:on_hand', 'punct_,', 'amod_compelling', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target heavy are: ['nsubj_story', 'cop_is', 'rootI_*root*', 'cc_and', 'conj_complex', 'prep:on_hand', 'punct_,', 'amod_compelling', 'punct_.']
Top most similar embeddings: counterintuitive 0.00131	overlong 0.00130	over-simplistic 0.00128	suspenseful 0.00128	well-written 0.00126	terse 0.00123	unarguable 0.00123	counter-intuitive 0.00122	well-drawn 0.00122	well-paced 0.00121

Generated lemmatized results
***************
GENERATED	heavy.a 638 ::: counterintuitive;overlong;suspenseful;terse;unarguable;instructive;clunky;engrossing;impressionistic;hillarious

Filtered results
***************
RANKED	heavy.a 638	weighty 0.00105	costly 0.00104	tedious 0.00099	harsh 0.00099	dark 0.00093	tough 0.00091	difficult 0.00088	onerous 0.00087	profuse 0.00086	strong 0.00084	abundant 0.00081	hard 0.00081	severe 0.00081	laboured 0.00080	strongest 0.00080	stout 0.00077	serious 0.00074	big 0.00073	wild 0.00073	fat 0.00070	overweight 0.00070	constant 0.00069	excessive 0.00069	extensive 0.00068	frequent 0.00068	substantial 0.00061	massive 0.00060	ample 0.00054	worst 0.00053	considerable 0.00052	regular 0.00037

Test context:
***************
heavy.a	639	11	in contrast , the private land around these cas may see __heavy__ use during firearms season .
Contexts for target heavy are: ['amodI_use']
Contexts in vocabulary for target heavy are: ['amodI_use']
Top most similar embeddings: heavy 0.52968	heavier 0.41269	heaviest 0.39214	widescale 0.38661	heavy-duty 0.38515	injudicious 0.38139	immoderate 0.37808	surreptitious 0.37378	continous 0.37321	hefty 0.37099

Generated lemmatized results
***************
GENERATED	heavy.a 639 ::: widescale;injudicious;immoderate;surreptitious;continous;hefty;excessive;ohmic;consumptive;unsubtle

Filtered results
***************
RANKED	heavy.a 639	excessive 0.37076	weighty 0.35049	regular 0.34665	massive 0.34625	extensive 0.34539	harsh 0.33961	profuse 0.33725	frequent 0.33710	substantial 0.33443	severe 0.33319	considerable 0.33092	costly 0.32638	strong 0.32517	serious 0.32120	onerous 0.31889	tough 0.31828	tedious 0.31825	big 0.31669	hard 0.31515	constant 0.31096	abundant 0.30618	ample 0.30419	stout 0.30263	dark 0.30029	strongest 0.29632	overweight 0.29385	difficult 0.29047	fat 0.28867	worst 0.28437	wild 0.28134	laboured 0.27687

Test context:
***************
heavy.a	640	19	" during a visit to a hospice , a nurse said that six of her friends , who were __heavy__ diet coke addicts , had all been diagnosed with ms.
Contexts for target heavy are: ['amodI_addicts']
Contexts in vocabulary for target heavy are: ['amodI_addicts']
Top most similar embeddings: heavy 0.48643	heavier 0.38335	heavy-metal 0.37254	dyed-in-the-wool 0.36466	out-of-control 0.36020	sea-borne 0.35608	self-confessed 0.35579	hefty 0.35526	small-time 0.35481	hard-core 0.35470

Generated lemmatized results
***************
GENERATED	heavy.a 640 ::: hefty;opiate;homicidal;bulky;unseasoned;persistant;mutinous;voracious;angsty;backbreaking

Filtered results
***************
RANKED	heavy.a 640	severe 0.33947	hard 0.33779	costly 0.33072	big 0.32679	massive 0.32673	serious 0.32649	tough 0.32637	excessive 0.32405	overweight 0.32402	weighty 0.32339	tedious 0.32128	regular 0.31283	harsh 0.31265	stout 0.31230	strong 0.30316	frequent 0.30163	difficult 0.29787	dark 0.29699	fat 0.29574	substantial 0.29064	profuse 0.28769	onerous 0.28759	extensive 0.28500	considerable 0.28187	worst 0.28079	constant 0.27987	strongest 0.27112	laboured 0.26827	wild 0.26773	abundant 0.26544	ample 0.26027

Test context:
***************
instead.r	641	5	anyway , what we did __instead__ was to use the mechanism that we brought people to the individual sites anyway .
Contexts for target instead are: ['advmodI_was']
Contexts in vocabulary for target instead are: ['advmodI_was']
Top most similar embeddings: instead 0.51181	proably 0.41496	however 0.40354	eventualy 0.39986	also 0.39900	apprently 0.39897	duely 0.39502	actaully 0.39476	alledgedly 0.39141	bascially 0.39124

Generated lemmatized results
***************
GENERATED	instead.r 641 ::: proably;however;eventualy;also;apprently;duely;actaully;alledgedly;bascially;actually

Filtered results
***************
RANKED	instead.r 641	rather 0.36805	alternatively 0.32676	alternately 0.31814	but 0.26407

Test context:
***************
instead.r	642	0	__instead__ , think about the following : dont feel that you must read everything on the reading list .
Contexts for target instead are: ['advmodI_think']
Contexts in vocabulary for target instead are: ['advmodI_think']
Top most similar embeddings: instead 0.51163	proably 0.41969	actaully 0.41397	acutally 0.40159	futhermore 0.39804	however 0.39504	apprently 0.39496	actually 0.39438	presumptuously 0.39268	defintely 0.39062

Generated lemmatized results
***************
GENERATED	instead.r 642 ::: proably;actaully;acutally;futhermore;however;apprently;actually;presumptuously;defintely;resignedly

Filtered results
***************
RANKED	instead.r 642	rather 0.37718	alternatively 0.33343	alternately 0.31455	but 0.26563

Test context:
***************
instead.r	643	20	start by making small changes to your daily activities , such as walking to the shops or using the stairs __instead__ of the lift or escalator .
Contexts for target instead are: ['advmodI_of']
Contexts in vocabulary for target instead are: ['advmodI_of']
Top most similar embeddings: instead 0.57408	also 0.39249	perhaps 0.38175	typically 0.37978	rather 0.37861	mainly 0.37697	generally 0.37490	thus 0.37229	nonetheless 0.37189	even 0.37045

Generated lemmatized results
***************
GENERATED	instead.r 643 ::: also;perhaps;typically;rather;mainly;generally;thus;nonetheless;even;usually

Filtered results
***************
RANKED	instead.r 643	rather 0.37861	alternatively 0.32256	alternately 0.30612	but 0.26602

Test context:
***************
instead.r	644	15	it makes good sense to spend a little time talking to someone about your concerns __instead__ of waiting until things get worse .
Contexts for target instead are: ['advmodI_of']
Contexts in vocabulary for target instead are: ['advmodI_of']
Top most similar embeddings: instead 0.57408	also 0.39249	perhaps 0.38175	typically 0.37978	rather 0.37861	mainly 0.37697	generally 0.37490	thus 0.37229	nonetheless 0.37189	even 0.37045

Generated lemmatized results
***************
GENERATED	instead.r 644 ::: also;perhaps;typically;rather;mainly;generally;thus;nonetheless;even;usually

Filtered results
***************
RANKED	instead.r 644	rather 0.37861	alternatively 0.32256	alternately 0.30612	but 0.26602

Test context:
***************
instead.r	645	15	interestingly , his finished work did not reflect the sophistication of his search strategy , __instead__ he met the minimum perceived requirements of the assignment , which perhaps is an indication that he selected learning strategies appropriate to the assessment criteria as he saw them .
Contexts for target instead are: ['advmodI_met']
Contexts in vocabulary for target instead are: ['advmodI_met']
Top most similar embeddings: instead 0.51019	duely 0.39973	proably 0.38891	also 0.38846	actaully 0.38749	actually 0.38595	eventualy 0.38528	cannily 0.38328	again 0.38256	however 0.38216

Generated lemmatized results
***************
GENERATED	instead.r 645 ::: duely;proably;also;actaully;actually;eventualy;cannily;again;however;finally

Filtered results
***************
RANKED	instead.r 645	rather 0.34666	alternately 0.32532	alternatively 0.32065	but 0.26488

Test context:
***************
instead.r	646	11	someone believes that this is a quite unlikely event ; others __instead__ believe that if the biochemical evolution is given enough time , there is a good chance that complex compounds can be created .
Contexts for target instead are: ['advmodI_believe']
Contexts in vocabulary for target instead are: ['advmodI_believe']
Top most similar embeddings: instead 0.51043	however 0.40386	proably 0.40141	futhermore 0.39712	also 0.39554	actaully 0.39204	actually 0.39172	nonetheless 0.39021	apprently 0.38831	misguidedly 0.38469

Generated lemmatized results
***************
GENERATED	instead.r 646 ::: however;proably;futhermore;also;actaully;actually;nonetheless;apprently;misguidedly;duely

Filtered results
***************
RANKED	instead.r 646	rather 0.37170	alternatively 0.33174	alternately 0.30008	but 0.27263

Test context:
***************
instead.r	647	29	they 're running at full capacity already - can you imagine what they would be like if car travel were suddenly banned and everyone had to go by tube __instead__ ?
Contexts for target instead are: ['advmodI_go']
Contexts in vocabulary for target instead are: ['advmodI_go']
Top most similar embeddings: instead 0.51917	proably 0.42988	actaully 0.40890	defintely 0.40512	eventualy 0.40429	belly-up 0.39878	duely 0.39689	acutally 0.39499	beserk 0.39323	apprently 0.39315

Generated lemmatized results
***************
GENERATED	instead.r 647 ::: proably;actaully;defintely;eventualy;duely;acutally;beserk;apprently;resignedly;futhermore

Filtered results
***************
RANKED	instead.r 647	rather 0.37572	alternatively 0.35436	alternately 0.33532	but 0.27556

Test context:
***************
instead.r	648	17	it is seen as bad manners to try and pretend that death is somehow not natural ; __instead__ death is seen as giving shape to life .
Contexts for target instead are: ['advmodI_death']
Contexts in vocabulary for target instead are: ['advmodI_death']
Top most similar embeddings: instead 0.48636	even 0.39516	proably 0.37663	eventually 0.37625	finally 0.37508	sometimes 0.37374	however 0.37322	rather 0.37171	everlastingly 0.37120	resignedly 0.37114

Generated lemmatized results
***************
GENERATED	instead.r 648 ::: even;proably;eventually;finally;sometimes;however;rather;everlastingly;resignedly;duely

Filtered results
***************
RANKED	instead.r 648	rather 0.37171	alternatively 0.31993	alternately 0.31079	but 0.26735

Test context:
***************
instead.r	649	0	__instead__ , mr gould is pursuing a claim for compensation with the backing of his local mp .
Contexts for target instead are: ['advmodI_pursuing']
Contexts in vocabulary for target instead are: ['advmodI_pursuing']
Top most similar embeddings: instead 0.50952	aggressively 0.39137	also 0.38878	meanwhile 0.38853	ceaselessly 0.38635	hypocritically 0.38538	cannily 0.38288	nonetheless 0.38150	proably 0.38115	virtuously 0.38094

Generated lemmatized results
***************
GENERATED	instead.r 649 ::: aggressively;also;meanwhile;ceaselessly;hypocritically;cannily;nonetheless;proably;virtuously;resignedly

Filtered results
***************
RANKED	instead.r 649	rather 0.35987	alternately 0.32074	alternatively 0.31346	but 0.26162

Test context:
***************
instead.r	650	19	in the 1870 's however the owners enclosed part of it with a hedge and the public playground became __instead__ the riverbank between the teviot bridge and the old suspension bridge .
Contexts for target instead are: ['advmodI_riverbank']
Contexts in vocabulary for target instead are: []
Top most similar embeddings: instead 1.00000	proably 0.75449	also 0.74776	however 0.74521	rather 0.74403	duely 0.74149	virtuously 0.73965	resignedly 0.73537	futhermore 0.73303	magnanimously 0.73287

Generated lemmatized results
***************
GENERATED	instead.r 650 ::: proably;also;however;rather;duely;virtuously;resignedly;futhermore;magnanimously;presumptuously

Filtered results
***************
RANKED	instead.r 650	rather 0.74403	but 0.68603	alternatively 0.67015	alternately 0.64897

Test context:
***************
live.a	651	12	and i understand the particular sensitivity in northern australia as far as __live__ cattle exports are concerned .
Contexts for target live are: ['amodI_exports']
Contexts in vocabulary for target live are: ['amodI_exports']
Top most similar embeddings: live 0.52439	home-produced 0.36302	non-oil 0.35556	sea-borne 0.35044	multibillion-dollar 0.34051	genetically-modified 0.33912	much-touted 0.33820	low-quality 0.33745	lived 0.33690	nuclear-related 0.33666

Generated lemmatized results
***************
GENERATED	live.a 651 ::: lived;pyrotechnic;unrestrained;unamplified;multibillion;unlicenced;farmed;senegalese;yugoslavian;argentinean

Filtered results
***************
RANKED	live.a 651	living 0.30829	direct 0.30653	active 0.29892	performing 0.28471	real 0.28235	realtime 0.27581	existent 0.27351	sustainable 0.27291	viewable 0.26710	performed 0.26597	online 0.26496	charged 0.26315	operative 0.26291	powered 0.26211	running 0.25965	animate 0.25883	connected 0.25840	functioning 0.24848	showing 0.24749	working 0.23881	circulated 0.22520	breathing 0.21066

Test context:
***************
live.a	652	4	they are not the __live__ variety but bronze statues made by the 84-year old sculptress who crafted the platypus for the golden paw award perpetual trophy .
Contexts for target live are: ['amodI_variety']
Contexts in vocabulary for target live are: ['amodI_variety']
Top most similar embeddings: live 0.43753	easy-listening 0.34945	disease-resistant 0.34469	cross-generational 0.33792	much-touted 0.33737	factory-farmed 0.33709	salt-tolerant 0.33683	gene-spliced 0.33544	sugar-coated 0.33542	ever-widening 0.33527

Generated lemmatized results
***************
GENERATED	live.a 652 ::: kaleidoscopic;clubby;lived;diegetic;unparalled;comtemporary;unicellular;insectivorous;triploid;carnivorous

Filtered results
***************
RANKED	live.a 652	living 0.31426	real 0.29706	active 0.28511	direct 0.27666	existent 0.27335	animate 0.27130	performing 0.27009	realtime 0.27004	online 0.26909	viewable 0.26693	charged 0.26475	functioning 0.25856	sustainable 0.25531	working 0.25298	operative 0.25227	powered 0.25093	running 0.24984	performed 0.24744	connected 0.24555	breathing 0.24100	showing 0.23822	circulated 0.21971

Test context:
***************
live.a	653	2	pub with __live__ music four time per week , italian food and guinness beer on tap .
Contexts for target live are: ['amodI_music']
Contexts in vocabulary for target live are: ['amodI_music']
Top most similar embeddings: live 0.53950	unamplified 0.42788	guitar-based 0.42483	acousmatic 0.41610	easy-listening 0.40049	prerecorded 0.39241	foot-tapping 0.39161	spoken-word 0.38836	guitar-driven 0.38835	diegetic 0.38744

Generated lemmatized results
***************
GENERATED	live.a 653 ::: unamplified;acousmatic;prerecorded;diegetic;cantorial;podsafe;quadraphonic;electroacoustic;comtemporary;tuneless

Filtered results
***************
RANKED	live.a 653	living 0.32472	real 0.30547	realtime 0.30179	performing 0.30140	active 0.29649	online 0.29318	direct 0.29071	existent 0.28583	performed 0.28561	animate 0.28285	viewable 0.27072	running 0.27032	connected 0.26820	working 0.25892	charged 0.25868	sustainable 0.25499	powered 0.25297	functioning 0.25087	operative 0.24388	showing 0.24079	circulated 0.23719	breathing 0.23550

Test context:
***************
live.a	654	9	like the philadelphia match , this event was covered __live__ on the world wide web .
Contexts for target live are: ['acompI_covered', 'prep:on_web']
Contexts in vocabulary for target live are: ['acompI_covered', 'prep:on_web']
Top most similar embeddings: live 0.25851	available 0.16069	unencrypted 0.15959	reside 0.15920	free-of-charge 0.15743	avaialable 0.15584	free 0.15451	avilable 0.15428	availiable 0.15208	alive 0.15066

Generated lemmatized results
***************
GENERATED	live.a 654 ::: available;unencrypted;reside;avaialable;free;avilable;availiable;alive;avaliable;avalible

Filtered results
***************
RANKED	live.a 654	viewable 0.14494	living 0.13503	direct 0.13293	realtime 0.12951	active 0.12915	online 0.12737	existent 0.12354	performing 0.11600	operative 0.11213	performed 0.11125	real 0.10988	running 0.10958	animate 0.10935	working 0.10899	charged 0.10792	connected 0.10755	sustainable 0.10499	powered 0.10447	circulated 0.10400	functioning 0.10154	showing 0.10102	breathing 0.09481

Test context:
***************
live.a	655	12	the drama was staged and recorded in nairobi in front of a __live__ audience .
Contexts for target live are: ['amodI_audience']
Contexts in vocabulary for target live are: ['amodI_audience']
Top most similar embeddings: live 0.51043	cross-generational 0.36465	sold-out 0.36277	invitation-only 0.36156	20-strong 0.35993	non-english-speaking 0.35891	50-strong 0.35757	unamplified 0.35688	prime-time 0.35306	non-art 0.35282

Generated lemmatized results
***************
GENERATED	live.a 655 ::: unamplified;lived;peaktime;unrehearsed;diegetic;enthusiatic;unoffical;comtemporary;geniune;terrestial

Filtered results
***************
RANKED	live.a 655	living 0.31544	active 0.31112	real 0.30161	online 0.29636	realtime 0.28813	direct 0.28475	performing 0.28368	working 0.27801	charged 0.27740	animate 0.27688	viewable 0.27497	existent 0.27091	connected 0.26835	sustainable 0.26192	functioning 0.25813	running 0.25765	performed 0.25734	operative 0.25417	powered 0.25035	showing 0.24663	breathing 0.23824	circulated 0.23317

Test context:
***************
live.a	656	1	from __live__ oaks on the coast to white oaks and chestnut oaks in the mountains , this year 's mast crop has been heavy and widespread .
Contexts for target live are: ['amodI_oaks']
Contexts in vocabulary for target live are: ['amodI_oaks']
Top most similar embeddings: live 0.49940	well-grown 0.35724	full-grown 0.35541	leafless 0.35138	pure-bred 0.35124	semi-mature 0.34891	bare-root 0.34761	pedunculate 0.34514	fully-grown 0.34065	two-headed 0.34002

Generated lemmatized results
***************
GENERATED	live.a 656 ::: leafless;pedunculate;gnarled;mature;largish;pollarded;lived;reside;gnarly;naturalised

Filtered results
***************
RANKED	live.a 656	living 0.32218	active 0.27644	real 0.27396	direct 0.27155	existent 0.27108	realtime 0.27032	functioning 0.26385	online 0.26011	animate 0.25788	viewable 0.25595	performing 0.25391	running 0.25167	connected 0.25166	working 0.25042	sustainable 0.24853	powered 0.24307	operative 0.24147	charged 0.23554	performed 0.23518	showing 0.23496	circulated 0.22632	breathing 0.22587

Test context:
***************
live.a	657	8	skilled in leading projects , especially in deploying __live__ end-user systems .
Contexts for target live are: ['amodI_systems']
Contexts in vocabulary for target live are: ['amodI_systems']
Top most similar embeddings: live 0.47271	multi-camera 0.39920	siphonic 0.39364	computer-driven 0.38872	non-unix 0.38836	microprocessor-based 0.38798	multi-cellular 0.38336	large-screen 0.38226	air-to-ground 0.38157	off-grid 0.38090

Generated lemmatized results
***************
GENERATED	live.a 657 ::: siphonic;quadraphonic;microfluidic;autopoietic;integumentary;mechatronic;lentiviral;multiband;magnocellular;multiagent

Filtered results
***************
RANKED	live.a 657	living 0.34517	active 0.31376	realtime 0.31368	real 0.30252	existent 0.29854	online 0.29762	direct 0.29278	sustainable 0.29274	animate 0.28764	functioning 0.28659	connected 0.28658	working 0.27997	performing 0.27876	operative 0.27771	running 0.27765	powered 0.27743	viewable 0.26591	charged 0.25438	performed 0.25301	breathing 0.24931	circulated 0.24595	showing 0.23189

Test context:
***************
live.a	658	8	next to her head , we see a __live__ power-line , still sparking .
Contexts for target live are: ['amodI_power-line']
Contexts in vocabulary for target live are: []
Top most similar embeddings: live 1.00000	lived 0.76463	reside 0.73157	cohabit 0.70585	unamplified 0.70338	multi-camera 0.69478	living 0.69404	guitar-based 0.69111	audio-described 0.69086	honeymooned 0.69033

Generated lemmatized results
***************
GENERATED	live.a 658 ::: lived;reside;cohabit;unamplified;living;honeymooned;prerecorded;singsational;procreate;acousmatic

Filtered results
***************
RANKED	live.a 658	living 0.69404	active 0.62312	realtime 0.61853	animate 0.60649	working 0.60262	direct 0.60064	performed 0.59850	real 0.59764	performing 0.59695	online 0.59660	viewable 0.59262	existent 0.59128	charged 0.58910	running 0.58708	connected 0.58566	showing 0.57890	functioning 0.57633	powered 0.56819	operative 0.56432	sustainable 0.55922	breathing 0.55602	circulated 0.55291

Test context:
***************
live.a	659	14	the video lesson done at the end of the test has to be done __live__ and that also runs into a lot more time .
Contexts for target live are: ['nsubjI_runs', 'cc_and', 'conj_that']
Contexts in vocabulary for target live are: ['nsubjI_runs', 'cc_and', 'conj_that']
Top most similar embeddings: live 0.09350	skinnyman 0.07364	pgr3 0.07319	liveth 0.07297	pyramus 0.07281	otello 0.07247	eateth 0.07235	coheed 0.07168	abimelech 0.07068	jehst 0.07064

Generated lemmatized results
***************
GENERATED	live.a 659 ::: skinnyman;liveth;pyramus;otello;eateth;coheed;abimelech;jehst;faramir;powerdvd

Filtered results
***************
RANKED	live.a 659	living 0.06370	animate 0.06218	existent 0.05936	breathing 0.05795	direct 0.05640	realtime 0.05579	running 0.05505	functioning 0.05420	active 0.05392	connected 0.05265	performing 0.05200	operative 0.05185	powered 0.05130	online 0.05112	real 0.05055	circulated 0.05012	viewable 0.04951	charged 0.04903	showing 0.04894	performed 0.04723	working 0.04630	sustainable 0.04610

Test context:
***************
live.a	660	4	your ad will be __live__ within a 5 hours of the time you posted it .
Contexts for target live are: ['nsubj_ad', 'aux_will', 'cop_be', 'rootI_*root*', 'prep:within_hours', 'ccomp_posted', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target live are: ['nsubj_ad', 'aux_will', 'cop_be', 'rootI_*root*', 'prep:within_hours', 'ccomp_posted', 'punct_.']
Top most similar embeddings: live 0.00563	availiable 0.00515	anounced 0.00496	re-enabled 0.00496	avilable 0.00493	contactable 0.00489	available 0.00485	re-credited 0.00478	e-mailed 0.00477	cross-posted 0.00477

Generated lemmatized results
***************
GENERATED	live.a 660 ::: availiable;anounced;avilable;contactable;available;emailed;availabe;viewable;redisplayed;euthanased

Filtered results
***************
RANKED	live.a 660	viewable 0.00460	circulated 0.00354	active 0.00334	charged 0.00328	performed 0.00303	animate 0.00298	running 0.00293	living 0.00287	operative 0.00280	online 0.00279	existent 0.00276	powered 0.00271	direct 0.00271	showing 0.00267	performing 0.00265	connected 0.00263	realtime 0.00241	working 0.00239	functioning 0.00231	breathing 0.00226	sustainable 0.00200	real 0.00181

Test context:
***************
mass.n	661	5	80 year-old granny rallies the __masses__ to fight a nuclear war .
Contexts for target masses are: ['det_the', 'dobjI_rallies', 'infmod_fight']
Contexts in vocabulary for target masses are: ['det_the', 'dobjI_rallies', 'infmod_fight']
Top most similar embeddings: masses 0.13154	legions 0.09413	toilers 0.09397	militias 0.09334	populace 0.09121	besiegers 0.09108	armies 0.09081	troops 0.09075	jama'a 0.09074	proletariat 0.09068

Generated lemmatized results
***************
GENERATED	mass.n 661 ::: legion;toiler;militia;populace;besieger;army;troop;proletariat;ulstermen;jihadist

Filtered results
***************
RANKED	mass.n 661	populace 0.09121	proletariat 0.09068	crowd 0.08722	multitude 0.08471	throng 0.08022	public 0.07469	majority 0.07409	people 0.07121	bulk 0.06962	expanse 0.06151	body 0.06149	extent 0.06142	quantity 0.06065	magnitude 0.05967	accumulation 0.05894	aggregate 0.05828	climax 0.05812	conglomeration 0.05808	volume 0.05695	weight 0.05683	shock 0.05636	density 0.05429	host 0.05328	splash 0.05180	means 0.04955

Test context:
***************
mass.n	662	5	they generally lack the critical __mass__ to be able to deliver services in a cost effective manner .
Contexts for target mass are: ['det_the', 'amod_critical', 'dobjI_lack', 'infmod_able']
Contexts in vocabulary for target mass are: ['det_the', 'amod_critical', 'dobjI_lack', 'infmod_able']
Top most similar embeddings: mass 0.05937	masses 0.04788	gravitas 0.04460	self-assurance 0.04318	skill-set 0.04264	momentum 0.04208	wherewithal 0.04176	sureness 0.04141	abilty 0.04140	infrastructure 0.04123

Generated lemmatized results
***************
GENERATED	mass.n 662 ::: gravitas;momentum;wherewithal;sureness;abilty;infrastructure;acuteness;resiliency;aptness;solidity

Filtered results
***************
RANKED	mass.n 662	density 0.03790	magnitude 0.03535	proletariat 0.03436	weight 0.03398	quantity 0.03234	bulk 0.03186	extent 0.03182	accumulation 0.03145	volume 0.03128	multitude 0.03103	throng 0.03065	populace 0.03054	crowd 0.02983	majority 0.02972	climax 0.02903	body 0.02886	public 0.02881	conglomeration 0.02848	shock 0.02811	expanse 0.02762	means 0.02744	aggregate 0.02675	host 0.02530	people 0.02469	splash 0.02419

Test context:
***************
mass.n	663	10	their growth is often very vigorous but they provide a __mass__ of colour in summer .
Contexts for target mass are: ['det_a', 'dobjI_provide', 'prep:of_colour']
Contexts in vocabulary for target mass are: ['det_a', 'dobjI_provide', 'prep:of_colour']
Top most similar embeddings: mass 0.12406	consistence 0.09099	back-drop 0.09003	backcloth 0.08977	smidgeon 0.08683	wealth 0.08604	masses 0.08603	superabundance 0.08568	sackful 0.08532	counterpoise 0.08528

Generated lemmatized results
***************
GENERATED	mass.n 663 ::: consistence;backcloth;smidgeon;wealth;superabundance;sackful;counterpoise;gradation;varity;boatload

Filtered results
***************
RANKED	mass.n 663	density 0.08102	multitude 0.08061	splash 0.07926	conglomeration 0.07755	expanse 0.07556	bulk 0.07234	quantity 0.07214	magnitude 0.07180	climax 0.07107	majority 0.06914	accumulation 0.06837	weight 0.06726	host 0.06674	volume 0.06625	throng 0.06454	shock 0.06453	body 0.06422	aggregate 0.06310	means 0.06255	populace 0.06159	proletariat 0.05886	crowd 0.05866	extent 0.05798	people 0.05593	public 0.05269

Test context:
***************
mass.n	664	8	colin and his boss are assembled with the __masses__ in vatican square when colin says , " this will never work .
Contexts for target masses are: ['det_the', 'prep:withI_assembled', 'prep:in_square']
Contexts in vocabulary for target masses are: ['det_the', 'prep:withI_assembled', 'prep:in_square']
Top most similar embeddings: masses 0.13364	mass 0.09571	crowds 0.09091	multitudes 0.08842	toilers 0.08759	throngs 0.08625	throng 0.08614	mourners 0.08559	congregation 0.08402	besiegers 0.08400

Generated lemmatized results
***************
GENERATED	mass.n 664 ::: crowd;multitude;toiler;throng;mourner;congregation;besieger;acclamation;demonstrator;cartouch

Filtered results
***************
RANKED	mass.n 664	crowd 0.09091	multitude 0.08842	throng 0.08625	proletariat 0.08062	populace 0.07534	majority 0.07338	density 0.06956	bulk 0.06916	magnitude 0.06796	accumulation 0.06742	public 0.06652	expanse 0.06603	climax 0.06568	body 0.06544	weight 0.06509	people 0.06436	quantity 0.06328	extent 0.06277	aggregate 0.06086	host 0.05970	splash 0.05853	conglomeration 0.05718	volume 0.05714	shock 0.05712	means 0.04580

Test context:
***************
mass.n	665	5	the size , shape and __mass__ of the boulder are not considered and a cinematic simulation of the rock-fall process is performed .
Contexts for target mass are: ['conjI_size']
Contexts in vocabulary for target mass are: ['conjI_size']
Top most similar embeddings: mass 0.50605	masses 0.38583	density 0.36782	wieght 0.35888	hydrophobicity 0.35454	crystallinity 0.35327	roundness 0.35175	luminosities 0.35144	coercivity 0.35027	fineness 0.34919

Generated lemmatized results
***************
GENERATED	mass.n 665 ::: density;wieght;hydrophobicity;crystallinity;roundness;luminosity;coercivity;fineness;weight;undulation

Filtered results
***************
RANKED	mass.n 665	density 0.36782	weight 0.34849	bulk 0.33263	magnitude 0.33215	volume 0.32043	quantity 0.30967	conglomeration 0.29899	accumulation 0.29172	extent 0.28980	throng 0.28731	multitude 0.28568	expanse 0.28446	aggregate 0.27452	crowd 0.27445	populace 0.27123	body 0.27031	majority 0.26907	proletariat 0.26761	climax 0.25768	splash 0.25540	host 0.25525	people 0.24861	shock 0.24704	public 0.24555	means 0.24475

Test context:
***************
mass.n	666	27	it deserves and needs to be heard in our age as well , when the growing affluence of a few people parallels the growing poverty of the __masses__ .
Contexts for target masses are: ['det_the', 'prep:ofI_poverty']
Contexts in vocabulary for target masses are: ['det_the', 'prep:ofI_poverty']
Top most similar embeddings: masses 0.27487	peasantry 0.22175	toilers 0.21233	mass 0.19914	peasants 0.19855	proletariat 0.19547	plebeians 0.19286	hellenes 0.19276	besiegers 0.18974	latins 0.18951

Generated lemmatized results
***************
GENERATED	mass.n 666 ::: peasantry;toiler;peasant;proletariat;plebeian;hellene;besieger;latin;pleb;intelligentsia

Filtered results
***************
RANKED	mass.n 666	proletariat 0.19547	multitude 0.18673	populace 0.18632	crowd 0.17639	majority 0.17541	throng 0.16577	people 0.16428	bulk 0.16036	public 0.15969	density 0.15447	expanse 0.15321	accumulation 0.15183	quantity 0.15033	body 0.14979	volume 0.14539	magnitude 0.14377	climax 0.13928	extent 0.13925	aggregate 0.13539	conglomeration 0.13502	weight 0.13079	host 0.12762	shock 0.12360	splash 0.11713	means 0.11607

Test context:
***************
mass.n	667	7	even better , step-by-step instructions for the __masses__ would be absolutely excellent .
Contexts for target masses are: ['det_the', 'prep:forI_instructions']
Contexts in vocabulary for target masses are: ['det_the', 'prep:forI_instructions']
Top most similar embeddings: masses 0.25532	mass 0.18779	plebeians 0.17607	toilers 0.17527	eucharist 0.17447	dwarfers 0.17385	annotators 0.17349	multitudes 0.17339	mom-to-be 0.17157	ms-200 0.17124

Generated lemmatized results
***************
GENERATED	mass.n 667 ::: plebeian;toiler;eucharist;dwarfers;annotator;multitude;eloader;groundling;besieger;antiphon

Filtered results
***************
RANKED	mass.n 667	multitude 0.17339	proletariat 0.16883	populace 0.16518	throng 0.16439	crowd 0.16306	majority 0.15769	bulk 0.15736	magnitude 0.15665	quantity 0.15663	public 0.15320	accumulation 0.15189	weight 0.14876	people 0.14624	volume 0.14481	extent 0.14259	density 0.14063	expanse 0.13965	body 0.13802	climax 0.13771	aggregate 0.13549	host 0.12957	conglomeration 0.12841	shock 0.12325	splash 0.12325	means 0.11262

Test context:
***************
mass.n	668	8	at that size , it would have a __mass__ of about the same as an average galaxy .
Contexts for target mass are: ['det_a', 'dobjI_have']
Contexts in vocabulary for target mass are: ['det_a', 'dobjI_have']
Top most similar embeddings: mass 0.25116	sackful 0.18792	pr0 0.18776	plateful 0.18742	mojito 0.18730	sizzler 0.18728	prolactinoma 0.18428	roomful 0.18305	tracheotomy 0.18244	superabundance 0.18243

Generated lemmatized results
***************
GENERATED	mass.n 668 ::: sackful;plateful;mojito;sizzler;prolactinoma;roomful;tracheotomy;superabundance;wieght;shedload

Filtered results
***************
RANKED	mass.n 668	density 0.16947	multitude 0.16821	conglomeration 0.15594	weight 0.15569	magnitude 0.15534	quantity 0.15100	expanse 0.15055	throng 0.14907	crowd 0.14795	majority 0.14642	volume 0.14636	body 0.14486	bulk 0.14410	splash 0.14142	host 0.14111	accumulation 0.13898	climax 0.13875	shock 0.13634	populace 0.13551	aggregate 0.13010	means 0.12992	extent 0.12870	proletariat 0.12845	people 0.11537	public 0.11207

Test context:
***************
mass.n	669	6	then have the children measure the __mass__ of two potatoes and freeze them .
Contexts for target mass are: ['det_the', 'dobjI_measure', 'prep:of_potatoes']
Contexts in vocabulary for target mass are: ['det_the', 'dobjI_measure', 'prep:of_potatoes']
Top most similar embeddings: mass 0.12157	masses 0.10526	molarity 0.09191	compressibility 0.09041	hardenability 0.09021	fineness 0.08950	flowrate 0.08896	productiveness 0.08824	wettability 0.08817	absorbance 0.08724

Generated lemmatized results
***************
GENERATED	mass.n 669 ::: molarity;compressibility;hardenability;fineness;flowrate;productiveness;wettability;absorbance;density;thickness

Filtered results
***************
RANKED	mass.n 669	density 0.08711	quantity 0.08350	weight 0.08164	bulk 0.07825	volume 0.07647	magnitude 0.07607	accumulation 0.07308	multitude 0.07038	extent 0.06931	expanse 0.06730	majority 0.06561	crowd 0.06535	throng 0.06491	aggregate 0.06359	body 0.06299	proletariat 0.06191	conglomeration 0.06134	populace 0.06061	splash 0.05873	shock 0.05825	climax 0.05719	public 0.05670	people 0.05501	host 0.05366	means 0.04990

Test context:
***************
mass.n	670	5	again , they might hear __mass__ with so much reverence that all their sins were remitted .
Contexts for target mass are: ['dobjI_hear']
Contexts in vocabulary for target mass are: ['dobjI_hear']
Top most similar embeddings: mass 0.48267	masses 0.38434	mass. 0.37515	adhan 0.36085	pitter-patter 0.35632	vespers 0.35193	evensong 0.34330	miserere 0.34182	footfalls 0.33951	footstep 0.33832

Generated lemmatized results
***************
GENERATED	mass.n 670 ::: adhan;vesper;evensong;miserere;footfall;footstep;thunderclap;kirtan;dirge;acclamation

Filtered results
***************
RANKED	mass.n 670	throng 0.30781	density 0.30382	bulk 0.29620	multitude 0.29532	crowd 0.29201	volume 0.29183	climax 0.28856	weight 0.28751	magnitude 0.28558	body 0.28308	splash 0.28307	majority 0.27609	accumulation 0.27577	conglomeration 0.26985	quantity 0.26937	people 0.26817	shock 0.26652	populace 0.26624	expanse 0.26425	host 0.26302	aggregate 0.25924	proletariat 0.25621	extent 0.24978	public 0.24740	means 0.23467

Test context:
***************
match.n	671	28	the ideal preparation would be a light meal about 2-2 1/2 hours pre-match , followed by a warm-up hit and perhaps a top-up with extra fluid before the __match__ .
Contexts for target match are: ['det_the', 'prep:beforeI_top-up']
Contexts in vocabulary for target match are: ['det_the']
Top most similar embeddings: match 0.50724	matches 0.41507	game 0.38578	cup-tie 0.38474	semifinal 0.37681	decider 0.37374	clash 0.37168	semifinals 0.36971	minerva-press 0.36888	fixture 0.36836

Generated lemmatized results
***************
GENERATED	match.n 671 ::: game;semifinal;decider;clash;fixture;lent;afternoone;tournament;quarterfinal;windies

Filtered results
***************
RANKED	match.n 671	game 0.38578	contest 0.35591	event 0.32903	competition 0.31752	pairing 0.31386	bout 0.30965	correlation 0.30950	link 0.30725	partnership 0.29966	correspondence 0.29828	equivalent 0.29683	fit 0.29663	choice 0.29409	association 0.29280	rival 0.29007	marriage 0.28591	counterpart 0.28563	matchstick 0.28184	competitor 0.28171	couple 0.27717	hit 0.27027	equal 0.26599

Test context:
***************
match.n	672	19	' the software is the program that sifts through the millions of pages recorded in the index to find __matches__ to a search and rank them in order of what it believes is most relevant .
Contexts for target matches are: ['dobjI_find']
Contexts in vocabulary for target matches are: ['dobjI_find']
Top most similar embeddings: matches 0.50341	match 0.42013	fixtures 0.34861	friendlies 0.34578	subkeys 0.33905	deatils 0.33797	endemics 0.33707	games 0.33706	beenz 0.33696	stashes 0.33497

Generated lemmatized results
***************
GENERATED	match.n 672 ::: fixture;friendly;subkeys;deatils;endemic;game;beenz;stash;qualifier;googlewhack

Filtered results
***************
RANKED	match.n 672	game 0.33706	contest 0.31416	correspondence 0.31296	correlation 0.30500	competition 0.30481	rival 0.30370	link 0.29995	equivalent 0.29944	pairing 0.29939	bout 0.29508	fit 0.29371	hit 0.29277	competitor 0.28866	event 0.28469	association 0.28248	counterpart 0.28085	choice 0.27704	matchstick 0.27692	equal 0.27652	marriage 0.26829	couple 0.26362	partnership 0.25185

Test context:
***************
match.n	673	13	the tag consists of a tiny chip , about the size of a __match__ head that serves as a portable database .
Contexts for target match are: ['nnI_head']
Contexts in vocabulary for target match are: ['nnI_head']
Top most similar embeddings: match 0.46047	hengistbury 0.36668	rame 0.35755	matches 0.35489	flamborough 0.35407	duncansby 0.34145	dunnet 0.34103	viiis 0.33918	clash 0.33813	strumble 0.33567

Generated lemmatized results
***************
GENERATED	match.n 673 ::: hengistbury;rame;flamborough;duncansby;dunnet;viii;clash;strumble;sculler;harlequin

Filtered results
***************
RANKED	match.n 673	game 0.33194	contest 0.30778	matchstick 0.29697	rival 0.28718	bout 0.28497	competition 0.27743	pairing 0.27597	fit 0.27493	event 0.26948	partnership 0.26894	link 0.26807	equal 0.26786	correspondence 0.25968	association 0.25937	counterpart 0.25888	choice 0.25685	correlation 0.25620	hit 0.25598	competitor 0.25431	marriage 0.25330	equivalent 0.24195	couple 0.23842

Test context:
***************
match.n	674	20	journey time is around 8 hours , so plenty of time to sit back , relax and start the post __match__ analysis .
Contexts for target match are: ['nnI_analysis']
Contexts in vocabulary for target match are: ['nnI_analysis']
Top most similar embeddings: match 0.47406	matches 0.38858	matching 0.34917	track-by-track 0.34679	oligomer 0.34398	ice-core 0.34396	fixture 0.34301	game 0.34203	rapd 0.34023	matched 0.33717

Generated lemmatized results
***************
GENERATED	match.n 674 ::: matching;oligomer;fixture;game;rapd;matched;rflp;multicriteria;microwindow;nlo

Filtered results
***************
RANKED	match.n 674	game 0.34203	correlation 0.32188	contest 0.31573	competitor 0.29782	event 0.29681	correspondence 0.29674	fit 0.28959	link 0.28718	competition 0.28650	pairing 0.28268	choice 0.27806	bout 0.27800	matchstick 0.27703	rival 0.27571	counterpart 0.27259	partnership 0.26785	marriage 0.26421	equal 0.26314	association 0.26134	equivalent 0.25647	hit 0.24831	couple 0.23023

Test context:
***************
match.n	675	3	other costs ( __match__ day , ground and administration ) were down by 12 % on 2001/02 levels .
Contexts for target match are: ['nnI_day']
Contexts in vocabulary for target match are: ['nnI_day']
Top most similar embeddings: match 0.50619	groundhog 0.38382	manygates 0.38359	matches 0.38143	saterday 0.37146	twenty20 0.36596	quds 0.36514	red-letter 0.36409	purnima 0.36332	tri-nations 0.36206

Generated lemmatized results
***************
GENERATED	match.n 675 ::: groundhog;manygates;saterday;quds;purnima;rogation;kickoff;beezumph;fixture;wkg

Filtered results
***************
RANKED	match.n 675	game 0.34309	contest 0.33042	competition 0.29308	bout 0.29056	event 0.29049	fit 0.28167	marriage 0.28002	partnership 0.27977	pairing 0.27826	matchstick 0.27674	rival 0.27609	equal 0.27548	link 0.27262	choice 0.26784	correspondence 0.26682	counterpart 0.26407	correlation 0.26190	equivalent 0.26079	association 0.25948	hit 0.25136	couple 0.25132	competitor 0.25072

Test context:
***************
match.n	676	13	this is at least 26 weeks by the week in which the approved __match__ with the child is made .
Contexts for target match are: ['det_the', 'amod_approved', 'nsubjpassI_made', 'prep:with_child']
Contexts in vocabulary for target match are: ['det_the', 'amod_approved', 'nsubjpassI_made', 'prep:with_child']
Top most similar embeddings: match 0.05360	matches 0.04237	tie 0.03877	childcarer 0.03848	fixture 0.03835	arrangement 0.03583	cup-tie 0.03551	arrangements 0.03543	analogy 0.03538	substitutes 0.03499

Generated lemmatized results
***************
GENERATED	match.n 676 ::: tie;childcarer;fixture;arrangement;analogy;substitute;game;repairer;comparison;allegation

Filtered results
***************
RANKED	match.n 676	game 0.03497	pairing 0.03394	correspondence 0.03286	marriage 0.03189	partnership 0.03157	contest 0.03127	link 0.03056	association 0.02968	equivalent 0.02957	competition 0.02956	correlation 0.02944	bout 0.02897	choice 0.02860	couple 0.02819	fit 0.02819	event 0.02803	competitor 0.02632	rival 0.02632	counterpart 0.02623	hit 0.02571	matchstick 0.02349	equal 0.02283

Test context:
***************
match.n	677	6	she struggled , but proved no __match__ for the powerful , unseen force .
Contexts for target match are: ['det_no', 'dobjI_proved', 'prep:for_force']
Contexts in vocabulary for target match are: ['det_no', 'dobjI_proved', 'prep:for_force']
Top most similar embeddings: match 0.11773	matches 0.08928	qualifier 0.08192	fixture 0.08113	substitute 0.08024	let-up 0.07987	substantiation 0.07947	justification 0.07925	decider 0.07856	blueprint 0.07852

Generated lemmatized results
***************
GENERATED	match.n 677 ::: qualifier;fixture;substitute;substantiation;justification;decider;blueprint;arguements;yardstick;pushover

Filtered results
***************
RANKED	match.n 677	contest 0.07700	correlation 0.07439	game 0.07214	choice 0.07074	rival 0.06654	competition 0.06557	counterpart 0.06545	hit 0.06337	competitor 0.06281	pairing 0.06243	equivalent 0.06177	fit 0.06142	event 0.06096	link 0.05957	correspondence 0.05917	marriage 0.05806	equal 0.05802	bout 0.05539	partnership 0.05503	matchstick 0.05313	association 0.05229	couple 0.04711

Test context:
***************
match.n	678	15	so what started out as a perfectly lovely stroll ended up as a public wrestling __match__ between grandma and baby girl , with baby girl loving every second of it .
Contexts for target match are: ['det_a', 'amod_public', 'nn_wrestling', 'prep:asI_ended', 'prep:between_girl']
Contexts in vocabulary for target match are: ['det_a', 'amod_public', 'nn_wrestling', 'prep:asI_ended', 'prep:between_girl']
Top most similar embeddings: match 0.02649	contest 0.02198	clash 0.02183	showdown 0.02104	duel 0.02057	bust-up 0.01974	cup-tie 0.01968	tussle 0.01967	feud 0.01960	confrontation 0.01950

Generated lemmatized results
***************
GENERATED	match.n 678 ::: contest;clash;showdown;duel;tussle;feud;confrontation;encounter;brawl;fixture

Filtered results
***************
RANKED	match.n 678	contest 0.02198	game 0.01870	bout 0.01735	competition 0.01565	pairing 0.01491	event 0.01479	marriage 0.01466	counterpart 0.01450	partnership 0.01436	rival 0.01370	competitor 0.01352	correspondence 0.01258	correlation 0.01246	choice 0.01245	link 0.01236	fit 0.01142	matchstick 0.01135	association 0.01126	couple 0.01122	equal 0.01118	hit 0.01106	equivalent 0.01039

Test context:
***************
match.n	679	5	it seemed to be a __match__ made in heaven , except that jesse was
Contexts for target match are: ['aux_to', 'cop_be', 'det_a', 'xcompI_seemed', 'partmod_made']
Contexts in vocabulary for target match are: ['aux_to', 'cop_be', 'det_a', 'xcompI_seemed', 'partmod_made']
Top most similar embeddings: match 0.02894	tie 0.02040	compliment 0.02030	walkover 0.02018	bookend 0.01988	cross-breed 0.01969	match-up 0.01969	holograph 0.01963	suit 0.01963	fixture 0.01960

Generated lemmatized results
***************
GENERATED	match.n 679 ::: tie;compliment;walkover;bookend;holograph;suit;fixture;clash;compromise;mistake

Filtered results
***************
RANKED	match.n 679	fit 0.01901	contest 0.01801	correlation 0.01636	rival 0.01620	choice 0.01582	game 0.01539	link 0.01532	hit 0.01508	pairing 0.01472	bout 0.01371	competitor 0.01360	equivalent 0.01347	marriage 0.01320	equal 0.01293	event 0.01282	couple 0.01279	matchstick 0.01252	counterpart 0.01227	competition 0.01200	correspondence 0.01091	partnership 0.01077	association 0.00885

Test context:
***************
match.n	680	3	finding a best __match__ includes : responding to the infant 's needs appropriately and as soon as possible .
Contexts for target match are: ['det_a', 'amod_best', 'dobjI_finding']
Contexts in vocabulary for target match are: ['det_a', 'amod_best', 'dobjI_finding']
Top most similar embeddings: match 0.12663	matches 0.09888	googlewhack 0.08867	match-up 0.08768	solution 0.08672	hairstylist 0.08628	mortage 0.08621	rematch 0.08608	game 0.08591	landing-place 0.08562

Generated lemmatized results
***************
GENERATED	match.n 680 ::: googlewhack;solution;hairstylist;mortage;rematch;game;babysitter;childcarer;cure;way

Filtered results
***************
RANKED	match.n 680	game 0.08591	correlation 0.07901	contest 0.07899	fit 0.07585	bout 0.07294	choice 0.07154	pairing 0.07081	rival 0.06999	competitor 0.06921	competition 0.06902	counterpart 0.06542	event 0.06512	link 0.06388	partnership 0.06381	marriage 0.06371	couple 0.06316	correspondence 0.06246	matchstick 0.05876	hit 0.05839	equivalent 0.05735	equal 0.05463	association 0.05182

Test context:
***************
mood.n	681	22	these abnormally intense moods may last for days , weeks , or months and are often separated by periods of fairly normal __moods__ .
Contexts for target moods are: ['amod_normal', 'prep:ofI_periods']
Contexts in vocabulary for target moods are: ['amod_normal', 'prep:ofI_periods']
Top most similar embeddings: moods 0.23336	menses 0.20216	torpor 0.19814	wakefulness 0.19368	mood 0.19245	decrepitude 0.17834	quiescence 0.17756	emotions 0.17719	vocalisation 0.17680	micturition 0.17648

Generated lemmatized results
***************
GENERATED	mood.n 681 ::: menses;torpor;wakefulness;decrepitude;quiescence;emotion;vocalisation;micturition;tiredness;tide

Filtered results
***************
RANKED	mood.n 681	feeling 0.16290	tone 0.15898	temperament 0.15830	demeanour 0.15517	timbre 0.15471	humour 0.15443	temper 0.15375	attitude 0.15117	mode 0.15077	atmosphere 0.14739	outlook 0.14666	manner 0.14623	disposition 0.14484	vibe 0.14141	mindset 0.14106	ambience 0.14006	modality 0.13993	form 0.12419

Test context:
***************
mood.n	682	9	which scenes are most pivotal in conveying such a __mood__ ?
Contexts for target mood are: ['predet_such', 'det_a', 'dobjI_conveying']
Contexts in vocabulary for target mood are: ['predet_such', 'det_a', 'dobjI_conveying']
Top most similar embeddings: mood 0.13315	atmosphere 0.09613	undertone 0.09428	paroxysm 0.09417	ambience 0.09411	vibe 0.09346	sentiment 0.09308	ambiance 0.09287	mind-set 0.09165	tone 0.09161

Generated lemmatized results
***************
GENERATED	mood.n 682 ::: atmosphere;undertone;paroxysm;ambience;vibe;sentiment;ambiance;tone;attitude;piquancy

Filtered results
***************
RANKED	mood.n 682	atmosphere 0.09613	ambience 0.09411	vibe 0.09346	tone 0.09161	attitude 0.09131	feeling 0.08792	temperament 0.08468	demeanour 0.08356	mindset 0.08296	disposition 0.08293	temper 0.08109	timbre 0.07696	manner 0.07647	outlook 0.07413	humour 0.07086	modality 0.06723	mode 0.06693	form 0.06259

Test context:
***************
mood.n	683	8	" " trying to take away my good __mood__ .
Contexts for target mood are: ['poss_my', 'amod_good', 'dobjI_take']
Contexts in vocabulary for target mood are: ['poss_my', 'amod_good', 'dobjI_take']
Top most similar embeddings: mood 0.12402	moods 0.09791	opinon 0.09466	mynde 0.09302	lunchbreak 0.09129	temper 0.09048	iudgement 0.09031	minde 0.08942	attitude 0.08727	oppinion 0.08670

Generated lemmatized results
***************
GENERATED	mood.n 683 ::: opinon;mynde;lunchbreak;temper;iudgement;minde;attitude;oppinion;missis;tone

Filtered results
***************
RANKED	mood.n 683	temper 0.09048	attitude 0.08727	tone 0.08568	temperament 0.08395	feeling 0.08391	vibe 0.08220	demeanour 0.07950	manner 0.07651	humour 0.07512	atmosphere 0.07359	disposition 0.07297	outlook 0.07297	mindset 0.07101	ambience 0.07012	form 0.06533	mode 0.06249	timbre 0.06197	modality 0.05445

Test context:
***************
mood.n	684	33	3. there are a number of verb-preposition combinations which are formally like " add on " but have the meaning " of continuing or resuming an action " when used in the imperative __mood__ .
Contexts for target mood are: ['det_the', 'amod_imperative', 'prep:inI_used']
Contexts in vocabulary for target mood are: ['det_the', 'amod_imperative', 'prep:inI_used']
Top most similar embeddings: mood 0.12863	moods 0.08979	tone 0.08616	context 0.08452	mode 0.08401	ambiance 0.08371	atmosphere 0.08309	subjunctive 0.08186	minibuffer 0.08177	conjuncture 0.08161

Generated lemmatized results
***************
GENERATED	mood.n 684 ::: tone;context;mode;ambiance;atmosphere;subjunctive;minibuffer;conjuncture;tense;combinator

Filtered results
***************
RANKED	mood.n 684	tone 0.08616	mode 0.08401	atmosphere 0.08309	manner 0.07842	modality 0.07659	ambience 0.07536	humour 0.07432	mindset 0.07366	form 0.07197	temperament 0.07087	attitude 0.07052	timbre 0.06956	demeanour 0.06912	outlook 0.06797	vibe 0.06696	disposition 0.06663	feeling 0.06449	temper 0.06429

Test context:
***************
mood.n	685	5	i was in a writing __mood__ , had a sharp pencil and a piece of paper and so i wrote out my thoughts .
Contexts for target mood are: ['det_a', 'amod_writing', 'prep:inI_was']
Contexts in vocabulary for target mood are: ['det_a', 'amod_writing', 'prep:inI_was']
Top most similar embeddings: mood 0.13798	habit 0.09207	tone 0.09101	tizzy 0.09038	rut 0.08864	undertone 0.08726	paroxysm 0.08637	frame 0.08569	style 0.08557	stupor 0.08523

Generated lemmatized results
***************
GENERATED	mood.n 685 ::: habit;tone;tizzy;rut;undertone;paroxysm;frame;style;stupor;tailspin

Filtered results
***************
RANKED	mood.n 685	tone 0.09101	temper 0.08223	atmosphere 0.08132	mindset 0.07862	mode 0.07795	attitude 0.07717	demeanour 0.07577	temperament 0.07472	ambience 0.07163	vibe 0.07133	manner 0.07088	humour 0.07025	outlook 0.07009	form 0.06845	disposition 0.06832	feeling 0.06809	timbre 0.06774	modality 0.06358

Test context:
***************
mood.n	686	19	in the room was perhaps 10 teachers , all friends and colleagues , when the director walked in the __mood__ stiffened .
Contexts for target mood are: ['det_the', 'prep:inI_walked']
Contexts in vocabulary for target mood are: ['det_the', 'prep:inI_walked']
Top most similar embeddings: mood 0.25170	semi-darkness 0.20766	gloaming 0.20544	afternoone 0.19495	half-light 0.19365	firelight 0.18982	dimness 0.18942	moods 0.18634	lamplight 0.18535	heavenlies 0.18452

Generated lemmatized results
***************
GENERATED	mood.n 686 ::: gloaming;afternoone;firelight;dimness;lamplight;heavenlies;gloom;endzone;footwell;spirit

Filtered results
***************
RANKED	mood.n 686	tone 0.17634	atmosphere 0.17615	ambience 0.16927	demeanour 0.16223	vibe 0.15975	attitude 0.15867	mindset 0.15755	temper 0.15725	temperament 0.15340	humour 0.15257	manner 0.15070	feeling 0.15008	mode 0.14378	disposition 0.14067	outlook 0.14041	form 0.13439	timbre 0.13213	modality 0.13202

Test context:
***************
mood.n	687	33	" and , of course , " he went on to say , " the teacher should demonstrate vibratos of various widths and speeds and their application to music of various styles and __moods__ .
Contexts for target moods are: ['conjI_styles']
Contexts in vocabulary for target moods are: ['conjI_styles']
Top most similar embeddings: moods 0.56065	styles 0.41431	tonalities 0.40150	voicings 0.40077	tempos 0.39959	timbres 0.39907	rhythms 0.39047	emotions 0.38920	sub-genres 0.38637	textures 0.38557

Generated lemmatized results
***************
GENERATED	mood.n 687 ::: style;tonality;voicing;tempo;timbre;rhythm;emotion;texture;genre;ragas

Filtered results
***************
RANKED	mood.n 687	timbre 0.39907	temperament 0.37682	tone 0.35660	feeling 0.35156	attitude 0.34957	outlook 0.34937	mindset 0.34861	disposition 0.34387	mode 0.33857	humour 0.33680	atmosphere 0.33534	ambience 0.33332	vibe 0.33199	modality 0.32697	manner 0.32618	temper 0.32002	demeanour 0.31746	form 0.30394

Test context:
***************
mood.n	688	25	choose your support person carefully - they must be fully supportive of your choice and not easily freaked out - kids will pick up the __moods__ of those around them .
Contexts for target moods are: ['det_the', 'dobjI_pick', 'prep:of_those']
Contexts in vocabulary for target moods are: ['det_the', 'dobjI_pick', 'prep:of_those']
Top most similar embeddings: moods 0.11569	mood 0.09650	emotions 0.09168	heartstrings 0.09123	foibles 0.09094	whims 0.09087	nomber 0.08997	peccadilloes 0.08993	caprices 0.08990	feelings 0.08803

Generated lemmatized results
***************
GENERATED	mood.n 688 ::: emotion;heartstrings;foible;whim;nomber;peccadillo;caprice;feeling;nuance;sensibility

Filtered results
***************
RANKED	mood.n 688	feeling 0.08803	humour 0.08415	temperament 0.08210	tone 0.08001	mindset 0.07885	timbre 0.07716	vibe 0.07666	attitude 0.07620	disposition 0.07530	temper 0.07528	demeanour 0.07186	ambience 0.07165	manner 0.07124	outlook 0.07112	atmosphere 0.06815	mode 0.06321	form 0.06144	modality 0.06115

Test context:
***************
mood.n	689	24	aroma enters through the olfactory nerve directly to our brain - to the hypothalamus which controls the subjective response from memories , feelings and __moods__ , triggering the limbic system to signal the release of neurotransmitters .
Contexts for target moods are: ['conjI_memories']
Contexts in vocabulary for target moods are: ['conjI_memories']
Top most similar embeddings: moods 0.52958	emotions 0.41445	feelings 0.40648	mood 0.39150	forebodings 0.38752	fascinations 0.38390	thoughts 0.38331	yearnings 0.38287	imaginings 0.38246	longings 0.38058

Generated lemmatized results
***************
GENERATED	mood.n 689 ::: emotion;feeling;foreboding;fascination;thought;yearning;imaginings;longing;revery;anticipation

Filtered results
***************
RANKED	mood.n 689	feeling 0.40648	disposition 0.35016	humour 0.34477	temper 0.34354	temperament 0.34288	attitude 0.34229	timbre 0.34045	outlook 0.33263	atmosphere 0.33086	vibe 0.32888	mindset 0.32703	ambience 0.32203	tone 0.31462	manner 0.31367	demeanour 0.30459	mode 0.29439	modality 0.28868	form 0.26573

Test context:
***************
mood.n	690	13	the verb is inflected to show person , number , tense , and __mood__ ; and the subjunctive is frequently used .
Contexts for target mood are: ['conjI_person']
Contexts in vocabulary for target mood are: ['conjI_person']
Top most similar embeddings: mood 0.46452	moods 0.34514	demeanor 0.33730	tone 0.33247	demeanour 0.33240	spirit 0.33231	feelings 0.32626	atmosphere 0.32560	temperament 0.32469	conciousness 0.32199

Generated lemmatized results
***************
GENERATED	mood.n 690 ::: demeanor;tone;demeanour;spirit;feeling;atmosphere;temperament;conciousness;situation;personality

Filtered results
***************
RANKED	mood.n 690	tone 0.33247	demeanour 0.33240	feeling 0.32626	atmosphere 0.32560	temperament 0.32469	ambience 0.31956	attitude 0.31929	disposition 0.31173	vibe 0.31064	temper 0.30867	mindset 0.30501	manner 0.30329	outlook 0.29861	modality 0.28212	humour 0.28189	mode 0.27855	timbre 0.27307	form 0.25219

Test context:
***************
phone.n	691	4	do n't forget my __phone__ number , javier .
Contexts for target phone are: ['nnI_number']
Contexts in vocabulary for target phone are: ['nnI_number']
Top most similar embeddings: phone 0.55135	telephone 0.47981	randy_adams 0.44450	free-phone 0.43679	n.i.e. 0.43456	michael_bachman 0.43013	freefone 0.42974	slothbert 0.42930	manosludge 0.42866	jeff_whiteaker 0.42457

Generated lemmatized results
***************
GENERATED	phone.n 691 ::: telephone;freefone;slothbert;manosludge;eudract;bigbud;imei;fone;cwatters;videophone

Filtered results
***************
RANKED	phone.n 691	telephone 0.47981	handset 0.38979	mobile 0.36601	telecom 0.30843	telecommunication 0.29937	cellular 0.29304	phoneme 0.27475	speech 0.25087	sound 0.24059

Test context:
***************
phone.n	692	7	periodically , they would bring over their __phone__ bills and lott would reimburse them out of his own pocket--either in cash or by check .
Contexts for target phone are: ['nnI_bills']
Contexts in vocabulary for target phone are: ['nnI_bills']
Top most similar embeddings: phone 0.53367	telephone 0.44940	cellphone 0.41118	phones 0.38876	landline 0.38415	videophone 0.38327	fone 0.38183	handset 0.38111	credit-card 0.37723	mobile-phone 0.37384

Generated lemmatized results
***************
GENERATED	phone.n 692 ::: telephone;cellphone;landline;videophone;fone;handset;skypeout;voicemail;mobile;phonecard

Filtered results
***************
RANKED	phone.n 692	telephone 0.44940	handset 0.38111	mobile 0.35495	telecom 0.33917	telecommunication 0.31862	cellular 0.28740	speech 0.25385	phoneme 0.24198	sound 0.23417

Test context:
***************
phone.n	693	5	one end connects to your __phone__ and the other to your internet connection .
Contexts for target phone are: ['poss_your', 'prep:toI_connects', 'cc_and', 'conj_other']
Contexts in vocabulary for target phone are: ['poss_your', 'prep:toI_connects', 'cc_and', 'conj_other']
Top most similar embeddings: phone 0.05583	cellphone 0.04929	landline 0.04886	voice-mail 0.04762	handset 0.04670	pc/laptop 0.04667	pabx 0.04626	mobiles 0.04603	laptop 0.04583	voicemail 0.04567

Generated lemmatized results
***************
GENERATED	phone.n 693 ::: cellphone;landline;handset;pabx;mobile;laptop;voicemail;staffmail;pda;pbx

Filtered results
***************
RANKED	phone.n 693	handset 0.04670	mobile 0.04603	telephone 0.04405	telecom 0.03493	cellular 0.03333	telecommunication 0.03258	speech 0.02767	phoneme 0.02533	sound 0.02448

Test context:
***************
phone.n	694	37	for example , american versus australian versus british pronounciation every phrase book , dictionary , guide book , tutorial , or western text uses a different transliteration scheme further complicating matters is the fact that the " __phone__ " or sound of a thai consonant depends on whether it appears in the beginning ( " initial " ) or ending ( " final " ) position of a syllable .
Contexts for target phone are: ['det_the', "punct_''", 'nsubjI_depends', "punct_''", 'cc_or', 'conj_sound', 'prep:of_consonant']
Contexts in vocabulary for target phone are: ['det_the', 'nsubjI_depends', 'cc_or', 'conj_sound']
Top most similar embeddings: phone 0.05027	handset 0.04169	videophone 0.04156	d600 0.04107	loudness 0.04092	t610 0.04089	telephone 0.03944	digibox 0.03942	hdp 0.03932	camcorder 0.03902

Generated lemmatized results
***************
GENERATED	phone.n 694 ::: handset;videophone;loudness;telephone;digibox;hdp;camcorder;smartphone;beeper;fone

Filtered results
***************
RANKED	phone.n 694	handset 0.04169	telephone 0.03944	phoneme 0.03461	mobile 0.03405	sound 0.03253	speech 0.03024	telecommunication 0.02967	telecom 0.02681	cellular 0.02547

Test context:
***************
phone.n	695	39	elementary " units " ( i.e. , speech segments ) are , for example , phones ( a vowel or a consonant ) , or phone-to-phone transitions ( " diphones " ) that encompass the second half of one __phone__ plus the first half of the next phone ( e.g. , a vowel-to-consonant transition ) .
Contexts for target phone are: ['num_one', 'prep:ofI_half']
Contexts in vocabulary for target phone are: ['num_one', 'prep:ofI_half']
Top most similar embeddings: phone 0.21085	fone 0.18013	cellphone 0.17496	handset 0.17462	phones 0.16674	rfr 0.16257	carucate 0.16252	ruble 0.16187	landline 0.16157	year 0.16134

Generated lemmatized results
***************
GENERATED	phone.n 695 ::: fone;cellphone;handset;rfr;carucate;ruble;landline;year;telephone;virgate

Filtered results
***************
RANKED	phone.n 695	handset 0.17462	telephone 0.16087	mobile 0.15639	phoneme 0.13888	speech 0.12759	telecom 0.12680	cellular 0.12581	sound 0.11599	telecommunication 0.11519

Test context:
***************
phone.n	696	9	" musharraf himself even called me on my cell __phone__ " to apologize .
Contexts for target phone are: ['poss_my', 'nn_cell', 'prep:onI_called']
Contexts in vocabulary for target phone are: ['poss_my', 'nn_cell', 'prep:onI_called']
Top most similar embeddings: phone 0.13832	cellphone 0.11228	phones 0.09788	fone 0.09171	telephone 0.09136	t610 0.09132	voicemail 0.09130	landline 0.09047	handset 0.09012	cell-phone 0.08839

Generated lemmatized results
***************
GENERATED	phone.n 696 ::: cellphone;fone;telephone;voicemail;landline;handset;mobile;pager;videophone;laptop

Filtered results
***************
RANKED	phone.n 696	telephone 0.09136	handset 0.09012	mobile 0.08739	telecom 0.06410	telecommunication 0.06168	cellular 0.05995	speech 0.05679	phoneme 0.05067	sound 0.04683

Test context:
***************
phone.n	697	45	here we have word labels ( time markings for the end of words ) , tone labels ( symbolic representations of the " melody " of the utterance , here in the tobi standard , [ 8 ] ) , syllable and stress labels , __phone__ labels ( see above ) , and break indices ( that distinguish between breaks between words , sub-phrases , and sentences , for example ) .
Contexts for target phone are: ['nnI_labels']
Contexts in vocabulary for target phone are: ['nnI_labels']
Top most similar embeddings: phone 0.47997	telephone 0.40049	cellphone 0.37638	bar-code 0.37172	videophone 0.36402	fone 0.36384	handset 0.36318	mobile-phone 0.36277	phones 0.36262	cell-phone 0.35492

Generated lemmatized results
***************
GENERATED	phone.n 697 ::: telephone;cellphone;videophone;fone;handset;sazo;phonecard;dect;audiovox;starline

Filtered results
***************
RANKED	phone.n 697	telephone 0.40049	handset 0.36318	mobile 0.33787	cellular 0.29434	telecommunication 0.29395	phoneme 0.28511	telecom 0.28470	speech 0.26273	sound 0.25599

Test context:
***************
phone.n	698	15	a : always talk to a lawyer before contacting the ins ( even on the __phone__ ) .
Contexts for target phone are: ['det_the', 'prep:onI_ins']
Contexts in vocabulary for target phone are: ['det_the']
Top most similar embeddings: phone 0.50166	telephone 0.41272	p990i 0.40315	p910i 0.39785	videophone 0.39641	w550i 0.39634	z1010 0.39552	handset 0.39544	m600i 0.39459	3510i 0.39439

Generated lemmatized results
***************
GENERATED	phone.n 698 ::: telephone;videophone;handset;cellphone;fone;otherhand;pebl;mediamvp;jasjar;livebox

Filtered results
***************
RANKED	phone.n 698	telephone 0.41272	handset 0.39544	mobile 0.34102	speech 0.32381	telecom 0.29339	phoneme 0.29236	telecommunication 0.28772	sound 0.28160	cellular 0.27334

Test context:
***************
phone.n	699	23	as long as the phones keep ringing ( which they do nearly all the time ) we do n't think much about the __phone__ company .
Contexts for target phone are: ['nnI_company']
Contexts in vocabulary for target phone are: ['nnI_company']
Top most similar embeddings: phone 0.51094	telephone 0.43475	mobile-phone 0.40535	shobana 0.40362	usthe 0.40054	cellphone 0.39262	lifecoaching 0.38296	credit-card 0.37758	uksbd 0.37618	phones 0.37614

Generated lemmatized results
***************
GENERATED	phone.n 699 ::: telephone;shobana;usthe;cellphone;lifecoaching;uksbd;audiovox;handset;fone;catv

Filtered results
***************
RANKED	phone.n 699	telephone 0.43475	handset 0.37292	mobile 0.35890	telecom 0.34561	telecommunication 0.34332	cellular 0.30414	sound 0.26015	speech 0.25596	phoneme 0.25498

Test context:
***************
phone.n	700	14	we were not able to travel in the weather , and there was no __phone__ .
Contexts for target phone are: ['det_no', 'nsubjI_was']
Contexts in vocabulary for target phone are: ['det_no', 'nsubjI_was']
Top most similar embeddings: phone 0.21646	qualm 0.18233	fone 0.17860	telephone 0.17625	let-up 0.17476	sympathie 0.17274	harme 0.17017	keyholder 0.16787	chimenea 0.16725	noice 0.16660

Generated lemmatized results
***************
GENERATED	phone.n 700 ::: qualm;fone;telephone;sympathie;harme;keyholder;chimenea;noice;pretence;misgiving

Filtered results
***************
RANKED	phone.n 700	telephone 0.17625	handset 0.16160	mobile 0.15170	sound 0.13332	speech 0.12738	phoneme 0.12671	telecom 0.12633	telecommunication 0.12387	cellular 0.11360

Test context:
***************
post.n	701	3	however , both __posts__ include a one-year hand over period and consequently the elections need to be held one year in advance of the end of their terms .
Contexts for target posts are: ['det_both', 'nsubjI_include']
Contexts in vocabulary for target posts are: ['det_both', 'nsubjI_include']
Top most similar embeddings: posts 0.23969	postions 0.17528	positions 0.17345	co-options 0.17192	subspecialties 0.16930	intiatives 0.16904	roles 0.16718	professorships 0.16634	racedays 0.16610	mini-pupillages 0.16604

Generated lemmatized results
***************
GENERATED	post.n 701 ::: postions;position;subspecialties;intiatives;role;professorship;racedays;timeslots;subtopics;charsets

Filtered results
***************
RANKED	post.n 701	position 0.17345	role 0.16718	appointment 0.16404	job 0.15254	upright 0.15232	station 0.14835	situation 0.14809	employment 0.14754	announcement 0.14599	marker 0.14475	message 0.14428	crossing 0.14232	target 0.14004	lookout 0.13910	pole 0.13895	mail 0.13455	stake 0.13361	boundary 0.13226	fence 0.13115	date 0.12773	support 0.10560

Test context:
***************
post.n	702	13	application details closing date : friday 2 september 2005 ( applications must be __post__ marked on or before this day - no late applications can be considered .
Contexts for target post are: ['nsubj_applications', 'aux_must', 'cop_be', 'depI_date', 'amod_marked', 'punct_-', 'dep_considered', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target post are: ['nsubj_applications', 'aux_must', 'cop_be', 'depI_date', 'amod_marked', 'punct_-', 'dep_considered', 'punct_.']
Top most similar embeddings: postmarked 0.00197	time-stamped 0.00194	post 0.00190	re-submitted 0.00188	pre-booked 0.00187	negotiable 0.00183	pro-rated 0.00180	anonymous 0.00177	typewritten 0.00177	rsvp 0.00173

Generated lemmatized results
***************
GENERATED	post.n 702 ::: postmarked;negotiable;anonymous;typewritten;rsvp;publicised;literate;subject;moderated;cached

Filtered results
***************
RANKED	post.n 702	mail 0.00126	date 0.00123	target 0.00116	message 0.00110	upright 0.00110	marker 0.00109	pole 0.00104	position 0.00104	appointment 0.00103	boundary 0.00102	announcement 0.00101	job 0.00096	stake 0.00094	crossing 0.00092	fence 0.00089	support 0.00088	lookout 0.00088	employment 0.00087	role 0.00084	situation 0.00078	station 0.00066

Test context:
***************
post.n	703	4	so i put fence __posts__ all the way around the clearing .
Contexts for target posts are: ['nn_fence', 'dobjI_put']
Contexts in vocabulary for target posts are: ['nn_fence', 'dobjI_put']
Top most similar embeddings: posts 0.24652	palings 0.17629	fences 0.17058	fence 0.16873	post 0.16794	uprights 0.16435	trellis 0.16271	krabs 0.16240	bollards 0.16233	barricades 0.16179

Generated lemmatized results
***************
GENERATED	post.n 703 ::: paling;fence;upright;trellis;krabs;bollard;barricade;blinder;waymarkers;slat

Filtered results
***************
RANKED	post.n 703	fence 0.17058	upright 0.16435	position 0.15379	pole 0.15232	marker 0.14994	stake 0.14928	lookout 0.14671	job 0.14127	crossing 0.14082	boundary 0.13837	appointment 0.13338	date 0.13270	message 0.13267	station 0.12892	situation 0.12629	role 0.12596	employment 0.12399	mail 0.12399	announcement 0.12300	target 0.11897	support 0.10343

Test context:
***************
post.n	704	8	and i put a second rail around the __posts__ .
Contexts for target posts are: ['det_the', 'prep:aroundI_put']
Contexts in vocabulary for target posts are: ['det_the', 'prep:aroundI_put']
Top most similar embeddings: posts 0.22257	uprights 0.17690	doorframe 0.17527	cross-bar 0.17423	palings 0.17300	grindstone 0.17251	goolies 0.17179	forestay 0.17112	side-netting 0.17092	breastbone 0.17044

Generated lemmatized results
***************
GENERATED	post.n 704 ::: upright;doorframe;paling;grindstone;goolies;forestay;breastbone;glans;exclosure;stanchion

Filtered results
***************
RANKED	post.n 704	upright 0.17690	position 0.15736	pole 0.15732	fence 0.15709	stake 0.14975	station 0.14276	message 0.14239	lookout 0.14208	boundary 0.14164	role 0.14012	marker 0.13806	date 0.13627	situation 0.13505	job 0.13478	appointment 0.13375	target 0.13339	mail 0.13190	announcement 0.13087	crossing 0.12663	employment 0.12149	support 0.10645

Test context:
***************
post.n	705	14	received 2 the other day from the aura mansfield to buller ultra in the __post__ at no charge .
Contexts for target post are: ['det_the', 'prep:inI_received']
Contexts in vocabulary for target post are: ['det_the', 'prep:inI_received']
Top most similar embeddings: post 0.25287	hot-seat 0.18820	t&a 0.18252	afternoone 0.18144	countie 0.17788	mid-fifties 0.17480	1550s 0.17465	sin-bin 0.17282	mid-seventies 0.17250	senate-house 0.17245

Generated lemmatized results
***************
GENERATED	post.n 705 ::: afternoone;countie;mail;consulship;mailbag;furture;moluccas;pastorate;guardroom;scco

Filtered results
***************
RANKED	post.n 705	mail 0.17036	role 0.14930	position 0.14778	job 0.14733	stake 0.14724	appointment 0.14479	employment 0.13900	fence 0.13833	announcement 0.13829	message 0.13791	situation 0.13646	station 0.13361	upright 0.13038	lookout 0.12792	support 0.12758	target 0.12647	boundary 0.12627	pole 0.12251	date 0.12124	marker 0.11953	crossing 0.11494

Test context:
***************
post.n	706	14	26/8/2004 base jumping goodness filed in : sport by reevo | link to this __post__ | comments ( 0 ) there 's nothing quite like spending ten minutes watching base jumpers doing their thing all around the world , check them out , you wont regret it .
Contexts for target post are: ['det_this', 'prep:toI_link']
Contexts in vocabulary for target post are: ['det_this', 'prep:toI_link']
Top most similar embeddings: post 0.25893	e-brochure 0.18256	webite 0.18041	moblog 0.18032	webpage 0.17928	page 0.17651	blog 0.17388	sub-site 0.17376	artical 0.17368	posting 0.17364

Generated lemmatized results
***************
GENERATED	post.n 706 ::: webite;moblog;webpage;page;blog;artical;posting;article;site;webinar

Filtered results
***************
RANKED	post.n 706	mail 0.14940	announcement 0.14102	message 0.14035	appointment 0.13965	job 0.13955	station 0.13912	role 0.13764	position 0.13515	target 0.13358	situation 0.13102	marker 0.12969	date 0.12848	boundary 0.12719	fence 0.12666	stake 0.12303	upright 0.12125	employment 0.12060	pole 0.11991	lookout 0.11554	crossing 0.11552	support 0.11318

Test context:
***************
post.n	707	18	pro centre manager the board for this post had taken place and the successful applicant would be in __post__ in november .
Contexts for target post are: ['prep:inI_be', 'prep:in_november']
Contexts in vocabulary for target post are: ['prep:inI_be', 'prep:in_november']
Top most similar embeddings: post 0.21934	hot-seat 0.15494	posting 0.15293	hotseat 0.15244	drydock 0.15145	euro-elections 0.15116	dry-dock 0.15067	semi-retirement 0.14700	attendence 0.14680	reconvening 0.14657

Generated lemmatized results
***************
GENERATED	post.n 707 ::: posting;hotseat;drydock;attendence;reconvening;gothenburg;abeyance;consulship;position;abuja

Filtered results
***************
RANKED	post.n 707	position 0.14462	appointment 0.13984	mail 0.13671	stake 0.13156	announcement 0.12766	job 0.12729	situation 0.12502	role 0.12481	employment 0.12403	fence 0.11907	date 0.11412	target 0.11163	upright 0.11140	station 0.11127	crossing 0.10999	message 0.10968	support 0.10796	pole 0.10592	boundary 0.10538	marker 0.10265	lookout 0.10244

Test context:
***************
post.n	708	12	it 's becoming really frustrating and they keep on moving the goal __post__ with regard to what they require as security .
Contexts for target post are: ['det_the', 'nn_goal', 'dobjI_moving']
Contexts in vocabulary for target post are: ['det_the', 'nn_goal', 'dobjI_moving']
Top most similar embeddings: post 0.12039	goalposts 0.08493	posts 0.08211	hot-seat 0.08209	goalpost 0.08188	side-netting 0.08134	cue-ball 0.08057	crossbar 0.08019	cross-bar 0.07970	object-ball 0.07862

Generated lemmatized results
***************
GENERATED	post.n 708 ::: goalpost;crossbar;gangplank;leaderboard;keeper;handstick;stanchion;crosshairs;line;postion

Filtered results
***************
RANKED	post.n 708	mail 0.07639	position 0.07616	stake 0.07382	fence 0.07362	boundary 0.07290	target 0.07207	upright 0.07150	marker 0.07138	job 0.06751	pole 0.06746	situation 0.06647	appointment 0.06600	role 0.06589	message 0.06565	announcement 0.06467	employment 0.06231	station 0.06117	date 0.06008	lookout 0.05930	crossing 0.05845	support 0.05226

Test context:
***************
post.n	709	2	a consultants __post__ , with a special interest in otology at st georges hospital was advertised in february .
Contexts for target post are: ['det_a', 'nn_consultants', 'nsubjpassI_advertised', 'punct_,', 'prep:with_interest']
Contexts in vocabulary for target post are: ['det_a', 'nn_consultants', 'nsubjpassI_advertised', 'punct_,', 'prep:with_interest']
Top most similar embeddings: post 0.02595	lectureship 0.01926	professorship 0.01856	diabetologist 0.01821	vacancy 0.01807	neurologist 0.01798	radiographer 0.01785	engineer 0.01767	dietitian 0.01764	histopathologist 0.01748

Generated lemmatized results
***************
GENERATED	post.n 709 ::: lectureship;professorship;diabetologist;vacancy;neurologist;radiographer;engineer;dietitian;histopathologist;lecturership

Filtered results
***************
RANKED	post.n 709	appointment 0.01633	job 0.01584	position 0.01518	role 0.01496	mail 0.01284	announcement 0.01276	lookout 0.01264	target 0.01246	stake 0.01223	date 0.01220	upright 0.01213	message 0.01168	situation 0.01166	marker 0.01160	employment 0.01156	fence 0.01131	crossing 0.01106	boundary 0.01078	station 0.01075	pole 0.01001	support 0.00956

Test context:
***************
post.n	710	8	the next morning we arrived at the border __post__ at 7:30 .
Contexts for target post are: ['det_the', 'nn_border', 'prep:atI_arrived']
Contexts in vocabulary for target post are: ['det_the', 'nn_border', 'prep:atI_arrived']
Top most similar embeddings: post 0.12343	guardroom 0.09072	checkpoint 0.08876	trailhead 0.08705	roadhead 0.08671	kraal 0.08510	hot-seat 0.08456	foundery 0.08451	chancellery 0.08427	cosmodrome 0.08327

Generated lemmatized results
***************
GENERATED	post.n 710 ::: guardroom;checkpoint;trailhead;roadhead;kraal;foundery;chancellery;cosmodrome;buscentre;guardhouse

Filtered results
***************
RANKED	post.n 710	fence 0.08122	station 0.07597	boundary 0.07451	position 0.07395	mail 0.07253	stake 0.07056	crossing 0.07048	situation 0.06893	appointment 0.06890	pole 0.06791	upright 0.06709	marker 0.06590	lookout 0.06582	job 0.06457	message 0.06260	announcement 0.06212	role 0.06080	target 0.05949	date 0.05885	employment 0.05743	support 0.04726

Test context:
***************
pound.n	711	12	mr cleary recalled flour being 10 pounds per bag and 3d per __pound__ for beef when the line was being built .
Contexts for target pound are: ['prep:perI_3d']
Contexts in vocabulary for target pound are: []
Top most similar embeddings: pound 1.00000	dollar 0.81304	pounds 0.77493	ruble 0.74985	shekel 0.73178	rupee 0.72860	zloty 0.72393	rouble 0.72319	drachma 0.72227	krona 0.72129

Generated lemmatized results
***************
GENERATED	pound.n 711 ::: dollar;ruble;shekel;rupee;zloty;rouble;drachma;krona;penny;peso

Filtered results
***************
RANKED	pound.n 711	dollar 0.81304	kilo 0.70808	kilogram 0.70382	sterling 0.69745	quid 0.68970	lb 0.64944	thump 0.61077	throb 0.61046	weight 0.59943	prison 0.59389	beat 0.59196	kennel 0.58310	lot 0.57825	cage 0.57726	store 0.57387	enclosure 0.56212	hammer 0.56097	pn 0.55520

Test context:
***************
pound.n	712	6	some people do gain a few __pounds__ after they stop smoking , but you do n't have to .
Contexts for target pounds are: ['det_a', 'amod_few', 'dobjI_gain']
Contexts in vocabulary for target pounds are: ['det_a', 'amod_few', 'dobjI_gain']
Top most similar embeddings: pounds 0.13271	dollars 0.10352	quid 0.09971	ducats 0.09845	kilograms 0.09715	pence 0.09537	millimetres 0.09468	pennies 0.09435	pound 0.09424	centimetres 0.09423

Generated lemmatized results
***************
GENERATED	pound.n 712 ::: dollar;quid;ducat;kilogram;penny;millimetre;centimetre;kilo;hundredweight;ounce

Filtered results
***************
RANKED	pound.n 712	dollar 0.10352	quid 0.09971	kilogram 0.09715	kilo 0.09408	lb 0.08019	weight 0.07559	sterling 0.07479	lot 0.07282	thump 0.06470	kennel 0.06122	store 0.06023	beat 0.05995	throb 0.05984	hammer 0.05783	prison 0.05426	cage 0.05375	enclosure 0.05289	pn 0.05274

Test context:
***************
pound.n	713	6	vehicles are towed to a car __pound__ and a significant fee ( up to 160 euro ) may be charged for their release .
Contexts for target pound are: ['det_a', 'nn_car', 'prep:toI_towed']
Contexts in vocabulary for target pound are: ['det_a', 'nn_car', 'prep:toI_towed']
Top most similar embeddings: pound 0.12092	scrapyard 0.09190	yard 0.08741	dollar 0.08554	lay-by 0.08529	pounds 0.08452	carpark 0.08358	gallon 0.08306	reservior 0.08260	car-park 0.08144

Generated lemmatized results
***************
GENERATED	pound.n 713 ::: scrapyard;yard;dollar;carpark;gallon;reservior;garage;standpipe;dealership;bodyshop

Filtered results
***************
RANKED	pound.n 713	dollar 0.08554	kilo 0.07519	kilogram 0.07265	quid 0.07137	lb 0.06537	store 0.06489	kennel 0.06475	enclosure 0.06333	throb 0.06310	cage 0.06273	sterling 0.06252	lot 0.06145	prison 0.06093	thump 0.06087	weight 0.06022	hammer 0.05602	beat 0.05365	pn 0.05238

Test context:
***************
pound.n	714	3	currency the cypriot __pound__ is the legal currency in cyprus .
Contexts for target pound are: ['nn_currency', 'det_the', 'nn_cypriot', 'nsubjI_currency']
Contexts in vocabulary for target pound are: ['nn_currency', 'det_the', 'nn_cypriot', 'nsubjI_currency']
Top most similar embeddings: pound 0.06825	dollar 0.06028	peso 0.05620	rupee 0.05411	rouble 0.05218	ruble 0.05176	lira 0.05028	dinar 0.05025	renminbi 0.05008	deutschmark 0.04996

Generated lemmatized results
***************
GENERATED	pound.n 714 ::: dollar;peso;rupee;rouble;ruble;lira;dinar;renminbi;deutschmark;euro

Filtered results
***************
RANKED	pound.n 714	dollar 0.06028	sterling 0.04427	kilogram 0.03608	kilo 0.03495	quid 0.03297	weight 0.02844	beat 0.02795	lb 0.02770	store 0.02687	prison 0.02680	throb 0.02668	hammer 0.02601	cage 0.02467	thump 0.02449	enclosure 0.02436	kennel 0.02420	pn 0.02268	lot 0.02045

Test context:
***************
pound.n	715	25	our test version of the gun did n't have any modifications to the trigger , but even with a trigger that broke at 5 3/4 __pounds__ it was possible to shoot decent groups .
Contexts for target pounds are: ['num_5\xc2\xa03/4', 'prep:atI_broke']
Contexts in vocabulary for target pounds are: ['prep:atI_broke']
Top most similar embeddings: pounds 0.46707	kilograms 0.37248	8lbs 0.37156	ounces 0.37141	dollars 0.37135	shillings 0.37110	10lbs 0.37009	francs 0.36412	tonnes 0.36395	kilos 0.36326

Generated lemmatized results
***************
GENERATED	pound.n 715 ::: kilogram;ounce;dollar;shilling;franc;tonne;kilo;euro;bushel;quid

Filtered results
***************
RANKED	pound.n 715	kilogram 0.37248	dollar 0.37135	kilo 0.36326	quid 0.36141	lb 0.35687	sterling 0.32425	weight 0.29155	store 0.28098	kennel 0.28026	prison 0.27286	beat 0.27144	thump 0.27131	hammer 0.26320	throb 0.25877	lot 0.25243	cage 0.25058	enclosure 0.24831	pn 0.23868

Test context:
***************
pound.n	716	2	8d. a __pound__ , and there is therefore no substance in the argument that a small advance in price would inflict hardship even on the poorer classes .
Contexts for target pound are: ['det_a', 'depI_8d', 'punct_,', 'cc_and', 'conj_is']
Contexts in vocabulary for target pound are: ['det_a', 'depI_8d', 'punct_,', 'cc_and', 'conj_is']
Top most similar embeddings: pound 0.02226	shilling 0.01928	shillings 0.01779	dollar 0.01757	messuage 0.01740	drachm 0.01732	bushel 0.01729	shekel 0.01721	denarius 0.01718	liter 0.01714

Generated lemmatized results
***************
GENERATED	pound.n 716 ::: shilling;dollar;messuage;drachm;bushel;shekel;denarius;liter;groat;halfpenny

Filtered results
***************
RANKED	pound.n 716	dollar 0.01757	kilo 0.01634	quid 0.01599	sterling 0.01583	kilogram 0.01532	thump 0.01384	lb 0.01352	beat 0.01279	throb 0.01250	weight 0.01248	hammer 0.01233	pn 0.01232	cage 0.01214	enclosure 0.01202	kennel 0.01200	lot 0.01119	store 0.01103	prison 0.01067

Test context:
***************
pound.n	717	23	minister to give army barracks multi-million pound overhaul by brian carroll security correspondent army barracks that have escaped closure will get a multi-million __pound__ overhaul .
Contexts for target pound are: ['nnI_overhaul']
Contexts in vocabulary for target pound are: ['nnI_overhaul']
Top most similar embeddings: pound 0.52318	dollar 0.40213	pounds 0.36329	ruble 0.36250	rouble 0.36126	peso 0.34828	euro 0.34753	root-and-branch 0.34166	franc 0.33940	penny 0.33917

Generated lemmatized results
***************
GENERATED	pound.n 717 ::: dollar;ruble;rouble;peso;euro;franc;penny;shekel;sterling;rupee

Filtered results
***************
RANKED	pound.n 717	dollar 0.40213	sterling 0.33685	kilo 0.32986	kilogram 0.32913	quid 0.32309	lb 0.31779	prison 0.28856	weight 0.28610	thump 0.27118	kennel 0.27056	pn 0.26957	throb 0.26394	beat 0.25995	store 0.25873	cage 0.25607	enclosure 0.25164	hammer 0.25160	lot 0.24700

Test context:
***************
pound.n	718	17	your money will be better employed and your account wo n't end up looking like the dog __pound__ .
Contexts for target pound are: ['det_the', 'nn_dog', 'prep:likeI_looking']
Contexts in vocabulary for target pound are: ['det_the', 'nn_dog', 'prep:likeI_looking']
Top most similar embeddings: pound 0.12253	dollar 0.09047	turds 0.08930	porker 0.08919	whipper 0.08904	poop 0.08573	poo 0.08544	weimaraner 0.08427	piskie 0.08418	turd 0.08398

Generated lemmatized results
***************
GENERATED	pound.n 718 ::: dollar;turd;porker;whipper;poop;poo;weimaraner;piskie;hatchling;stegosaurus

Filtered results
***************
RANKED	pound.n 718	dollar 0.09047	kilo 0.08214	kilogram 0.07747	kennel 0.07611	cage 0.07552	prison 0.07018	sterling 0.06984	throb 0.06856	enclosure 0.06826	quid 0.06653	store 0.06441	thump 0.06387	weight 0.06340	lb 0.06308	hammer 0.06228	beat 0.05820	lot 0.05478	pn 0.05131

Test context:
***************
pound.n	719	11	badger : i 'll tell you where it is for a __pound__ .
Contexts for target pound are: ['det_a', 'prep:forI_is']
Contexts in vocabulary for target pound are: ['det_a', 'prep:forI_is']
Top most similar embeddings: pound 0.24617	dollar 0.19543	pounds 0.18212	fiver 0.18158	shekel 0.18065	tenner 0.17866	rupee 0.17682	kilo 0.17672	shilling 0.17633	quid 0.17554

Generated lemmatized results
***************
GENERATED	pound.n 719 ::: dollar;fiver;shekel;tenner;rupee;kilo;shilling;quid;hundredweight;pittance

Filtered results
***************
RANKED	pound.n 719	dollar 0.19543	kilo 0.17672	quid 0.17554	kilogram 0.16998	sterling 0.15236	lot 0.14449	lb 0.14165	cage 0.13520	prison 0.13327	weight 0.13208	thump 0.13032	store 0.12915	throb 0.12776	kennel 0.12765	hammer 0.12639	enclosure 0.12605	beat 0.12118	pn 0.12034

Test context:
***************
pound.n	720	15	" he asked with a knowing smile that made her breath catch and her heart __pound__ .
Contexts for target pound are: ['poss_her', 'nn_heart', 'conjI_catch']
Contexts in vocabulary for target pound are: ['poss_her', 'nn_heart', 'conjI_catch']
Top most similar embeddings: pound 0.10601	purse 0.07867	pounds 0.07710	flutter 0.07665	flutters 0.07630	throb 0.07441	clench 0.07413	quiver 0.07344	thump 0.07309	pail 0.07296

Generated lemmatized results
***************
GENERATED	pound.n 720 ::: purse;flutter;throb;clench;quiver;thump;pail;pounding;dollar;lash

Filtered results
***************
RANKED	pound.n 720	throb 0.07441	thump 0.07309	dollar 0.07279	beat 0.06979	kilo 0.06579	lb 0.06462	weight 0.06412	kilogram 0.06194	sterling 0.06144	cage 0.06141	hammer 0.06058	prison 0.06024	kennel 0.05718	quid 0.05587	store 0.05492	enclosure 0.05280	lot 0.05025	pn 0.04485

Test context:
***************
raw.a	721	5	there was a danger of __raw__ sewage spilling from a fire-damaged sewerage plant .
Contexts for target raw are: ['amodI_spilling']
Contexts in vocabulary for target raw are: ['amodI_spilling']
Top most similar embeddings: raw 0.49294	sludgy 0.36260	unseasoned 0.36045	white-hot 0.36015	foul-smelling 0.35735	vaporous 0.35656	sweet-smelling 0.35640	floury 0.35561	putrid 0.35484	stringy 0.35434

Generated lemmatized results
***************
GENERATED	raw.a 721 ::: sludgy;unseasoned;vaporous;floury;putrid;stringy;odorous;unprocessed;yellowy;glutinous

Filtered results
***************
RANKED	raw.a 721	unprocessed 0.35258	unrefined 0.34723	uncooked 0.34617	naked 0.31374	natural 0.31198	rough 0.31030	crude 0.30696	bloody 0.30568	untreated 0.30487	uncompressed 0.30348	immature 0.29775	harsh 0.29288	unsophisticated 0.28987	undressed 0.28904	austere 0.28796	untaught 0.28484	open 0.28111	genuine 0.27574	inexperienced 0.27569	rudimentary 0.27490	basic 0.27330	exposed 0.27075	bad 0.27009	unspoilt 0.26981	refreshing 0.26218	unspun 0.25711	unfair 0.25619	excoriated 0.24079

Test context:
***************
raw.a	722	9	he proposed to reduce customs duty on apparel grade __raw__ wool from a total of 25 per cent to 20 per cent .
Contexts for target raw are: ['amodI_wool']
Contexts in vocabulary for target raw are: ['amodI_wool']
Top most similar embeddings: raw 0.53196	undyed 0.39160	locally-grown 0.39063	super-soft 0.38177	iron-rich 0.38013	locally-produced 0.37715	unseasoned 0.37523	light-coloured 0.37154	unrefined 0.36984	cellulosic 0.36974

Generated lemmatized results
***************
GENERATED	raw.a 722 ::: undyed;unseasoned;unrefined;cellulosic;supersoft;sludgy;pure;unbleached;stringy;floury

Filtered results
***************
RANKED	raw.a 722	unrefined 0.36984	unprocessed 0.35593	uncooked 0.34531	rough 0.33582	natural 0.32840	harsh 0.30788	untreated 0.30779	naked 0.30492	bloody 0.30303	crude 0.30214	uncompressed 0.30198	basic 0.30191	genuine 0.29740	undressed 0.29139	unspun 0.29082	austere 0.28373	immature 0.28194	unsophisticated 0.27957	untaught 0.27809	bad 0.27656	exposed 0.27512	open 0.27298	unspoilt 0.27296	inexperienced 0.27272	refreshing 0.27096	rudimentary 0.26651	excoriated 0.26484	unfair 0.24847

Test context:
***************
raw.a	723	4	not only is the __raw__ size of the xhtml file not shorter than the html file , but it would n't matter if it were , as they would both compress down to something about the same size .
Contexts for target raw are: ['amodI_size']
Contexts in vocabulary for target raw are: ['amodI_size']
Top most similar embeddings: raw 0.49227	ever-decreasing 0.38168	13-inch 0.37943	photo-postcard 0.37798	much-reduced 0.37212	unfeasibly 0.36490	48-bit 0.36396	unlabeled 0.36280	untrimmed 0.36141	user-specified 0.36068

Generated lemmatized results
***************
GENERATED	raw.a 723 ::: unfeasibly;unlabeled;untrimmed;unscaled;managable;lowish;uncompressed;humungous;vanishingly;multipage

Filtered results
***************
RANKED	raw.a 723	uncompressed 0.35298	unprocessed 0.34193	uncooked 0.33726	unrefined 0.32957	rough 0.32741	natural 0.31967	basic 0.31779	crude 0.31028	unsophisticated 0.29813	untreated 0.29467	naked 0.29353	genuine 0.29177	immature 0.29011	austere 0.28716	bloody 0.28706	undressed 0.28672	rudimentary 0.28487	harsh 0.28165	untaught 0.28134	bad 0.28134	inexperienced 0.27973	open 0.27172	exposed 0.27107	refreshing 0.26950	unfair 0.26710	unspoilt 0.26224	unspun 0.26220	excoriated 0.24887

Test context:
***************
raw.a	724	20	in new zealand nuts are not a major part of the diet , most often being eaten in small quantities __raw__ or as peanut butter .
Contexts for target raw are: ['amodI_quantities', 'cc_or', 'conj_as', 'conj:as_butter']
Contexts in vocabulary for target raw are: ['amodI_quantities', 'cc_or', 'conj_as']
Top most similar embeddings: raw 0.11929	singly 0.08682	indigestible 0.08615	instrumentally 0.08560	25ml 0.08523	uniaxial 0.08297	statically 0.08208	anti-a 0.08201	uncooked 0.08167	unripe 0.08137

Generated lemmatized results
***************
GENERATED	raw.a 724 ::: singly;indigestible;instrumentally;uniaxial;statically;uncooked;unripe;unprocessed;individually;transiently

Filtered results
***************
RANKED	raw.a 724	uncooked 0.08167	unprocessed 0.08134	unrefined 0.07820	uncompressed 0.07649	untreated 0.07135	crude 0.06928	rough 0.06865	immature 0.06776	natural 0.06642	unsophisticated 0.06596	untaught 0.06529	inexperienced 0.06468	basic 0.06461	naked 0.06425	harsh 0.06409	austere 0.06282	rudimentary 0.06198	genuine 0.06189	undressed 0.06158	unfair 0.05823	bloody 0.05799	bad 0.05767	refreshing 0.05744	exposed 0.05593	open 0.05380	unspoilt 0.05164	excoriated 0.04998	unspun 0.04405

Test context:
***************
raw.a	725	11	many institutional investors are now deciding that they are getting a __raw__ deal from the company boards of australia .
Contexts for target raw are: ['amodI_deal']
Contexts in vocabulary for target raw are: ['amodI_deal']
Top most similar embeddings: raw 0.53519	seven-figure 0.38209	2-for-1 0.37211	season-long 0.36546	multimillion-pound 0.35997	multi-million-pound 0.35919	alibabacom 0.35604	big-money 0.35547	multi-year 0.35103	rawer 0.35028

Generated lemmatized results
***************
GENERATED	raw.a 725 ::: alibabacom;multibillion;agreat;faustian;real;geat;fresh;rough;inital;great

Filtered results
***************
RANKED	raw.a 725	rough 0.33893	unprocessed 0.32696	uncooked 0.31913	unrefined 0.31901	crude 0.31559	uncompressed 0.30926	bad 0.30742	basic 0.30738	unsophisticated 0.30385	bloody 0.30340	harsh 0.30032	genuine 0.30025	natural 0.29869	naked 0.29857	unfair 0.28740	untaught 0.28470	rudimentary 0.28355	austere 0.28252	inexperienced 0.27899	refreshing 0.27371	immature 0.27080	untreated 0.26963	exposed 0.26939	unspun 0.26666	open 0.26296	undressed 0.26210	unspoilt 0.25940	excoriated 0.24916

Test context:
***************
raw.a	726	1	the __raw__ , natural beauty of the sinai coast is celebrated by taba heights resort 's unique architectural style , a reinterpretation of an ancient egyptian village .
Contexts for target raw are: ['amodI_beauty']
Contexts in vocabulary for target raw are: ['amodI_beauty']
Top most similar embeddings: raw 0.51911	unadulterated 0.37505	unrefined 0.37119	fathomless 0.36890	drop-dead 0.36759	earthy 0.36583	unalloyed 0.36543	otherworldly 0.36511	voluptuous 0.36362	supernal 0.36239

Generated lemmatized results
***************
GENERATED	raw.a 726 ::: unadulterated;unrefined;fathomless;earthy;unalloyed;otherworldly;voluptuous;supernal;unwonted;limpid

Filtered results
***************
RANKED	raw.a 726	unrefined 0.37119	unprocessed 0.35725	natural 0.35333	uncooked 0.33361	austere 0.32821	naked 0.32582	unsophisticated 0.32181	unspoilt 0.32057	rough 0.31772	harsh 0.31654	crude 0.31138	genuine 0.30602	basic 0.30520	uncompressed 0.30496	untaught 0.30063	untreated 0.29798	undressed 0.29170	rudimentary 0.28825	refreshing 0.28825	bloody 0.28637	immature 0.28545	bad 0.27344	unspun 0.27278	inexperienced 0.27197	exposed 0.27120	excoriated 0.26729	unfair 0.26705	open 0.26604

Test context:
***************
raw.a	727	1	the __raw__ honesty of that basic crudeness makes you feel stronger in a way .
Contexts for target raw are: ['amodI_honesty']
Contexts in vocabulary for target raw are: ['amodI_honesty']
Top most similar embeddings: raw 0.51743	unadulterated 0.37770	undisguised 0.37488	unalloyed 0.37368	unflinching 0.36913	unmitigated 0.36901	unwonted 0.36593	unvarnished 0.36293	uncompromised 0.36237	soldierly 0.35977

Generated lemmatized results
***************
GENERATED	raw.a 727 ::: unadulterated;undisguised;unalloyed;unflinching;unmitigated;unwonted;unvarnished;uncompromised;soldierly;unflagging

Filtered results
***************
RANKED	raw.a 727	unprocessed 0.34311	unrefined 0.34133	crude 0.33301	basic 0.32718	naked 0.32437	unsophisticated 0.32399	rough 0.32364	austere 0.32269	refreshing 0.31704	natural 0.31448	uncooked 0.31438	rudimentary 0.31418	genuine 0.31395	harsh 0.30945	bloody 0.30612	untaught 0.29867	uncompressed 0.29503	immature 0.29105	open 0.28564	excoriated 0.28229	exposed 0.27975	undressed 0.27968	untreated 0.27833	unspoilt 0.27677	bad 0.27634	inexperienced 0.27292	unfair 0.26970	unspun 0.26861

Test context:
***************
raw.a	728	4	" the wound was __raw__ and vicious , but at least the bleeding had seemed to have slowed , which ezra was hoping was a good sign .
Contexts for target raw are: ["punct_''", 'nsubj_wound', 'cop_was', 'rootI_*root*', 'cc_and', 'conj_vicious', 'punct_,', 'cc_but', 'conj_seemed', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target raw are: ['nsubj_wound', 'cop_was', 'rootI_*root*', 'cc_and', 'conj_vicious', 'punct_,', 'cc_but', 'conj_seemed', 'punct_.']
Top most similar embeddings: unpaved 0.00152	fitful 0.00151	morose 0.00149	inconsolable 0.00148	flighty 0.00148	ornery 0.00146	unspectacular 0.00138	over-produced 0.00138	hillarious 0.00137	yelped 0.00137

Generated lemmatized results
***************
GENERATED	raw.a 728 ::: unpaved;fitful;morose;inconsolable;flighty;ornery;unspectacular;hillarious;yelped;lethargic

Filtered results
***************
RANKED	raw.a 728	harsh 0.00118	undressed 0.00116	bloody 0.00115	rough 0.00115	unsophisticated 0.00110	immature 0.00105	austere 0.00102	refreshing 0.00099	bad 0.00098	crude 0.00098	excoriated 0.00098	unrefined 0.00092	rudimentary 0.00091	naked 0.00090	untaught 0.00088	unfair 0.00085	inexperienced 0.00084	open 0.00081	untreated 0.00073	genuine 0.00071	uncooked 0.00067	uncompressed 0.00067	exposed 0.00067	unspoilt 0.00064	natural 0.00063	unprocessed 0.00061	basic 0.00053	unspun 0.00045

Test context:
***************
raw.a	729	19	street girl is a vision of youth to come in the ' 70s and ' 80s , expressing a __raw__ anger at the world of adults , school , authority , and society .
Contexts for target raw are: ['amodI_anger']
Contexts in vocabulary for target raw are: ['amodI_anger']
Top most similar embeddings: raw 0.53380	pent-up 0.40048	undisguised 0.38700	white-hot 0.36981	unreasoning 0.36887	unadulterated 0.36870	unwonted 0.36692	all-pervading 0.36603	unbridled 0.36519	atavistic 0.36419

Generated lemmatized results
***************
GENERATED	raw.a 729 ::: undisguised;unreasoning;unadulterated;unwonted;unbridled;atavistic;overweening;unquenchable;unexpressed;wrathful

Filtered results
***************
RANKED	raw.a 729	unprocessed 0.34653	unrefined 0.33149	uncooked 0.32565	crude 0.32144	naked 0.32078	natural 0.31989	genuine 0.31787	harsh 0.31350	rough 0.30851	bloody 0.30811	unsophisticated 0.30585	untaught 0.30585	basic 0.30002	uncompressed 0.29923	immature 0.29682	austere 0.29604	untreated 0.29570	unspun 0.28676	rudimentary 0.28385	excoriated 0.28162	inexperienced 0.28119	bad 0.27972	refreshing 0.27796	undressed 0.27211	exposed 0.27163	open 0.26822	unfair 0.26496	unspoilt 0.26343

Test context:
***************
raw.a	730	16	while the image suffers in quality - the artifacts and digital noise are aplenty , the __raw__ feel to this image in fact adds to the ambience .
Contexts for target raw are: ['amodI_feel']
Contexts in vocabulary for target raw are: ['amodI_feel']
Top most similar embeddings: raw 0.52342	old-skool 0.40052	chilled-out 0.39680	dubby 0.39214	down-home 0.39088	bluesy 0.37866	earthy 0.37839	good-time 0.37818	squelchy 0.37723	folksy 0.37689

Generated lemmatized results
***************
GENERATED	raw.a 730 ::: dubby;bluesy;earthy;squelchy;folksy;druggy;grungy;sludgy;edgy;biscuity

Filtered results
***************
RANKED	raw.a 730	unrefined 0.35328	unprocessed 0.34743	rough 0.34107	natural 0.32896	uncooked 0.32604	unsophisticated 0.32172	austere 0.31926	basic 0.31869	genuine 0.31722	harsh 0.31507	untaught 0.31408	uncompressed 0.31205	crude 0.31196	unspoilt 0.30482	refreshing 0.30461	naked 0.30306	bloody 0.30124	undressed 0.30070	rudimentary 0.29843	inexperienced 0.29747	open 0.29265	untreated 0.29045	bad 0.28816	immature 0.28642	exposed 0.28312	unspun 0.26638	unfair 0.26418	excoriated 0.25442

Test context:
***************
remainder.n	731	19	if we divide any number by 4 , we would get 1 or 2 or 3 , as the __remainders__ .
Contexts for target remainders are: ['det_the', 'prep:asI_get']
Contexts in vocabulary for target remainders are: ['det_the', 'prep:asI_get']
Top most similar embeddings: remainders 0.24050	mancs 0.17598	dwarfers 0.17324	grundys 0.17045	lilim 0.17040	opposers 0.17033	inquisitors 0.16998	dustmen 0.16993	cognoscenti 0.16949	biggies 0.16886

Generated lemmatized results
***************
GENERATED	remainder.n 731 ::: mancs;dwarfers;grundys;lilim;opposer;inquisitor;dustman;cognoscenti;biggies;bailor

Filtered results
***************
RANKED	remainder.n 731	residue 0.16233	leftover 0.16200	rest 0.15812	residual 0.15531	surplus 0.14186	balance 0.13495

Test context:
***************
remainder.n	732	19	only one third of the young people questioned said that they had recently had a satiating meal. , the __remainder__ could not remember when they last had one .
Contexts for target remainder are: ['det_the', 'nsubjI_remember']
Contexts in vocabulary for target remainder are: ['det_the', 'nsubjI_remember']
Top most similar embeddings: remainder 0.22481	rest 0.19220	dwarfers 0.18246	strs 0.18080	grundys 0.18057	argives 0.17797	gopis 0.17432	groundlings 0.17220	die-hards 0.16964	mom-to-be 0.16908

Generated lemmatized results
***************
GENERATED	remainder.n 732 ::: rest;dwarfers;strs;grundys;argive;gopis;groundling;argentinian;ionian;prole

Filtered results
***************
RANKED	remainder.n 732	rest 0.19220	residue 0.13995	leftover 0.13813	balance 0.13405	residual 0.12947	surplus 0.12631

Test context:
***************
remainder.n	733	17	the majority of subjects , 90 percent , came from the metropolitan seattle area , with the __remainder__ coming from across the united states .
Contexts for target remainder are: ['det_the', 'nsubjI_coming']
Contexts in vocabulary for target remainder are: ['det_the', 'nsubjI_coming']
Top most similar embeddings: remainder 0.27364	rest 0.20872	grundys 0.20495	dwarfers 0.19819	argives 0.19816	homesters 0.19654	sontarans 0.19344	windies 0.19084	gopis 0.19047	seasiders 0.18732

Generated lemmatized results
***************
GENERATED	remainder.n 733 ::: rest;grundys;dwarfers;argive;homesters;sontarans;windies;gopis;seasiders;glazer

Filtered results
***************
RANKED	remainder.n 733	rest 0.20872	balance 0.14651	residue 0.14548	residual 0.14426	leftover 0.14360	surplus 0.14057

Test context:
***************
remainder.n	734	29	humor books , which are ephemeral , and appeal to a narrow audience , often go out of print quickly ; they are especially likely to turn up at __remainder__ houses or remainder tables in bookstores .
Contexts for target remainder are: ['nnI_houses']
Contexts in vocabulary for target remainder are: ['nnI_houses']
Top most similar embeddings: remainder 0.45235	rest 0.38313	c15th 0.35459	charnel 0.35308	single-family 0.34718	five-bedroom 0.34647	burgage 0.34488	ex-council 0.34268	lamplighters 0.34123	gwydyr 0.34057

Generated lemmatized results
***************
GENERATED	remainder.n 734 ::: rest;charnel;burgage;lamplighter;gwydyr;clapboard;herriard;dormy;littlecote;ickworth

Filtered results
***************
RANKED	remainder.n 734	rest 0.38313	surplus 0.29866	residue 0.28444	balance 0.26856	leftover 0.26526	residual 0.25476

Test context:
***************
remainder.n	735	1	the __remainder__ of the soup list evokes eastern europe , comprising soljanka , a ruddy vegetable-based soup containing a significant fraction of some unfortunate animal ( $ 4.50 ) and a sweetish roasted beet soup ( $ 4 ) .
Contexts for target remainder are: ['det_the', 'nsubjI_evokes', 'prep:of_list']
Contexts in vocabulary for target remainder are: ['det_the', 'nsubjI_evokes', 'prep:of_list']
Top most similar embeddings: remainder 0.12199	rest 0.09521	starkness 0.08578	sparseness 0.08359	tail-end 0.08271	portion 0.08095	bulk 0.08076	peshitta 0.08050	flyleaf 0.07931	centrepiece 0.07829

Generated lemmatized results
***************
GENERATED	remainder.n 735 ::: rest;starkness;sparseness;portion;bulk;peshitta;flyleaf;centrepiece;deepness;briefest

Filtered results
***************
RANKED	remainder.n 735	rest 0.09521	residue 0.06847	balance 0.06564	leftover 0.06218	residual 0.05700	surplus 0.05657

Test context:
***************
remainder.n	736	10	however , with only .14 of an inch falling the __remainder__ of the month , this left only 2.86 for the month , or .69 of an inch below normal .
Contexts for target remainder are: ['det_the', 'dobjI_falling', 'prep:of_month']
Contexts in vocabulary for target remainder are: ['det_the', 'dobjI_falling', 'prep:of_month']
Top most similar embeddings: remainder 0.12610	rest 0.10458	tail-end 0.08460	end 0.08384	fourths 0.08379	psbr 0.08284	winline 0.08273	run-rate 0.08264	expiration 0.08170	half 0.08128

Generated lemmatized results
***************
GENERATED	remainder.n 736 ::: rest;end;fourth;psbr;winline;expiration;half;ember;otherside;threshhold

Filtered results
***************
RANKED	remainder.n 736	rest 0.10458	residue 0.07389	balance 0.06844	leftover 0.06789	residual 0.06688	surplus 0.06373

Test context:
***************
remainder.n	737	9	jimfurtado - this thread is the sum of a __remainder__ of an unbalanced equation inherent to the programming of the primate .
Contexts for target remainder are: ['det_a', 'prep:ofI_sum', 'prep:of_equation']
Contexts in vocabulary for target remainder are: ['det_a', 'prep:ofI_sum', 'prep:of_equation']
Top most similar embeddings: remainder 0.11352	portion 0.09013	moiety 0.08849	rest 0.08521	factorization 0.08344	perturbation 0.08284	divisor 0.08254	reactance 0.08225	subgraph 0.08215	half 0.08133

Generated lemmatized results
***************
GENERATED	remainder.n 737 ::: portion;moiety;rest;factorization;perturbation;divisor;reactance;subgraph;half;logarithm

Filtered results
***************
RANKED	remainder.n 737	rest 0.08521	residue 0.07659	balance 0.07310	residual 0.06933	surplus 0.06839	leftover 0.05940

Test context:
***************
remainder.n	738	18	of course a whole number can be negative and we have to agree what we mean by the __remainder__ in this case ; for example , what is the remainder of -12 when we divide it by 10 ?
Contexts for target remainder are: ['det_the', 'prep:byI_mean', 'prep:in_case']
Contexts in vocabulary for target remainder are: ['det_the', 'prep:byI_mean', 'prep:in_case']
Top most similar embeddings: remainder 0.10578	rest 0.08422	undesirability 0.08037	impracticality 0.07844	tie-breaker 0.07742	latter 0.07706	permissibility 0.07698	inappropriateness 0.07668	settlor 0.07662	indivisibility 0.07656

Generated lemmatized results
***************
GENERATED	remainder.n 738 ::: rest;undesirability;impracticality;latter;permissibility;inappropriateness;settlor;indivisibility;nullification;cetv

Filtered results
***************
RANKED	remainder.n 738	rest 0.08422	balance 0.07010	residue 0.06692	surplus 0.06624	residual 0.06470	leftover 0.06186

Test context:
***************
remainder.n	739	27	cost : $ 1,990.00 for the eleven day trip , ( payable with a non- refundable deposit of $ 500 by july 31 , 2001 and the __remainder__ by september 1 , 2001 ) .
Contexts for target remainder are: ['det_the', 'conjI_july', 'prep:by_september']
Contexts in vocabulary for target remainder are: ['det_the', 'conjI_july', 'prep:by_september']
Top most similar embeddings: remainder 0.11646	rest 0.08211	apcm 0.07824	corms 0.07589	seedings 0.07404	half 0.07323	re-opening 0.07320	cheshires 0.07285	inlands 0.07280	upratings 0.07246

Generated lemmatized results
***************
GENERATED	remainder.n 739 ::: rest;apcm;corm;seedings;half;cheshires;inlands;upratings;expiry;surrey

Filtered results
***************
RANKED	remainder.n 739	rest 0.08211	surplus 0.06697	leftover 0.06355	balance 0.05768	residual 0.05657	residue 0.05548

Test context:
***************
remainder.n	740	19	if there is one child then the first $ 20,000 would go to the widow or widower and the __remainder__ would be divided equally , half to the child and half to the widow .
Contexts for target remainder are: ['det_the', 'conjI_widow']
Contexts in vocabulary for target remainder are: ['det_the', 'conjI_widow']
Top most similar embeddings: remainder 0.23888	rest 0.19601	tsarina 0.18120	vicarial 0.17870	co-heiress 0.17761	commonalty 0.17672	maidservant 0.17643	advowson 0.17639	cohabitee 0.17635	chavvies 0.17565

Generated lemmatized results
***************
GENERATED	remainder.n 740 ::: rest;tsarina;vicarial;commonalty;maidservant;advowson;cohabitee;chavvies;jailor;percy

Filtered results
***************
RANKED	remainder.n 740	rest 0.19601	residue 0.14495	leftover 0.13444	residual 0.13024	balance 0.13003	surplus 0.12960

Test context:
***************
rude.a	741	29	in the year 1600 , during the times of shakespeare , the region to the south of the east indies was still as little known as ever ; the __rude__ maps of those days had only a great blank where the islands of australia should have been .
Contexts for target rude are: ['amodI_maps']
Contexts in vocabulary for target rude are: ['amodI_maps']
Top most similar embeddings: rude 0.43871	nice-looking 0.37217	out-of-copyright 0.36583	near-identical 0.36299	zoomable 0.36037	rough-and-ready 0.35821	smutty 0.35797	cartoon-style 0.35777	strange-looking 0.35765	odd-looking 0.35731

Generated lemmatized results
***************
GENERATED	rude.a 741 ::: zoomable;smutty;wacky;kitschy;cheeky;cutesy;gossipy;artsy;unoffical;naughty

Filtered results
***************
RANKED	rude.a 741	naughty 0.34739	crude 0.34143	impolite 0.33811	lewd 0.33362	abusive 0.32945	unkind 0.32909	rough 0.32856	disrespectful 0.32804	insulting 0.32661	vulgar 0.32659	offensive 0.32163	awkward 0.31831	rudimentary 0.31706	primitive 0.31635	coarse 0.31545	unpleasant 0.31405	inexact 0.30760	wild 0.30673	unrefined 0.30272	basic 0.30144	raw 0.29765	abrupt 0.29718	unfinished 0.29668	approximate 0.29217	savage 0.27763	sudden 0.26818	surprise 0.22993

Test context:
***************
rude.a	742	35	the speaker of the house , realizing that the prime minister had been caught with his hand in the cookie jar , joined in and also started to interrupt the hon. finnegan in a most __rude__ manner .
Contexts for target rude are: ['advmod_most', 'amodI_manner']
Contexts in vocabulary for target rude are: ['advmod_most', 'amodI_manner']
Top most similar embeddings: rude 0.25371	media-friendly 0.22053	intemperate 0.21930	vituperative 0.21727	discourteous 0.21521	cretinous 0.21435	slovenly 0.21423	statesmanlike 0.21388	insolent 0.21360	ungentlemanly 0.21344

Generated lemmatized results
***************
GENERATED	rude.a 742 ::: intemperate;vituperative;discourteous;cretinous;slovenly;statesmanlike;insolent;ungentlemanly;gentlemanly;tactless

Filtered results
***************
RANKED	rude.a 742	impolite 0.21047	disrespectful 0.20587	lewd 0.19786	vulgar 0.19383	unkind 0.19178	abusive 0.19165	insulting 0.18870	unpleasant 0.18649	abrupt 0.18381	awkward 0.18273	naughty 0.17741	crude 0.17607	offensive 0.17552	primitive 0.17346	savage 0.17028	rudimentary 0.16778	inexact 0.16602	unrefined 0.15623	rough 0.15182	wild 0.15095	raw 0.15079	coarse 0.14891	basic 0.14631	sudden 0.14306	approximate 0.13717	unfinished 0.13503	surprise 0.11035

Test context:
***************
rude.a	743	4	the cabin crew are __rude__ and unprofessional and seem to treat the paying passenger as an unwelcome burden .
Contexts for target rude are: ['nsubj_crew', 'cop_are', 'rootI_*root*', 'cc_and', 'conj_unprofessional', 'cc_and', 'conj_seem', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target rude are: ['nsubj_crew', 'cop_are', 'rootI_*root*', 'cc_and', 'conj_unprofessional', 'cc_and', 'conj_seem', 'punct_.']
Top most similar embeddings: rude 0.00394	polite 0.00319	undisciplined 0.00299	unprofessional 0.00299	short-tempered 0.00298	arrogant 0.00292	uncommunicative 0.00291	flighty 0.00287	unhelpful 0.00284	disorganised 0.00283

Generated lemmatized results
***************
GENERATED	rude.a 743 ::: polite;undisciplined;unprofessional;arrogant;uncommunicative;flighty;unhelpful;disorganised;shortsighted;discourteous

Filtered results
***************
RANKED	rude.a 743	impolite 0.00278	unkind 0.00271	disrespectful 0.00255	naughty 0.00237	insulting 0.00233	awkward 0.00218	abusive 0.00211	abrupt 0.00206	crude 0.00204	unpleasant 0.00200	vulgar 0.00198	rough 0.00195	inexact 0.00195	lewd 0.00194	rudimentary 0.00185	offensive 0.00173	primitive 0.00161	approximate 0.00157	coarse 0.00151	unrefined 0.00149	unfinished 0.00149	savage 0.00147	wild 0.00140	raw 0.00134	surprise 0.00131	sudden 0.00129	basic 0.00103

Test context:
***************
rude.a	744	12	unfortunately , this headlong run to achieve nirvana often results in a __rude__ awakening .
Contexts for target rude are: ['amodI_awakening']
Contexts in vocabulary for target rude are: ['amodI_awakening']
Top most similar embeddings: rude 0.55282	jocular 0.38374	polite 0.38232	disrespectful 0.38150	impolite 0.38108	ungracious 0.38088	jingoistic 0.37861	intemperate 0.37840	insolent 0.37767	immodest 0.37715

Generated lemmatized results
***************
GENERATED	rude.a 744 ::: jocular;polite;disrespectful;impolite;ungracious;jingoistic;intemperate;insolent;immodest;thoughtless

Filtered results
***************
RANKED	rude.a 744	disrespectful 0.38150	impolite 0.38108	lewd 0.37323	naughty 0.36630	insulting 0.36203	vulgar 0.36010	unkind 0.35239	abrupt 0.34851	crude 0.33875	abusive 0.33804	unpleasant 0.33481	awkward 0.33394	sudden 0.32538	offensive 0.32488	savage 0.31211	primitive 0.30615	wild 0.30383	raw 0.30072	inexact 0.29588	coarse 0.29509	rough 0.29392	unrefined 0.28762	rudimentary 0.28173	unfinished 0.27745	basic 0.27292	approximate 0.26615	surprise 0.25559

Test context:
***************
rude.a	745	5	it 's a raucous , __rude__ night alright and followed by a disco until 1am .
Contexts for target rude are: ['amodI_alright']
Contexts in vocabulary for target rude are: ['amodI_alright']
Top most similar embeddings: rude 0.48380	wanky 0.38222	soppy 0.37994	smarmy 0.37982	snobby 0.37592	cheeky 0.37551	cutesy 0.37412	pervy 0.37408	big-headed 0.37241	tarty 0.37160

Generated lemmatized results
***************
GENERATED	rude.a 745 ::: wanky;soppy;smarmy;snobby;cheeky;cutesy;pervy;tarty;bitchy;smutty

Filtered results
***************
RANKED	rude.a 745	naughty 0.36843	impolite 0.35705	unkind 0.35570	disrespectful 0.35350	lewd 0.34702	insulting 0.34480	awkward 0.33188	vulgar 0.32949	raw 0.32025	abrupt 0.31897	abusive 0.31681	unpleasant 0.30997	offensive 0.30721	rough 0.30407	savage 0.30387	unfinished 0.29947	crude 0.29905	sudden 0.29877	primitive 0.29746	wild 0.28697	inexact 0.28353	coarse 0.27805	unrefined 0.27725	basic 0.27628	rudimentary 0.27514	approximate 0.25935	surprise 0.24317

Test context:
***************
rude.a	746	7	fun-loving caro enjoys a joke - the __ruder__ the better , in fact , and often turns up to work with a hangover .
Contexts for target ruder are: ['det_the', 'depI_joke', 'rcmod_turns']
Contexts in vocabulary for target ruder are: ['det_the', 'depI_joke', 'rcmod_turns']
Top most similar embeddings: ruder 0.08968	know-it-all 0.08604	baddy 0.08599	prankster 0.08571	leprechaun 0.08539	libertine 0.08488	moralist 0.08440	windbag 0.08439	villian 0.08431	scoundrel 0.08418

Generated lemmatized results
***************
GENERATED	rude.a 746 ::: baddy;prankster;leprechaun;libertine;moralist;windbag;villian;scoundrel;hedonist;slitheen

Filtered results
***************
RANKED	rude.a 746	vulgar 0.07388	wild 0.07135	raw 0.06771	offensive 0.06707	lewd 0.06597	naughty 0.06440	savage 0.06431	unkind 0.06142	surprise 0.06135	primitive 0.06119	rough 0.06097	crude 0.05952	unpleasant 0.05834	insulting 0.05768	awkward 0.05682	impolite 0.05640	coarse 0.05620	sudden 0.05557	unfinished 0.05551	abusive 0.05338	disrespectful 0.05321	inexact 0.05075	unrefined 0.04980	rudimentary 0.04848	abrupt 0.04763	basic 0.04689	approximate 0.04317

Test context:
***************
rude.a	747	20	the thumbs-up gesture is a positive sign in most of the world , but in some cultures it considered a __rude__ gesture .
Contexts for target rude are: ['amodI_gesture']
Contexts in vocabulary for target rude are: ['amodI_gesture']
Top most similar embeddings: rude 0.53729	thoughtless 0.41797	impolite 0.41543	ungracious 0.41480	polite 0.41398	accusatory 0.41199	spiteful 0.41151	unmeaning 0.40994	high-flown 0.40704	intemperate 0.40639

Generated lemmatized results
***************
GENERATED	rude.a 747 ::: thoughtless;impolite;ungracious;polite;accusatory;spiteful;unmeaning;intemperate;tactless;jingoistic

Filtered results
***************
RANKED	rude.a 747	impolite 0.41543	disrespectful 0.40355	lewd 0.40030	unkind 0.38706	insulting 0.38510	naughty 0.37192	abusive 0.36799	vulgar 0.36255	awkward 0.35839	abrupt 0.35467	offensive 0.34567	crude 0.34091	unpleasant 0.32873	rudimentary 0.32120	primitive 0.32112	savage 0.31619	raw 0.31102	inexact 0.31056	wild 0.30912	sudden 0.30753	coarse 0.30659	unrefined 0.30535	rough 0.30328	basic 0.29487	unfinished 0.29143	approximate 0.26165	surprise 0.24073

Test context:
***************
rude.a	748	29	the use of bells for general and even for religious purposes is of very ancient origin , although it is likely that in early ages they were of very __rude__ form and imperfect sound , and that they were gradually developed into their present perfection .
Contexts for target rude are: ['advmod_very', 'amodI_form']
Contexts in vocabulary for target rude are: ['advmod_very', 'amodI_form']
Top most similar embeddings: rude 0.25104	polite 0.20683	epigrammatic 0.20052	un-english 0.20018	rough-and-ready 0.19970	ceremonious 0.19938	uncomplimentary 0.19902	nice-looking 0.19899	well-mannered 0.19865	jocular 0.19848

Generated lemmatized results
***************
GENERATED	rude.a 748 ::: polite;epigrammatic;ceremonious;uncomplimentary;jocular;crotchety;impolite;smutty;modernistic;accusatory

Filtered results
***************
RANKED	rude.a 748	impolite 0.19608	naughty 0.18973	disrespectful 0.18617	crude 0.18397	lewd 0.18386	unkind 0.18324	vulgar 0.18154	unpleasant 0.17962	abusive 0.17755	raw 0.17745	insulting 0.17653	primitive 0.17556	rudimentary 0.17480	abrupt 0.17428	awkward 0.17126	rough 0.17081	coarse 0.16999	unrefined 0.16909	inexact 0.16100	basic 0.16005	offensive 0.15977	savage 0.15435	wild 0.15281	unfinished 0.14780	sudden 0.14277	approximate 0.14160	surprise 0.10717

Test context:
***************
rude.a	749	9	unless a capital was employed in transporting either the __rude__ or manufactured produce from the places where it abounds to those where it is wanted , no more of either could be produced than was necessary for the consumption of the neighbourhood .
Contexts for target rude are: ['preconj_either', 'det_the', 'amodI_produce', 'cc_or', 'conj_manufactured']
Contexts in vocabulary for target rude are: ['preconj_either', 'det_the', 'amodI_produce', 'cc_or', 'conj_manufactured']
Top most similar embeddings: rude 0.02094	impure 0.01908	semi-skimmed 0.01871	vulgar 0.01869	heat-treated 0.01857	unprocessed 0.01852	consignor 0.01848	inedible 0.01822	prepacked 0.01820	frivolous 0.01791

Generated lemmatized results
***************
GENERATED	rude.a 749 ::: impure;vulgar;unprocessed;consignor;inedible;prepacked;frivolous;meretricious;substandard;obscene

Filtered results
***************
RANKED	rude.a 749	vulgar 0.01869	raw 0.01779	unrefined 0.01685	crude 0.01649	offensive 0.01632	coarse 0.01597	wild 0.01594	lewd 0.01589	primitive 0.01567	naughty 0.01517	unfinished 0.01497	abusive 0.01482	insulting 0.01460	impolite 0.01458	rough 0.01422	inexact 0.01412	disrespectful 0.01377	savage 0.01269	rudimentary 0.01259	unpleasant 0.01258	unkind 0.01251	sudden 0.01235	abrupt 0.01227	awkward 0.01223	basic 0.01210	approximate 0.01139	surprise 0.00865

Test context:
***************
rude.a	750	12	' the war of 1914, ' he wrote , ' was a __rude__ shock for the socialist religion .
Contexts for target rude are: ['amodI_shock']
Contexts in vocabulary for target rude are: ['amodI_shock']
Top most similar embeddings: rude 0.52898	nasty 0.40176	spiteful 0.38612	cruel 0.37946	hypovolaemic 0.37808	boorish 0.37498	cacophonous 0.37489	anaphylactic 0.37358	intemperate 0.37322	disrespectful 0.37203

Generated lemmatized results
***************
GENERATED	rude.a 750 ::: nasty;spiteful;cruel;hypovolaemic;boorish;cacophonous;anaphylactic;intemperate;disrespectful;supercilious

Filtered results
***************
RANKED	rude.a 750	disrespectful 0.37203	impolite 0.36761	unpleasant 0.36293	unkind 0.35871	naughty 0.35674	abrupt 0.35583	insulting 0.35326	lewd 0.34989	abusive 0.34669	vulgar 0.33442	awkward 0.33353	sudden 0.32908	offensive 0.32056	crude 0.31476	wild 0.31183	savage 0.31117	raw 0.31022	rough 0.29975	unrefined 0.29871	coarse 0.29412	unfinished 0.28352	primitive 0.28196	rudimentary 0.27987	basic 0.27865	inexact 0.26782	approximate 0.26324	surprise 0.25288

Test context:
***************
saint.n	751	4	this is a different __saint__ from the ulster/connaught saint erc but coincidentally has produced a similar mnemonic in english .
Contexts for target saint are: ['nsubj_this', 'cop_is', 'det_a', 'amod_different', 'rootI_*root*', 'prep:from_erc', 'cc_but', 'conj_produced', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target saint are: ['nsubj_this', 'cop_is', 'det_a', 'amod_different', 'rootI_*root*', 'cc_but', 'conj_produced', 'punct_.']
Top most similar embeddings: toughie 0.00261	ballgame 0.00255	no-no 0.00237	pipedream 0.00236	money-spinner 0.00235	misnomer 0.00233	personalzine 0.00228	kludge 0.00226	half-truth 0.00222	time-saver 0.00222

Generated lemmatized results
***************
GENERATED	saint.n 751 ::: toughie;ballgame;pipedream;misnomer;personalzine;kludge;truism;sequitur;pastime;pseudonym

Filtered results
***************
RANKED	saint.n 751	disciple 0.00171	martyr 0.00165	figure 0.00163	prophet 0.00148	blessed 0.00134	angel 0.00132	paladin 0.00126	canonised 0.00123	good 0.00116	pn 0.00092	goodman 0.00073

Test context:
***************
saint.n	752	29	all would like to ignore death , and yet all must face it the prince and the peasant , the fool and the philosopher , the murderer and the __saint__ alike .
Contexts for target saint are: ['det_the', 'conjI_prince', 'advmod_alike']
Contexts in vocabulary for target saint are: ['det_the', 'conjI_prince', 'advmod_alike']
Top most similar embeddings: saint 0.11426	charioteer 0.09425	high-priest 0.09267	confessors 0.09184	patriarch 0.09108	hierarch 0.09060	prophet 0.09052	potentate 0.09000	emperor 0.08991	patroness 0.08965

Generated lemmatized results
***************
GENERATED	saint.n 752 ::: charioteer;confessor;patriarch;hierarch;prophet;potentate;emperor;patroness;usurper;aesthete

Filtered results
***************
RANKED	saint.n 752	prophet 0.09052	martyr 0.08772	disciple 0.08131	paladin 0.07606	angel 0.07466	goodman 0.06421	figure 0.06269	blessed 0.06246	canonised 0.06077	good 0.05433	pn 0.05032

Test context:
***************
saint.n	753	11	milosz replied that slozhenitsyn was returning as a prophet , a __saint__ , a guru ; milosz felt he was just and old poet coming home .
Contexts for target saint are: ['det_a', 'npadvmodI_replied', 'punct_,', 'appos_guru']
Contexts in vocabulary for target saint are: ['det_a', 'punct_,', 'appos_guru']
Top most similar embeddings: saint 0.12019	monk 0.09597	bhakta 0.09557	martyr 0.09527	philologist 0.09522	rhetorician 0.09474	prophetess 0.09473	shaheed 0.09445	charlatan 0.09438	faun 0.09320

Generated lemmatized results
***************
GENERATED	saint.n 753 ::: monk;bhakta;martyr;philologist;rhetorician;prophetess;shaheed;charlatan;faun;jurist

Filtered results
***************
RANKED	saint.n 753	martyr 0.09527	prophet 0.08675	paladin 0.08467	angel 0.08273	disciple 0.08213	goodman 0.06812	figure 0.06606	canonised 0.06218	pn 0.06033	blessed 0.05978	good 0.04522

Test context:
***************
saint.n	754	5	comrade stalin posed before the __saints__ and worshippers .
Contexts for target saints are: ['det_the', 'prep:beforeI_posed', 'cc_and', 'conj_worshippers']
Contexts in vocabulary for target saints are: ['det_the', 'cc_and', 'conj_worshippers']
Top most similar embeddings: saints 0.13373	monastics 0.10608	moonies 0.10537	priests 0.10519	brahmins 0.10419	wesleyans 0.10414	hellenes 0.10339	patriarchs 0.10304	nazarenes 0.10302	ascetics 0.10296

Generated lemmatized results
***************
GENERATED	saint.n 754 ::: monastic;moonie;priest;brahmin;wesleyan;hellene;patriarch;nazarene;ascetic;zoroastrian

Filtered results
***************
RANKED	saint.n 754	martyr 0.10176	prophet 0.09849	angel 0.09221	disciple 0.08955	figure 0.06796	paladin 0.06783	good 0.06643	blessed 0.06492	goodman 0.06221	canonised 0.06065	pn 0.04975

Test context:
***************
saint.n	755	5	escriva may have been a __saint__ -- who am i to judge ?
Contexts for target saint are: ['nsubj_escriva', 'aux_may', 'aux_have', 'cop_been', 'det_a', 'rootI_*root*', 'punct_--', 'dep_i', 'punct_?', 'dep_<eol>']
Contexts in vocabulary for target saint are: ['aux_may', 'aux_have', 'cop_been', 'det_a', 'rootI_*root*', 'punct_--', 'dep_i', 'punct_?']
Top most similar embeddings: prude 0.00232	saint 0.00228	iudge 0.00223	martyr 0.00216	figment 0.00214	heretic 0.00212	subiect 0.00210	sene 0.00210	foole 0.00209	hypocrite 0.00208

Generated lemmatized results
***************
GENERATED	saint.n 755 ::: prude;iudge;martyr;figment;heretic;subiect;sene;foole;hypocrite;writt

Filtered results
***************
RANKED	saint.n 755	martyr 0.00216	disciple 0.00193	prophet 0.00164	canonised 0.00162	blessed 0.00158	figure 0.00150	angel 0.00148	good 0.00109	paladin 0.00107	pn 0.00103	goodman 0.00070

Test context:
***************
saint.n	756	9	he can be a saint , something like a __saint__ .
Contexts for target saint are: ['det_a', 'prep:likeI_something']
Contexts in vocabulary for target saint are: ['det_a', 'prep:likeI_something']
Top most similar embeddings: saint 0.23244	martyr 0.18349	charioteer 0.17921	longship 0.17868	koan 0.17799	carbuncle 0.17709	demi-god 0.17649	faun 0.17641	theophany 0.17636	martlet 0.17605

Generated lemmatized results
***************
GENERATED	saint.n 756 ::: martyr;charioteer;longship;koan;carbuncle;faun;theophany;martlet;wino;banshee

Filtered results
***************
RANKED	saint.n 756	martyr 0.18349	prophet 0.16835	disciple 0.15487	angel 0.15333	paladin 0.14936	figure 0.14764	goodman 0.12694	canonised 0.11979	pn 0.11854	blessed 0.11632	good 0.10158

Test context:
***************
saint.n	757	22	each writer told the tale as he heard it , or thereabouts , and gave to his book the name of the __saint__ or the apostle whom tradition had given as the eye-witness .
Contexts for target saint are: ['det_the', 'prep:ofI_name', 'cc_or', 'conj_apostle']
Contexts in vocabulary for target saint are: ['det_the', 'prep:ofI_name', 'cc_or', 'conj_apostle']
Top most similar embeddings: saint 0.06491	paraclete 0.05171	apostle 0.05154	nazarene 0.05115	prophet 0.05038	sun-god 0.04914	metatron 0.04908	high-priest 0.04902	presbyter 0.04841	deity 0.04838

Generated lemmatized results
***************
GENERATED	saint.n 757 ::: paraclete;apostle;nazarene;prophet;metatron;presbyter;deity;hierarch;suzerain;woden

Filtered results
***************
RANKED	saint.n 757	prophet 0.05038	martyr 0.04783	angel 0.04219	disciple 0.04081	paladin 0.03637	blessed 0.02947	good 0.02694	canonised 0.02618	figure 0.02605	goodman 0.02500	pn 0.02327

Test context:
***************
saint.n	758	7	i truly believe this woman was a __saint__ because the stench was overwhelming !
Contexts for target saint are: ['nsubj_woman', 'cop_was', 'det_a', 'ccompI_believe', 'advcl_overwhelming']
Contexts in vocabulary for target saint are: ['nsubj_woman', 'cop_was', 'det_a', 'ccompI_believe', 'advcl_overwhelming']
Top most similar embeddings: saint 0.02187	blasphemer 0.02017	martyr 0.01982	charlatan 0.01970	weakling 0.01968	sinner 0.01937	non-entity 0.01920	stumbling-block 0.01920	persecutor 0.01888	proselyte 0.01879

Generated lemmatized results
***************
GENERATED	saint.n 758 ::: blasphemer;martyr;charlatan;weakling;sinner;persecutor;proselyte;sadist;partaker;nymphomaniac

Filtered results
***************
RANKED	saint.n 758	martyr 0.01982	prophet 0.01765	disciple 0.01696	blessed 0.01360	angel 0.01343	canonised 0.01338	figure 0.01292	paladin 0.01124	good 0.01090	pn 0.00714	goodman 0.00626

Test context:
***************
saint.n	759	21	during a visit to italy he was shown a stain on the floor of a church on the spot where a __saint__ had died .
Contexts for target saint are: ['det_a', 'nsubjI_died']
Contexts in vocabulary for target saint are: ['det_a', 'nsubjI_died']
Top most similar embeddings: saint 0.25009	martyr 0.20099	she-wolf 0.19871	noblewoman 0.19459	mother-of-three 0.19292	father-of-two 0.19245	woodchuck 0.19139	father-of-three 0.19130	prophetess 0.19013	nightwatchman 0.18987

Generated lemmatized results
***************
GENERATED	saint.n 759 ::: martyr;noblewoman;woodchuck;prophetess;nightwatchman;charioteer;townsman;levite;frenchwoman;brickmaker

Filtered results
***************
RANKED	saint.n 759	martyr 0.20099	prophet 0.18067	disciple 0.16967	paladin 0.15763	angel 0.15602	figure 0.13860	canonised 0.13299	goodman 0.12801	blessed 0.12659	pn 0.11685	good 0.09828

Test context:
***************
saint.n	760	15	the masses worship her , not for her intellect , but as a sort of __saint__ who is to lead them in the days of trial and temptation .
Contexts for target saint are: ['prep:ofI_sort']
Contexts in vocabulary for target saint are: ['prep:ofI_sort']
Top most similar embeddings: saint 0.48168	martyr 0.36876	demi-god 0.36134	prig 0.35820	fantasist 0.35611	do-gooder 0.35200	charlatan 0.35120	busybody 0.35005	hero 0.34963	devilry 0.34790

Generated lemmatized results
***************
GENERATED	saint.n 760 ::: martyr;prig;fantasist;charlatan;busybody;hero;devilry;poseur;weirdo;blackguard

Filtered results
***************
RANKED	saint.n 760	martyr 0.36876	prophet 0.32337	disciple 0.32231	angel 0.31848	paladin 0.31179	figure 0.29178	blessed 0.28150	canonised 0.28093	good 0.24569	goodman 0.23485	pn 0.22876

Test context:
***************
still.a	761	9	it is important to apply the herbicide on a __still__ day , because spray drift can kill non-target plants .
Contexts for target still are: ['advmodI_day']
Contexts in vocabulary for target still are: ['advmodI_day']
Top most similar embeddings: still 0.50824	proably 0.43705	probaly 0.41529	apprently 0.40924	everlastingly 0.40634	even 0.40322	usally 0.40289	defintely 0.40280	also 0.40278	just 0.40215

Generated lemmatized results
***************
GENERATED	still.a 761 ::: proably;probaly;apprently;everlastingly;even;usally;defintely;also;just;actaully

Filtered results
***************
RANKED	still.a 761	motionless 0.29642	calm 0.28021	quiet 0.27745	windless 0.27711	unmoving 0.27019	smooth 0.26464	serene 0.26207	peaceful 0.26065	unruffled 0.25685	stationary 0.25197	tranquil 0.24965	fixed 0.24684	arranged 0.23690	static 0.23589	hushed 0.23202

Test context:
***************
still.a	762	19	when you dance , all the stars and the planets , and the endless univers es dance around that __still__ point .
Contexts for target still are: ['advmodI_point']
Contexts in vocabulary for target still are: ['advmodI_point']
Top most similar embeddings: still 0.51843	proably 0.43719	defintely 0.42445	also 0.42143	apprently 0.41515	nonetheless 0.41471	probaly 0.41410	always 0.40921	certainly 0.40780	contrastingly 0.40617

Generated lemmatized results
***************
GENERATED	still.a 762 ::: proably;defintely;also;apprently;nonetheless;probaly;always;certainly;contrastingly;really

Filtered results
***************
RANKED	still.a 762	motionless 0.29653	unmoving 0.28183	quiet 0.26741	peaceful 0.26325	windless 0.26191	stationary 0.26003	serene 0.25704	calm 0.25505	smooth 0.25072	unruffled 0.24811	fixed 0.24636	static 0.24390	tranquil 0.23413	hushed 0.23243	arranged 0.23108

Test context:
***************
still.a	763	6	the only noise in the suddenly __still__ room was the shallow rasp of lainys breathing .
Contexts for target still are: ['advmodI_room']
Contexts in vocabulary for target still are: ['advmodI_room']
Top most similar embeddings: still 0.52772	proably 0.42057	apprently 0.41147	even 0.40769	also 0.40548	everlastingly 0.40529	always 0.40414	certainly 0.40253	defintely 0.40007	temptingly 0.39996

Generated lemmatized results
***************
GENERATED	still.a 763 ::: proably;apprently;even;also;everlastingly;always;certainly;defintely;temptingly;intially

Filtered results
***************
RANKED	still.a 763	motionless 0.30877	unmoving 0.28782	quiet 0.28221	windless 0.26954	serene 0.26463	peaceful 0.26394	calm 0.26232	stationary 0.25872	unruffled 0.25123	arranged 0.24863	tranquil 0.24752	smooth 0.24520	hushed 0.24467	static 0.24058	fixed 0.23839

Test context:
***************
still.a	764	47	i had seen nothing in the united states like its level green banks , with trees slanting over the water , festooned with the wild vine ; the groups of cattle beneath them ; the distant steam-boat , scarcely seeming to disturb the grey surface of the __still__ waters .
Contexts for target still are: ['advmodI_waters']
Contexts in vocabulary for target still are: ['advmodI_waters']
Top most similar embeddings: still 0.55631	sometimes 0.39603	everlastingly 0.39410	even 0.39024	nonetheless 0.38814	proably 0.38800	defintely 0.38320	contrastingly 0.38264	often 0.38163	apprently 0.38093

Generated lemmatized results
***************
GENERATED	still.a 764 ::: sometimes;everlastingly;even;nonetheless;proably;defintely;contrastingly;often;apprently;actually

Filtered results
***************
RANKED	still.a 764	motionless 0.30875	unmoving 0.27847	calm 0.26884	quiet 0.26872	serene 0.26595	windless 0.26133	smooth 0.25609	peaceful 0.25580	unruffled 0.25538	stationary 0.25042	tranquil 0.24383	hushed 0.24214	static 0.24068	arranged 0.23300	fixed 0.22405

Test context:
***************
still.a	765	11	a movie is a visual document comprised of a series of __still__ images .
Contexts for target still are: ['advmodI_images']
Contexts in vocabulary for target still are: ['advmodI_images']
Top most similar embeddings: still 0.55675	even 0.40165	proably 0.39949	also 0.39569	nonetheless 0.39354	everlastingly 0.39195	garishly 0.39165	contrastingly 0.39049	defintely 0.38809	unconventionally 0.38698

Generated lemmatized results
***************
GENERATED	still.a 765 ::: even;proably;also;nonetheless;everlastingly;garishly;contrastingly;defintely;unconventionally;sometimes

Filtered results
***************
RANKED	still.a 765	motionless 0.30553	quiet 0.26854	unmoving 0.26695	peaceful 0.26616	smooth 0.26227	serene 0.26147	calm 0.25197	stationary 0.25084	windless 0.25070	static 0.24957	unruffled 0.24804	hushed 0.24085	arranged 0.24029	tranquil 0.23112	fixed 0.23066

Test context:
***************
still.a	766	15	i loaded and holstered my gun , safety on , and reached gently for the __still__ place inside myself that every martial artist knows .
Contexts for target still are: ['advmodI_place']
Contexts in vocabulary for target still are: ['advmodI_place']
Top most similar embeddings: still 0.52735	proably 0.44294	apprently 0.42678	also 0.42503	defintely 0.41938	probaly 0.41608	everlastingly 0.41426	certainly 0.41407	always 0.41114	nonetheless 0.40858

Generated lemmatized results
***************
GENERATED	still.a 766 ::: proably;apprently;also;defintely;probaly;everlastingly;certainly;always;nonetheless;actually

Filtered results
***************
RANKED	still.a 766	motionless 0.29974	unmoving 0.28528	quiet 0.27180	calm 0.26546	stationary 0.26390	serene 0.26225	peaceful 0.26205	smooth 0.26119	windless 0.25752	unruffled 0.25193	tranquil 0.24608	arranged 0.24313	fixed 0.24121	static 0.24112	hushed 0.23769

Test context:
***************
still.a	767	2	in the __still__ mountain air it would be heard clearly in the rustic cabin before him .
Contexts for target still are: ['advmodI_air']
Contexts in vocabulary for target still are: ['advmodI_air']
Top most similar embeddings: still 0.53856	everlastingly 0.41392	proably 0.40806	even 0.40342	cryogenically 0.40098	electrostatically 0.40039	insecurely 0.39987	contrastingly 0.39922	apprently 0.39671	monotonously 0.39604

Generated lemmatized results
***************
GENERATED	still.a 767 ::: everlastingly;proably;even;cryogenically;electrostatically;insecurely;contrastingly;apprently;monotonously;freakishly

Filtered results
***************
RANKED	still.a 767	motionless 0.29599	unmoving 0.27540	quiet 0.27078	windless 0.26886	peaceful 0.26645	serene 0.26215	calm 0.26146	smooth 0.25954	unruffled 0.25634	stationary 0.25396	static 0.25382	hushed 0.24641	fixed 0.24560	arranged 0.23802	tranquil 0.23565

Test context:
***************
still.a	768	9	it 's fine for a quiet room on a __still__ night , but challenge it a little and it capitulates completely .
Contexts for target still are: ['advmodI_night']
Contexts in vocabulary for target still are: ['advmodI_night']
Top most similar embeddings: still 0.51903	proably 0.42528	probaly 0.41691	apprently 0.41523	everlastingly 0.41509	certainly 0.40497	defintely 0.40143	even 0.40136	actaully 0.40070	actually 0.39720

Generated lemmatized results
***************
GENERATED	still.a 768 ::: proably;probaly;apprently;everlastingly;certainly;defintely;even;actaully;actually;probally

Filtered results
***************
RANKED	still.a 768	motionless 0.30170	quiet 0.28030	calm 0.27759	serene 0.27464	unmoving 0.27362	windless 0.27314	peaceful 0.26498	smooth 0.25642	unruffled 0.25417	tranquil 0.25112	hushed 0.24917	stationary 0.24845	static 0.24056	arranged 0.23180	fixed 0.22994

Test context:
***************
still.a	769	7	each photographer picked an animal and a __still__ life subject to photograph .
Contexts for target still are: ['advmodI_life']
Contexts in vocabulary for target still are: ['advmodI_life']
Top most similar embeddings: still 0.54480	everlastingly 0.42736	proably 0.42060	even 0.41123	defintely 0.40799	apprently 0.40503	ineffably 0.40227	contrastingly 0.40153	tensely 0.39969	icily 0.39867

Generated lemmatized results
***************
GENERATED	still.a 769 ::: everlastingly;proably;even;defintely;apprently;ineffably;contrastingly;tensely;icily;also

Filtered results
***************
RANKED	still.a 769	motionless 0.29403	calm 0.27753	serene 0.27588	quiet 0.27532	peaceful 0.27112	unmoving 0.27029	smooth 0.26977	windless 0.26845	unruffled 0.26135	stationary 0.25250	static 0.24554	fixed 0.24213	tranquil 0.24192	hushed 0.24087	arranged 0.23438

Test context:
***************
still.a	770	11	they understand that steering a tornado requires getting leverage on a __still__ point .
Contexts for target still are: ['advmodI_point']
Contexts in vocabulary for target still are: ['advmodI_point']
Top most similar embeddings: still 0.51843	proably 0.43719	defintely 0.42445	also 0.42143	apprently 0.41515	nonetheless 0.41471	probaly 0.41410	always 0.40921	certainly 0.40780	contrastingly 0.40617

Generated lemmatized results
***************
GENERATED	still.a 770 ::: proably;defintely;also;apprently;nonetheless;probaly;always;certainly;contrastingly;really

Filtered results
***************
RANKED	still.a 770	motionless 0.29653	unmoving 0.28183	quiet 0.26741	peaceful 0.26325	windless 0.26191	stationary 0.26003	serene 0.25704	calm 0.25505	smooth 0.25072	unruffled 0.24811	fixed 0.24636	static 0.24390	tranquil 0.23413	hushed 0.23243	arranged 0.23108

Test context:
***************
straight.a	771	10	there is one question that demands an answer - a __straight__ answer - from those who would seek to lead this nation and its people .
Contexts for target straight are: ['amodI_answer']
Contexts in vocabulary for target straight are: ['amodI_answer']
Top most similar embeddings: straight 0.52691	definative 0.37940	straightforward 0.36127	two-word 0.35494	rough-and-ready 0.35339	quick-fire 0.35084	one-word 0.35062	hard-and-fast 0.34925	straightest 0.34861	point-by-point 0.34737

Generated lemmatized results
***************
GENERATED	straight.a 771 ::: definative;straightforward;quickfire;monosyllabic;simple;nonchalant;backhanded;glib;longish;unvarnished

Filtered results
***************
RANKED	straight.a 771	truthful 0.33298	direct 0.32702	right 0.32553	plain 0.32539	honest 0.32461	clear 0.32046	correct 0.31806	candid 0.31666	accurate 0.31460	true 0.31334	consecutive 0.30381	unbending 0.30272	smooth 0.30243	linear 0.30112	unswerving 0.30022	forthright 0.29678	pure 0.29660	genuine 0.29472	undistorted 0.29348	vertical 0.29219	undiluted 0.29183	successive 0.28955	orderly 0.28951	heterosexual 0.28865	unadulterated 0.28658	continuous 0.28450	uninterrupted 0.27552	standard 0.27514	sorted 0.25738	level 0.23959

Test context:
***************
straight.a	772	38	this strong youth culture rapidly influenced other musical styles with its phrasing and break beats and gave birth to many contrasting styles including pop , funk , dance , techno , acid jazz , indie rock etc. a __straight__ rap record is still hard-core and only relevant for a specific group and market , it does not have a commercial appeal .
Contexts for target straight are: ['amodI_record']
Contexts in vocabulary for target straight are: ['amodI_record']
Top most similar embeddings: straight 0.47736	100-metre 0.36162	definative 0.35829	35-minute 0.35781	newly-released 0.35456	50-year 0.35438	win/loss 0.35287	28-year 0.35179	2000th 0.35131	metronomic 0.35056

Generated lemmatized results
***************
GENERATED	straight.a 772 ::: definative;metronomic;sleekly;continous;searingly;shortish;palaeomagnetic;crackly;compendious;checkable

Filtered results
***************
RANKED	straight.a 772	accurate 0.32377	vertical 0.32135	truthful 0.31767	continuous 0.31620	true 0.31465	consecutive 0.31336	candid 0.31206	plain 0.31091	direct 0.30899	clear 0.30698	correct 0.30495	unswerving 0.30467	pure 0.30062	heterosexual 0.30050	honest 0.29993	smooth 0.29533	successive 0.29425	uninterrupted 0.29394	unadulterated 0.29296	unbending 0.29082	undistorted 0.29031	linear 0.29000	genuine 0.28898	right 0.28881	orderly 0.28176	undiluted 0.28159	forthright 0.27707	standard 0.26538	sorted 0.26498	level 0.23227

Test context:
***************
straight.a	773	22	what is sure , but i do n't believe anyone needs this warning , is that is most important to do things __straight__ , fair and honest , and never think you can outsmart scientology on your own .
Contexts for target straight are: ['advmodI_do']
Contexts in vocabulary for target straight are: ['advmodI_do']
Top most similar embeddings: straight 0.49443	imediately 0.37428	proably 0.37259	defintely 0.36944	absent-mindedly 0.36247	singlehandedly 0.36242	probally 0.36161	actaully 0.36153	usally 0.36033	easilly 0.35935

Generated lemmatized results
***************
GENERATED	straight.a 773 ::: imediately;proably;defintely;singlehandedly;probally;actaully;usally;easilly;anally;dexterously

Filtered results
***************
RANKED	straight.a 773	right 0.30890	plain 0.28804	direct 0.28108	honest 0.27885	true 0.26884	pure 0.26763	vertical 0.26643	uninterrupted 0.26555	accurate 0.26504	smooth 0.26372	truthful 0.26301	clear 0.26170	consecutive 0.25858	heterosexual 0.25789	linear 0.25669	correct 0.24835	successive 0.24636	orderly 0.24634	candid 0.24631	undiluted 0.24592	unadulterated 0.24367	unswerving 0.24219	continuous 0.24040	genuine 0.24013	unbending 0.23827	sorted 0.23732	undistorted 0.23552	forthright 0.23160	standard 0.21983	level 0.21890

Test context:
***************
straight.a	774	4	i am very much __straight__ ( much to the approval of my girlfriend ) and i intend fully to stay that way .
Contexts for target straight are: ['amodI_much']
Contexts in vocabulary for target straight are: ['amodI_much']
Top most similar embeddings: straight 0.46240	straighter 0.35480	goddamned 0.34700	straight-up 0.34509	pritty 0.34214	repetative 0.33988	oh-so 0.33971	downhill 0.33906	crazily 0.33900	niggly 0.33831

Generated lemmatized results
***************
GENERATED	straight.a 774 ::: goddamned;pritty;repetative;downhill;crazily;niggly;wrinkly;gnarly;soooooooo;numbingly

Filtered results
***************
RANKED	straight.a 774	vertical 0.31101	true 0.31052	plain 0.30950	smooth 0.30889	clear 0.30479	honest 0.30129	unbending 0.29962	right 0.29961	direct 0.29733	unadulterated 0.29631	pure 0.29505	accurate 0.29382	heterosexual 0.29268	undistorted 0.29227	truthful 0.29187	uninterrupted 0.28723	consecutive 0.28388	correct 0.28079	undiluted 0.28063	continuous 0.28051	linear 0.28013	unswerving 0.27905	genuine 0.27537	candid 0.27301	orderly 0.26986	successive 0.26691	forthright 0.26306	sorted 0.25590	standard 0.25281	level 0.23057

Test context:
***************
straight.a	775	10	the event was held in an 2000m rowing course with __straight__ sides .
Contexts for target straight are: ['amodI_sides']
Contexts in vocabulary for target straight are: ['amodI_sides']
Top most similar embeddings: straight 0.52055	near-vertical 0.39380	steepish 0.38087	cleated 0.37264	slabby 0.37103	straight-sided 0.36635	straightest 0.36480	straighter 0.36447	sinewy 0.36320	half-round 0.36244

Generated lemmatized results
***************
GENERATED	straight.a 775 ::: steepish;cleated;slabby;sinewy;righthand;cambered;beveled;shortish;sleekly;seamy

Filtered results
***************
RANKED	straight.a 775	vertical 0.34773	smooth 0.32596	consecutive 0.31768	plain 0.31683	right 0.31215	unbending 0.30791	direct 0.30362	pure 0.30175	honest 0.30029	successive 0.29871	heterosexual 0.29784	linear 0.29775	uninterrupted 0.29596	clear 0.29531	truthful 0.29261	undistorted 0.29196	continuous 0.29124	true 0.29017	candid 0.28973	unswerving 0.28669	forthright 0.28382	genuine 0.28062	accurate 0.27911	undiluted 0.27513	correct 0.27080	orderly 0.26766	unadulterated 0.26593	standard 0.24890	sorted 0.24873	level 0.24450

Test context:
***************
straight.a	776	5	lou can we get this __straight__ ?
Contexts for target straight are: ['nsubj_this', 'xcompI_get']
Contexts in vocabulary for target straight are: ['nsubj_this', 'xcompI_get']
Top most similar embeddings: straight 0.23388	stright 0.16538	wrong 0.16167	straightened 0.15790	fifty-fifty 0.15742	straighter 0.15707	scot-free 0.15677	groovin 0.15657	straightforward 0.15620	silly 0.15594

Generated lemmatized results
***************
GENERATED	straight.a 776 ::: stright;wrong;straightened;groovin;straightforward;silly;dualled;treck;ridiculous;worsens

Filtered results
***************
RANKED	straight.a 776	correct 0.15058	sorted 0.14999	right 0.14809	clear 0.14517	true 0.14502	smooth 0.14238	vertical 0.13970	direct 0.13771	honest 0.13663	accurate 0.13520	heterosexual 0.13326	truthful 0.13270	plain 0.13141	pure 0.12988	linear 0.12814	uninterrupted 0.12717	candid 0.12678	genuine 0.12605	consecutive 0.12397	undiluted 0.12162	undistorted 0.11713	forthright 0.11706	continuous 0.11675	level 0.11660	orderly 0.11646	standard 0.11451	unadulterated 0.11390	successive 0.11315	unswerving 0.10692	unbending 0.10626

Test context:
***************
straight.a	777	13	it should be recognized that the ideal route for a cycle is a __straight__ one between origin and destination .
Contexts for target straight are: ['amodI_one']
Contexts in vocabulary for target straight are: ['amodI_one']
Top most similar embeddings: straight 0.50469	five-foot 0.36724	straight-sided 0.36700	four-card 0.36488	extra-long 0.36463	fine-looking 0.36438	right-most 0.36014	shortish 0.36003	definative 0.35982	fiesty 0.35974

Generated lemmatized results
***************
GENERATED	straight.a 777 ::: shortish;definative;fiesty;sleekly;oldish;teensy;gnarly;goddamned;sinewy;slutty

Filtered results
***************
RANKED	straight.a 777	vertical 0.32490	smooth 0.31926	right 0.31802	plain 0.31763	heterosexual 0.31621	pure 0.31517	consecutive 0.31483	direct 0.31243	truthful 0.31154	true 0.31111	linear 0.30853	honest 0.30738	undistorted 0.30487	correct 0.30444	accurate 0.30162	continuous 0.30067	unbending 0.30057	genuine 0.30022	candid 0.29974	clear 0.29872	orderly 0.29769	successive 0.29299	uninterrupted 0.29180	unswerving 0.29168	unadulterated 0.29099	forthright 0.28044	undiluted 0.27837	standard 0.27050	sorted 0.24426	level 0.23896

Test context:
***************
straight.a	778	14	pittsburgh pirates slugger paul waner set a new national league record after finishing fourteen __straight__ games with at least one long hit ( twelve doubles , five triples , three home runs ) .
Contexts for target straight are: ['amodI_games']
Contexts in vocabulary for target straight are: ['amodI_games']
Top most similar embeddings: straight 0.52698	small-sided 0.40773	arcade-style 0.38949	squad-based 0.38470	four-player 0.38458	multi-table 0.37592	2-player 0.37567	high-scoring 0.37484	side-scrolling 0.37327	german-style 0.37163

Generated lemmatized results
***************
GENERATED	straight.a 778 ::: quickfire;silly;niggly;squiggly;kitschy;blackly;smutty;cheesy;sleekly;shortish

Filtered results
***************
RANKED	straight.a 778	consecutive 0.34119	successive 0.31891	vertical 0.31447	pure 0.30915	direct 0.30596	smooth 0.30524	linear 0.29906	plain 0.29691	heterosexual 0.29453	honest 0.29352	continuous 0.29270	true 0.29200	unadulterated 0.29196	uninterrupted 0.28684	candid 0.28403	truthful 0.28371	clear 0.28270	orderly 0.28243	accurate 0.28175	genuine 0.27835	undistorted 0.27807	right 0.27519	unswerving 0.27310	unbending 0.27181	standard 0.26848	undiluted 0.26637	correct 0.26010	sorted 0.25850	forthright 0.25710	level 0.21635

Test context:
***************
straight.a	779	17	it is certainly an impolitic statement by kerry , but i also think it is some welcome __straight__ talk regarding how he can win this election .
Contexts for target straight are: ['amodI_talk']
Contexts in vocabulary for target straight are: ['amodI_talk']
Top most similar embeddings: straight 0.51300	six-way 0.36438	25-minute 0.36170	straighter 0.36123	off-the-cuff 0.35904	smutty 0.35813	35-minute 0.35734	twenty-minute 0.35538	ten-minute 0.35437	shortish 0.35386

Generated lemmatized results
***************
GENERATED	straight.a 779 ::: smutty;shortish;blackly;longish;extemporaneous;uncomplimentary;definative;interminable;goddamned;silly

Filtered results
***************
RANKED	straight.a 779	direct 0.31668	smooth 0.31569	plain 0.31193	honest 0.30991	pure 0.30796	continuous 0.30653	vertical 0.30551	truthful 0.30545	candid 0.30532	consecutive 0.29905	linear 0.29627	uninterrupted 0.29590	clear 0.29434	true 0.29432	genuine 0.29419	forthright 0.29401	unswerving 0.29182	unadulterated 0.29110	orderly 0.29061	right 0.29050	heterosexual 0.28940	undiluted 0.28590	undistorted 0.28443	unbending 0.28268	successive 0.28001	accurate 0.27851	correct 0.27014	standard 0.26157	sorted 0.26151	level 0.23036

Test context:
***************
straight.a	780	8	the stock market never goes up in a __straight__ line , so there will always be crashes .
Contexts for target straight are: ['amodI_line']
Contexts in vocabulary for target straight are: ['amodI_line']
Top most similar embeddings: straight 0.55183	chat-up 0.39695	15-metre 0.39264	streight 0.38605	straightest 0.38500	15-mile 0.38498	research-proven 0.38478	near-vertical 0.38055	18-yard 0.38053	extra-long 0.37706

Generated lemmatized results
***************
GENERATED	straight.a 780 ::: streight;wiggly;shortish;dispensational;squiggly;steepish;sleekly;sinuous;sinewy;crackly

Filtered results
***************
RANKED	straight.a 780	vertical 0.35276	direct 0.34167	smooth 0.32335	continuous 0.31707	clear 0.31653	pure 0.31653	unbending 0.31363	consecutive 0.31262	linear 0.31194	uninterrupted 0.31157	plain 0.30906	true 0.30725	orderly 0.30228	unswerving 0.30131	undistorted 0.30090	right 0.30067	heterosexual 0.29819	successive 0.29715	truthful 0.29643	accurate 0.29466	correct 0.29340	undiluted 0.29269	candid 0.29135	honest 0.28631	forthright 0.28437	genuine 0.28131	unadulterated 0.28076	standard 0.27801	sorted 0.26911	level 0.23090

Test context:
***************
strain.n	781	4	the colonies of one __strain__ appeared smooth .
Contexts for target strain are: ['num_one', 'prep:ofI_colonies']
Contexts in vocabulary for target strain are: ['num_one', 'prep:ofI_colonies']
Top most similar embeddings: strain 0.24129	strains 0.19774	serotype 0.17625	bacterium 0.17247	microorganism 0.17113	marmoset 0.17082	parasitoid 0.17031	lovebird 0.17002	microbe 0.16869	pallida 0.16719

Generated lemmatized results
***************
GENERATED	strain.n 781 ::: serotype;bacterium;microorganism;marmoset;parasitoid;lovebird;microbe;pallida;organism;begomovirus

Filtered results
***************
RANKED	strain.n 781	stress 0.14635	breed 0.14549	type 0.14008	pressure 0.13832	tension 0.13776	burden 0.13534	variety 0.13463	load 0.13257	kind 0.13193	sort 0.12990	stock 0.12931	line 0.12607	exertion 0.12578	effort 0.12506	form 0.12296	worry 0.12244	tune 0.12191	group 0.12145	trace 0.12133	melody 0.11560	anxiety 0.11466	music 0.11090	extraction 0.10806

Test context:
***************
strain.n	782	4	which puts a real __strain__ on joe and i , i can tell you ) and i wanted this one to have its own category .
Contexts for target strain are: ['det_a', 'amod_real', 'dobjI_puts', 'prep:on_joe']
Contexts in vocabulary for target strain are: ['det_a', 'amod_real', 'dobjI_puts']
Top most similar embeddings: strain 0.13719	dampener 0.10858	question-mark 0.09141	burden 0.08978	strains 0.08965	firecracker 0.08843	pressure 0.08841	onus 0.08740	twist 0.08732	slant 0.08652

Generated lemmatized results
***************
GENERATED	strain.n 782 ::: dampener;burden;firecracker;pressure;onus;twist;slant;emphasis;presure;snorter

Filtered results
***************
RANKED	strain.n 782	burden 0.08978	pressure 0.08841	stress 0.08390	tension 0.08350	effort 0.08242	load 0.08005	variety 0.07025	exertion 0.06667	worry 0.06663	melody 0.06519	kind 0.06361	line 0.06323	anxiety 0.06266	breed 0.06244	tune 0.06160	sort 0.06102	stock 0.06090	type 0.05978	trace 0.05827	group 0.05761	form 0.05759	music 0.05428	extraction 0.04915

Test context:
***************
strain.n	783	8	the transgenic rice performed better than the parent __strain__ in heat and in recovery from heat shock [ 13 ] .
Contexts for target strain are: ['det_the', 'nn_parent', 'prep:thanI_better', 'prep:in_heat']
Contexts in vocabulary for target strain are: ['det_the', 'nn_parent', 'prep:thanI_better', 'prep:in_heat']
Top most similar embeddings: strain 0.05100	strains 0.04404	pes 0.03594	monotony 0.03545	pairing 0.03516	stress 0.03513	hornets 0.03502	manics 0.03489	hives 0.03478	exertions 0.03460

Generated lemmatized results
***************
GENERATED	strain.n 783 ::: pe;monotony;pairing;stress;hornet;manics;hive;exertion;birdy;homesters

Filtered results
***************
RANKED	strain.n 783	stress 0.03513	exertion 0.03460	pressure 0.03434	effort 0.03328	burden 0.03163	breed 0.03138	variety 0.03136	load 0.03118	tension 0.03117	stock 0.02908	line 0.02859	anxiety 0.02801	tune 0.02770	worry 0.02731	form 0.02725	kind 0.02724	type 0.02710	extraction 0.02653	sort 0.02638	group 0.02622	melody 0.02537	music 0.02399	trace 0.02372

Test context:
***************
strain.n	784	8	melt , melt my pains with thy soft __strains__ ; that , having ease me given , with full delight i leave this light , and take my flight for heaven .
Contexts for target strains are: ['poss_thy', 'amod_soft', 'prep:withI_melt']
Contexts in vocabulary for target strains are: ['poss_thy', 'amod_soft', 'prep:withI_melt']
Top most similar embeddings: strains 0.10480	strain 0.09236	sweetness 0.08753	caresses 0.08645	tones 0.08541	pungency 0.08374	billows 0.08332	exhalations 0.08328	caress 0.08253	mellowness 0.08138

Generated lemmatized results
***************
GENERATED	strain.n 784 ::: sweetness;caress;tone;pungency;billow;exhalation;mellowness;paleness;liquor;vibration

Filtered results
***************
RANKED	strain.n 784	melody 0.07473	variety 0.07256	exertion 0.06789	stress 0.06404	breed 0.06215	tune 0.06203	burden 0.06081	trace 0.06053	tension 0.06018	music 0.06002	pressure 0.06000	line 0.05967	anxiety 0.05701	load 0.05653	form 0.05522	kind 0.05426	stock 0.05414	effort 0.05279	extraction 0.05275	worry 0.05206	sort 0.05165	type 0.04999	group 0.04161

Test context:
***************
strain.n	785	3	they normally include __strains__ in current or recent circulation .
Contexts for target strains are: ['dobjI_include', 'prep:in_current']
Contexts in vocabulary for target strains are: ['dobjI_include', 'prep:in_current']
Top most similar embeddings: strains 0.20360	strain 0.16912	modulations 0.16272	variations 0.16259	chlorosis 0.16191	inhomogeneities 0.16108	accelerations 0.16041	dinoflagellates 0.15957	non-linearities 0.15946	taxa 0.15833

Generated lemmatized results
***************
GENERATED	strain.n 785 ::: modulation;variation;chlorosis;inhomogeneity;acceleration;dinoflagellate;taxon;trypanosomes;differentiation;periodicity

Filtered results
***************
RANKED	strain.n 785	variety 0.15447	stress 0.14537	pressure 0.14233	tension 0.13797	line 0.13663	breed 0.13660	stock 0.13619	trace 0.13359	form 0.13288	music 0.13287	melody 0.13193	tune 0.13084	type 0.13049	burden 0.12867	anxiety 0.12742	exertion 0.12723	kind 0.12666	load 0.12651	extraction 0.12648	group 0.12369	sort 0.12021	effort 0.11567	worry 0.11337

Test context:
***************
strain.n	786	12	seed for sustainable gardens needs to be from the old , reproducible __strains__ , with the parent plant selected from the best .
Contexts for target strains are: ['det_the', 'amod_old', 'punct_,', 'amod_reproducible', 'prep:fromI_be']
Contexts in vocabulary for target strains are: ['det_the', 'amod_old', 'punct_,', 'amod_reproducible', 'prep:fromI_be']
Top most similar embeddings: strains 0.02561	strain 0.02060	acetates 0.01954	genotypes 0.01873	varieties 0.01845	bacterium 0.01844	negatives 0.01842	bloodlines 0.01837	lineages 0.01829	cultivars 0.01813

Generated lemmatized results
***************
GENERATED	strain.n 786 ::: acetate;genotype;variety;bacterium;negative;bloodline;lineage;cultivar;woodblocks;polymorph

Filtered results
***************
RANKED	strain.n 786	variety 0.01845	melody 0.01653	stress 0.01652	music 0.01650	breed 0.01584	tune 0.01563	line 0.01551	tension 0.01543	form 0.01529	pressure 0.01528	exertion 0.01461	stock 0.01433	extraction 0.01424	type 0.01422	anxiety 0.01404	burden 0.01385	kind 0.01343	trace 0.01340	group 0.01335	load 0.01272	sort 0.01137	worry 0.01128	effort 0.01104

Test context:
***************
strain.n	787	24	we were n't doing the really hard work , the local greeks who came to do the heavy stuff were under a lot more __strain__ .
Contexts for target strain are: ['dep_lot', 'amod_more', 'prep:underI_were']
Contexts in vocabulary for target strain are: ['dep_lot', 'amod_more', 'prep:underI_were']
Top most similar embeddings: strain 0.11600	strains 0.08742	stress 0.08661	pressure 0.08587	presure 0.08075	understeer 0.07894	spunk 0.07524	oomph 0.07332	hassel 0.07310	cosh 0.07280

Generated lemmatized results
***************
GENERATED	strain.n 787 ::: stress;pressure;presure;understeer;spunk;oomph;hassel;cosh;pizzazz;lot

Filtered results
***************
RANKED	strain.n 787	stress 0.08661	pressure 0.08587	tension 0.07123	effort 0.06897	burden 0.06732	load 0.06703	exertion 0.06682	worry 0.06528	anxiety 0.06126	variety 0.06108	sort 0.06028	stock 0.05884	kind 0.05693	melody 0.05664	breed 0.05642	tune 0.05641	line 0.05601	type 0.05543	trace 0.05371	form 0.05137	extraction 0.05036	music 0.04928	group 0.04798

Test context:
***************
strain.n	788	22	if you have poor posture , your bones are not properly aligned and your muscles , joints and ligaments , take more __strain__ than nature intended .
Contexts for target strain are: ['amod_more', 'dobjI_take', 'prep:than_nature']
Contexts in vocabulary for target strain are: ['amod_more', 'dobjI_take', 'prep:than_nature']
Top most similar embeddings: strain 0.11434	strains 0.08399	umbrage 0.08264	stress 0.08162	cognisance 0.07816	burdens 0.07465	drudgery 0.07437	onus 0.07364	vigour 0.07280	hassle 0.07274

Generated lemmatized results
***************
GENERATED	strain.n 788 ::: umbrage;stress;cognisance;burden;drudgery;onus;vigour;hassle;reponsibility;pressure

Filtered results
***************
RANKED	strain.n 788	stress 0.08162	burden 0.07465	pressure 0.07254	tension 0.07089	effort 0.06935	exertion 0.06408	anxiety 0.06373	load 0.06223	stock 0.06108	form 0.06000	worry 0.05960	variety 0.05925	melody 0.05813	breed 0.05516	kind 0.05482	trace 0.05332	sort 0.05324	extraction 0.05243	type 0.05193	line 0.05067	music 0.04969	tune 0.04936	group 0.04847

Test context:
***************
strain.n	789	8	i was grateful for the respite for the __strain__ on my ever present ego was interfering with my receptivity toward james .
Contexts for target strain are: ['det_the', 'prep:forI_respite', 'prep:on_ego']
Contexts in vocabulary for target strain are: ['det_the', 'prep:forI_respite']
Top most similar embeddings: strain 0.21858	strains 0.18711	homesters 0.16729	socceroos 0.16720	hornets 0.16705	silkmen 0.16672	grundys 0.16627	windies 0.16546	argentines 0.16495	seasiders 0.16405

Generated lemmatized results
***************
GENERATED	strain.n 789 ::: homesters;socceroos;hornet;silkmen;grundys;windies;argentine;seasiders;jambos;dairyman

Filtered results
***************
RANKED	strain.n 789	pressure 0.15289	burden 0.15135	stress 0.15039	exertion 0.14605	tension 0.14326	effort 0.13850	load 0.13512	anxiety 0.13193	variety 0.12929	breed 0.12815	group 0.12683	tune 0.12563	melody 0.12547	line 0.12534	stock 0.12470	kind 0.12191	trace 0.12050	sort 0.12007	type 0.12004	worry 0.11997	form 0.11695	music 0.11023	extraction 0.10951

Test context:
***************
strain.n	790	13	i 've always been a big fan of both the r&b and bluegrass __strains__ of gospel music .
Contexts for target strains are: ['nn_bluegrass', 'conjI_r', 'prep:of_music']
Contexts in vocabulary for target strains are: ['nn_bluegrass', 'conjI_r', 'prep:of_music']
Top most similar embeddings: strains 0.11586	strain 0.08791	stylings 0.08578	rhythms 0.08300	voicings 0.08165	fusions 0.08144	rythm 0.08112	renditions 0.08073	medleys 0.08010	folk-rock 0.08006

Generated lemmatized results
***************
GENERATED	strain.n 790 ::: stylings;rhythm;voicing;fusion;rythm;rendition;medley;style;exponent;songbook

Filtered results
***************
RANKED	strain.n 790	melody 0.07663	tune 0.07552	variety 0.07208	music 0.07099	type 0.06797	form 0.06494	stress 0.06472	load 0.06278	trace 0.06159	pressure 0.06086	breed 0.06069	kind 0.06060	sort 0.05918	tension 0.05858	exertion 0.05723	stock 0.05679	line 0.05628	burden 0.05531	group 0.05443	effort 0.05398	extraction 0.05294	anxiety 0.05160	worry 0.04762

Test context:
***************
time.n	791	16	usually involved wandering around in caves solving complicated puzzles , and became completely obsolete around the __time__ reagan left office , as graphics became less crappy .
Contexts for target time are: ['det_the', 'prep:aroundI_obsolete', 'rcmod_left']
Contexts in vocabulary for target time are: ['det_the', 'rcmod_left']
Top most similar embeddings: time 0.26068	afternoone 0.19823	mid-eighties 0.19463	mid-fifties 0.19282	mid-seventies 0.18863	1570s 0.18724	1560s 0.18598	moment 0.18597	get-go 0.18545	mid-1920s 0.18413

Generated lemmatized results
***************
GENERATED	time.n 791 ::: afternoone;moment;forenoon;daie;blackstuff;yeere;houre;kopje;grundys;moneth

Filtered results
***************
RANKED	time.n 791	moment 0.18597	instant 0.17256	day 0.16816	interval 0.16630	period 0.16528	epoch 0.16380	juncture 0.16281	occasion 0.16197	point 0.15334	age 0.15327	space 0.15179	chance 0.15136	era 0.15056	instance 0.14685	deadline 0.14172	opportunity 0.14150	allotment 0.13982	allocation 0.13005	occasionally 0.09340

Test context:
***************
time.n	792	7	unless we receive an answer by this __time__ , stepan demirtchyan will not take part in the meeting .
Contexts for target time are: ['det_this', 'prep:byI_receive']
Contexts in vocabulary for target time are: ['det_this', 'prep:byI_receive']
Top most similar embeddings: time 0.24344	daie 0.16974	houre 0.16684	week 0.16545	mid-2005 0.16538	time/date 0.16489	week/month 0.16477	post 0.16454	way 0.16386	lunchtime 0.16372

Generated lemmatized results
***************
GENERATED	time.n 792 ::: daie;houre;week;post;way;lunchtime;bucketload;month;announcment;morning

Filtered results
***************
RANKED	time.n 792	day 0.15991	deadline 0.15797	juncture 0.15645	moment 0.15546	period 0.14944	occasion 0.14842	interval 0.14718	epoch 0.14559	age 0.14386	opportunity 0.14204	chance 0.14106	point 0.13957	era 0.13767	allocation 0.13665	instant 0.13608	instance 0.13592	space 0.13400	allotment 0.12357	occasionally 0.10102

Test context:
***************
time.n	793	12	their concern was being able to check their answers at that later __time__ .
Contexts for target time are: ['det_that', 'amod_later', 'prep:atI_check']
Contexts in vocabulary for target time are: ['det_that', 'amod_later', 'prep:atI_check']
Top most similar embeddings: time 0.13525	juncture 0.09165	moment 0.08995	date 0.08898	stage 0.08709	time-step 0.08365	timeslot 0.08262	tyme 0.08254	point 0.08224	period 0.08170

Generated lemmatized results
***************
GENERATED	time.n 793 ::: juncture;moment;date;stage;timeslot;tyme;point;period;epoch;tine

Filtered results
***************
RANKED	time.n 793	juncture 0.09165	moment 0.08995	point 0.08224	period 0.08170	epoch 0.08082	occasion 0.07531	interval 0.07518	day 0.07498	instant 0.07406	age 0.07394	era 0.07378	deadline 0.06661	instance 0.06616	opportunity 0.06430	space 0.06205	chance 0.05913	allotment 0.05814	allocation 0.05402	occasionally 0.03764

Test context:
***************
time.n	794	5	australia 's boys are five __times__ more likely to kill themselves than girls , they are more likely to be unemployed and much more likely to die in car accidents .
Contexts for target times are: ['number_five', 'depI_likely']
Contexts in vocabulary for target times are: ['number_five', 'depI_likely']
Top most similar embeddings: times 0.30243	trillion 0.16174	off-peak 0.16015	thousand 0.15472	billion 0.15453	1971-2000 0.15296	1961-90 0.15231	million 0.15219	3.000 0.15207	twice 0.15200

Generated lemmatized results
***************
GENERATED	time.n 794 ::: trillion;thousand;billion;million;twice;wsje;hundred;milion;tymes;least

Filtered results
***************
RANKED	time.n 794	instant 0.13634	period 0.13450	occasion 0.12663	interval 0.12378	era 0.12229	juncture 0.11883	age 0.11769	instance 0.11741	day 0.11716	epoch 0.11715	chance 0.11378	occasionally 0.11064	moment 0.10803	deadline 0.10744	point 0.10165	allocation 0.09834	allotment 0.09650	opportunity 0.09355	space 0.08963

Test context:
***************
time.n	795	2	in victorian __times__ i 'd have been packed of to the army to fight the natives in the empire !
Contexts for target times are: ['amod_victorian', 'prep:inI_packed']
Contexts in vocabulary for target times are: ['amod_victorian', 'prep:inI_packed']
Top most similar embeddings: times 0.23846	hey-day 0.16313	schoolrooms 0.16000	eras 0.15866	slipcase 0.15845	trays 0.15539	finery 0.15523	caskets 0.15455	glasshouses 0.15428	cruet 0.15427

Generated lemmatized results
***************
GENERATED	time.n 795 ::: schoolroom;era;slipcase;tray;finery;casket;glasshouse;cruet;cowshed;warehouse

Filtered results
***************
RANKED	time.n 795	era 0.15866	period 0.15038	day 0.14712	epoch 0.14602	occasion 0.14360	instant 0.14265	instance 0.14175	moment 0.14039	age 0.13875	interval 0.13539	juncture 0.13136	allotment 0.12680	deadline 0.11722	space 0.11704	point 0.10814	opportunity 0.10685	chance 0.10660	allocation 0.10365	occasionally 0.09956

Test context:
***************
time.n	796	13	fixed a problem where navigation tools would not display properly at at certain __times__ .
Contexts for target times are: ['amod_certain', 'pcomp:atI_at']
Contexts in vocabulary for target times are: ['amod_certain', 'pcomp:atI_at']
Top most similar embeddings: times 0.25584	junctures 0.19586	tymes 0.17505	instants 0.17118	humidities 0.16875	epochs 0.16839	intervals 0.16611	gestations 0.16540	cross-purposes 0.16518	altitudes 0.16308

Generated lemmatized results
***************
GENERATED	time.n 796 ::: juncture;tymes;instant;humidity;epoch;interval;gestation;altitude;magnification;locality

Filtered results
***************
RANKED	time.n 796	juncture 0.19586	instant 0.17118	epoch 0.16839	interval 0.16611	age 0.15679	period 0.15405	era 0.15404	occasion 0.15399	moment 0.15280	instance 0.14316	point 0.14263	deadline 0.14161	day 0.13645	allocation 0.12414	allotment 0.12293	chance 0.11445	opportunity 0.11341	space 0.10471	occasionally 0.09533

Test context:
***************
time.n	797	27	one ring to rule them all , one ring to find them , one ring to bring them all and in the darkness bind them in ancient __times__ the rings of power were crafted by the elven-smiths , and sauron , the dark lord , forged the one ring to rule all the others .
Contexts for target times are: ['amod_ancient', 'prep:inI_bind']
Contexts in vocabulary for target times are: ['amod_ancient', 'prep:inI_bind']
Top most similar embeddings: times 0.24247	tymes 0.16896	heathenism 0.15409	ploughsoil 0.15390	heavenlies 0.15388	corinth 0.15382	hieroglyphics 0.15298	epochs 0.15284	trances 0.15271	thebes 0.15249

Generated lemmatized results
***************
GENERATED	time.n 797 ::: tymes;heathenism;ploughsoil;heavenlies;corinth;hieroglyphic;epoch;trance;thebe;way

Filtered results
***************
RANKED	time.n 797	epoch 0.15284	day 0.14689	instant 0.14637	era 0.14256	period 0.14031	juncture 0.13945	instance 0.13801	age 0.13182	occasion 0.12989	moment 0.12941	interval 0.12737	deadline 0.11984	space 0.11802	allotment 0.11524	allocation 0.10840	point 0.10531	chance 0.10474	opportunity 0.10005	occasionally 0.09739

Test context:
***************
time.n	798	10	it was my very first trip solo and my first __time__ doing like a backpacker rather than a tourist with money to burn .
Contexts for target time are: ['poss_my', 'amod_first', 'conjI_solo', 'partmod_doing']
Contexts in vocabulary for target time are: ['poss_my', 'amod_first', 'conjI_solo', 'partmod_doing']
Top most similar embeddings: time 0.05335	teamers 0.04178	stint 0.04145	lunchbreak 0.04143	stints 0.04112	experiance 0.04083	solo 0.03932	earlies 0.03901	ex-racer 0.03878	nads 0.03873

Generated lemmatized results
***************
GENERATED	time.n 798 ::: teamers;stint;lunchbreak;experiance;solo;earlies;nad;skydives;christmas;job

Filtered results
***************
RANKED	time.n 798	moment 0.03328	point 0.03194	chance 0.03131	period 0.03127	epoch 0.03118	interval 0.03103	day 0.03092	occasion 0.03044	allotment 0.02993	instance 0.02897	instant 0.02798	deadline 0.02789	opportunity 0.02750	era 0.02683	age 0.02666	juncture 0.02654	space 0.02617	allocation 0.02248	occasionally 0.01650

Test context:
***************
time.n	799	19	in many visits the doctor starts asking about the first problem mentioned , and the patient does not have __time__ to bring up other important problems .
Contexts for target time are: ['dobjI_have', 'infmod_bring']
Contexts in vocabulary for target time are: ['dobjI_have', 'infmod_bring']
Top most similar embeddings: time 0.24510	temerity 0.19905	oppertunity 0.19851	gumption 0.19663	abilty 0.19049	oppotunity 0.18915	oppurtunity 0.18798	will-power 0.18520	oportunity 0.18498	opportunity 0.18466

Generated lemmatized results
***************
GENERATED	time.n 799 ::: temerity;oppertunity;gumption;abilty;oppotunity;oppurtunity;oportunity;opportunity;nouse;syntometrine

Filtered results
***************
RANKED	time.n 799	opportunity 0.18466	chance 0.17905	occasion 0.15492	moment 0.15384	space 0.15275	period 0.14585	day 0.14324	deadline 0.14301	interval 0.14060	point 0.13701	juncture 0.13651	allocation 0.13189	epoch 0.13115	instant 0.13015	instance 0.12973	allotment 0.12818	age 0.12562	era 0.11985	occasionally 0.09520

Test context:
***************
time.n	800	6	it would have been the perfect __time__ to kiss her , had he not been driving .
Contexts for target time are: ['nsubj_it', 'aux_would', 'aux_have', 'cop_been', 'det_the', 'amod_perfect', 'rootI_*root*', 'prep:to_kiss', 'dep_her', 'punct_,', 'dep_driving', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target time are: ['nsubj_it', 'aux_would', 'aux_have', 'cop_been', 'det_the', 'amod_perfect', 'rootI_*root*', 'prep:to_kiss', 'dep_her', 'punct_,', 'dep_driving', 'punct_.']
Top most similar embeddings: tiem 0.00013	wiser 0.00012	imprudent 0.00012	pity 0.00012	sacrilege 0.00012	knowne 0.00011	truer 0.00011	priviledge 0.00011	ridiculous 0.00011	irresistable 0.00011

Generated lemmatized results
***************
GENERATED	time.n 800 ::: tiem;wiser;imprudent;pity;sacrilege;knowne;truer;priviledge;ridiculous;irresistable

Filtered results
***************
RANKED	time.n 800	occasion 0.00008	moment 0.00008	chance 0.00007	opportunity 0.00007	instant 0.00006	point 0.00006	day 0.00006	age 0.00005	interval 0.00005	epoch 0.00005	era 0.00004	deadline 0.00004	allotment 0.00004	juncture 0.00004	instance 0.00004	space 0.00004	period 0.00004	allocation 0.00003	occasionally 0.00002

Test context:
***************
yard.n	801	6	- always identify people in your __yard__ before shooting at them .
Contexts for target yard are: ['poss_your', 'prep:inI_identify']
Contexts in vocabulary for target yard are: ['poss_your', 'prep:inI_identify']
Top most similar embeddings: yard 0.23069	backyard 0.18134	birdroom 0.17384	garden 0.17058	birthchart 0.17039	roofspace 0.16852	in-box 0.16761	locality 0.16734	inbox 0.16733	driveway 0.16624

Generated lemmatized results
***************
GENERATED	yard.n 801 ::: backyard;birdroom;garden;birthchart;roofspace;locality;inbox;driveway;workroom;toolstore

Filtered results
***************
RANKED	yard.n 801	garden 0.17058	area 0.16154	lawn 0.16005	courtyard 0.15943	depot 0.15562	playground 0.14839	patio 0.14014	enclosure 0.13858	metre 0.13457	terrace 0.13035	ground 0.12828	property 0.12824	lot 0.11457	pn 0.09923

Test context:
***************
yard.n	802	10	the garden should be checked for poisonous plants and the __yard__ adequately fenced .
Contexts for target yard are: ['det_the', 'conjI_plants', 'dep_fenced']
Contexts in vocabulary for target yard are: ['det_the', 'conjI_plants', 'dep_fenced']
Top most similar embeddings: yard 0.11202	paddocks 0.09036	shrubbery 0.09014	pond 0.09007	garden 0.08992	farmyard 0.08948	rockery 0.08932	courtyard 0.08889	shrubberies 0.08825	out-buildings 0.08814

Generated lemmatized results
***************
GENERATED	yard.n 802 ::: paddock;shrubbery;pond;garden;farmyard;rockery;courtyard;fishpond;understory;polytunnel

Filtered results
***************
RANKED	yard.n 802	garden 0.08992	courtyard 0.08889	lawn 0.08598	playground 0.07793	patio 0.07772	enclosure 0.07750	ground 0.07744	terrace 0.07658	metre 0.07289	depot 0.06994	area 0.06873	property 0.06095	lot 0.05435	pn 0.04286

Test context:
***************
yard.n	803	22	63 mins : vladimir smicer is determined to make his farewell appearance a memorable one as he hits a shot from 20 __yards__ which dida manages to save .
Contexts for target yards are: ['num_20', 'prep:fromI_shot', 'rcmod_manages']
Contexts in vocabulary for target yards are: ['num_20', 'prep:fromI_shot', 'rcmod_manages']
Top most similar embeddings: yards 0.13066	yds 0.10343	metres 0.09651	yarder 0.09073	kilometres 0.08957	vaas 0.08809	miles 0.08591	feet 0.08561	kilometers 0.08537	kasprowicz 0.08522

Generated lemmatized results
***************
GENERATED	yard.n 803 ::: yds;metre;yarder;kilometre;vaas;mile;foot;kilometer;kasprowicz;meter

Filtered results
***************
RANKED	yard.n 803	metre 0.09651	depot 0.06990	terrace 0.06680	courtyard 0.06486	playground 0.05876	garden 0.05717	enclosure 0.05647	ground 0.05642	property 0.05531	patio 0.05508	lawn 0.05499	area 0.05074	lot 0.04786	pn 0.04639

Test context:
***************
yard.n	804	4	the rest of the __yard__ had been suffering from a cough , and we were worried about it for the rock , but there was never any question in our mind that so long as he was fit he would race .
Contexts for target yard are: ['det_the', 'prep:ofI_rest']
Contexts in vocabulary for target yard are: ['det_the', 'prep:ofI_rest']
Top most similar embeddings: yard 0.24754	henhouse 0.18786	headshunt 0.18680	woodshed 0.18576	afternoone 0.18445	doorframe 0.18368	pitlane 0.18302	toolstore 0.18296	endzone 0.18295	courtyard 0.18248

Generated lemmatized results
***************
GENERATED	yard.n 804 ::: henhouse;headshunt;woodshed;afternoone;doorframe;pitlane;toolstore;endzone;courtyard;farmyard

Filtered results
***************
RANKED	yard.n 804	courtyard 0.18248	garden 0.17878	lawn 0.17034	depot 0.16847	playground 0.16043	area 0.15899	enclosure 0.15599	ground 0.15344	patio 0.15094	metre 0.14854	terrace 0.14747	property 0.14164	lot 0.11556	pn 0.11334

Test context:
***************
yard.n	805	22	at one point a user seemed to walk the 50 miles from one district to another by simply walking a couple of __yards__ !
Contexts for target yards are: ['prep:ofI_couple']
Contexts in vocabulary for target yards are: ['prep:ofI_couple']
Top most similar embeddings: yards 0.52803	metres 0.43386	kilometres 0.41229	kilometers 0.40547	miles 0.40353	yds 0.40002	centimetres 0.39998	meters 0.39550	inches 0.38834	paces 0.38693

Generated lemmatized results
***************
GENERATED	yard.n 805 ::: metre;kilometre;kilometer;mile;yds;centimetre;meter;inch;pace;millimetre

Filtered results
***************
RANKED	yard.n 805	metre 0.43386	courtyard 0.31528	depot 0.30437	terrace 0.29479	enclosure 0.29404	patio 0.29120	playground 0.28661	lawn 0.28255	area 0.27397	garden 0.27391	ground 0.27388	lot 0.27130	property 0.26907	pn 0.22560

Test context:
***************
yard.n	806	12	after years of wanting one of those plastic flamingos in the front __yard__ , the in-laws brought a light-up version .
Contexts for target yard are: ['det_the', 'amod_front', 'prep:inI_flamingos']
Contexts in vocabulary for target yard are: ['det_the', 'amod_front']
Top most similar embeddings: yard 0.26804	tubeplate 0.20737	courtyard 0.20174	headshunt 0.19984	cantrail 0.19896	doorframe 0.19892	companionway 0.19695	crossmember 0.19626	guardroom 0.19435	hatchway 0.19425

Generated lemmatized results
***************
GENERATED	yard.n 806 ::: tubeplate;courtyard;headshunt;cantrail;doorframe;companionway;crossmember;guardroom;hatchway;garden

Filtered results
***************
RANKED	yard.n 806	courtyard 0.20174	garden 0.19350	lawn 0.18613	patio 0.17454	terrace 0.16946	depot 0.16670	playground 0.16420	area 0.16367	enclosure 0.16212	ground 0.15357	metre 0.14534	property 0.13929	lot 0.11734	pn 0.11324

Test context:
***************
yard.n	807	41	over two-thirds of the lace- runners lived in compton or the adjacent areas , with a smaller group in mutton lane and others scattered around the other working class areas of the town , although curiously , not in the densely-populated __yards__ off dig street .
Contexts for target yards are: ['det_the', 'amod_densely-populated', 'prep:inI_curiously', 'prep:off_street']
Contexts in vocabulary for target yards are: ['det_the', 'prep:off_street']
Top most similar embeddings: yards 0.24048	yard 0.20547	yds 0.19698	metres 0.18733	headshunt 0.18315	alleyway 0.18305	car-park 0.18264	mile 0.18125	a689 0.18123	half-mile 0.18081

Generated lemmatized results
***************
GENERATED	yard.n 807 ::: yds;metre;headshunt;alleyway;mile;hatchway;companionway;carpark;boathouse;seld

Filtered results
***************
RANKED	yard.n 807	metre 0.18733	courtyard 0.17465	ground 0.16042	terrace 0.15623	garden 0.15455	enclosure 0.15170	depot 0.15159	playground 0.15018	area 0.14736	lawn 0.14374	property 0.14282	patio 0.13579	lot 0.12020	pn 0.10325

Test context:
***************
yard.n	808	3	inside the fenced __yard__ was a gigantic fireplace , and beside it was a pile of huge bones .
Contexts for target yard are: ['det_the', 'amod_fenced', 'prep:insideI_was']
Contexts in vocabulary for target yard are: ['det_the', 'amod_fenced', 'prep:insideI_was']
Top most similar embeddings: yard 0.13108	car-park 0.10202	courtyard 0.10166	paddock 0.09760	henhouse 0.09652	outhouse 0.09650	enclosure 0.09551	graveyard 0.09539	garden 0.09493	carpark 0.09435

Generated lemmatized results
***************
GENERATED	yard.n 808 ::: courtyard;paddock;henhouse;outhouse;enclosure;graveyard;garden;carpark;alleyway;exclosure

Filtered results
***************
RANKED	yard.n 808	courtyard 0.10166	enclosure 0.09551	garden 0.09493	area 0.08462	playground 0.08326	ground 0.08177	lawn 0.08112	patio 0.08047	depot 0.07774	terrace 0.07458	metre 0.07131	property 0.06117	lot 0.05029	pn 0.04935

Test context:
***************
yard.n	809	16	this goes back to the grade school playground rules , you should tell on the school __yard__ bully , but you will not since your friends will think your a snitch .
Contexts for target yard are: ['nnI_bully']
Contexts in vocabulary for target yard are: ['nnI_bully']
Top most similar embeddings: yard 0.45432	schoolyard 0.39040	farmyard 0.36893	playground 0.36158	graveyard 0.35079	backyard 0.35035	paddock 0.34949	sweetshop 0.34473	scrapyard 0.34155	outhouse 0.33906

Generated lemmatized results
***************
GENERATED	yard.n 809 ::: schoolyard;farmyard;playground;graveyard;backyard;paddock;sweetshop;scrapyard;outhouse;boardroom

Filtered results
***************
RANKED	yard.n 809	playground 0.36158	courtyard 0.33782	garden 0.33201	lawn 0.30819	metre 0.30517	enclosure 0.30052	depot 0.29871	terrace 0.28717	patio 0.28560	area 0.27811	ground 0.27316	property 0.25021	lot 0.24319	pn 0.21856

Test context:
***************
yard.n	810	11	are you sick of dragging the hose and sprinkler around the __yard__ ?
Contexts for target yard are: ['det_the', 'prep:aroundI_dragging']
Contexts in vocabulary for target yard are: ['det_the']
Top most similar embeddings: yard 0.51838	headshunt 0.40493	guardroom 0.39449	courtyard 0.39032	minerva-press 0.39028	roadhead 0.38703	coach-house 0.38652	roofspace 0.38647	woodshed 0.38614	henhouse 0.38586

Generated lemmatized results
***************
GENERATED	yard.n 810 ::: headshunt;guardroom;courtyard;roadhead;roofspace;woodshed;henhouse;foundery;tanyard;drydock

Filtered results
***************
RANKED	yard.n 810	courtyard 0.39032	depot 0.36562	garden 0.36397	lawn 0.34752	playground 0.34494	area 0.33398	patio 0.33200	enclosure 0.32958	metre 0.32851	terrace 0.32733	ground 0.32557	property 0.29549	lot 0.26539	pn 0.24563

Test context:
***************
apparently.r	811	4	the rapid disintegration of __apparently__ strong and united countries , and the bitter internal conflicts which usually followed , has made a real impact in rangoon .
Contexts for target apparently are: ['advmodI_strong']
Contexts in vocabulary for target apparently are: ['advmodI_strong']
Top most similar embeddings: apparently 0.51665	seemingly 0.42071	obviously 0.40589	reportedly 0.40386	contrastingly 0.40272	extemely 0.40227	freakishly 0.40211	allegedly 0.39851	tiresomely 0.39819	fearsomely 0.39708

Generated lemmatized results
***************
GENERATED	apparently.r 811 ::: seemingly;obviously;reportedly;contrastingly;extemely;freakishly;allegedly;tiresomely;fearsomely;nonetheless

Filtered results
***************
RANKED	apparently.r 811	seemingly 0.42071	obviously 0.40589	evidently 0.38300	clearly 0.36436	palpably 0.35731	manifestly 0.35425	supposedly 0.34922	ostensibly 0.33085	plainly 0.32033	looking 0.23386

Test context:
***************
apparently.r	812	11	for example in 1794 a man called isaac rooke was found __apparently__ dead in a close near nottingham .
Contexts for target apparently are: ['advmodI_dead']
Contexts in vocabulary for target apparently are: ['advmodI_dead']
Top most similar embeddings: apparently 0.53523	seemingly 0.43743	alledgedly 0.42455	allegedly 0.41993	proably 0.41729	obviously 0.41252	apprently 0.41072	probably 0.41057	unfortuantely 0.41035	actually 0.40935

Generated lemmatized results
***************
GENERATED	apparently.r 812 ::: seemingly;alledgedly;allegedly;proably;obviously;apprently;probably;unfortuantely;actually;everlastingly

Filtered results
***************
RANKED	apparently.r 812	seemingly 0.43743	obviously 0.41252	evidently 0.38326	clearly 0.37201	supposedly 0.37193	palpably 0.36460	manifestly 0.35862	ostensibly 0.34784	plainly 0.34302	looking 0.22592

Test context:
***************
apparently.r	813	24	moreover , play seems not only inefficient because of its vigor ; it seems to be sometimes downright dangerous , exposing the organism to __apparently__ unnecessary risks .
Contexts for target apparently are: ['advmodI_unnecessary']
Contexts in vocabulary for target apparently are: ['advmodI_unnecessary']
Top most similar embeddings: apparently 0.52051	seemingly 0.43713	obviously 0.41865	probably 0.41538	perhaps 0.40642	allegedly 0.39805	unarguably 0.39532	actually 0.39515	surely 0.39392	unfortuantely 0.39248

Generated lemmatized results
***************
GENERATED	apparently.r 813 ::: seemingly;obviously;probably;perhaps;allegedly;unarguably;actually;surely;unfortuantely;apprently

Filtered results
***************
RANKED	apparently.r 813	seemingly 0.43713	obviously 0.41865	clearly 0.37885	manifestly 0.37610	evidently 0.37032	palpably 0.36949	supposedly 0.36453	plainly 0.34844	ostensibly 0.34588	looking 0.22410

Test context:
***************
apparently.r	814	3	however , this __apparently__ crushing blow early in a promising career took a strange twist .
Contexts for target apparently are: ['advmodI_crushing']
Contexts in vocabulary for target apparently are: ['advmodI_crushing']
Top most similar embeddings: apparently 0.50091	seemingly 0.42277	allegedly 0.41782	bloodily 0.41675	comically 0.41397	everlastingly 0.40455	humiliatingly 0.39782	audaciously 0.39700	dexterously 0.39695	deviously 0.39586

Generated lemmatized results
***************
GENERATED	apparently.r 814 ::: seemingly;allegedly;bloodily;comically;everlastingly;humiliatingly;audaciously;dexterously;deviously;inexcusably

Filtered results
***************
RANKED	apparently.r 814	seemingly 0.42277	obviously 0.39138	evidently 0.36231	palpably 0.35356	supposedly 0.35213	clearly 0.35120	manifestly 0.34724	ostensibly 0.34337	plainly 0.32432	looking 0.22835

Test context:
***************
apparently.r	815	6	the rest of the world is __apparently__ not doing too differently or even better , whatever the latter may mean in consequence .
Contexts for target apparently are: ['advmodI_doing']
Contexts in vocabulary for target apparently are: ['advmodI_doing']
Top most similar embeddings: apparently 0.52298	proably 0.43304	actually 0.42368	obviously 0.41684	defintely 0.41598	alledgedly 0.41586	seemingly 0.41427	apprently 0.41427	unfortuantely 0.41382	allegedly 0.41257

Generated lemmatized results
***************
GENERATED	apparently.r 815 ::: proably;actually;obviously;defintely;alledgedly;seemingly;apprently;unfortuantely;allegedly;probally

Filtered results
***************
RANKED	apparently.r 815	obviously 0.41684	seemingly 0.41427	evidently 0.38009	clearly 0.37296	supposedly 0.36360	ostensibly 0.34868	manifestly 0.34799	palpably 0.34427	plainly 0.33332	looking 0.22670

Test context:
***************
apparently.r	816	5	the chilling conclusion is that __apparently__ fairly modest changes in initial conditions can produce huge differences in the final outcome .
Contexts for target apparently are: ['advmodI_changes']
Contexts in vocabulary for target apparently are: ['advmodI_changes']
Top most similar embeddings: apparently 0.51766	obviously 0.41409	seemingly 0.41062	actually 0.40627	proably 0.40047	allegedly 0.39826	however 0.39756	arithmetically 0.39731	sometimes 0.39724	nonetheless 0.39602

Generated lemmatized results
***************
GENERATED	apparently.r 816 ::: obviously;seemingly;actually;proably;allegedly;however;arithmetically;sometimes;nonetheless;even

Filtered results
***************
RANKED	apparently.r 816	obviously 0.41409	seemingly 0.41062	evidently 0.37889	clearly 0.37582	supposedly 0.36051	manifestly 0.35694	palpably 0.35502	ostensibly 0.35309	plainly 0.32226	looking 0.22651

Test context:
***************
apparently.r	817	3	" the system __apparently__ requires nothing more than an internet connection and a web browser to use -- no software or hardware required .
Contexts for target apparently are: ['advmodI_requires']
Contexts in vocabulary for target apparently are: ['advmodI_requires']
Top most similar embeddings: apparently 0.51699	obviously 0.42517	however 0.41253	futhermore 0.41050	also 0.40995	seemingly 0.40967	actually 0.40804	unfortunately 0.40519	allegedly 0.40450	usually 0.40344

Generated lemmatized results
***************
GENERATED	apparently.r 817 ::: obviously;however;futhermore;also;seemingly;actually;unfortunately;allegedly;usually;furthermore

Filtered results
***************
RANKED	apparently.r 817	obviously 0.42517	seemingly 0.40967	clearly 0.38758	evidently 0.38749	manifestly 0.36714	supposedly 0.36394	ostensibly 0.35701	plainly 0.35140	palpably 0.34491	looking 0.22186

Test context:
***************
apparently.r	818	4	the world has been __apparently__ powerless to do anything about it .
Contexts for target apparently are: ['advmodI_powerless']
Contexts in vocabulary for target apparently are: ['advmodI_powerless']
Top most similar embeddings: apparently 0.52738	seemingly 0.45283	allegedly 0.41119	bureaucratically 0.40523	obviously 0.40193	essentially 0.40085	nonetheless 0.39832	inexcusably 0.39820	apprently 0.39671	everlastingly 0.39645

Generated lemmatized results
***************
GENERATED	apparently.r 818 ::: seemingly;allegedly;bureaucratically;obviously;essentially;nonetheless;inexcusably;apprently;everlastingly;however

Filtered results
***************
RANKED	apparently.r 818	seemingly 0.45283	obviously 0.40193	evidently 0.38088	manifestly 0.37562	palpably 0.37054	supposedly 0.36977	clearly 0.36512	ostensibly 0.35894	plainly 0.33906	looking 0.22226

Test context:
***************
apparently.r	819	12	in those twenty years , the national highway traffic safety administration has __apparently__ never deemed the location of the malibu 's fuel system to be a problem .
Contexts for target apparently are: ['advmodI_deemed']
Contexts in vocabulary for target apparently are: ['advmodI_deemed']
Top most similar embeddings: apparently 0.52092	obviously 0.41699	allegedly 0.40776	seemingly 0.40654	unfortuantely 0.40334	alledgedly 0.40162	nonetheless 0.39900	however 0.39875	proably 0.39811	reportedly 0.39767

Generated lemmatized results
***************
GENERATED	apparently.r 819 ::: obviously;allegedly;seemingly;unfortuantely;alledgedly;nonetheless;however;proably;reportedly;doubtlessly

Filtered results
***************
RANKED	apparently.r 819	obviously 0.41699	seemingly 0.40654	evidently 0.38401	clearly 0.37156	manifestly 0.36393	supposedly 0.36155	ostensibly 0.35616	palpably 0.34585	plainly 0.33826	looking 0.21648

Test context:
***************
apparently.r	820	0	__apparently__ you had to write in to the show requesting tickets at least 9 months in advance .
Contexts for target apparently are: ['advmodI_had']
Contexts in vocabulary for target apparently are: ['advmodI_had']
Top most similar embeddings: apparently 0.54217	allegedly 0.43616	proably 0.43600	unfortuantely 0.43222	alledgedly 0.43177	obviously 0.43153	apprently 0.42662	reportedly 0.42566	regretably 0.42339	actually 0.41985

Generated lemmatized results
***************
GENERATED	apparently.r 820 ::: allegedly;proably;unfortuantely;alledgedly;obviously;apprently;reportedly;regretably;actually;seemingly

Filtered results
***************
RANKED	apparently.r 820	obviously 0.43153	seemingly 0.41842	evidently 0.40881	clearly 0.38666	supposedly 0.38158	manifestly 0.36089	ostensibly 0.35911	palpably 0.35578	plainly 0.34948	looking 0.21588

Test context:
***************
around.r	821	9	as well as this , newton was no longer __around__ to tear strips off anyone who dared to disagree .
Contexts for target around are: ['advmod_longer', 'amodI_<eol>', 'pcomp_tear', 'punct_.']
Contexts in vocabulary for target around are: ['advmod_longer', 'pcomp_tear', 'punct_.']
Top most similar embeddings: around 0.09918	with 0.07873	about 0.07634	under 0.07581	beside 0.07567	beneath 0.07446	between 0.07435	among 0.07426	in 0.07328	toward 0.07242

Generated lemmatized results
***************
GENERATED	around.r 821 ::: with;about;under;beside;beneath;between;among;in;toward;unlike

Filtered results
***************
RANKED	around.r 821	about 0.07634	over 0.06222	alive 0.05442	approximately 0.05316	everywhere 0.05160	roughly 0.05018	living 0.04980	round 0.04555	surrounding 0.04478	encircling 0.04459	here 0.04305	there 0.03812

Test context:
***************
around.r	822	21	no , but will he be in a year or two ... probably and he most likely would n't have been __around__ in two years .
Contexts for target around are: ['advmodI_been']
Contexts in vocabulary for target around are: ['advmodI_been']
Top most similar embeddings: around 0.53832	apprently 0.37765	proably 0.37517	usally 0.36273	actaully 0.36160	defintely 0.36045	probally 0.35919	acutally 0.35735	probaly 0.35675	over 0.35613

Generated lemmatized results
***************
GENERATED	around.r 822 ::: apprently;proably;usally;actaully;defintely;probally;acutally;probaly;over;out

Filtered results
***************
RANKED	around.r 822	over 0.35613	about 0.34296	everywhere 0.33694	there 0.33144	here 0.32753	approximately 0.32457	roughly 0.32036	alive 0.27335	round 0.25710	surrounding 0.24710	encircling 0.23918	living 0.21112

Test context:
***************
around.r	823	29	bolt the mount on and then secure the whole thing with a small zip tie through one of the original holes at the bottom of the map holder and __around__ the mount .
Contexts for target around are: ['conjI_holes']
Contexts in vocabulary for target around are: ['conjI_holes']
Top most similar embeddings: around 0.44791	across 0.34104	sinkholes 0.33936	along 0.33612	beneath 0.33387	tabletops 0.33387	beside 0.33252	over 0.33207	underneath 0.32968	pinholes 0.32908

Generated lemmatized results
***************
GENERATED	around.r 823 ::: across;sinkholes;along;beneath;tabletops;beside;over;underneath;pinholes;throughs

Filtered results
***************
RANKED	around.r 823	over 0.33207	about 0.31973	everywhere 0.29473	roughly 0.29318	approximately 0.29155	surrounding 0.28754	round 0.28285	there 0.28159	encircling 0.27821	here 0.25813	alive 0.24560	living 0.22260

Test context:
***************
around.r	824	8	a : me and if i am not __around__ , marcus .
Contexts for target around are: ['mark_if', 'nsubj_i', 'cop_am', 'neg_not', 'advmodI_marcus']
Contexts in vocabulary for target around are: ['mark_if', 'nsubj_i', 'cop_am', 'neg_not']
Top most similar embeddings: over-weight 0.06718	ovulating 0.06578	vat-registered 0.06565	athiest 0.06182	interested 0.06174	technophobic 0.06126	ex-directory 0.06125	stiff-necked 0.06120	around 0.06119	raed 0.06100

Generated lemmatized results
***************
GENERATED	around.r 824 ::: ovulating;athiest;interested;technophobic;raed;affraid;hungover;eligable;salvageable;churchgoer

Filtered results
***************
RANKED	around.r 824	about 0.05461	alive 0.04912	over 0.04322	here 0.04097	everywhere 0.03859	living 0.03783	round 0.03719	roughly 0.03629	approximately 0.03594	there 0.03550	encircling 0.03348	surrounding 0.02861

Test context:
***************
around.r	825	9	for the last bit of the ramp it wraps __around__ and starts again from t=0 .
Contexts for target around are: ['advmodI_wraps']
Contexts in vocabulary for target around are: ['advmodI_wraps']
Top most similar embeddings: around 0.52931	about 0.38713	moodily 0.36541	absent-mindedly 0.36321	expectantly 0.35311	over 0.35221	regally 0.35129	unsuitably 0.34762	dexterously 0.34606	cooly 0.34560

Generated lemmatized results
***************
GENERATED	around.r 825 ::: about;moodily;expectantly;over;regally;unsuitably;dexterously;cooly;enticingly;ocassionally

Filtered results
***************
RANKED	around.r 825	about 0.38713	over 0.35221	roughly 0.33898	approximately 0.33486	everywhere 0.30714	here 0.29586	there 0.28194	round 0.26783	alive 0.26173	encircling 0.25178	surrounding 0.24677	living 0.20687

Test context:
***************
around.r	826	24	the strength of its radiation increases with altitude , as does its boundaries , until it completely merges with the inner belt proper at __around__ 600 miles from the surface of the earth .
Contexts for target around are: ['quantmodI_600']
Contexts in vocabulary for target around are: ['quantmodI_600']
Top most similar embeddings: around 0.54037	over 0.40859	about 0.38817	approximately 0.37308	at 0.35620	than 0.35444	between 0.34667	up 0.34497	nearly 0.34027	roughly 0.33968

Generated lemmatized results
***************
GENERATED	around.r 826 ::: over;about;approximately;at;than;between;up;nearly;roughly;almost

Filtered results
***************
RANKED	around.r 826	over 0.40859	about 0.38817	approximately 0.37308	roughly 0.33968	everywhere 0.27807	here 0.26490	there 0.25436	surrounding 0.25028	encircling 0.24988	round 0.24949	alive 0.24350	living 0.20907

Test context:
***************
around.r	827	19	this will be a halloween he will never forget! ' and with that they returned to kicking the ball __around__ .
Contexts for target around are: ['advmodI_kicking']
Contexts in vocabulary for target around are: ['advmodI_kicking']
Top most similar embeddings: around 0.53979	moodily 0.37080	about 0.36743	absent-mindedly 0.36442	restlessly 0.36420	regally 0.36181	skyward 0.36020	drunkenly 0.35954	ineffectually 0.35570	acrobatically 0.35563

Generated lemmatized results
***************
GENERATED	around.r 827 ::: moodily;about;restlessly;regally;skyward;drunkenly;ineffectually;acrobatically;nimbly;sleepily

Filtered results
***************
RANKED	around.r 827	about 0.36743	over 0.35234	everywhere 0.33037	roughly 0.32435	approximately 0.32169	here 0.30106	there 0.27286	round 0.26498	alive 0.26408	encircling 0.23969	surrounding 0.23929	living 0.19608

Test context:
***************
around.r	828	8	it 's tasty and a great deal at __around__ ten bucks .
Contexts for target around are: ['quantmodI_ten']
Contexts in vocabulary for target around are: ['quantmodI_ten']
Top most similar embeddings: around 0.52824	about 0.39619	over 0.39388	at 0.36894	approximately 0.36878	than 0.35406	in 0.34895	just 0.34582	up 0.34559	roughly 0.34311

Generated lemmatized results
***************
GENERATED	around.r 828 ::: about;over;at;approximately;than;in;just;up;roughly;nearly

Filtered results
***************
RANKED	around.r 828	about 0.39619	over 0.39388	approximately 0.36878	roughly 0.34311	everywhere 0.28845	here 0.26762	round 0.26028	surrounding 0.25918	there 0.25900	alive 0.25878	encircling 0.25501	living 0.21037

Test context:
***************
around.r	829	14	i think that maya angelou 's words will be very inspiring to readers all __around__ .
Contexts for target around are: ['dep_all', 'advmodI_readers']
Contexts in vocabulary for target around are: ['dep_all', 'advmodI_readers']
Top most similar embeddings: around 0.26112	over 0.18333	along 0.17766	alike 0.17534	aboard 0.17231	pleasurably 0.16936	across 0.16790	probally 0.16603	enticingly 0.16583	everywhere 0.16548

Generated lemmatized results
***************
GENERATED	around.r 829 ::: over;along;alike;aboard;pleasurably;across;probally;enticingly;everywhere;about

Filtered results
***************
RANKED	around.r 829	over 0.18333	everywhere 0.16548	about 0.16547	here 0.15227	roughly 0.14697	approximately 0.13944	there 0.12964	round 0.12708	alive 0.12562	encircling 0.11444	surrounding 0.10823	living 0.09740

Test context:
***************
around.r	830	1	been __around__ longer than some of my kids .
Contexts for target around are: ['advmodI_longer']
Contexts in vocabulary for target around are: ['advmodI_longer']
Top most similar embeddings: around 0.50355	noticably 0.35132	over 0.35059	probally 0.34482	slighly 0.34431	about 0.34366	perceptibly 0.33999	commensurately 0.33955	probaly 0.33951	usally 0.33571

Generated lemmatized results
***************
GENERATED	around.r 830 ::: noticably;over;probally;slighly;about;perceptibly;commensurately;probaly;usally;proably

Filtered results
***************
RANKED	around.r 830	over 0.35059	about 0.34366	approximately 0.32426	roughly 0.30451	there 0.30190	everywhere 0.29893	here 0.29786	alive 0.28026	round 0.25942	surrounding 0.24927	encircling 0.24018	living 0.21241

Test context:
***************
away.r	831	14	i mean , if you just let it run wild , people will walk __away__ with a negative impression .
Contexts for target away are: ['advmodI_walk']
Contexts in vocabulary for target away are: ['advmodI_walk']
Top most similar embeddings: away 0.55745	regally 0.39319	jauntily 0.38937	absent-mindedly 0.38669	acrobatically 0.37916	noiselessly 0.37888	moodily 0.37854	proably 0.37853	listlessly 0.37773	nimbly 0.37430

Generated lemmatized results
***************
GENERATED	away.r 831 ::: regally;jauntily;acrobatically;noiselessly;moodily;proably;listlessly;nimbly;inconspicuously;unsteadily

Filtered results
***************
RANKED	away.r 831	apart 0.37145	ahead 0.35169	along 0.34530	out 0.34523	off 0.34440	aside 0.32260	elsewhere 0.32015	continuously 0.30945	repeatedly 0.30320	distant 0.30171	hence 0.29767	afar 0.29586	distance 0.27585	absent 0.27328	depart 0.26777	removing 0.25102	confiscate 0.24564	repel 0.24257	gone 0.23965	stealing 0.23625	go 0.22971	leave 0.22232	rebuff 0.21987	seizing 0.20987

Test context:
***************
away.r	832	20	the following day she was out there on the steps screaming and yelling , " they 're taking our land __away__ from us .
Contexts for target away are: ['advmodI_taking', 'prep:from_us']
Contexts in vocabulary for target away are: ['advmodI_taking', 'prep:from_us']
Top most similar embeddings: away 0.28215	apart 0.20009	precipitously 0.17230	languidly 0.17198	acrobatically 0.17111	tamely 0.17091	skyward 0.17047	regally 0.17010	sacrificially 0.17010	restlessly 0.16909

Generated lemmatized results
***************
GENERATED	away.r 832 ::: apart;precipitously;languidly;acrobatically;tamely;skyward;regally;sacrificially;restlessly;nimbly

Filtered results
***************
RANKED	away.r 832	apart 0.20009	aside 0.16761	off 0.16463	along 0.15589	ahead 0.15481	elsewhere 0.15354	out 0.14873	continuously 0.14686	distant 0.14607	repeatedly 0.13895	absent 0.13858	hence 0.13721	depart 0.13015	afar 0.12935	distance 0.12918	confiscate 0.12846	stealing 0.12507	removing 0.12351	repel 0.11532	gone 0.11402	rebuff 0.10591	seizing 0.10413	leave 0.09993	go 0.09900

Test context:
***************
away.r	833	6	they just go ahead and puff __away__ .
Contexts for target away are: ['advmodI_puff']
Contexts in vocabulary for target away are: ['advmodI_puff']
Top most similar embeddings: away 0.53061	absent-mindedly 0.36440	acrobatically 0.36405	regally 0.36375	languidly 0.35918	up 0.35379	moodily 0.35251	hungrily 0.35242	vacantly 0.35231	convulsively 0.35197

Generated lemmatized results
***************
GENERATED	away.r 833 ::: acrobatically;regally;languidly;up;moodily;hungrily;vacantly;convulsively;just;imperiously

Filtered results
***************
RANKED	away.r 833	apart 0.34742	ahead 0.33274	off 0.33175	out 0.32853	aside 0.32491	along 0.30164	elsewhere 0.30142	repeatedly 0.29864	continuously 0.29725	distant 0.27286	hence 0.27236	afar 0.25827	absent 0.25543	removing 0.24830	distance 0.24458	depart 0.24377	confiscate 0.23261	stealing 0.22974	repel 0.22761	gone 0.21979	go 0.21954	seizing 0.21440	rebuff 0.20816	leave 0.20711

Test context:
***************
away.r	834	18	less any deductible expenses that they paid in the quarter , and any deductible expenses that were paid __away__ in the quarter at their direction by another person .
Contexts for target away are: ['advmodI_paid']
Contexts in vocabulary for target away are: ['advmodI_paid']
Top most similar embeddings: away 0.49209	duely 0.38525	proably 0.37931	electrostatically 0.37286	intially 0.37229	publickly 0.37143	ususally 0.37029	eventualy 0.36858	automaticly 0.36707	singlehandedly 0.36628

Generated lemmatized results
***************
GENERATED	away.r 834 ::: duely;proably;electrostatically;intially;publickly;ususally;eventualy;automaticly;singlehandedly;bascially

Filtered results
***************
RANKED	away.r 834	apart 0.35737	off 0.35711	out 0.34028	elsewhere 0.33091	ahead 0.32818	aside 0.32497	along 0.31820	repeatedly 0.30941	continuously 0.30605	hence 0.30266	absent 0.28470	distant 0.27252	afar 0.26287	confiscate 0.26037	removing 0.25086	stealing 0.24998	depart 0.24689	repel 0.24055	go 0.23813	gone 0.23744	distance 0.23706	rebuff 0.23008	leave 0.22578	seizing 0.21936

Test context:
***************
away.r	835	4	" instead of pushing __away__ , there were movements of acceptance .
Contexts for target away are: ['prtI_pushing']
Contexts in vocabulary for target away are: ['prtI_pushing']
Top most similar embeddings: away 0.52314	down 0.37177	out 0.37010	off 0.36533	aside 0.36254	up 0.36070	forward 0.35581	back 0.35462	apart 0.34829	through 0.33882

Generated lemmatized results
***************
GENERATED	away.r 835 ::: down;out;off;aside;up;forward;back;apart;through;along

Filtered results
***************
RANKED	away.r 835	out 0.37010	off 0.36533	aside 0.36254	apart 0.34829	along 0.33866	ahead 0.31785	elsewhere 0.28010	continuously 0.26687	distant 0.26501	absent 0.26226	removing 0.26093	hence 0.25852	distance 0.25438	depart 0.25101	confiscate 0.24727	afar 0.24702	repeatedly 0.24270	gone 0.23672	stealing 0.23373	repel 0.22938	go 0.22673	seizing 0.22099	leave 0.22061	rebuff 0.21219

Test context:
***************
away.r	836	12	if two planes are on a collision course , they are directed __away__ from each other .
Contexts for target away are: ['advmodI_directed', 'prep:from_other']
Contexts in vocabulary for target away are: ['advmodI_directed', 'prep:from_other']
Top most similar embeddings: away 0.26869	radially 0.19236	fluidly 0.18553	deductively 0.18451	perpendicularly 0.18319	outwards 0.18262	apart 0.18201	transversely 0.18101	asymmetrically 0.17678	inwardly 0.17594

Generated lemmatized results
***************
GENERATED	away.r 836 ::: radially;fluidly;deductively;perpendicularly;outwards;apart;transversely;asymmetrically;inwardly;orthogonally

Filtered results
***************
RANKED	away.r 836	apart 0.18201	elsewhere 0.15882	continuously 0.15755	aside 0.15631	distant 0.15556	off 0.15241	ahead 0.14636	along 0.14051	absent 0.14030	out 0.13838	afar 0.13813	repeatedly 0.13250	distance 0.13203	hence 0.13197	depart 0.12864	removing 0.12580	repel 0.12092	confiscate 0.11943	seizing 0.10783	stealing 0.10761	gone 0.10414	rebuff 0.10238	leave 0.09688	go 0.09407

Test context:
***************
away.r	837	15	the majority of home and apartment burglaries occur during the daytime when most people are __away__ at work or school .
Contexts for target away are: ['advmodI_are', 'prep:at_work']
Contexts in vocabulary for target away are: ['advmodI_are', 'prep:at_work']
Top most similar embeddings: away 0.24694	busily 0.18038	industriously 0.17626	sneakily 0.17189	back 0.17060	ineffectually 0.16778	everywhere 0.16756	here 0.16690	forlornly 0.16604	constantly 0.16597

Generated lemmatized results
***************
GENERATED	away.r 837 ::: busily;industriously;sneakily;back;ineffectually;everywhere;here;forlornly;constantly;regally

Filtered results
***************
RANKED	away.r 837	apart 0.16421	ahead 0.16314	off 0.16029	out 0.15843	continuously 0.15836	elsewhere 0.15668	aside 0.15001	along 0.13866	absent 0.13698	repeatedly 0.13539	hence 0.13221	afar 0.12394	distant 0.12114	depart 0.11441	removing 0.11237	stealing 0.11216	confiscate 0.10886	gone 0.10577	repel 0.10549	leave 0.10535	distance 0.10533	go 0.10422	seizing 0.09718	rebuff 0.09389

Test context:
***************
away.r	838	6	keep it at least 6 inches __away__ from the trunk .
Contexts for target away are: ['advmodI_inches', 'prep:from_trunk']
Contexts in vocabulary for target away are: ['advmodI_inches', 'prep:from_trunk']
Top most similar embeddings: away 0.28427	apart 0.20197	radially 0.19596	skywards 0.19283	perpendicularly 0.18799	skyward 0.18785	transversely 0.18697	outwards 0.18690	distally 0.18294	crosswise 0.18055

Generated lemmatized results
***************
GENERATED	away.r 838 ::: apart;radially;skywards;perpendicularly;skyward;transversely;outwards;distally;crosswise;diagonally

Filtered results
***************
RANKED	away.r 838	apart 0.20197	aside 0.15873	distant 0.15505	ahead 0.14767	along 0.14680	off 0.14634	out 0.14485	afar 0.14330	distance 0.14285	elsewhere 0.14267	continuously 0.13664	hence 0.13322	removing 0.13230	depart 0.13207	absent 0.12781	repeatedly 0.11771	stealing 0.11291	repel 0.11218	confiscate 0.10939	seizing 0.10421	gone 0.10078	go 0.09144	leave 0.08949	rebuff 0.08521

Test context:
***************
away.r	839	15	your expiration date will change if the current expiration date is more than 35 days __away__ .
Contexts for target away are: ['npadvmod_days', 'advmodI_more']
Contexts in vocabulary for target away are: ['npadvmod_days', 'advmodI_more']
Top most similar embeddings: away 0.25035	ago 0.18206	apart 0.17756	later 0.17460	postoperatively 0.17458	aproximately 0.17270	probaly 0.17132	even 0.17023	ahead 0.17023	afterward 0.16927

Generated lemmatized results
***************
GENERATED	away.r 839 ::: ago;apart;later;postoperatively;aproximately;probaly;even;ahead;afterward;intially

Filtered results
***************
RANKED	away.r 839	apart 0.17756	ahead 0.17023	off 0.16394	out 0.16221	aside 0.15426	elsewhere 0.15344	hence 0.14990	continuously 0.14860	along 0.14494	absent 0.13421	distant 0.13344	repeatedly 0.13314	afar 0.12190	depart 0.12185	distance 0.11297	removing 0.11215	repel 0.10937	gone 0.10905	confiscate 0.10263	leave 0.10234	go 0.09910	stealing 0.09906	rebuff 0.08707	seizing 0.08695

Test context:
***************
away.r	840	15	when we arrived we saw some of our colleagues up on the bar counter boogying __away__ - so of course we got up there and joined in the fun .
Contexts for target away are: ['advmodI_boogying']
Contexts in vocabulary for target away are: []
Top most similar embeddings: away 1.00000	acrobatically 0.72426	regally 0.72410	belly-up 0.72224	apart 0.71923	maually 0.71544	electrostatically 0.71516	vacantly 0.71032	absent-mindedly 0.70909	listlessly 0.70766

Generated lemmatized results
***************
GENERATED	away.r 840 ::: acrobatically;regally;apart;maually;electrostatically;vacantly;listlessly;perpendicularly;convulsively;tantalizingly

Filtered results
***************
RANKED	away.r 840	apart 0.71923	out 0.70042	off 0.69634	ahead 0.67226	aside 0.67061	along 0.66055	distant 0.65399	absent 0.64950	elsewhere 0.64692	removing 0.63312	go 0.62251	continuously 0.61824	depart 0.61631	gone 0.61611	repeatedly 0.61548	distance 0.61372	confiscate 0.60628	afar 0.60391	hence 0.60201	repel 0.59677	stealing 0.58068	leave 0.57225	rebuff 0.55503	seizing 0.54195

Test context:
***************
blue.a	841	11	it does this by averaging the red , green , and __blue__ colours around each pixel position .
Contexts for target blue are: ['amodI_colours']
Contexts in vocabulary for target blue are: ['amodI_colours']
Top most similar embeddings: blue 0.51406	grey-blue 0.42924	sky-blue 0.42855	red-orange 0.42853	bluish 0.42467	red 0.41703	red-and-white 0.41700	mauve 0.41515	blue/green 0.41493	golden-brown 0.41445

Generated lemmatized results
***************
GENERATED	blue.a 841 ::: bluish;red;mauve;pearlescent;purple;iridescent;pale;yellow;dayglo;cerulean

Filtered results
***************
RANKED	blue.a 841	purple 0.41342	grey 0.37023	azure 0.32122	cobalt 0.31628	sapphire 0.30910	naughty 0.30032	melancholy 0.29528	sad 0.28918	shady 0.28650	conservative 0.28080	pornographic 0.27670	indecent 0.27578	unhappy 0.27102	depressed 0.24999	pn 0.24953	speculative 0.24643	down 0.23704

Test context:
***************
blue.a	842	11	i hope you guys have n't thought i 've been feeling __blue__ this whole week , after last week 's appointment .
Contexts for target blue are: ['acompI_feeling']
Contexts in vocabulary for target blue are: ['acompI_feeling']
Top most similar embeddings: blue 0.50461	purple 0.38293	red 0.37671	leaden 0.36690	yellow 0.36648	bluish 0.36473	pink 0.36345	yellowy 0.36048	yucky 0.35809	ornery 0.35757

Generated lemmatized results
***************
GENERATED	blue.a 842 ::: purple;red;leaden;yellow;bluish;pink;yellowy;yucky;ornery;broody

Filtered results
***************
RANKED	blue.a 842	purple 0.38293	grey 0.33622	sad 0.32092	melancholy 0.31987	depressed 0.31622	naughty 0.31208	unhappy 0.30905	azure 0.29352	cobalt 0.29343	shady 0.29177	sapphire 0.28905	indecent 0.27628	conservative 0.27542	pornographic 0.27514	speculative 0.26057	pn 0.24716	down 0.23615

Test context:
***************
blue.a	843	4	but when daniel turned __blue__ one time and he totally stopped breathing .
Contexts for target blue are: ['amodI_time']
Contexts in vocabulary for target blue are: ['amodI_time']
Top most similar embeddings: blue 0.45588	double-quick 0.38341	yellow 0.36419	red 0.36380	world-record 0.35837	umpteenth 0.35789	button-down 0.35687	50-metre 0.35638	40-day 0.35629	back-to-school 0.35524

Generated lemmatized results
***************
GENERATED	blue.a 843 ::: yellow;red;umpteenth;purple;swizzle;pink;agreat;multicolor;psychokinetic;troublous

Filtered results
***************
RANKED	blue.a 843	purple 0.35505	grey 0.32992	sad 0.30754	melancholy 0.30077	naughty 0.29985	azure 0.29376	unhappy 0.29145	cobalt 0.29121	shady 0.28984	conservative 0.27238	sapphire 0.27189	pn 0.26928	indecent 0.26535	down 0.26404	pornographic 0.25998	depressed 0.25944	speculative 0.25728

Test context:
***************
blue.a	844	10	the common image of the sky is that of a __blue__ dome enclosing us and touching the earth at the horizon .
Contexts for target blue are: ['amodI_dome']
Contexts in vocabulary for target blue are: ['amodI_dome']
Top most similar embeddings: blue 0.50842	grey-blue 0.41666	red-and-white 0.41664	bluish 0.40708	blue/green 0.40438	blue-green 0.40260	sky-blue 0.40234	fan-shaped 0.40233	diamond-shaped 0.40183	dome-shaped 0.40002

Generated lemmatized results
***************
GENERATED	blue.a 844 ::: bluish;cerulean;purple;filmy;purplish;mauve;pink;yellow;opalescent;pearlised

Filtered results
***************
RANKED	blue.a 844	purple 0.39763	grey 0.36308	azure 0.33843	sapphire 0.32486	cobalt 0.32021	melancholy 0.30147	shady 0.29540	naughty 0.28872	pornographic 0.27137	sad 0.26719	conservative 0.26177	speculative 0.26032	unhappy 0.25613	depressed 0.25532	indecent 0.24814	pn 0.24377	down 0.23029

Test context:
***************
blue.a	845	37	as lynn bartels reviews in an excellent article for the january 22 rocky mountain news , state senator jennifer veiga , a democrat from denver , has introduced senate bill 77 to repeal a section of the __blue__ laws that prohibits the sale of most alcohol on sundays .
Contexts for target blue are: ['amodI_laws']
Contexts in vocabulary for target blue are: ['amodI_laws']
Top most similar embeddings: blue 0.44680	sumptuary 0.37216	anti-pollution 0.36222	anti-trade 0.35774	blue-green 0.35670	antiterrorist 0.35561	hard-and-fast 0.35159	yellow 0.35126	anti-free 0.35117	self-same 0.35035

Generated lemmatized results
***************
GENERATED	blue.a 845 ::: sumptuary;antiterrorist;yellow;newfangled;levitical;burghal;beige;supernal;monarchic;corporative

Filtered results
***************
RANKED	blue.a 845	grey 0.33786	purple 0.32592	azure 0.29878	naughty 0.29191	shady 0.29021	conservative 0.28696	sad 0.28216	melancholy 0.28092	indecent 0.27982	cobalt 0.27671	sapphire 0.27536	pornographic 0.27167	unhappy 0.26965	speculative 0.25817	depressed 0.24329	pn 0.24022	down 0.23630

Test context:
***************
blue.a	846	13	do they use research , brainstorming , linguistics , databases , software , __blue__ sky , or proprietary creation tactics ?
Contexts for target blue are: ['amodI_sky']
Contexts in vocabulary for target blue are: ['amodI_sky']
Top most similar embeddings: blue 0.55661	grey-blue 0.44695	bluish 0.41856	blue-green 0.41602	purple 0.41599	cerulean 0.41583	blue-grey 0.41518	red 0.41399	yellow 0.41311	blue-white 0.41305

Generated lemmatized results
***************
GENERATED	blue.a 846 ::: bluish;purple;cerulean;red;yellow;purplish;iridescent;turquoise;pink;grey

Filtered results
***************
RANKED	blue.a 846	purple 0.41599	grey 0.40198	azure 0.35217	cobalt 0.33135	sapphire 0.32229	melancholy 0.30894	shady 0.29423	sad 0.29399	naughty 0.29397	pornographic 0.27920	unhappy 0.27620	depressed 0.26451	indecent 0.26112	conservative 0.25945	pn 0.25774	speculative 0.25465	down 0.22904

Test context:
***************
blue.a	847	16	carbs will fast-flame but then you go into low blood sugar and you start to feel __blue__ and will forget what delirious pleasure it is to be a bottom feeder .
Contexts for target blue are: ['acompI_feel']
Contexts in vocabulary for target blue are: ['acompI_feel']
Top most similar embeddings: blue 0.47242	red 0.37041	purple 0.36938	yellow 0.36695	squashy 0.36141	leaden 0.35697	vaporous 0.35255	bluish 0.35251	broody 0.35155	clammy 0.35142

Generated lemmatized results
***************
GENERATED	blue.a 847 ::: red;purple;yellow;squashy;leaden;vaporous;bluish;broody;clammy;yucky

Filtered results
***************
RANKED	blue.a 847	purple 0.36938	grey 0.32864	sad 0.31598	melancholy 0.31174	naughty 0.31018	depressed 0.30852	unhappy 0.30770	shady 0.29308	indecent 0.28625	pornographic 0.28534	cobalt 0.28487	sapphire 0.27752	azure 0.27744	conservative 0.27332	speculative 0.25194	pn 0.24564	down 0.23971

Test context:
***************
blue.a	848	16	phalanxes of hookers re-emerge on bourbon street , music fills the air , the night turns __blue__ .
Contexts for target blue are: ['dobjI_turns']
Contexts in vocabulary for target blue are: ['dobjI_turns']
Top most similar embeddings: blue 0.51709	purple 0.42190	yellow 0.40892	pink 0.40730	red 0.40718	purplish 0.39576	blood-red 0.39543	mauve 0.39485	blue-green 0.39326	yellow-green 0.39324

Generated lemmatized results
***************
GENERATED	blue.a 848 ::: purple;yellow;pink;red;purplish;mauve;bluish;puce;orange;turquoise

Filtered results
***************
RANKED	blue.a 848	purple 0.42190	grey 0.37033	sapphire 0.32762	azure 0.32473	cobalt 0.32396	melancholy 0.30994	naughty 0.28988	sad 0.28342	shady 0.28332	pn 0.26299	pornographic 0.25313	down 0.25130	conservative 0.24959	depressed 0.24869	unhappy 0.24820	speculative 0.24478	indecent 0.23662

Test context:
***************
blue.a	849	4	every time i got __blue__ , i would put on the song , turn it up really loud and dance around the living room for twenty minutes and i would feel better .
Contexts for target blue are: ['nsubj_i', 'dep_got', 'rcmodI_time']
Contexts in vocabulary for target blue are: ['nsubj_i', 'dep_got', 'rcmodI_time']
Top most similar embeddings: blue 0.13312	farted 0.12789	puked 0.11884	itched 0.11825	wheezed 0.11797	beeped 0.11735	hollered 0.11697	flounced 0.11631	overslept 0.11612	bided 0.11584

Generated lemmatized results
***************
GENERATED	blue.a 849 ::: farted;puked;itched;wheezed;beeped;hollered;flounced;overslept;bided;bleeped

Filtered results
***************
RANKED	blue.a 849	grey 0.11441	purple 0.10032	naughty 0.09882	depressed 0.09563	sad 0.09469	unhappy 0.08627	melancholy 0.08288	azure 0.08036	cobalt 0.07774	sapphire 0.07576	shady 0.07330	conservative 0.07274	pn 0.07095	pornographic 0.07066	down 0.07001	speculative 0.06749	indecent 0.06630

Test context:
***************
blue.a	850	7	i.ve never once had my skin turn __blue__ , or had any real problems with circulation .
Contexts for target blue are: ['poss_my', 'amod_skin', 'nn_turn', 'dobjI_had']
Contexts in vocabulary for target blue are: ['poss_my', 'amod_skin', 'nn_turn', 'dobjI_had']
Top most similar embeddings: blue 0.04828	pink 0.04164	clit 0.04009	earlobes 0.03902	tans 0.03888	oversuit 0.03880	yellow 0.03878	nose 0.03864	purple 0.03848	eyes 0.03840

Generated lemmatized results
***************
GENERATED	blue.a 850 ::: pink;clit;earlobes;tans;oversuit;yellow;nose;purple;eyes;hair

Filtered results
***************
RANKED	blue.a 850	purple 0.03848	grey 0.03361	sapphire 0.03360	azure 0.03253	cobalt 0.03180	melancholy 0.02735	sad 0.02453	naughty 0.02412	pn 0.02316	shady 0.02260	pornographic 0.02049	conservative 0.01944	down 0.01931	depressed 0.01889	unhappy 0.01717	speculative 0.01697	indecent 0.01600

Test context:
***************
check.v	851	17	the first is that the " check " buttons on the web form do not stop respondents __checking__ more than one response at a time .
Contexts for target checking are: ['partmodI_respondents', 'dobj_response', 'prep:at_time']
Contexts in vocabulary for target checking are: ['partmodI_respondents', 'dobj_response', 'prep:at_time']
Top most similar embeddings: checking 0.10932	prejudging 0.08492	verifying 0.08331	querying 0.08313	ascertaining 0.08254	inspecting 0.08238	receiving 0.08189	approving 0.08181	triggering 0.08180	revisiting 0.08174

Generated lemmatized results
***************
GENERATED	check.v 851 ::: prejudge;verify;query;ascertain;inspect;receive;approve;trigger;revisit;request

Filtered results
***************
RANKED	check.v 851	verify 0.08331	inspect 0.08238	report 0.07940	scrutinise 0.07917	confirm 0.07721	submit 0.07689	note 0.07657	register 0.07630	admit 0.07522	mark 0.07436	examine 0.07419	put 0.07239	investigate 0.07187	select 0.07082	test 0.06853	search 0.06697	tick 0.06691	survey 0.06528

Test context:
***************
check.v	852	4	we recommend that you __check__ with us beforehand .
Contexts for target check are: ['mark_that', 'nsubj_you', 'ccompI_recommend', 'advcl_beforehand']
Contexts in vocabulary for target check are: ['mark_that', 'nsubj_you', 'ccompI_recommend']
Top most similar embeddings: check 0.12539	re-check 0.10283	double-check 0.09728	checked 0.09672	self-register 0.09237	consult 0.09157	recheck 0.09139	re-visit 0.09122	untick 0.09034	peruse 0.09028

Generated lemmatized results
***************
GENERATED	check.v 852 ::: consult;recheck;untick;peruse;revisit;reconfirm;prebook;proofread;verify;inspect

Filtered results
***************
RANKED	check.v 852	verify 0.08763	inspect 0.08756	confirm 0.08214	submit 0.07723	scrutinise 0.07708	examine 0.07639	select 0.07637	tick 0.07592	investigate 0.07478	register 0.07417	put 0.07124	test 0.06908	search 0.06826	admit 0.06452	mark 0.06360	note 0.06203	survey 0.05890	report 0.05825

Test context:
***************
check.v	853	4	bear unfortunately had to __check__ himself into an asylum for doing all this .
Contexts for target check are: ['aux_to', 'xcompI_had', 'dobj_himself', 'prep:into_asylum']
Contexts in vocabulary for target check are: ['aux_to', 'xcompI_had', 'dobj_himself']
Top most similar embeddings: check 0.11585	unburden 0.10294	reacquaint 0.10271	re-shoot 0.10232	baby-sit 0.09989	manhandle 0.09925	fumigate 0.09887	proove 0.09875	rearm 0.09800	embarass 0.09780

Generated lemmatized results
***************
GENERATED	check.v 853 ::: unburden;reacquaint;manhandle;fumigate;proove;rearm;embarass;retune;circumcise;recalibrate

Filtered results
***************
RANKED	check.v 853	verify 0.08885	inspect 0.08751	examine 0.08537	put 0.08209	admit 0.08099	submit 0.08006	investigate 0.07998	confirm 0.07991	scrutinise 0.07821	test 0.07436	register 0.07228	select 0.06915	tick 0.06826	search 0.06731	mark 0.06517	note 0.05991	report 0.05922	survey 0.05900

Test context:
***************
check.v	854	12	many schools in the area also use hand-held metal detectors to randomly __check__ students for weapons .
Contexts for target check are: ['aux_to', 'advmod_randomly', 'xcompI_use', 'dobj_students', 'prep:for_weapons']
Contexts in vocabulary for target check are: ['aux_to', 'advmod_randomly', 'xcompI_use', 'dobj_students', 'prep:for_weapons']
Top most similar embeddings: check 0.02822	inspect 0.02261	pre-qualify 0.02138	recheck 0.02115	pre-screen 0.02092	re-check 0.02089	interrogate 0.02051	cross-check 0.02048	authenticate 0.02023	assess 0.02015

Generated lemmatized results
***************
GENERATED	check.v 854 ::: inspect;recheck;interrogate;authenticate;assess;allocate;penalize;orientate;refuel;reconnoiter

Filtered results
***************
RANKED	check.v 854	inspect 0.02261	verify 0.01977	search 0.01919	select 0.01907	examine 0.01887	test 0.01824	investigate 0.01767	scrutinise 0.01721	confirm 0.01717	register 0.01644	admit 0.01572	submit 0.01531	put 0.01512	tick 0.01469	survey 0.01366	note 0.01233	mark 0.01218	report 0.01084

Test context:
***************
check.v	855	4	and if we just __check__ the right boxes on the vote cards , we 'll get closer !
Contexts for target check are: ['mark_if', 'nsubj_we', 'advmod_just', 'advclI_get', 'dobj_boxes', 'prep:on_cards']
Contexts in vocabulary for target check are: ['mark_if', 'nsubj_we', 'advmod_just', 'advclI_get', 'dobj_boxes', 'prep:on_cards']
Top most similar embeddings: check 0.01232	checked 0.01048	ticked 0.01026	checking 0.01010	re-check 0.00985	untick 0.00975	misplace 0.00963	tick 0.00962	mucked 0.00948	recive 0.00941

Generated lemmatized results
***************
GENERATED	check.v 855 ::: tick;untick;misplace;muck;recive;bung;uncheck;repack;stash;want

Filtered results
***************
RANKED	check.v 855	tick 0.01026	put 0.00854	inspect 0.00794	verify 0.00790	select 0.00753	confirm 0.00751	search 0.00723	test 0.00683	submit 0.00675	register 0.00664	examine 0.00661	scrutinise 0.00660	admit 0.00639	mark 0.00637	investigate 0.00594	survey 0.00567	note 0.00566	report 0.00528

Test context:
***************
check.v	856	2	you may __check__ the status of their security certificate at any time during the checkout process .
Contexts for target check are: ['nsubj_you', 'aux_may', 'rootI_*root*', 'dobj_status', 'prep:at_time', 'prep:during_process', 'punct_.', 'dobj_<eol>']
Contexts in vocabulary for target check are: ['nsubj_you', 'aux_may', 'rootI_*root*', 'dobj_status', 'prep:at_time', 'prep:during_process', 'punct_.']
Top most similar embeddings: check 0.00755	double-check 0.00615	recheck 0.00599	checked 0.00588	re-check 0.00576	re-apply 0.00542	indicate 0.00538	confirm 0.00537	queried 0.00534	reconfirm 0.00531

Generated lemmatized results
***************
GENERATED	check.v 856 ::: recheck;indicate;confirm;query;reconfirm;specify;inspect;override;revise;terminate

Filtered results
***************
RANKED	check.v 856	confirm 0.00537	inspect 0.00530	verify 0.00487	select 0.00450	submit 0.00439	examine 0.00430	register 0.00425	search 0.00412	tick 0.00410	note 0.00401	scrutinise 0.00391	test 0.00382	investigate 0.00380	admit 0.00366	report 0.00360	mark 0.00359	survey 0.00339	put 0.00332

Test context:
***************
check.v	857	0	__check__ the shoulders so it hangs well , stops at hips or below , and make sure the pants are long enough .
Contexts for target check are: ['rootI_*root*', 'dobj_shoulders', 'advcl_hangs', 'punct_,', 'conj_stops', 'punct_,', 'cc_and', 'conj_make', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target check are: ['rootI_*root*', 'dobj_shoulders', 'advcl_hangs', 'punct_,', 'conj_stops', 'punct_,', 'cc_and', 'conj_make', 'punct_.']
Top most similar embeddings: stiffens 0.00159	unbolt 0.00153	unclip 0.00141	shrugs 0.00136	tutted 0.00135	scrunch 0.00135	wrings 0.00134	moisturize 0.00134	check 0.00134	numbs 0.00134

Generated lemmatized results
***************
GENERATED	check.v 857 ::: stiffen;unbolt;unclip;shrug;tutted;scrunch;wring;moisturize;numb;kneel

Filtered results
***************
RANKED	check.v 857	inspect 0.00102	scrutinise 0.00100	put 0.00097	select 0.00095	examine 0.00092	investigate 0.00088	verify 0.00086	tick 0.00082	submit 0.00081	search 0.00078	mark 0.00075	confirm 0.00073	admit 0.00072	register 0.00070	note 0.00070	test 0.00069	survey 0.00065	report 0.00062

Test context:
***************
check.v	858	6	have your posture or muscle strength __checked__ at a health fair or another free screening program .
Contexts for target checked are: ['aux_have', 'nsubj_posture', 'rootI_*root*', 'prep:at_fair', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target checked are: ['aux_have', 'nsubj_posture', 'rootI_*root*', 'prep:at_fair', 'punct_.']
Top most similar embeddings: checked 0.02752	demonstrated 0.02240	helped 0.02157	unveiled 0.02133	double-checked 0.02122	exhibited 0.02104	rechecked 0.02099	doffed 0.02074	highlighted 0.02057	shown 0.02056

Generated lemmatized results
***************
GENERATED	check.v 858 ::: demonstrate;help;unveil;exhibit;rechecked;doff;highlight;show;boost;team

Filtered results
***************
RANKED	check.v 858	inspect 0.01965	examine 0.01946	confirm 0.01944	test 0.01941	search 0.01922	scrutinise 0.01813	note 0.01760	verify 0.01756	select 0.01747	investigate 0.01739	survey 0.01736	tick 0.01726	report 0.01726	mark 0.01694	submit 0.01668	put 0.01662	admit 0.01577	register 0.01466

Test context:
***************
check.v	859	2	i have __checked__ multiple times with my order and that is not the case .
Contexts for target checked are: ['nsubj_i', 'aux_have', 'rootI_*root*', 'dobj_times', 'prep:with_order', 'cc_and', 'conj_case', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target checked are: ['nsubj_i', 'aux_have', 'rootI_*root*', 'dobj_times', 'prep:with_order', 'cc_and', 'conj_case', 'punct_.']
Top most similar embeddings: checked 0.00476	double-checked 0.00405	rechecked 0.00401	re-checked 0.00378	cross-checked 0.00377	dowsed 0.00367	inspected 0.00356	phoned 0.00350	x-rayed 0.00348	quarrelled 0.00348

Generated lemmatized results
***************
GENERATED	check.v 859 ::: rechecked;dowse;inspect;phone;quarrel;weigh;fiddle;gigged;experiment;try

Filtered results
***************
RANKED	check.v 859	inspect 0.00356	examine 0.00327	test 0.00325	search 0.00323	scrutinise 0.00321	investigate 0.00311	confirm 0.00293	verify 0.00289	report 0.00285	mark 0.00285	note 0.00282	select 0.00279	survey 0.00276	tick 0.00274	submit 0.00259	admit 0.00258	register 0.00243	put 0.00231

Test context:
***************
check.v	860	28	customers who have printed their own boarding passes from continental 's portal can go directly through security to their flight gate , if they have no bags to __check__ .
Contexts for target check are: ['aux_to', 'infmodI_bags']
Contexts in vocabulary for target check are: ['aux_to', 'infmodI_bags']
Top most similar embeddings: check 0.25271	re-check 0.20759	recheck 0.19276	decontaminate 0.19037	sterilize 0.19004	double-check 0.18980	re-stock 0.18911	reseal 0.18830	recondition 0.18733	mass-produce 0.18488

Generated lemmatized results
***************
GENERATED	check.v 860 ::: recheck;decontaminate;sterilize;reseal;recondition;sanitise;refuel;repack;retreive;fumigate

Filtered results
***************
RANKED	check.v 860	inspect 0.18173	verify 0.17934	examine 0.16467	confirm 0.16460	investigate 0.16315	scrutinise 0.15655	put 0.15563	test 0.15482	select 0.14874	tick 0.14820	register 0.14400	submit 0.14332	search 0.14287	admit 0.14179	mark 0.13345	note 0.13320	report 0.12966	survey 0.12199

Test context:
***************
clear.v	861	26	the elderly simply ca n't afford current prices , dentists , and there 's not doubt at all that if they could that backlog could be __cleared__ very quickly .
Contexts for target cleared are: ['mark_if', 'nsubj_they', 'aux_could', 'nsubjpass_backlog', 'aux_could', 'auxpass_be', 'advclI_that', 'advmod_quickly', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target cleared are: ['mark_if', 'nsubj_they', 'aux_could', 'nsubjpass_backlog', 'aux_could', 'auxpass_be', 'advclI_that', 'advmod_quickly', 'punct_.']
Top most similar embeddings: cleared 0.00202	remedied 0.00161	eliminated 0.00151	redressed 0.00144	recouped 0.00143	solved 0.00141	rectified 0.00139	dealt 0.00137	removed 0.00137	detected 0.00135

Generated lemmatized results
***************
GENERATED	clear.v 861 ::: remedied;eliminate;redress;recoup;solve;rectify;deal;remove;detect;recover

Filtered results
***************
RANKED	clear.v 861	eliminate 0.00151	remove 0.00137	sort 0.00127	free 0.00123	process 0.00117	improve 0.00117	empty 0.00116	pass 0.00114	tidy 0.00113	cash 0.00112	pardon 0.00112	unblock 0.00110	change 0.00109	take 0.00109	exonerate 0.00107	release 0.00104	move 0.00103	skim 0.00099	absolve 0.00097	acquit 0.00096	brighten 0.00087	authorise 0.00083	vindicate 0.00080	over 0.00027	above 0.00022

Test context:
***************
clear.v	862	38	the mccarthy brothers who run the place are great hosts , and between them , their gourmet fare and an excellent reading room with a well-tended fireplace , i am well taken care of until the weather finally __clears__ .
Contexts for target clears are: ['mark_until', 'nsubj_weather', 'advmod_finally', 'advclI_taken']
Contexts in vocabulary for target clears are: ['mark_until', 'nsubj_weather', 'advmod_finally', 'advclI_taken']
Top most similar embeddings: clears 0.07221	abates 0.05823	cleared 0.05502	settles 0.05089	stabilises 0.05006	subsided 0.04956	relents 0.04940	arrives 0.04909	implodes 0.04867	disappears 0.04756

Generated lemmatized results
***************
GENERATED	clear.v 862 ::: abate;settle;stabilise;subside;relent;arrive;implode;disappear;soften;thaw

Filtered results
***************
RANKED	clear.v 862	improve 0.04331	empty 0.04024	sort 0.03924	remove 0.03910	tidy 0.03843	brighten 0.03746	free 0.03713	eliminate 0.03668	pass 0.03652	unblock 0.03549	take 0.03490	pardon 0.03478	exonerate 0.03466	move 0.03424	cash 0.03402	change 0.03338	absolve 0.03314	vindicate 0.03265	release 0.03252	authorise 0.03239	acquit 0.03110	process 0.03105	skim 0.03086	over 0.02169	above 0.01736

Test context:
***************
clear.v	863	32	you probably would n't even notice the 30 cars down the track that were n't damaged in any way , and are ready to move forward as soon as the track is __cleared__ .
Contexts for target cleared are: ['mark_as', 'nsubjpass_track', 'auxpass_is', 'ccompI_soon']
Contexts in vocabulary for target cleared are: ['mark_as', 'nsubjpass_track', 'auxpass_is', 'ccompI_soon']
Top most similar embeddings: cleared 0.06824	lifted 0.04869	finalized 0.04601	tarmaced 0.04592	removed 0.04573	strimmed 0.04525	loosened 0.04444	tidied 0.04425	finished 0.04423	zeroed 0.04416

Generated lemmatized results
***************
GENERATED	clear.v 863 ::: lift;finalize;tarmac;remove;strimmed;loosen;tidy;finish;zero;block

Filtered results
***************
RANKED	clear.v 863	remove 0.04573	tidy 0.04425	release 0.04286	eliminate 0.04256	empty 0.04241	free 0.04078	process 0.04066	pass 0.04045	sort 0.04024	move 0.03952	take 0.03949	unblock 0.03861	cash 0.03726	brighten 0.03695	exonerate 0.03648	skim 0.03644	change 0.03632	pardon 0.03622	authorise 0.03589	improve 0.03552	acquit 0.03431	vindicate 0.03256	absolve 0.02996	over 0.01786	above 0.01775

Test context:
***************
clear.v	864	5	the design team opted to __clear__ a large area of trees behind the 4th green to help give the hole the same sense of drama and scale as one experiences when standing on the 10th tee of the old course at sunningdale .
Contexts for target clear are: ['aux_to', 'xcompI_opted', 'dobj_area', 'prep:behind_green', 'xcomp_help']
Contexts in vocabulary for target clear are: ['aux_to', 'xcompI_opted', 'dobj_area', 'xcomp_help']
Top most similar embeddings: re-stock 0.04909	clear 0.04683	re-develop 0.04598	re-equip 0.04591	reconnoiter 0.04558	free-up 0.04538	electrify 0.04489	re-lay 0.04476	fumigate 0.04463	earmark 0.04436

Generated lemmatized results
***************
GENERATED	clear.v 864 ::: reconnoiter;electrify;fumigate;earmark;decontaminate;excavate;sanitise;computerise;aerate;repopulate

Filtered results
***************
RANKED	clear.v 864	unblock 0.03981	brighten 0.03751	take 0.03656	tidy 0.03647	eliminate 0.03617	improve 0.03610	remove 0.03546	skim 0.03439	authorise 0.03235	absolve 0.03202	pass 0.03197	move 0.03194	free 0.03191	exonerate 0.03128	empty 0.03077	vindicate 0.03067	change 0.03012	release 0.02842	acquit 0.02770	sort 0.02626	process 0.02565	cash 0.02546	pardon 0.02396	above 0.01816	over 0.01707

Test context:
***************
clear.v	865	5	with the sun just barely __clearing__ the horizon , mike switched to a split-shot rig .
Contexts for target clearing are: ['advmod_just', 'advmod_barely', 'depI_switched', 'dobj_horizon']
Contexts in vocabulary for target clearing are: ['advmod_just', 'advmod_barely', 'depI_switched', 'dobj_horizon']
Top most similar embeddings: clearing 0.05187	cleared 0.04192	obscuring 0.04069	scraping 0.04014	squeezing 0.03962	skimming 0.03935	flicking 0.03892	clears 0.03862	abaft 0.03845	surfed 0.03812

Generated lemmatized results
***************
GENERATED	clear.v 865 ::: obscure;scrap;squeeze;skim;flick;abaft;surf;blank;glimpse;fog

Filtered results
***************
RANKED	clear.v 865	skim 0.03935	brighten 0.03736	tidy 0.03529	sort 0.03359	remove 0.03300	empty 0.03294	unblock 0.03216	move 0.03058	free 0.03035	cash 0.02977	pass 0.02946	change 0.02917	over 0.02882	above 0.02865	eliminate 0.02848	release 0.02803	absolve 0.02696	take 0.02621	improve 0.02603	vindicate 0.02545	authorise 0.02538	pardon 0.02412	process 0.02374	exonerate 0.02369	acquit 0.02313

Test context:
***************
clear.v	866	14	orders will be on hold until payment is received in full and or check __clears__ .
Contexts for target clears are: ['amod_full', 'prep:inI_received']
Contexts in vocabulary for target clears are: ['amod_full', 'prep:inI_received']
Top most similar embeddings: clears 0.17127	recompense 0.15511	seisin 0.15257	remission 0.15155	reponse 0.15023	shoeboxes 0.14980	clearing 0.14882	expiation 0.14655	restitution 0.14576	compensation 0.14562

Generated lemmatized results
***************
GENERATED	clear.v 866 ::: recompense;seisin;remission;reponse;shoeboxes;expiation;restitution;compensation;acknowledgement;minuite

Filtered results
***************
RANKED	clear.v 866	pardon 0.13960	take 0.13590	empty 0.13505	release 0.13220	pass 0.12985	tidy 0.12639	cash 0.12594	brighten 0.12443	process 0.12013	free 0.11878	sort 0.11766	unblock 0.11730	skim 0.11510	move 0.11492	absolve 0.11467	exonerate 0.11371	vindicate 0.11255	authorise 0.10999	change 0.10990	remove 0.10941	acquit 0.10814	eliminate 0.10264	above 0.10175	improve 0.10043	over 0.09645

Test context:
***************
clear.v	867	10	this is the furthest point till which bodies have been __cleared__ .
Contexts for target cleared are: ['prep:till_which', 'nsubjpass_bodies', 'aux_have', 'auxpass_been', 'rcmodI_point']
Contexts in vocabulary for target cleared are: ['nsubjpass_bodies', 'aux_have', 'auxpass_been', 'rcmodI_point']
Top most similar embeddings: cleared 0.06335	recovered 0.04811	disinterred 0.04721	bulldozed 0.04649	made 0.04642	eliminated 0.04626	removed 0.04622	accreted 0.04596	extirpated 0.04584	grubbed 0.04570

Generated lemmatized results
***************
GENERATED	clear.v 867 ::: recover;disinter;bulldoze;make;eliminate;remove;accrete;extirpate;grub;dredge

Filtered results
***************
RANKED	clear.v 867	eliminate 0.04626	remove 0.04622	take 0.04289	tidy 0.04258	move 0.04158	empty 0.04149	free 0.04128	exonerate 0.04043	pass 0.04002	acquit 0.03994	sort 0.03991	change 0.03950	pardon 0.03923	process 0.03875	release 0.03828	skim 0.03825	unblock 0.03747	vindicate 0.03730	cash 0.03727	authorise 0.03711	improve 0.03605	brighten 0.03501	absolve 0.03385	over 0.01799	above 0.01595

Test context:
***************
clear.v	868	3	marine generals have __cleared__ other infantrymen in somewhat similar circumstances , such as the fallujah shooting , because of the nature of the combat the marines are seeing in iraq .
Contexts for target cleared are: ['nsubj_generals', 'aux_have', 'rootI_*root*', 'dobj_infantrymen', 'prep:in_circumstances', 'punct_,', 'prep:of_nature', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target cleared are: ['nsubj_generals', 'aux_have', 'rootI_*root*', 'prep:in_circumstances', 'punct_,', 'prep:of_nature', 'punct_.']
Top most similar embeddings: cleared 0.00542	complained 0.00512	resorted 0.00499	asserted 0.00498	pleaded 0.00497	counseled 0.00492	waived 0.00491	demanded 0.00490	dismissed 0.00490	warned 0.00490

Generated lemmatized results
***************
GENERATED	clear.v 868 ::: complain;resort;assert;plead;counsel;waive;demand;dismiss;warn;object

Filtered results
***************
RANKED	clear.v 868	absolve 0.00471	pardon 0.00466	acquit 0.00465	exonerate 0.00453	eliminate 0.00452	vindicate 0.00435	remove 0.00430	take 0.00421	change 0.00407	pass 0.00404	free 0.00398	move 0.00392	empty 0.00376	brighten 0.00363	tidy 0.00358	release 0.00355	authorise 0.00355	cash 0.00340	skim 0.00340	improve 0.00338	process 0.00331	sort 0.00319	unblock 0.00298	above 0.00190	over 0.00167

Test context:
***************
clear.v	869	7	when he stands , he begins to __clear__ the dishes from the table .
Contexts for target clear are: ['aux_to', 'xcompI_begins', 'dobj_dishes', 'prep:from_table']
Contexts in vocabulary for target clear are: ['aux_to', 'xcompI_begins', 'dobj_dishes', 'prep:from_table']
Top most similar embeddings: clear 0.05535	thicken 0.04406	mass-produce 0.04321	curdle 0.04287	regurgitate 0.04161	expunge 0.04143	winnow 0.04130	rehydrate 0.04116	re-stock 0.04102	re-draw 0.04101

Generated lemmatized results
***************
GENERATED	clear.v 869 ::: thicken;curdle;regurgitate;expunge;winnow;rehydrate;reorder;unhook;unroll;distill

Filtered results
***************
RANKED	clear.v 869	remove 0.03948	skim 0.03698	brighten 0.03560	exonerate 0.03540	tidy 0.03534	eliminate 0.03454	empty 0.03425	move 0.03421	take 0.03370	unblock 0.03178	vindicate 0.03102	pass 0.03041	improve 0.02897	acquit 0.02889	change 0.02873	free 0.02860	sort 0.02852	absolve 0.02849	process 0.02830	release 0.02797	authorise 0.02605	cash 0.02531	pardon 0.02324	over 0.01717	above 0.01716

Test context:
***************
clear.v	870	12	here they oppose bikeways , claiming that these bikeways are intended to __clear__ the roads for motor transportation for the convenience of the motoring elite .
Contexts for target clear are: ['aux_to', 'xcompI_intended', 'dobj_roads']
Contexts in vocabulary for target clear are: ['aux_to', 'xcompI_intended', 'dobj_roads']
Top most similar embeddings: clear 0.10790	electrify 0.09897	re-stock 0.09596	reconnoitre 0.09570	delineate 0.09451	reconnoiter 0.09441	demarcate 0.09410	mass-produce 0.09404	re-develop 0.09403	democratize 0.09363

Generated lemmatized results
***************
GENERATED	clear.v 870 ::: electrify;reconnoitre;delineate;reconnoiter;demarcate;democratize;sanitise;modernize;extirpate;bisect

Filtered results
***************
RANKED	clear.v 870	improve 0.08722	eliminate 0.08355	brighten 0.08216	unblock 0.08197	exonerate 0.08132	tidy 0.08105	remove 0.07865	take 0.07542	skim 0.07274	vindicate 0.07203	absolve 0.06951	pass 0.06894	empty 0.06661	authorise 0.06560	move 0.06518	acquit 0.06487	free 0.06361	process 0.06133	change 0.06101	sort 0.06064	release 0.05989	cash 0.05729	pardon 0.05458	above 0.04266	over 0.04003

Test context:
***************
close.n	871	34	we look forward to seeing you at one of our branch meetings in 2003. ^ back to top new year greetings and thanks from your credit union as another year has drawn to a __close__ , the board and staff of holiday coast credit union wish members , their families and friends , a happy , safe and prosperous new year .
Contexts for target close are: ['det_a', 'prep:toI_drawn']
Contexts in vocabulary for target close are: ['det_a', 'prep:toI_drawn']
Top most similar embeddings: close 0.24234	disjuncture 0.16477	backwater 0.16411	standstill 0.16411	conclusion 0.16398	precipice 0.16135	boarding-house 0.16120	climax 0.16084	resemblence 0.15939	time-warp 0.15918

Generated lemmatized results
***************
GENERATED	close.n 871 ::: disjuncture;backwater;standstill;conclusion;precipice;climax;resemblence;sandbank;backcloth;millpond

Filtered results
***************
RANKED	close.n 871	conclusion 0.16398	finale 0.14548	shutdown 0.13640	finish 0.13604	ending 0.13419	end 0.13380	shut 0.11825	free 0.09641

Test context:
***************
close.n	872	20	a motion to suspend standing orders shall be open to debate and the suspension shall cease no later than the __close__ of the meeting .
Contexts for target close are: ['det_the', 'prep:thanI_later', 'prep:of_meeting']
Contexts in vocabulary for target close are: ['det_the', 'prep:thanI_later', 'prep:of_meeting']
Top most similar embeddings: close 0.10940	end 0.08676	commencement 0.08192	conclusion 0.08145	apcm 0.08126	climax 0.08117	twenty-seventh 0.07994	time/date 0.07971	beginning 0.07930	end-date 0.07884

Generated lemmatized results
***************
GENERATED	close.n 872 ::: end;commencement;conclusion;apcm;climax;beginning;closest;date;prorogation;reconvening

Filtered results
***************
RANKED	close.n 872	end 0.08676	conclusion 0.08145	finale 0.07036	shutdown 0.06539	ending 0.06493	finish 0.06441	shut 0.04828	free 0.04166

Test context:
***************
close.n	873	13	for the winnipeg commodity exchange and the chicago board of trade , the __close__ of trade is 115 p.m. cst .
Contexts for target close are: ['det_the', 'nsubjI_cst', 'prep:of_trade']
Contexts in vocabulary for target close are: ['det_the', 'prep:of_trade']
Top most similar embeddings: close 0.20587	devolvement 0.16927	resumption 0.16616	high-point 0.16381	hurly-burly 0.16379	floodgates 0.16236	fountainhead 0.16141	opening-up 0.16073	nitty-gritty 0.16050	closest 0.16046

Generated lemmatized results
***************
GENERATED	close.n 873 ::: devolvement;resumption;floodgate;fountainhead;closest;reinvigoration;epicentre;commissariat;end;closeness

Filtered results
***************
RANKED	close.n 873	end 0.15958	conclusion 0.14919	shutdown 0.14888	ending 0.14084	finale 0.13998	finish 0.12013	shut 0.11195	free 0.10900

Test context:
***************
close.n	874	13	the final act of this imaginative drama , which brings it to a __close__ , which marks the last stage of the connected series , is the end as end-in-view .
Contexts for target close are: ['det_a', 'prep:toI_brings', 'punct_,', 'rcmod_marks', 'punct_,']
Contexts in vocabulary for target close are: ['det_a', 'prep:toI_brings', 'punct_,', 'rcmod_marks', 'punct_,']
Top most similar embeddings: close 0.02315	water-mill 0.02180	foxhole 0.02066	souterrain 0.02056	totso 0.02049	telos 0.02038	farm-house 0.02032	cromlech 0.02028	caldron 0.02027	swannery 0.02026

Generated lemmatized results
***************
GENERATED	close.n 874 ::: foxhole;souterrain;totso;telos;cromlech;caldron;swannery;sheol;baptistery;temenos

Filtered results
***************
RANKED	close.n 874	finale 0.01816	conclusion 0.01704	finish 0.01459	ending 0.01404	shutdown 0.01376	end 0.01282	shut 0.01124	free 0.00991

Test context:
***************
close.n	875	17	they do , however , make the german advance exponentially easier , and 1928 comes to a __close__ with the allies ' triumphant conquest of denmark .
Contexts for target close are: ['det_a', 'prep:toI_comes', 'prep:with_conquest']
Contexts in vocabulary for target close are: ['det_a', 'prep:toI_comes', 'prep:with_conquest']
Top most similar embeddings: close 0.10475	climax 0.08250	halt 0.07805	ending 0.07738	standstill 0.07392	denouement 0.07304	showdown 0.07275	finale 0.07271	conclusion 0.07226	end 0.07176

Generated lemmatized results
***************
GENERATED	close.n 875 ::: climax;halt;ending;standstill;denouement;showdown;finale;conclusion;end;flirtation

Filtered results
***************
RANKED	close.n 875	ending 0.07738	finale 0.07271	conclusion 0.07226	end 0.07176	finish 0.06574	shutdown 0.06318	shut 0.05061	free 0.03915

Test context:
***************
close.n	876	21	the fun begins at an engagement party for fiona 's cousin , elizabeth , and does n't end until novel 's __close__ .
Contexts for target close are: ['poss_novel', 'prep:untilI_end']
Contexts in vocabulary for target close are: ['poss_novel', 'prep:untilI_end']
Top most similar embeddings: close 0.22640	climax 0.17301	denouement 0.15990	finale 0.15906	conclusion 0.15737	end 0.15560	closing 0.15194	closer 0.14981	closest 0.14861	turning-point 0.14624

Generated lemmatized results
***************
GENERATED	close.n 876 ::: climax;denouement;finale;conclusion;end;closing;closer;closest;cliffhanger;ending

Filtered results
***************
RANKED	close.n 876	finale 0.15906	conclusion 0.15737	end 0.15560	ending 0.14534	finish 0.13280	shutdown 0.12298	shut 0.10889	free 0.08341

Test context:
***************
close.n	877	17	this leads to a race condition where another thread could have reused the filehandle before the second __close__ would be executed .
Contexts for target close are: ['det_the', 'amod_second', 'prep:beforeI_reused']
Contexts in vocabulary for target close are: ['det_the', 'amod_second']
Top most similar embeddings: close 0.19602	prisme 0.17748	premolar 0.17714	rebelay 0.17086	instar 0.17077	semifinal 0.17070	inning 0.17047	closest 0.17038	round-about 0.16951	afternoone 0.16867

Generated lemmatized results
***************
GENERATED	close.n 877 ::: prisme;premolar;rebelay;instar;semifinal;inning;closest;afternoone;trimester;trie

Filtered results
***************
RANKED	close.n 877	conclusion 0.15728	finale 0.14893	end 0.14480	shutdown 0.14027	finish 0.13705	ending 0.13101	shut 0.11108	free 0.10187

Test context:
***************
close.n	878	5	as 2002 drew to a __close__ , his regime worked hard to counter anything that might be seen as supporting the coalition 's assertion that wmd still remained in iraq .
Contexts for target close are: ['det_a', 'prep:toI_drew']
Contexts in vocabulary for target close are: ['det_a', 'prep:toI_drew']
Top most similar embeddings: close 0.26030	halt 0.17488	conclusion 0.17101	disjuncture 0.16884	standstill 0.16356	climax 0.16234	boarding-house 0.16107	precipice 0.16025	re-trial 0.15942	peroration 0.15827

Generated lemmatized results
***************
GENERATED	close.n 878 ::: halt;conclusion;disjuncture;standstill;climax;precipice;peroration;closer;disparity;quandry

Filtered results
***************
RANKED	close.n 878	conclusion 0.17101	shutdown 0.14875	finale 0.14289	end 0.14217	ending 0.13791	finish 0.13431	shut 0.12939	free 0.09153

Test context:
***************
close.n	879	14	22 i spoke for fifteen or twenty minutes , and was surprised at the __close__ of my address to receive the hearty congratulations of the georgia committee and of the members of congress who were present .
Contexts for target close are: ['det_the', 'prep:atI_surprised', 'prep:of_address', 'infmod_receive']
Contexts in vocabulary for target close are: ['det_the', 'prep:atI_surprised', 'prep:of_address', 'infmod_receive']
Top most similar embeddings: close 0.04292	closest 0.03823	closeness 0.03693	commencement 0.03623	proximity 0.03613	conclusion 0.03584	paucity 0.03583	end 0.03566	refusal 0.03533	check-box 0.03529

Generated lemmatized results
***************
GENERATED	close.n 879 ::: closest;closeness;commencement;proximity;conclusion;paucity;end;refusal;effrontery;nearness

Filtered results
***************
RANKED	close.n 879	conclusion 0.03584	end 0.03566	finale 0.02998	shutdown 0.02905	ending 0.02905	finish 0.02480	free 0.01982	shut 0.01752

Test context:
***************
close.n	880	15	there is also an unfortunate deus ex machina used to push the book to its __close__ .
Contexts for target close are: ['poss_its', 'prep:toI_push']
Contexts in vocabulary for target close are: ['poss_its', 'prep:toI_push']
Top most similar embeddings: close 0.21575	apogee 0.17354	conclusion 0.17018	climax 0.16961	closest 0.16601	nadir 0.16240	headwaters 0.16031	mid-point 0.15992	detriment 0.15980	sea-front 0.15774

Generated lemmatized results
***************
GENERATED	close.n 880 ::: apogee;conclusion;climax;closest;nadir;headwater;detriment;closer;fruition;fundament

Filtered results
***************
RANKED	close.n 880	conclusion 0.17018	end 0.14589	shutdown 0.14355	finale 0.14245	finish 0.13940	ending 0.12796	shut 0.12266	free 0.11083

Test context:
***************
come.v	881	9	scream all you like : no one will be __coming__ to rescue you .
Contexts for target coming are: ['nsubj_one', 'aux_will', 'aux_be', 'depI_like', 'xcomp_rescue']
Contexts in vocabulary for target coming are: ['nsubj_one', 'aux_will', 'aux_be', 'depI_like', 'xcomp_rescue']
Top most similar embeddings: coming 0.02945	comming 0.02230	winging 0.02086	swanning 0.01981	jetting 0.01960	appearing 0.01958	rushing 0.01939	going 0.01937	traveling 0.01936	arriving 0.01887

Generated lemmatized results
***************
GENERATED	come.v 881 ::: comming;wing;swanning;jet;appear;rush;go;travel;arrive;step

Filtered results
***************
RANKED	come.v 881	appear 0.01958	arrive 0.01887	return 0.01819	join 0.01729	get 0.01665	happen 0.01602	leave 0.01595	rally 0.01561	fall 0.01552	spring 0.01501	reach 0.01485	encounter 0.01474	notice 0.01427	considering 0.01413	occur 0.01394	unite 0.01372	find 0.01317	gather 0.01306	report 0.01258	originate 0.01202	combine 0.01199	lever 0.01197	concern 0.01108

Test context:
***************
come.v	882	4	now we have to __come__ together again " to help the people of iraq .
Contexts for target come are: ['aux_to', 'xcompI_have', 'advmod_together']
Contexts in vocabulary for target come are: ['aux_to', 'xcompI_have', 'advmod_together']
Top most similar embeddings: come 0.13542	bring 0.10321	go 0.10151	wheedle 0.10149	remove@pressbox.co.uk 0.10059	get 0.09939	put 0.09929	cohabit 0.09923	manhandle 0.09750	sit 0.09604

Generated lemmatized results
***************
GENERATED	come.v 882 ::: bring;go;wheedle;get;put;cohabit;manhandle;sit;commiserate;immigrate

Filtered results
***************
RANKED	come.v 882	get 0.09939	gather 0.09242	join 0.08901	unite 0.08627	arrive 0.08478	combine 0.08468	leave 0.07961	appear 0.07872	originate 0.07796	happen 0.07746	find 0.07740	reach 0.07681	fall 0.07597	occur 0.07528	return 0.07075	spring 0.07055	lever 0.06843	rally 0.06529	encounter 0.06359	report 0.06189	considering 0.06014	concern 0.05855	notice 0.05768

Test context:
***************
come.v	883	2	when it __comes__ to music , the figures do n't tell us anything new really .
Contexts for target comes are: ['advmod_when', 'nsubj_it', 'advclI_tell', 'prep:to_music']
Contexts in vocabulary for target comes are: ['advmod_when', 'nsubj_it', 'advclI_tell', 'prep:to_music']
Top most similar embeddings: comes 0.07634	came 0.05060	happens 0.04848	arrives 0.04671	sizzles 0.04646	quietens 0.04596	goes 0.04566	succumbs 0.04468	reacts 0.04465	reappears 0.04398

Generated lemmatized results
***************
GENERATED	come.v 883 ::: happen;arrive;sizzle;quieten;go;succumb;react;reappear;reconvene;vibrate

Filtered results
***************
RANKED	come.v 883	happen 0.04848	arrive 0.04671	get 0.04253	occur 0.04204	reach 0.03934	appear 0.03904	fall 0.03843	originate 0.03795	join 0.03723	find 0.03572	gather 0.03561	spring 0.03537	unite 0.03375	return 0.03361	leave 0.03223	considering 0.03218	combine 0.03138	encounter 0.03115	rally 0.03026	lever 0.02714	notice 0.02635	report 0.02489	concern 0.02415

Test context:
***************
come.v	884	10	this is why we hear open source and embedded-friendly strategies __coming__ from companies like sap , oracle , ibm , sun , hp , and many others .
Contexts for target coming are: ['partmodI_strategies', 'prep:from_companies']
Contexts in vocabulary for target coming are: ['partmodI_strategies', 'prep:from_companies']
Top most similar embeddings: coming 0.23079	emanating 0.18375	comming 0.18227	emerging 0.17392	ranging 0.17380	stemming 0.16952	originating 0.16359	arising 0.16197	drawn 0.15973	emanate 0.15913

Generated lemmatized results
***************
GENERATED	come.v 884 ::: emanate;comming;emerge;range;stem;originate;arise;draw;attract;derive

Filtered results
***************
RANKED	come.v 884	originate 0.16359	appear 0.15625	spring 0.15328	combine 0.14712	arrive 0.14335	get 0.14178	gather 0.14175	occur 0.14170	concern 0.14137	fall 0.14099	return 0.14097	lever 0.13773	reach 0.13488	unite 0.13301	join 0.13233	report 0.12989	happen 0.12896	encounter 0.12795	leave 0.12479	find 0.12419	considering 0.12232	rally 0.11758	notice 0.11356

Test context:
***************
come.v	885	1	i __came__ home , partly sad , partly revolting and wrote an article on caste and class in india today and since i was n't a journalist i wrote 38 pages !
Contexts for target came are: ['nsubj_i', 'rootI_*root*', 'advmod_home', 'punct_,', 'acomp_sad', 'punct_,', 'dep_revolting', 'punct_!', 'dep_<eol>']
Contexts in vocabulary for target came are: ['nsubj_i', 'rootI_*root*', 'advmod_home', 'punct_,', 'acomp_sad', 'punct_,', 'dep_revolting', 'punct_!']
Top most similar embeddings: came 0.00444	panted 0.00437	went 0.00406	hullo 0.00392	drawled 0.00391	whined 0.00390	chortled 0.00389	yelped 0.00388	wailed 0.00387	purred 0.00387

Generated lemmatized results
***************
GENERATED	come.v 885 ::: pant;go;hullo;drawl;whine;chortle;yelp;wail;purr;holler

Filtered results
***************
RANKED	come.v 885	get 0.00327	arrive 0.00304	spring 0.00294	rally 0.00274	find 0.00272	appear 0.00272	return 0.00269	leave 0.00229	happen 0.00221	notice 0.00221	reach 0.00207	report 0.00207	originate 0.00204	fall 0.00202	join 0.00200	gather 0.00198	occur 0.00192	combine 0.00189	unite 0.00179	concern 0.00170	lever 0.00164	encounter 0.00160	considering 0.00148

Test context:
***************
come.v	886	24	posted by : fling93 | may 31 , 2005 at 03:39 pm it has long been the case that japanese tv programming does not __come__ in 30 minute chunks .
Contexts for target come are: ['dobj_that', 'nsubj_programming', 'aux_does', 'neg_not', 'rcmodI_case', 'prep:in_chunks']
Contexts in vocabulary for target come are: ['dobj_that', 'nsubj_programming', 'aux_does', 'neg_not', 'rcmodI_case', 'prep:in_chunks']
Top most similar embeddings: come 0.01114	appear 0.00951	occur 0.00950	materialize 0.00944	materialise 0.00944	transpire 0.00930	incur 0.00922	reoccur 0.00910	cohere 0.00909	exceed 0.00907

Generated lemmatized results
***************
GENERATED	come.v 886 ::: appear;occur;materialize;materialise;transpire;incur;reoccur;cohere;exceed;fail

Filtered results
***************
RANKED	come.v 886	appear 0.00951	occur 0.00950	fall 0.00885	happen 0.00870	originate 0.00857	arrive 0.00798	combine 0.00753	spring 0.00692	reach 0.00688	encounter 0.00683	leave 0.00676	get 0.00674	unite 0.00634	gather 0.00628	report 0.00621	notice 0.00612	find 0.00606	return 0.00604	considering 0.00555	join 0.00553	concern 0.00551	lever 0.00498	rally 0.00491

Test context:
***************
come.v	887	6	" the blair witch " movie __comes__ to mind. it very much reminds me of something starting out as a solid and going straight to a gas. anyway , thought i 'd throw that out there. and if someone could point me to where " cult " stuff is folded into all this - i 'd appreciate it .
Contexts for target comes are: ["punct_''", 'nsubj_movie', 'depI_reminds', 'prep:to_mind', 'punct_.']
Contexts in vocabulary for target comes are: ['nsubj_movie', 'depI_reminds', 'prep:to_mind', 'punct_.']
Top most similar embeddings: comes 0.06924	came 0.05176	brings 0.04705	dramatises 0.04604	harks 0.04508	epitomizes 0.04376	conveys 0.04334	lends 0.04327	resonates 0.04312	prefigures 0.04304

Generated lemmatized results
***************
GENERATED	come.v 887 ::: bring;dramatise;hark;epitomize;convey;lend;resonate;prefigure;gravitate;evoke

Filtered results
***************
RANKED	come.v 887	arrive 0.04231	spring 0.04102	originate 0.04071	appear 0.03999	get 0.03914	happen 0.03812	unite 0.03648	occur 0.03624	leave 0.03486	fall 0.03464	combine 0.03458	gather 0.03374	reach 0.03304	join 0.03269	find 0.03257	return 0.03029	rally 0.02879	encounter 0.02684	report 0.02584	notice 0.02542	considering 0.02473	concern 0.02445	lever 0.02423

Test context:
***************
come.v	888	3	the time will __come__ when the fed will no longer be able to dictate low interest rates .
Contexts for target come are: ['nsubj_time', 'aux_will', 'rootI_*root*', 'advcl_able', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target come are: ['nsubj_time', 'aux_will', 'rootI_*root*', 'advcl_able', 'punct_.']
Top most similar embeddings: come 0.03157	depend 0.02400	elapse 0.02350	pro-rated 0.02344	disappear 0.02226	vary 0.02213	re-credited 0.02211	ensue 0.02203	suffice 0.02200	apear 0.02198

Generated lemmatized results
***************
GENERATED	come.v 888 ::: depend;elapse;disappear;vary;ensue;suffice;apear;tell;allow;forearm

Filtered results
***************
RANKED	come.v 888	appear 0.02114	arrive 0.02037	occur 0.02013	return 0.01982	happen 0.01936	combine 0.01837	find 0.01816	rally 0.01809	leave 0.01774	gather 0.01754	reach 0.01734	report 0.01725	notice 0.01714	fall 0.01699	spring 0.01698	join 0.01690	get 0.01659	originate 0.01570	lever 0.01564	encounter 0.01555	concern 0.01519	unite 0.01509	considering 0.01455

Test context:
***************
come.v	889	13	thing the wagon was secured i moved forward , thud ' it had __come__ off and was rolling down the property .
Contexts for target come are: ['nsubj_it', 'aux_had', 'depI_thing', 'advmod_off', 'cc_and', 'conj_rolling']
Contexts in vocabulary for target come are: ['nsubj_it', 'aux_had', 'depI_thing', 'advmod_off', 'cc_and', 'conj_rolling']
Top most similar embeddings: come 0.01130	rained 0.01008	beeped 0.01004	farted 0.01001	slithered 0.00998	pissing 0.00995	drifted 0.00985	ricocheted 0.00965	scarpered 0.00961	raining 0.00953

Generated lemmatized results
***************
GENERATED	come.v 889 ::: rain;beep;fart;slither;piss;drift;ricochet;scarper;hop;swerve

Filtered results
***************
RANKED	come.v 889	get 0.00910	fall 0.00863	happen 0.00863	spring 0.00850	arrive 0.00830	occur 0.00773	lever 0.00756	rally 0.00754	originate 0.00739	appear 0.00736	gather 0.00679	notice 0.00674	reach 0.00650	return 0.00622	leave 0.00618	encounter 0.00604	join 0.00601	considering 0.00555	unite 0.00545	find 0.00511	report 0.00497	combine 0.00466	concern 0.00462

Test context:
***************
come.v	890	11	this is the type of pub you 're most likely to __come__ across if you 're visiting london .
Contexts for target come are: ['aux_to', 'xcompI_likely', 'advmod_across']
Contexts in vocabulary for target come are: ['aux_to', 'xcompI_likely', 'advmod_across']
Top most similar embeddings: come 0.14040	get 0.09920	stumble 0.09876	go 0.09665	emerge 0.09403	reoffend 0.09194	immigrate 0.09186	re-occur 0.09146	percolate 0.09059	wander 0.09052

Generated lemmatized results
***************
GENERATED	come.v 890 ::: get;stumble;go;emerge;reoffend;immigrate;percolate;wander;abscond;migrate

Filtered results
***************
RANKED	come.v 890	get 0.09920	occur 0.08600	arrive 0.08549	happen 0.08451	fall 0.08066	reach 0.08061	originate 0.08033	join 0.07765	find 0.07582	appear 0.07487	gather 0.07341	combine 0.07282	unite 0.07173	leave 0.07131	encounter 0.07074	lever 0.06978	spring 0.06856	return 0.06563	notice 0.06494	rally 0.05835	report 0.05731	concern 0.05657	considering 0.05647

Test context:
***************
cry.v	891	7	babies over 6 months or so may __cry__ from being uncomfortable or hungry , or because they remember you when you are not there and they know how important you are to them .
Contexts for target cry are: ['nsubj_babies', 'aux_may', 'rootI_*root*', 'punct_,', 'cc_or', 'conj_remember', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target cry are: ['nsubj_babies', 'aux_may', 'rootI_*root*', 'punct_,', 'cc_or', 'conj_remember', 'punct_.']
Top most similar embeddings: cry 0.00688	groan 0.00539	scoff 0.00527	bleat 0.00524	fretful 0.00521	winced 0.00518	fidget 0.00505	cried 0.00502	miscarry 0.00501	wince 0.00500

Generated lemmatized results
***************
GENERATED	cry.v 891 ::: groan;scoff;bleat;fretful;wince;fidget;miscarry;snort;bewail;weep

Filtered results
***************
RANKED	cry.v 891	weep 0.00497	shout 0.00493	wail 0.00483	yell 0.00463	exclaim 0.00463	sob 0.00449	complain 0.00432	shriek 0.00424	bawl 0.00391	call 0.00388	utter 0.00371	demand 0.00353	tear 0.00346	snivel 0.00282

Test context:
***************
cry.v	892	2	rachel still __cries__ out from the grave for her children who are no more .
Contexts for target cries are: ['nsubj_rachel', 'advmod_still', 'rootI_*root*', 'prt_out', 'prep:from_grave', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target cries are: ['nsubj_rachel', 'advmod_still', 'rootI_*root*', 'prt_out', 'prep:from_grave', 'punct_.']
Top most similar embeddings: cries 0.01686	shouts 0.01328	yells 0.01274	snorts 0.01273	cry 0.01268	screams 0.01252	winces 0.01249	snores 0.01245	crying 0.01225	sobbed 0.01211

Generated lemmatized results
***************
GENERATED	cry.v 892 ::: shout;yell;snort;scream;wince;snore;sob;grope;squirm;babble

Filtered results
***************
RANKED	cry.v 892	shout 0.01328	yell 0.01274	sob 0.01211	bawl 0.01164	wail 0.01155	shriek 0.01149	weep 0.01085	complain 0.00995	exclaim 0.00990	utter 0.00934	call 0.00899	tear 0.00806	snivel 0.00732	demand 0.00721

Test context:
***************
cry.v	893	15	they were now joined by some of the governments ' backbenchers , who began to __cry__ for " a human sacrifice " : germain had to go .
Contexts for target cry are: ['aux_to', 'xcompI_began']
Contexts in vocabulary for target cry are: ['aux_to', 'xcompI_began']
Top most similar embeddings: cry 0.26797	scream 0.21061	shout 0.21015	bawl 0.20846	wail 0.20245	shriek 0.20173	remonstrate 0.20104	hallucinate 0.19982	snore 0.19960	groan 0.19932

Generated lemmatized results
***************
GENERATED	cry.v 893 ::: scream;shout;bawl;wail;shriek;remonstrate;hallucinate;snore;groan;writhe

Filtered results
***************
RANKED	cry.v 893	shout 0.21015	bawl 0.20846	wail 0.20245	shriek 0.20173	sob 0.19677	yell 0.19568	exclaim 0.18804	weep 0.17215	complain 0.17143	call 0.15831	tear 0.15824	utter 0.14453	demand 0.14319	snivel 0.12981

Test context:
***************
cry.v	894	10	but the poor mother ran out of the house and __cried__ aloud for her child .
Contexts for target cried are: ['conjI_ran', 'advmod_aloud']
Contexts in vocabulary for target cried are: ['conjI_ran', 'advmod_aloud']
Top most similar embeddings: cried 0.28632	sobbed 0.23350	shrieked 0.22734	screamed 0.22537	wept 0.22282	shouted 0.22270	growled 0.22047	exclaimed 0.21781	yelled 0.21366	wailed 0.21256

Generated lemmatized results
***************
GENERATED	cry.v 894 ::: sob;shriek;scream;weep;shout;growl;exclaim;yell;wail;groan

Filtered results
***************
RANKED	cry.v 894	sob 0.23350	shriek 0.22734	weep 0.22282	shout 0.22270	exclaim 0.21781	yell 0.21366	wail 0.21256	bawl 0.19992	utter 0.16827	tear 0.16003	complain 0.14733	call 0.14256	snivel 0.13978	demand 0.13727

Test context:
***************
cry.v	895	26	practically every day i noticed at least one russian woman whose date stood her up , the signs are obvious , no , there is no __crying__ or stuff like that , these are strong willed women , after she is convinced there is no possibility of you coming , she will stand up , pick up her bag and leave .
Contexts for target crying are: ['det_no', 'nsubjI_is', 'cc_or', 'conj_stuff', 'prep:like_that']
Contexts in vocabulary for target crying are: ['det_no', 'nsubjI_is', 'cc_or', 'conj_stuff', 'prep:like_that']
Top most similar embeddings: crying 0.02465	moaning 0.02184	swearing 0.02165	farting 0.02141	pooing 0.02086	shouting 0.02083	quibbling 0.02052	cussing 0.02038	emoting 0.02036	anythin 0.02033

Generated lemmatized results
***************
GENERATED	cry.v 895 ::: moan;swear;fart;pooing;shout;quibble;cuss;emote;anythin;grumble

Filtered results
***************
RANKED	cry.v 895	shout 0.02083	wail 0.01874	weep 0.01828	bawl 0.01768	yell 0.01754	sob 0.01737	snivel 0.01716	tear 0.01636	shriek 0.01612	call 0.01326	complain 0.01277	demand 0.01263	exclaim 0.01210	utter 0.01193

Test context:
***************
cry.v	896	6	tv can make me laugh , __cry__ , think , or just simply entertain me .
Contexts for target cry are: ['dobjI_make']
Contexts in vocabulary for target cry are: ['dobjI_make']
Top most similar embeddings: cry 0.47904	yelp 0.37491	shriek 0.36896	descision 0.36784	du'a 0.36658	scream 0.36606	cries 0.36523	bee-line 0.36290	shout 0.36254	squeal 0.36146

Generated lemmatized results
***************
GENERATED	cry.v 896 ::: yelp;shriek;descision;scream;shout;squeal;weep;gurgle;groan;laugh

Filtered results
***************
RANKED	cry.v 896	shriek 0.36896	shout 0.36254	weep 0.35990	wail 0.35508	yell 0.34277	bawl 0.33498	exclaim 0.32582	sob 0.32493	call 0.32325	tear 0.31393	demand 0.30757	complain 0.28323	utter 0.27004	snivel 0.26263

Test context:
***************
cry.v	897	19	as the boys i teach have endeavored to enlighten me , i have n't known whether to laugh , __cry__ , or go find a new job .
Contexts for target cry are: ['conjI_laugh']
Contexts in vocabulary for target cry are: ['conjI_laugh']
Top most similar embeddings: cry 0.57331	laugh 0.43369	cries 0.42571	shout 0.41827	groan 0.40981	scream 0.40960	bawl 0.40889	shriek 0.40816	wail 0.40339	moan 0.40189

Generated lemmatized results
***************
GENERATED	cry.v 897 ::: laugh;shout;groan;scream;bawl;shriek;wail;moan;chuckle;yelp

Filtered results
***************
RANKED	cry.v 897	shout 0.41827	bawl 0.40889	shriek 0.40816	wail 0.40339	weep 0.39035	yell 0.38508	sob 0.37714	exclaim 0.37546	tear 0.32728	call 0.31359	complain 0.31187	utter 0.30993	snivel 0.30815	demand 0.26322

Test context:
***************
cry.v	898	19	it is indeed a singular abuse to call that idealism which is routine and copy ; a solecism which __cries__ aloud to common sense for extinction .
Contexts for target cries are: ['nsubj_which', 'rcmodI_solecism', 'advmod_aloud', 'prep:for_extinction']
Contexts in vocabulary for target cries are: ['nsubj_which', 'advmod_aloud', 'prep:for_extinction']
Top most similar embeddings: cries 0.11458	cry 0.09019	shouts 0.08627	screams 0.08456	crying 0.08228	weeps 0.08210	thirsts 0.08175	shrieks 0.08137	yearns 0.08047	cried 0.07951

Generated lemmatized results
***************
GENERATED	cry.v 898 ::: shout;scream;weep;thirst;shriek;yearn;groan;calleth;yell;roar

Filtered results
***************
RANKED	cry.v 898	shout 0.08627	weep 0.08210	shriek 0.08137	yell 0.07823	wail 0.07462	utter 0.07295	call 0.07293	sob 0.07180	exclaim 0.06886	bawl 0.06721	tear 0.06493	demand 0.06441	complain 0.06263	snivel 0.05230

Test context:
***************
cry.v	899	18	however , when my husband would try to put our son down for the night , he would __cry__ and cry until i took over .
Contexts for target cry are: ['advmod_however', 'punct_,', 'advcl_try', 'punct_,', 'nsubj_he', 'aux_would', 'rootI_*root*', 'cc_and', 'conj_cry', 'advcl_took', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target cry are: ['advmod_however', 'punct_,', 'advcl_try', 'punct_,', 'nsubj_he', 'aux_would', 'rootI_*root*', 'cc_and', 'conj_cry', 'advcl_took', 'punct_.']
Top most similar embeddings: winced 0.00039	tutted 0.00038	flinch 0.00038	cry 0.00038	demurred 0.00036	wept 0.00036	yelped 0.00036	flinched 0.00036	scowled 0.00035	wailed 0.00035

Generated lemmatized results
***************
GENERATED	cry.v 899 ::: wince;tutted;flinch;demur;weep;yelp;scowl;wail;blush;recoil

Filtered results
***************
RANKED	cry.v 899	weep 0.00036	wail 0.00035	sob 0.00033	shriek 0.00032	yell 0.00031	shout 0.00030	bawl 0.00030	exclaim 0.00030	demand 0.00025	complain 0.00023	utter 0.00023	tear 0.00021	call 0.00019	snivel 0.00014

Test context:
***************
cry.v	900	7	it seems a bit much to start __crying__ that the sky is falling in the pharma industry .
Contexts for target crying are: ['xcompI_start', 'ccomp_falling']
Contexts in vocabulary for target crying are: ['xcompI_start', 'ccomp_falling']
Top most similar embeddings: crying 0.24756	screaming 0.20163	bawling 0.19979	weeping 0.19974	yelling 0.19551	sniggering 0.19075	bleating 0.19070	meowing 0.19063	laughing 0.19012	shrieking 0.18963

Generated lemmatized results
***************
GENERATED	cry.v 900 ::: scream;bawl;weep;yell;snigger;bleat;meow;laugh;shriek;shout

Filtered results
***************
RANKED	cry.v 900	bawl 0.19979	weep 0.19974	yell 0.19551	shriek 0.18963	shout 0.18921	sob 0.18869	complain 0.18660	exclaim 0.18008	wail 0.17848	snivel 0.16590	utter 0.16032	tear 0.15663	call 0.15416	demand 0.14402

Test context:
***************
dismiss.v	901	15	schools and systems also seek quality assurance through using evaluation to assess basic competence , __dismiss__ teachers for incompetence and ensure that the ' right ' people are promoted to key positions .
Contexts for target dismiss are: ['conjI_seek', 'dobj_teachers', 'prep:for_incompetence']
Contexts in vocabulary for target dismiss are: ['conjI_seek', 'dobj_teachers', 'prep:for_incompetence']
Top most similar embeddings: dismiss 0.12972	castigate 0.10521	remunerate 0.09612	victimise 0.09563	criticise 0.09409	dismissed 0.09370	deride 0.09358	demonise 0.09252	berate 0.09247	dismissing 0.09159

Generated lemmatized results
***************
GENERATED	dismiss.v 901 ::: castigate;remunerate;victimise;criticise;deride;demonise;berate;exonerate;lambast;punish

Filtered results
***************
RANKED	dismiss.v 901	deride 0.09358	reject 0.08565	sack 0.07939	ignore 0.07736	excuse 0.07382	banish 0.07242	discard 0.06698	remove 0.06695	fire 0.06339	discharge 0.06069	see 0.05991	dispatch 0.05827	release 0.05642

Test context:
***************
dismiss.v	902	14	if we see ourselves as separate from the world , it is easy to __dismiss__ our actions as irrelevant or unlikely to make any difference .
Contexts for target dismiss are: ['aux_to', 'xcompI_easy', 'dobj_actions', 'advcl_make']
Contexts in vocabulary for target dismiss are: ['aux_to', 'xcompI_easy', 'dobj_actions', 'advcl_make']
Top most similar embeddings: dismiss 0.06889	criticise 0.05473	rationalize 0.05309	misinterpret 0.05144	criticize 0.05124	trivialise 0.05088	disparage 0.05081	notate 0.05073	demonize 0.05065	misconstrue 0.05056

Generated lemmatized results
***************
GENERATED	dismiss.v 902 ::: criticise;rationalize;misinterpret;criticize;trivialise;disparage;notate;demonize;misconstrue;enunciate

Filtered results
***************
RANKED	dismiss.v 902	deride 0.04753	ignore 0.04726	reject 0.04698	see 0.04220	discard 0.04180	remove 0.04078	banish 0.03867	excuse 0.03542	sack 0.03253	dispatch 0.03057	discharge 0.02993	release 0.02761	fire 0.02683

Test context:
***************
dismiss.v	903	31	when students must leave school for any reason during school hours they must present a note from their parent/guardian to the office for approval and then to their teacher to be __dismissed__ from class .
Contexts for target dismissed are: ['advmod_then', 'prep:to_teacher', 'aux_to', 'auxpass_be', 'conjI_present', 'prep:from_class']
Contexts in vocabulary for target dismissed are: ['advmod_then', 'prep:to_teacher', 'aux_to', 'auxpass_be', 'conjI_present', 'prep:from_class']
Top most similar embeddings: dismissed 0.01219	excused 0.01047	demoted 0.01036	transferred 0.01009	reassigned 0.00994	reallocated 0.00977	redeployed 0.00977	re-assigned 0.00957	debarred 0.00942	copied 0.00942

Generated lemmatized results
***************
GENERATED	dismiss.v 903 ::: excuse;demote;transfer;reassign;reallocate;redeploy;debar;copy;coopted;forward

Filtered results
***************
RANKED	dismiss.v 903	excuse 0.01047	sack 0.00915	discard 0.00867	banish 0.00865	remove 0.00860	reject 0.00820	discharge 0.00818	ignore 0.00799	release 0.00758	dispatch 0.00746	deride 0.00725	fire 0.00722	see 0.00627

Test context:
***************
dismiss.v	904	10	by law and by contract professional status employees cannot be __dismissed__ if a non professional status employee is retained in a position the tenured person has the certification to teach .
Contexts for target dismissed are: ['prep:by_law', 'aux_can', 'neg_not', 'auxpass_be', 'rootI_*root*', 'advcl_retained', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target dismissed are: ['prep:by_law', 'aux_can', 'neg_not', 'auxpass_be', 'rootI_*root*', 'advcl_retained', 'punct_.']
Top most similar embeddings: dismissed 0.00856	overemphasised 0.00663	overridden 0.00639	countermanded 0.00633	prevented 0.00630	penalized 0.00626	obviated 0.00624	overruled 0.00623	regarded 0.00616	eliminated 0.00615

Generated lemmatized results
***************
GENERATED	dismiss.v 904 ::: overemphasise;override;countermand;prevent;penalize;obviate;overrule;regard;eliminate;disregard

Filtered results
***************
RANKED	dismiss.v 904	excuse 0.00598	ignore 0.00582	reject 0.00575	remove 0.00552	discard 0.00525	sack 0.00514	banish 0.00501	dispatch 0.00488	see 0.00483	deride 0.00477	discharge 0.00475	fire 0.00460	release 0.00443

Test context:
***************
dismiss.v	905	14	brochures or fliers , however glossy , tend to be impersonal and may be __dismissed__ as " junk mail .
Contexts for target dismissed are: ['aux_may', 'auxpass_be', 'conjI_brochures', 'prep:as_mail']
Contexts in vocabulary for target dismissed are: ['aux_may', 'auxpass_be', 'conjI_brochures', 'prep:as_mail']
Top most similar embeddings: dismissed 0.04817	viewed 0.04016	misinterpreted 0.04003	down-loaded 0.04001	resold 0.04000	regarded 0.03996	faxed 0.03939	misclassified 0.03935	forwarded 0.03918	referred 0.03882

Generated lemmatized results
***************
GENERATED	dismiss.v 905 ::: view;misinterpret;resold;regard;fax;misclassified;forward;refer;bill;treat

Filtered results
***************
RANKED	dismiss.v 905	reject 0.03527	discard 0.03418	excuse 0.03391	see 0.03364	ignore 0.03362	sack 0.03295	dispatch 0.03259	deride 0.03191	remove 0.03077	fire 0.02991	discharge 0.02958	release 0.02865	banish 0.02840

Test context:
***************
dismiss.v	906	6	the enhanced bus service alternative was __dismissed__ from consideration because it would not meet the purpose and need of the project .
Contexts for target dismissed are: ['nsubjpass_alternative', 'auxpass_was', 'rootI_*root*', 'prep:from_consideration', 'advcl_meet', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target dismissed are: ['nsubjpass_alternative', 'auxpass_was', 'rootI_*root*', 'prep:from_consideration', 'advcl_meet', 'punct_.']
Top most similar embeddings: dismissed 0.01791	rejected 0.01343	rebuffed 0.01173	eliminated 0.01168	excluded 0.01157	precluded 0.01151	withdrawn 0.01143	ousted 0.01122	quashed 0.01118	expelled 0.01112

Generated lemmatized results
***************
GENERATED	dismiss.v 906 ::: reject;rebuff;eliminate;exclude;preclude;withdraw;oust;quash;expel;suspend

Filtered results
***************
RANKED	dismiss.v 906	reject 0.01343	sack 0.01047	banish 0.01031	deride 0.01024	excuse 0.01018	discard 0.00998	remove 0.00994	ignore 0.00987	see 0.00902	fire 0.00877	dispatch 0.00871	discharge 0.00856	release 0.00810

Test context:
***************
dismiss.v	907	7	when the visitors have left , she __dismisses__ suzuki and prepares herself for a ceremonial suicide .
Contexts for target dismisses are: ['advcl_left', 'punct_,', 'nsubj_she', 'rootI_*root*', 'dobj_suzuki', 'cc_and', 'conj_prepares', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target dismisses are: ['advcl_left', 'punct_,', 'nsubj_she', 'rootI_*root*', 'dobj_suzuki', 'cc_and', 'conj_prepares', 'punct_.']
Top most similar embeddings: dismisses 0.00370	berates 0.00346	befriends 0.00340	abandons 0.00317	shrugs 0.00316	scolds 0.00315	overhears 0.00313	disarms 0.00306	castigates 0.00305	kidnaps 0.00304

Generated lemmatized results
***************
GENERATED	dismiss.v 907 ::: berate;befriend;abandon;shrug;scold;overhear;disarm;castigate;kidnap;retaliate

Filtered results
***************
RANKED	dismiss.v 907	ignore 0.00279	banish 0.00266	reject 0.00256	see 0.00255	deride 0.00238	remove 0.00237	discard 0.00228	sack 0.00208	fire 0.00187	excuse 0.00186	dispatch 0.00180	discharge 0.00148	release 0.00147

Test context:
***************
dismiss.v	908	11	" simply thank your gremlin for his or her opinion , __dismiss__ him or her , and ask your true inner voice to turn up its volume .
Contexts for target dismiss are: ['depI_thank', 'dobj_him', 'cc_or', 'conj_her']
Contexts in vocabulary for target dismiss are: ['depI_thank', 'dobj_him', 'cc_or', 'conj_her']
Top most similar embeddings: dismiss 0.05032	dismissing 0.04703	re-employ 0.04283	disparages 0.04212	scold 0.04152	reprimanding 0.04143	placating 0.04133	reprimand 0.04085	disparage 0.04038	reprove 0.04013

Generated lemmatized results
***************
GENERATED	dismiss.v 908 ::: disparage;scold;reprimand;placate;reprove;harrassing;disqualify;harass;admonish;expel

Filtered results
***************
RANKED	dismiss.v 908	excuse 0.03873	reject 0.03827	deride 0.03650	sack 0.03619	banish 0.03576	ignore 0.03536	remove 0.03386	discharge 0.03256	see 0.03040	discard 0.02945	dispatch 0.02886	release 0.02855	fire 0.02714

Test context:
***************
dismiss.v	909	10	some have been fined and warned by the police to __dismiss__ their illegal workers .
Contexts for target dismiss are: ['aux_to', 'xcompI_warned', 'dobj_workers']
Contexts in vocabulary for target dismiss are: ['aux_to', 'xcompI_warned', 'dobj_workers']
Top most similar embeddings: dismiss 0.13206	re-employ 0.11106	browbeat 0.11094	readmit 0.11085	demonize 0.11002	castigate 0.10934	victimise 0.10845	demonise 0.10781	vilify 0.10557	pressurize 0.10537

Generated lemmatized results
***************
GENERATED	dismiss.v 909 ::: browbeat;readmit;demonize;castigate;victimise;demonise;vilify;pressurize;lambast;disenfranchise

Filtered results
***************
RANKED	dismiss.v 909	deride 0.09558	reject 0.09461	ignore 0.09314	sack 0.08874	banish 0.08558	remove 0.08523	discard 0.08231	see 0.07217	excuse 0.07036	dispatch 0.06889	release 0.06699	discharge 0.06620	fire 0.06260

Test context:
***************
dismiss.v	910	24	back to top trade unions an employee has the right to join a trade union , and should not be refused a job , __dismissed__ , harassed or selected for redundancy because they are a member of or wish to join a trade union .
Contexts for target dismissed are: ['ccomp_has', 'punct_,', 'rootI_*root*', 'punct_,', 'conj_harassed', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target dismissed are: ['ccomp_has', 'punct_,', 'rootI_*root*', 'punct_,', 'conj_harassed', 'punct_.']
Top most similar embeddings: dismissed 0.01549	avers 0.01400	insisted 0.01321	insists 0.01299	averred 0.01298	dismisses 0.01293	said 0.01288	contends 0.01282	asserts 0.01280	demurred 0.01279

Generated lemmatized results
***************
GENERATED	dismiss.v 910 ::: aver;insist;say;contend;assert;demur;gloat;argue;caution;deny

Filtered results
***************
RANKED	dismiss.v 910	reject 0.01134	deride 0.01067	sack 0.01062	ignore 0.01019	see 0.01009	excuse 0.01002	banish 0.00956	fire 0.00937	remove 0.00870	discard 0.00821	dispatch 0.00809	discharge 0.00776	release 0.00744

Test context:
***************
draw.v	911	4	4 each party shall __draw__ the attention of all other parties to any activity which in its opinion affects the implementation of the objectives and principles of this protocol .
Contexts for target draw are: ['nsubj_party', 'aux_shall', 'rootI_*root*', 'dobj_attention', 'prep:to_activity', 'punct_.', 'dobj_<eol>']
Contexts in vocabulary for target draw are: ['nsubj_party', 'aux_shall', 'rootI_*root*', 'dobj_attention', 'prep:to_activity', 'punct_.']
Top most similar embeddings: draw 0.01422	draws 0.01209	drew 0.01178	drawn 0.01087	confine 0.01050	invite 0.00980	devoting 0.00967	refer 0.00950	devote 0.00944	allude 0.00920

Generated lemmatized results
***************
GENERATED	draw.v 911 ::: confine;invite;devote;refer;allude;counterpose;apply;attract;seek;attach

Filtered results
***************
RANKED	draw.v 911	attract 0.00918	summon 0.00901	bring 0.00876	call 0.00845	withdraw 0.00803	receive 0.00801	focus 0.00787	gather 0.00787	consider 0.00769	rely 0.00769	take 0.00754	derive 0.00747	tie 0.00747	consult 0.00737	drag 0.00731	pull 0.00730	employ 0.00730	obtain 0.00727	remove 0.00713	choose 0.00709	depict 0.00706	claim 0.00699	make 0.00691	get 0.00681	select 0.00676	earn 0.00674	pit 0.00671	sketch 0.00661	play 0.00648	portray 0.00640	acquire 0.00634	haul 0.00621	exploit 0.00619	use 0.00615	extract 0.00614	schedule 0.00607	set 0.00605	paint 0.00571

Test context:
***************
draw.v	912	5	the data presented here are __drawn__ from the questions concerning women 's time use and social roles .
Contexts for target drawn are: ['nsubjpass_data', 'auxpass_are', 'rootI_*root*', 'prep:from_questions', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target drawn are: ['nsubjpass_data', 'auxpass_are', 'rootI_*root*', 'prep:from_questions', 'punct_.']
Top most similar embeddings: drawn 0.03599	derived 0.02565	compiled 0.02535	extracted 0.02525	abstracted 0.02477	collated 0.02440	excerpted 0.02404	obtained 0.02384	devided 0.02363	collected 0.02360

Generated lemmatized results
***************
GENERATED	draw.v 912 ::: derive;compile;extract;abstract;collate;excerpt;obtain;devided;collect;disjoin

Filtered results
***************
RANKED	draw.v 912	derive 0.02565	extract 0.02525	obtain 0.02384	gather 0.02345	take 0.02206	select 0.02193	attract 0.02172	choose 0.02146	acquire 0.02137	make 0.02117	use 0.02042	remove 0.02040	consider 0.02027	pull 0.02006	sketch 0.02005	withdraw 0.01987	depict 0.01936	consult 0.01915	drag 0.01889	receive 0.01887	focus 0.01857	schedule 0.01853	paint 0.01835	tie 0.01826	employ 0.01810	portray 0.01789	bring 0.01750	call 0.01740	rely 0.01729	claim 0.01709	pit 0.01707	play 0.01705	summon 0.01700	haul 0.01689	exploit 0.01634	earn 0.01604	set 0.01533	get 0.01527

Test context:
***************
draw.v	913	6	we also illustrate the themes by __drawing__ on the contributors stories .
Contexts for target drawing are: ['pcompI_by', 'prep:on_stories']
Contexts in vocabulary for target drawing are: ['pcompI_by', 'prep:on_stories']
Top most similar embeddings: drawing 0.27404	capitalizing 0.19423	recapping 0.19279	focusing 0.19264	focussing 0.19112	hinging 0.18926	superimposing 0.18848	concentrating 0.18548	sketching 0.18445	elaborating 0.18442

Generated lemmatized results
***************
GENERATED	draw.v 913 ::: capitalize;recap;focus;hinge;superimpose;concentrate;sketch;elaborate;capitalise;synthesize

Filtered results
***************
RANKED	draw.v 913	focus 0.19264	sketch 0.18445	drag 0.18103	pull 0.17946	rely 0.17221	bring 0.16541	call 0.16496	take 0.16072	tie 0.16071	paint 0.15937	select 0.15847	haul 0.15748	portray 0.15550	gather 0.15521	make 0.15464	use 0.15418	remove 0.15367	extract 0.15357	set 0.15239	employ 0.15190	choose 0.15025	derive 0.14965	attract 0.14861	consult 0.14854	exploit 0.14841	obtain 0.14838	acquire 0.14666	play 0.14614	receive 0.14352	get 0.14327	withdraw 0.14282	depict 0.14207	summon 0.14130	pit 0.13967	claim 0.13737	earn 0.13505	schedule 0.13210	consider 0.12393

Test context:
***************
draw.v	914	3	the board has __drawn__ heavily on the best brains in the educational measurement world and conducted more research than any other body in developing its certification system for teachers of accomplished practice .
Contexts for target drawn are: ['nsubj_board', 'aux_has', 'rootI_*root*', 'advmod_heavily', 'prep:on_brains', 'cc_and', 'conj_conducted', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target drawn are: ['nsubj_board', 'aux_has', 'rootI_*root*', 'advmod_heavily', 'prep:on_brains', 'cc_and', 'conj_conducted', 'punct_.']
Top most similar embeddings: drawn 0.00318	deliberated 0.00263	draws 0.00259	conducted 0.00259	lectured 0.00257	concentrated 0.00257	experimented 0.00253	focused 0.00252	drew 0.00251	commentated 0.00249

Generated lemmatized results
***************
GENERATED	draw.v 914 ::: deliberate;conduct;lecture;concentrate;experiment;focus;commentate;research;initiate;commission

Filtered results
***************
RANKED	draw.v 914	focus 0.00252	consult 0.00236	rely 0.00230	paint 0.00213	attract 0.00210	play 0.00205	gather 0.00200	sketch 0.00189	receive 0.00188	pull 0.00186	select 0.00185	drag 0.00185	make 0.00182	obtain 0.00181	summon 0.00180	pit 0.00179	employ 0.00178	tie 0.00177	depict 0.00175	take 0.00175	schedule 0.00175	earn 0.00171	derive 0.00171	acquire 0.00171	withdraw 0.00169	choose 0.00169	consider 0.00166	extract 0.00166	use 0.00165	portray 0.00164	haul 0.00163	get 0.00163	bring 0.00161	remove 0.00161	claim 0.00157	call 0.00156	exploit 0.00146	set 0.00139

Test context:
***************
draw.v	915	5	he said you do n't __draw__ a tree just like that with a bush around like that .
Contexts for target draw are: ['nsubj_you', 'aux_do', "neg_n't", 'ccompI_said', 'dobj_tree', 'prep:like_that']
Contexts in vocabulary for target draw are: ['nsubj_you', 'aux_do', "neg_n't", 'ccompI_said', 'dobj_tree', 'prep:like_that']
Top most similar embeddings: draw 0.01194	dawdle 0.01041	over-react 0.01011	embarass 0.01004	think 0.01003	masturbate 0.01001	wnat 0.00989	suck 0.00984	vandalise 0.00983	dignify 0.00981

Generated lemmatized results
***************
GENERATED	draw.v 915 ::: dawdle;embarass;think;masturbate;wnat;suck;vandalise;dignify;shoot;misjudge

Filtered results
***************
RANKED	draw.v 915	pull 0.00911	get 0.00898	tie 0.00856	make 0.00795	paint 0.00788	summon 0.00754	earn 0.00749	bring 0.00747	consider 0.00742	play 0.00742	take 0.00741	rely 0.00739	drag 0.00736	call 0.00731	remove 0.00722	employ 0.00715	choose 0.00710	derive 0.00709	depict 0.00708	portray 0.00708	gather 0.00695	attract 0.00693	receive 0.00692	consult 0.00679	withdraw 0.00678	use 0.00671	claim 0.00666	haul 0.00629	exploit 0.00627	obtain 0.00624	acquire 0.00620	sketch 0.00595	select 0.00571	set 0.00543	focus 0.00538	extract 0.00511	pit 0.00494	schedule 0.00457

Test context:
***************
draw.v	916	5	this group includes persons who __draw__ a wage or salary for their work in their own incorporated enterprise .
Contexts for target draw are: ['nsubj_who', 'rcmodI_persons', 'dobj_wage', 'prep:for_work', 'prep:in_enterprise']
Contexts in vocabulary for target draw are: ['nsubj_who', 'rcmodI_persons', 'dobj_wage', 'prep:for_work', 'prep:in_enterprise']
Top most similar embeddings: draw 0.02226	drew 0.01893	earn 0.01823	pays 0.01808	earned 0.01799	draws 0.01778	paid 0.01713	enrols 0.01696	earns 0.01690	paying 0.01689

Generated lemmatized results
***************
GENERATED	draw.v 916 ::: earn;pay;enrol;incapacitate;engage;fundraise;underpay;flout;employ;enroll

Filtered results
***************
RANKED	draw.v 916	earn 0.01823	employ 0.01655	receive 0.01578	obtain 0.01526	withdraw 0.01465	derive 0.01433	claim 0.01420	exploit 0.01419	acquire 0.01383	bring 0.01381	consult 0.01378	attract 0.01373	tie 0.01358	summon 0.01355	take 0.01350	gather 0.01347	rely 0.01331	choose 0.01327	consider 0.01283	sketch 0.01269	call 0.01262	extract 0.01249	use 0.01233	select 0.01216	make 0.01198	get 0.01196	portray 0.01188	play 0.01188	set 0.01179	pull 0.01171	depict 0.01153	drag 0.01148	pit 0.01120	haul 0.01104	remove 0.01104	focus 0.01076	paint 0.01053	schedule 0.01021

Test context:
***************
draw.v	917	8	approximately 150 york community members were present , __drawing__ connections between on-campus institutions and the us empire .
Contexts for target drawing are: ['xcompI_present', 'dobj_connections']
Contexts in vocabulary for target drawing are: ['xcompI_present', 'dobj_connections']
Top most similar embeddings: drawing 0.24486	draw 0.19135	tracing 0.17505	sketching 0.16908	making 0.16888	highlighting 0.16599	emphasising 0.16487	using 0.16464	revealing 0.16382	examining 0.16353

Generated lemmatized results
***************
GENERATED	draw.v 917 ::: trace;sketch;make;highlight;emphasise;use;reveal;examine;elucidate;enable

Filtered results
***************
RANKED	draw.v 917	sketch 0.16908	make 0.16888	use 0.16464	depict 0.15135	bring 0.15104	portray 0.14946	derive 0.14813	exploit 0.14774	set 0.14705	remove 0.14678	tie 0.14533	call 0.14477	focus 0.14437	receive 0.14358	attract 0.14307	obtain 0.14188	employ 0.14151	claim 0.14072	extract 0.13964	select 0.13881	gather 0.13842	acquire 0.13697	consider 0.13675	pull 0.13672	drag 0.13666	paint 0.13614	take 0.13513	summon 0.13454	choose 0.13413	earn 0.13302	consult 0.13292	withdraw 0.13287	play 0.13130	get 0.12814	haul 0.12741	rely 0.12457	schedule 0.12039	pit 0.12007

Test context:
***************
draw.v	918	30	the town is prettily situated on a hillside in the western curve of the bay , and moving about the roads we caught our first glimpse of the cape wagon __drawn__ by sixteen oxen .
Contexts for target drawn are: ['partmodI_wagon', 'prep:by_oxen']
Contexts in vocabulary for target drawn are: ['partmodI_wagon']
Top most similar embeddings: drawn 0.53020	pulled 0.36518	drawing 0.36253	built 0.35271	drafted 0.35213	constructed 0.34969	drew 0.34803	dragged 0.34407	rivetted 0.34388	hauled 0.34287

Generated lemmatized results
***************
GENERATED	draw.v 918 ::: pull;build;draft;construct;drag;rivetted;haul;transhipped;crib;load

Filtered results
***************
RANKED	draw.v 918	pull 0.36518	drag 0.34407	haul 0.34287	paint 0.33904	use 0.33717	depict 0.33583	derive 0.33186	tie 0.32501	take 0.32304	attract 0.31691	make 0.31472	sketch 0.31395	withdraw 0.31384	select 0.31234	choose 0.30959	gather 0.30925	portray 0.30851	remove 0.30801	bring 0.30541	extract 0.30409	call 0.30158	summon 0.29899	acquire 0.29859	employ 0.29713	rely 0.29168	play 0.28816	focus 0.28786	consider 0.28762	obtain 0.28583	pit 0.28461	set 0.28423	schedule 0.28338	receive 0.27783	consult 0.27556	claim 0.27421	get 0.27118	earn 0.26334	exploit 0.25141

Test context:
***************
draw.v	919	15	refund cheques are made payable to the student from whose account the credit amount is __drawn__ .
Contexts for target drawn are: ['dep_account', 'nsubjpass_amount', 'auxpass_is', 'pcompI_from']
Contexts in vocabulary for target drawn are: ['dep_account', 'nsubjpass_amount', 'auxpass_is', 'pcompI_from']
Top most similar embeddings: drawn 0.04980	debited 0.04482	disbursed 0.03998	reinvested 0.03945	gleaned 0.03914	siphoned 0.03874	reabsorbed 0.03853	called 0.03849	based 0.03839	transferred 0.03830

Generated lemmatized results
***************
GENERATED	draw.v 919 ::: debit;disburse;reinvested;glean;siphon;reabsorb;call;base;transfer;credit

Filtered results
***************
RANKED	draw.v 919	call 0.03849	extract 0.03799	tie 0.03705	withdraw 0.03694	derive 0.03684	consider 0.03509	gather 0.03477	obtain 0.03451	take 0.03423	use 0.03370	sketch 0.03368	remove 0.03302	select 0.03276	earn 0.03271	make 0.03139	rely 0.03130	depict 0.03128	portray 0.03121	summon 0.03117	claim 0.03111	focus 0.03098	schedule 0.03097	drag 0.03096	choose 0.03062	attract 0.03053	pit 0.03050	bring 0.03048	employ 0.03046	pull 0.03012	exploit 0.02981	set 0.02970	receive 0.02967	acquire 0.02929	haul 0.02895	paint 0.02884	consult 0.02873	play 0.02807	get 0.02568

Test context:
***************
draw.v	920	11	the following examples highlight the risk : a non-league club is __drawn__ against manchester city in the third round of the fa cup .
Contexts for target drawn are: ['nsubjpass_club', 'auxpass_is', 'depI_risk', 'prep:against_city', 'prep:in_round']
Contexts in vocabulary for target drawn are: ['nsubjpass_club', 'auxpass_is', 'depI_risk', 'prep:against_city', 'prep:in_round']
Top most similar embeddings: drawn 0.02861	sidelined 0.01967	embroiled 0.01960	beaten 0.01905	robbed 0.01898	outplayed 0.01867	stretchered 0.01832	pitted 0.01827	deadlocked 0.01821	thrown 0.01816

Generated lemmatized results
***************
GENERATED	draw.v 920 ::: sideline;embroil;beat;rob;outplay;stretchered;pit;deadlocked;throw;steamroller

Filtered results
***************
RANKED	draw.v 920	pit 0.01827	pull 0.01683	withdraw 0.01643	drag 0.01617	tie 0.01600	haul 0.01593	gather 0.01583	attract 0.01569	play 0.01553	select 0.01548	schedule 0.01508	portray 0.01489	consult 0.01488	consider 0.01478	depict 0.01470	set 0.01466	summon 0.01464	take 0.01449	choose 0.01443	call 0.01442	earn 0.01437	bring 0.01408	derive 0.01401	employ 0.01397	make 0.01378	remove 0.01376	focus 0.01370	rely 0.01364	paint 0.01364	use 0.01357	exploit 0.01347	sketch 0.01346	claim 0.01331	obtain 0.01330	extract 0.01327	acquire 0.01320	receive 0.01268	get 0.01051

Test context:
***************
earlier.r	921	33	finno-ugrian languages , in the widest sense of the word , share a few core vocabulary items , though when critically examined , the number of satisfactory etymologies appears smaller than was thought __earlier__ ( janhunen 1981 ; sammallahti 1988 ) .
Contexts for target earlier are: ['advmodI_1981']
Contexts in vocabulary for target earlier are: []
Top most similar embeddings: earlier 1.00000	later 0.83264	early 0.75955	sooner 0.73526	second-century 0.72939	ago 0.72457	earliest 0.72184	long-ago 0.72056	52-inch 0.71569	ealier 0.71449

Generated lemmatized results
***************
GENERATED	earlier.r 921 ::: later;early;sooner;ago;earliest;ealier;eventualy;flippantly;pompously;serendipitously

Filtered results
***************
RANKED	earlier.r 921	sooner 0.73526	previously 0.67301	beforehand 0.67102	before 0.66624	initially 0.63641	formerly 0.59369

Test context:
***************
earlier.r	922	7	if you wish to collect your robes __earlier__ you should contact the above number to arrange collection .
Contexts for target earlier are: ['advmodI_contact']
Contexts in vocabulary for target earlier are: ['advmodI_contact']
Top most similar embeddings: earlier 0.48769	later 0.41399	early 0.37979	sooner 0.37816	imediately 0.36073	beforehand 0.35899	reguarly 0.35732	proably 0.35704	immediatly 0.35536	duely 0.35478

Generated lemmatized results
***************
GENERATED	earlier.r 922 ::: later;early;sooner;imediately;beforehand;reguarly;proably;immediatly;duely;prior

Filtered results
***************
RANKED	earlier.r 922	sooner 0.37816	beforehand 0.35899	initially 0.34412	previously 0.33050	before 0.31698	formerly 0.29201

Test context:
***************
earlier.r	923	8	it is possible that if he had gone __earlier__ he may have recovered .
Contexts for target earlier are: ['advmodI_gone']
Contexts in vocabulary for target earlier are: ['advmodI_gone']
Top most similar embeddings: earlier 0.50783	later 0.42156	eventualy 0.39638	duely 0.38580	alledgedly 0.38456	belly-up 0.38441	long-since 0.38362	proably 0.38144	sooner 0.37969	bloodily 0.37535

Generated lemmatized results
***************
GENERATED	earlier.r 923 ::: later;eventualy;duely;alledgedly;proably;sooner;bloodily;apprently;inexcusably;singlehandedly

Filtered results
***************
RANKED	earlier.r 923	sooner 0.37969	before 0.34954	previously 0.34923	beforehand 0.33039	initially 0.31697	formerly 0.29347

Test context:
***************
earlier.r	924	2	finding it __earlier__ would have saved me lots of time and made it easier to work with my architect .
Contexts for target earlier are: ['advmodI_saved']
Contexts in vocabulary for target earlier are: ['advmodI_saved']
Top most similar embeddings: earlier 0.50879	later 0.41760	duely 0.38890	alledgedly 0.38490	eventualy 0.38466	singlehandedly 0.37756	proably 0.37751	apprently 0.37511	audaciously 0.37282	serendipitously 0.36975

Generated lemmatized results
***************
GENERATED	earlier.r 924 ::: later;duely;alledgedly;eventualy;singlehandedly;proably;apprently;audaciously;serendipitously;ago

Filtered results
***************
RANKED	earlier.r 924	sooner 0.36490	previously 0.35956	beforehand 0.34022	initially 0.32713	before 0.32501	formerly 0.29166

Test context:
***************
earlier.r	925	19	i came to this realization later than some older and more perceptive scientists , but , even so , __earlier__ than many others .
Contexts for target earlier are: ['advmodI_came', 'prep:than_others']
Contexts in vocabulary for target earlier are: ['advmodI_came', 'prep:than_others']
Top most similar embeddings: earlier 0.25703	later 0.21737	sooner 0.19497	serendipitously 0.18162	sluggishly 0.17966	harshly 0.17772	fruitfully 0.17719	leniently 0.17643	faster 0.17606	quickly 0.17539

Generated lemmatized results
***************
GENERATED	earlier.r 925 ::: later;sooner;serendipitously;sluggishly;harshly;fruitfully;leniently;faster;quickly;early

Filtered results
***************
RANKED	earlier.r 925	sooner 0.19497	beforehand 0.15273	initially 0.14724	previously 0.14167	before 0.13703	formerly 0.12163

Test context:
***************
earlier.r	926	9	many countries have changed policies to allow investments that __earlier__ might have been prohibited or been otherwise difficult .
Contexts for target earlier are: ['advmodI_prohibited']
Contexts in vocabulary for target earlier are: ['advmodI_prohibited']
Top most similar embeddings: earlier 0.47167	later 0.39969	legislatively 0.37096	impliedly 0.36636	peremptorily 0.36225	ago 0.36000	wrongfully 0.35649	canonically 0.35607	long-since 0.35504	sooner 0.35315

Generated lemmatized results
***************
GENERATED	earlier.r 926 ::: later;legislatively;impliedly;peremptorily;ago;wrongfully;canonically;sooner;duely;dually

Filtered results
***************
RANKED	earlier.r 926	sooner 0.35315	previously 0.34503	beforehand 0.32158	initially 0.32140	before 0.30048	formerly 0.28788

Test context:
***************
earlier.r	927	0	__earlier__ , during world war i , hitler was an isolated human being , scorned for his strange pathetic ramblings .
Contexts for target earlier are: ['advmodI_human']
Contexts in vocabulary for target earlier are: ['advmodI_human']
Top most similar embeddings: earlier 0.46304	later 0.39161	early 0.36594	unforgettably 0.36410	ineffably 0.36286	contrastingly 0.36127	unnervingly 0.35880	surreally 0.35875	unmistakeably 0.35755	liturgically 0.35740

Generated lemmatized results
***************
GENERATED	earlier.r 927 ::: later;early;unforgettably;ineffably;contrastingly;unnervingly;surreally;unmistakeably;liturgically;inexcusably

Filtered results
***************
RANKED	earlier.r 927	sooner 0.35092	previously 0.32995	beforehand 0.31232	initially 0.30755	before 0.30582	formerly 0.29350

Test context:
***************
earlier.r	928	34	i mentioned that i would be seeing this new dr regarding counselling and psychology , jan thinks it is a good idea and it would probably help me , as i 'd missed out __earlier__ .
Contexts for target earlier are: ['advmodI_missed']
Contexts in vocabulary for target earlier are: ['advmodI_missed']
Top most similar embeddings: earlier 0.51380	later 0.41315	duely 0.37528	proably 0.37507	inexcusably 0.37413	alledgedly 0.37196	apprently 0.37118	eventualy 0.37091	early 0.37016	accidently 0.36531

Generated lemmatized results
***************
GENERATED	earlier.r 928 ::: later;duely;proably;inexcusably;alledgedly;apprently;eventualy;early;accidently;ago

Filtered results
***************
RANKED	earlier.r 928	sooner 0.35841	previously 0.34981	before 0.32857	beforehand 0.32559	initially 0.31906	formerly 0.28383

Test context:
***************
earlier.r	929	9	the key to public choice , as you said __earlier__ , is common sense .
Contexts for target earlier are: ['advmodI_said']
Contexts in vocabulary for target earlier are: ['advmodI_said']
Top most similar embeddings: earlier 0.54258	later 0.43942	pompously 0.40468	flippantly 0.40454	sourly 0.40374	glumly 0.40069	sardonically 0.39647	facetiously 0.39625	icily 0.39425	irritably 0.39386

Generated lemmatized results
***************
GENERATED	earlier.r 929 ::: later;pompously;flippantly;sourly;glumly;sardonically;facetiously;icily;irritably;breezily

Filtered results
***************
RANKED	earlier.r 929	sooner 0.37631	previously 0.35465	beforehand 0.35249	before 0.34728	initially 0.33053	formerly 0.30423

Test context:
***************
earlier.r	930	29	we have measures in place to keep it that way , " spokeswoman maeve o'beirne said. [ the key point is whether the us should have acted a week __earlier__ given the fact that france had imported 20,000 sheep from the uk during the critical period .
Contexts for target earlier are: ['npadvmod_week', 'advmodI_acted']
Contexts in vocabulary for target earlier are: ['npadvmod_week', 'advmodI_acted']
Top most similar embeddings: earlier 0.26284	later 0.22223	ago 0.19124	sooner 0.18625	afterward 0.18327	postoperatively 0.18085	honourably 0.17793	duely 0.17770	early 0.17738	previously 0.17725

Generated lemmatized results
***************
GENERATED	earlier.r 930 ::: later;ago;sooner;afterward;postoperatively;honourably;duely;early;previously;beforehand

Filtered results
***************
RANKED	earlier.r 930	sooner 0.18625	previously 0.17725	beforehand 0.17465	before 0.16869	initially 0.15271	formerly 0.13746

Test context:
***************
entirely.r	931	16	do not be swayed by herd constraints -- know that you are working on another level __entirely__ from the rest of the world .
Contexts for target entirely are: ['advmodI_working']
Contexts in vocabulary for target entirely are: ['advmodI_working']
Top most similar embeddings: entirely 0.50565	completely 0.40118	totally 0.39118	wholly 0.38872	cooperatively 0.38809	industriously 0.38744	solely 0.38736	cohesively 0.38566	unconventionally 0.38402	largely 0.38315

Generated lemmatized results
***************
GENERATED	entirely.r 931 ::: completely;totally;wholly;cooperatively;industriously;solely;cohesively;unconventionally;largely;predominently

Filtered results
***************
RANKED	entirely.r 931	completely 0.40118	totally 0.39118	wholly 0.38872	altogether 0.37551	exclusively 0.37012	fully 0.35594	continuously 0.33389	utterly 0.32699

Test context:
***************
entirely.r	932	17	the prohibitive cost of heroin in alice springs is keeping the drug off the streets but not __entirely__ out of the town .
Contexts for target entirely are: ['dep_not', 'advmodI_out']
Contexts in vocabulary for target entirely are: ['dep_not', 'advmodI_out']
Top most similar embeddings: entirely 0.27618	completely 0.22258	totally 0.21693	altogether 0.20530	completly 0.20508	totaly 0.20424	wholly 0.20139	necessarily 0.19875	largely 0.19552	solely 0.19543

Generated lemmatized results
***************
GENERATED	entirely.r 932 ::: completely;totally;altogether;completly;totaly;wholly;necessarily;largely;solely;neccesarily

Filtered results
***************
RANKED	entirely.r 932	completely 0.22258	totally 0.21693	altogether 0.20530	wholly 0.20139	exclusively 0.18633	utterly 0.18042	fully 0.16291	continuously 0.14333

Test context:
***************
entirely.r	933	17	if you link to any such websites you will leave the business essentials website and do so __entirely__ at your own risk .
Contexts for target entirely are: ['advmod_so', 'advmodI_do']
Contexts in vocabulary for target entirely are: ['advmod_so', 'advmodI_do']
Top most similar embeddings: entirely 0.25254	dexterously 0.21460	easilly 0.20967	presumptuously 0.20706	completely 0.20607	inexcusably 0.20503	promiscuously 0.20478	insensitively 0.20470	tiresomely 0.20256	thoughtlessly 0.20226

Generated lemmatized results
***************
GENERATED	entirely.r 933 ::: dexterously;easilly;presumptuously;completely;inexcusably;promiscuously;insensitively;tiresomely;thoughtlessly;boringly

Filtered results
***************
RANKED	entirely.r 933	completely 0.20607	totally 0.19950	wholly 0.18583	utterly 0.18429	altogether 0.18138	exclusively 0.16493	fully 0.15714	continuously 0.14784

Test context:
***************
entirely.r	934	7	usually , these test questions are based __entirely__ on the material covered in the text .
Contexts for target entirely are: ['advmodI_based']
Contexts in vocabulary for target entirely are: ['advmodI_based']
Top most similar embeddings: entirely 0.54158	largely 0.42342	wholly 0.42083	completely 0.41004	solely 0.40883	totally 0.40863	epistemologically 0.40060	predominently 0.39836	legislatively 0.39819	procedurally 0.39593

Generated lemmatized results
***************
GENERATED	entirely.r 934 ::: largely;wholly;completely;solely;totally;epistemologically;predominently;legislatively;procedurally;ecclesiastically

Filtered results
***************
RANKED	entirely.r 934	wholly 0.42083	completely 0.41004	totally 0.40863	exclusively 0.37877	altogether 0.36519	utterly 0.34659	fully 0.33774	continuously 0.30879

Test context:
***************
entirely.r	935	23	here are some of the principal sources for evidence in inductive arguments : 1. in essays on literature , the evidence comes almost __entirely__ from the text of the work you are evaluating , that is , from the words on the page .
Contexts for target entirely are: ['advmod_almost', 'advmodI_comes']
Contexts in vocabulary for target entirely are: ['advmod_almost', 'advmodI_comes']
Top most similar embeddings: entirely 0.27643	singlehandedly 0.23021	completely 0.20984	inaudibly 0.20873	wholly 0.20503	totally 0.20378	surreally 0.20305	mystically 0.20125	insolently 0.20027	exclusively 0.19889

Generated lemmatized results
***************
GENERATED	entirely.r 935 ::: singlehandedly;completely;inaudibly;wholly;totally;surreally;mystically;insolently;exclusively;certainly

Filtered results
***************
RANKED	entirely.r 935	completely 0.20984	wholly 0.20503	totally 0.20378	exclusively 0.19889	altogether 0.18192	fully 0.17545	utterly 0.16616	continuously 0.15823

Test context:
***************
entirely.r	936	4	both schemes are funded __entirely__ from general revenue and non-contributory .
Contexts for target entirely are: ['advmodI_funded']
Contexts in vocabulary for target entirely are: ['advmodI_funded']
Top most similar embeddings: entirely 0.53906	wholly 0.42073	totally 0.41353	completely 0.41340	largely 0.41114	federally 0.40013	solely 0.39738	partly 0.39225	predominently 0.38567	bureaucratically 0.37893

Generated lemmatized results
***************
GENERATED	entirely.r 936 ::: wholly;totally;completely;largely;federally;solely;partly;predominently;bureaucratically;completly

Filtered results
***************
RANKED	entirely.r 936	wholly 0.42073	totally 0.41353	completely 0.41340	fully 0.37283	exclusively 0.36710	altogether 0.36012	utterly 0.33835	continuously 0.30823

Test context:
***************
entirely.r	937	13	still , even against all odds , they have decided to put hope __entirely__ on what they see as a fresh start .
Contexts for target entirely are: ['advmodI_put']
Contexts in vocabulary for target entirely are: ['advmodI_put']
Top most similar embeddings: entirely 0.50434	completely 0.41360	totally 0.40276	singlehandedly 0.39517	dexterously 0.39087	expectedly 0.38968	bloodily 0.38948	proably 0.38643	inexcusably 0.38624	publickly 0.38557

Generated lemmatized results
***************
GENERATED	entirely.r 937 ::: completely;totally;singlehandedly;dexterously;expectedly;bloodily;proably;inexcusably;publickly;altogether

Filtered results
***************
RANKED	entirely.r 937	completely 0.41360	totally 0.40276	altogether 0.38508	wholly 0.38295	utterly 0.35152	exclusively 0.34202	fully 0.33967	continuously 0.31308

Test context:
***************
entirely.r	938	8	note that the expression reads in the file __entirely__ in one go .
Contexts for target entirely are: ['advmodI_reads']
Contexts in vocabulary for target entirely are: ['advmodI_reads']
Top most similar embeddings: entirely 0.47237	completely 0.38113	unconventionally 0.37832	expectedly 0.37497	presumptuously 0.37322	virtuously 0.37271	inexcusably 0.37148	singlehandedly 0.37071	publickly 0.37042	apprently 0.37004

Generated lemmatized results
***************
GENERATED	entirely.r 938 ::: completely;unconventionally;expectedly;presumptuously;virtuously;inexcusably;singlehandedly;publickly;apprently;tiresomely

Filtered results
***************
RANKED	entirely.r 938	completely 0.38113	totally 0.36818	altogether 0.36723	wholly 0.36176	exclusively 0.34780	utterly 0.33796	fully 0.32652	continuously 0.31496

Test context:
***************
entirely.r	939	3	their involvement depends __entirely__ on what the individual wants .
Contexts for target entirely are: ['advmodI_depends']
Contexts in vocabulary for target entirely are: ['advmodI_depends']
Top most similar embeddings: entirely 0.54818	totally 0.42212	largely 0.41959	completely 0.41631	wholly 0.41138	solely 0.39961	procedurally 0.38530	totaly 0.38270	obviously 0.38205	partly 0.38132

Generated lemmatized results
***************
GENERATED	entirely.r 939 ::: totally;largely;completely;wholly;solely;procedurally;totaly;obviously;partly;ontologically

Filtered results
***************
RANKED	entirely.r 939	totally 0.42212	completely 0.41631	wholly 0.41138	utterly 0.36521	altogether 0.36285	exclusively 0.35996	fully 0.33718	continuously 0.30246

Test context:
***************
entirely.r	940	16	avoid clich 's too - words and phrases that are so frequently used that they are __entirely__ predictable and emptied of any interesting content .
Contexts for target entirely are: ['advmodI_predictable']
Contexts in vocabulary for target entirely are: ['advmodI_predictable']
Top most similar embeddings: entirely 0.54486	totally 0.43201	completely 0.42831	wholly 0.41737	largely 0.40723	tiresomely 0.40200	boringly 0.39629	irredeemably 0.38870	totaly 0.38708	unrelentingly 0.38609

Generated lemmatized results
***************
GENERATED	entirely.r 940 ::: totally;completely;wholly;largely;tiresomely;boringly;irredeemably;totaly;unrelentingly;inexcusably

Filtered results
***************
RANKED	entirely.r 940	totally 0.43201	completely 0.42831	wholly 0.41737	utterly 0.38273	altogether 0.37978	fully 0.35026	exclusively 0.33271	continuously 0.29378

Test context:
***************
forth.r	941	35	initially the program is focusing in on people like the photographic shops and automobile paint/repair shops and there is one other , the kind of industry that tends to put the heavy metals and so __forth__ into the system more than others .
Contexts for target forth are: ['advmod_so', 'conjI_tends', 'prep:into_system']
Contexts in vocabulary for target forth are: ['advmod_so', 'conjI_tends', 'prep:into_system']
Top most similar embeddings: forth 0.11053	seamlessly 0.07441	fluidly 0.07401	insensibly 0.07370	neatly 0.07325	painlessly 0.07274	unpredictably 0.07267	shallowly 0.07253	destructively 0.07217	insistently 0.07211

Generated lemmatized results
***************
GENERATED	forth.r 941 ::: seamlessly;fluidly;insensibly;neatly;painlessly;unpredictably;shallowly;destructively;insistently;seeps

Filtered results
***************
RANKED	forth.r 941	onward 0.06567	forwards 0.06219	on 0.06161	across 0.05831	express 0.05459	onwards 0.05441	leave 0.05314	outward 0.05295	forward 0.05264	advance 0.05150	depart 0.04985	out 0.04930	about 0.04449	extract 0.04401	show 0.04378	phrase 0.04339	etcetera 0.04269

Test context:
***************
forth.r	942	21	( laughter. ) campaigns are campaigns but there are limits to the kind of accusations which should be traded back and __forth__ .
Contexts for target forth are: ['conjI_back']
Contexts in vocabulary for target forth are: ['conjI_back']
Top most similar embeddings: forth 0.57300	forearms 0.33324	onto 0.32895	buttocks 0.32793	hindquarters 0.32751	thence 0.32607	forearm 0.32562	delts 0.32520	loins 0.32466	wrists 0.32448

Generated lemmatized results
***************
GENERATED	forth.r 942 ::: forearms;onto;buttocks;hindquarters;thence;forearm;delts;loins;wrists;neck

Filtered results
***************
RANKED	forth.r 942	forward 0.32065	forwards 0.32005	onward 0.30385	across 0.29471	on 0.29014	out 0.27598	outward 0.27562	onwards 0.26554	etcetera 0.25427	express 0.24853	depart 0.24792	about 0.24679	leave 0.23982	show 0.23940	advance 0.23309	extract 0.21857	phrase 0.20353

Test context:
***************
forth.r	943	13	perhaps the developing countries consulted by the chairman were not able to put __forth__ their views strongly in these consultations , or the chairman simply did not consider their views important enough to be accommodated in the text .
Contexts for target forth are: ['prtI_put']
Contexts in vocabulary for target forth are: ['prtI_put']
Top most similar embeddings: forth 0.51411	down 0.34747	on 0.33268	back 0.33120	up 0.33046	aside 0.33008	forward 0.32979	together 0.32967	off 0.32683	out 0.32643

Generated lemmatized results
***************
GENERATED	forth.r 943 ::: down;on;back;up;aside;forward;together;off;out;away

Filtered results
***************
RANKED	forth.r 943	on 0.33268	forward 0.32979	out 0.32643	across 0.32126	forwards 0.28338	onward 0.27787	about 0.27392	onwards 0.24225	outward 0.24200	express 0.23286	extract 0.22360	depart 0.22136	etcetera 0.22055	advance 0.21566	leave 0.21268	show 0.20546	phrase 0.19274

Test context:
***************
forth.r	944	13	at one side of each factory there is a great chimney which belches __forth__ black smoke and indicates the presence of the powerful steam engines .
Contexts for target forth are: []
Contexts in vocabulary for target forth are: []
Top most similar embeddings: forth 1.00000	wreake 0.68470	oxus 0.68469	deveron 0.68415	ythan 0.68110	nith 0.68079	clyde 0.67714	irthing 0.67612	esk 0.67575	nethy 0.67572

Generated lemmatized results
***************
GENERATED	forth.r 944 ::: wreake;oxus;deveron;ythan;nith;clyde;irthing;esk;nethy;breamish

Filtered results
***************
RANKED	forth.r 944	onward 0.62746	on 0.61483	forward 0.61416	out 0.61006	forwards 0.60382	across 0.59871	onwards 0.58443	express 0.58176	about 0.57567	etcetera 0.56751	outward 0.56273	show 0.55928	depart 0.54323	leave 0.53895	advance 0.52765	phrase 0.51824	extract 0.51367

Test context:
***************
forth.r	945	35	i was thankful for that and when it came back , i drank it away again , and i 'm afraid to say but this became a regular pattern in my life from that time __forth__ .
Contexts for target forth are: ['advmodI_time']
Contexts in vocabulary for target forth are: ['advmodI_time']
Top most similar embeddings: forth 0.50895	proably 0.35861	defintely 0.34697	maybe 0.34593	tortuously 0.34444	breezily 0.34373	interminably 0.34148	ineffably 0.33974	all-in-all 0.33907	diabolically 0.33843

Generated lemmatized results
***************
GENERATED	forth.r 945 ::: proably;defintely;maybe;tortuously;breezily;interminably;ineffably;diabolically;murderously;ecstatically

Filtered results
***************
RANKED	forth.r 945	onward 0.32104	out 0.30975	forward 0.30455	forwards 0.29908	about 0.28215	across 0.28178	onwards 0.27350	on 0.26678	outward 0.25287	express 0.23490	depart 0.22668	etcetera 0.22452	show 0.21484	leave 0.21278	advance 0.21120	extract 0.21052	phrase 0.20328

Test context:
***************
forth.r	946	17	there was something of the martyr in him ; he had given up better jobs to go __forth__ , rake in hand , to show things up ; and he wanted them to be changed .
Contexts for target forth are: ['advmodI_go']
Contexts in vocabulary for target forth are: ['advmodI_go']
Top most similar embeddings: forth 0.53229	beserk 0.38429	belly-up 0.37510	toe-to-toe 0.37434	proably 0.37408	defintely 0.36395	eventualy 0.36119	ponderously 0.35916	jauntily 0.35436	breezily 0.35356

Generated lemmatized results
***************
GENERATED	forth.r 946 ::: beserk;proably;defintely;eventualy;ponderously;jauntily;breezily;boldly;victoriously;actaully

Filtered results
***************
RANKED	forth.r 946	forward 0.32703	onward 0.32679	forwards 0.31551	across 0.30696	out 0.30530	on 0.30305	about 0.28253	onwards 0.27528	etcetera 0.25990	outward 0.25680	express 0.23527	advance 0.22698	leave 0.21887	depart 0.21707	show 0.21029	phrase 0.20340	extract 0.20257

Test context:
***************
forth.r	947	13	the final results screen the journal , date , page numbers and so __forth__ for each article are listed on-screen , one-at-a-time .
Contexts for target forth are: ['advmod_so', 'conjI_journal', 'prep:for_article']
Contexts in vocabulary for target forth are: ['advmod_so', 'conjI_journal', 'prep:for_article']
Top most similar embeddings: forth 0.10814	eloquently 0.07057	boldly 0.06856	succinctly 0.06773	diligently 0.06760	valiantly 0.06677	reprinted 0.06616	desperately 0.06552	far 0.06536	cogently 0.06531

Generated lemmatized results
***************
GENERATED	forth.r 947 ::: eloquently;boldly;succinctly;diligently;valiantly;reprinted;desperately;far;cogently;copiously

Filtered results
***************
RANKED	forth.r 947	on 0.06253	etcetera 0.05940	onward 0.05892	forward 0.05769	onwards 0.05456	express 0.05329	across 0.05307	forwards 0.05206	depart 0.05025	about 0.05020	advance 0.04902	leave 0.04861	extract 0.04848	phrase 0.04637	outward 0.04484	show 0.04386	out 0.04274

Test context:
***************
forth.r	948	2	he sent __forth__ his daughter in disguise , and she waited for the criminal .
Contexts for target forth are: ['advmodI_sent']
Contexts in vocabulary for target forth are: ['advmodI_sent']
Top most similar embeddings: forth 0.53193	duely 0.37044	eventualy 0.36007	thither 0.35591	victoriously 0.35425	proably 0.35104	ceremoniously 0.35027	imediately 0.34843	breezily 0.34684	wordlessly 0.34607

Generated lemmatized results
***************
GENERATED	forth.r 948 ::: duely;eventualy;thither;victoriously;proably;ceremoniously;imediately;breezily;wordlessly;regally

Filtered results
***************
RANKED	forth.r 948	onward 0.32135	forward 0.31234	forwards 0.30236	out 0.29668	across 0.29390	on 0.27747	onwards 0.27217	about 0.26397	outward 0.25438	etcetera 0.24647	express 0.23627	advance 0.21983	depart 0.21979	leave 0.21591	extract 0.21200	show 0.21064	phrase 0.19897

Test context:
***************
forth.r	949	17	the many in one , dedicate our physical embodiments to the god expression in form , bring __forth__ by example , to this planet earth love , light and peace .
Contexts for target forth are: ['advmodI_bring']
Contexts in vocabulary for target forth are: ['advmodI_bring']
Top most similar embeddings: forth 0.54566	victoriously 0.35166	eventualy 0.34888	proably 0.34680	infallibly 0.34467	back 0.34457	ponderously 0.34440	regally 0.34439	defintely 0.34363	together 0.34239

Generated lemmatized results
***************
GENERATED	forth.r 949 ::: victoriously;eventualy;proably;infallibly;back;ponderously;regally;defintely;together;jauntily

Filtered results
***************
RANKED	forth.r 949	forward 0.32970	onward 0.31168	forwards 0.29866	across 0.29798	about 0.29278	out 0.28716	on 0.28063	onwards 0.26211	outward 0.25634	etcetera 0.24293	express 0.23841	show 0.21407	depart 0.21356	extract 0.21209	advance 0.20935	leave 0.20108	phrase 0.19440

Test context:
***************
forth.r	950	16	a 10 could be units of happiness , pleasure , pain , embarrassment , and so __forth__ , as well as dollars .
Contexts for target forth are: ['advmod_so', 'advmodI_happiness']
Contexts in vocabulary for target forth are: ['advmod_so', 'advmodI_happiness']
Top most similar embeddings: forth 0.27472	feelingly 0.18361	ardently 0.18078	blessedly 0.18003	meanly 0.18002	piously 0.17973	ineffably 0.17856	drearily 0.17633	eloquently 0.17518	presumptuously 0.17495

Generated lemmatized results
***************
GENERATED	forth.r 950 ::: feelingly;ardently;blessedly;meanly;piously;ineffably;drearily;eloquently;presumptuously;pompously

Filtered results
***************
RANKED	forth.r 950	onward 0.15164	forwards 0.13857	forward 0.13657	on 0.13444	across 0.12774	about 0.12172	out 0.11884	onwards 0.11598	outward 0.11276	etcetera 0.11215	express 0.10599	depart 0.10456	advance 0.09682	leave 0.09668	show 0.08713	phrase 0.08451	extract 0.08436

Test context:
***************
fresh.a	951	13	these songs are far too personal , far too low , far too __fresh__ , far too subjective to ever achieve i believe , that desired state of objectivity .
Contexts for target fresh are: ['advmod_far', 'advmod_too', 'conjI_personal']
Contexts in vocabulary for target fresh are: ['advmod_far', 'advmod_too', 'conjI_personal']
Top most similar embeddings: fresh 0.10219	unadventurous 0.08429	distant 0.08373	introspective 0.08371	po-faced 0.08271	wordy 0.08203	touchable 0.08179	vague 0.08143	contrasty 0.08128	appetizing 0.08124

Generated lemmatized results
***************
GENERATED	fresh.a 951 ::: unadventurous;distant;introspective;wordy;touchable;vague;contrasty;appetizing;contraversial;preachy

Filtered results
***************
RANKED	fresh.a 951	vivid 0.08108	pure 0.07114	bright 0.07066	refreshing 0.06997	raw 0.06928	unprocessed 0.06705	impertinent 0.06705	clear 0.06681	different 0.06678	relevant 0.06421	undimmed 0.06421	uncontaminated 0.06401	clean 0.06367	modern 0.06267	new 0.06098	original 0.06020	recent 0.05851	airy 0.05658	novel 0.05606	forward 0.05557	another 0.04409

Test context:
***************
fresh.a	952	8	at first the user is impressed by the __fresh__ clean smell coming out of the machine and how nice it makes their home smell .
Contexts for target fresh are: ['amodI_smell']
Contexts in vocabulary for target fresh are: ['amodI_smell']
Top most similar embeddings: fresh 0.53422	yeasty 0.40827	zingy 0.40605	zesty 0.40262	pungent 0.39965	sweet-smelling 0.39219	tangy 0.38843	peppery 0.38787	sulphurous 0.38516	sweetish 0.38472

Generated lemmatized results
***************
GENERATED	fresh.a 952 ::: yeasty;zingy;zesty;pungent;tangy;peppery;sulphurous;sweetish;appetizing;odorous

Filtered results
***************
RANKED	fresh.a 952	refreshing 0.36673	unprocessed 0.35185	raw 0.34553	vivid 0.34311	clean 0.34236	bright 0.33200	new 0.32805	pure 0.32637	different 0.31862	uncontaminated 0.31530	original 0.31040	airy 0.30913	clear 0.30432	modern 0.29333	undimmed 0.29098	relevant 0.29030	impertinent 0.28516	recent 0.28495	novel 0.26721	forward 0.24661	another 0.22495

Test context:
***************
fresh.a	953	24	if proof does emerge , and suspicion falls on the ukrainian authorities , it could help rally support for mr yushchenko ahead of a __fresh__ round of voting on december 26 .
Contexts for target fresh are: ['amodI_round']
Contexts in vocabulary for target fresh are: ['amodI_round']
Top most similar embeddings: fresh 0.51032	all-year 0.37468	three-cornered 0.36630	well-shaped 0.36325	zesty 0.36246	decent-sized 0.36214	flattish 0.36065	four-card 0.36053	vigourous 0.36017	late-afternoon 0.36007

Generated lemmatized results
***************
GENERATED	fresh.a 953 ::: zesty;flattish;vigourous;zingy;fishless;languorous;frothy;crispy;coruscating;longish

Filtered results
***************
RANKED	fresh.a 953	new 0.34525	refreshing 0.34092	bright 0.34001	unprocessed 0.32781	raw 0.32655	clean 0.31862	vivid 0.31669	recent 0.31404	clear 0.31363	original 0.31226	different 0.30673	uncontaminated 0.30373	pure 0.30207	modern 0.29722	airy 0.29490	undimmed 0.29394	relevant 0.29000	impertinent 0.27114	novel 0.26481	forward 0.26363	another 0.25025

Test context:
***************
fresh.a	954	13	the trauma of finding alyssa blue and limp and too cold is so __fresh__ in my mind , i want to will it all away !
Contexts for target fresh are: ['nsubj_trauma', 'cop_is', 'advmod_so', 'rootI_*root*', 'prep:in_mind', 'punct_,', 'ccomp_want', 'punct_!', 'dep_<eol>']
Contexts in vocabulary for target fresh are: ['nsubj_trauma', 'cop_is', 'advmod_so', 'rootI_*root*', 'prep:in_mind', 'punct_,', 'ccomp_want', 'punct_!']
Top most similar embeddings: fresh 0.00264	unbelieveable 0.00251	understandable 0.00243	hillarious 0.00238	earth-shattering 0.00237	unforgiveable 0.00234	forearmed 0.00234	unarguable 0.00231	ingrained 0.00228	palpable 0.00227

Generated lemmatized results
***************
GENERATED	fresh.a 954 ::: unbelieveable;understandable;hillarious;unforgiveable;forearmed;unarguable;ingrained;palpable;evident;obvious

Filtered results
***************
RANKED	fresh.a 954	refreshing 0.00223	clear 0.00214	vivid 0.00212	undimmed 0.00202	impertinent 0.00166	bright 0.00157	pure 0.00147	different 0.00142	clean 0.00141	novel 0.00130	relevant 0.00128	raw 0.00127	airy 0.00116	unprocessed 0.00107	original 0.00100	new 0.00095	uncontaminated 0.00091	forward 0.00088	modern 0.00074	another 0.00064	recent 0.00062

Test context:
***************
fresh.a	955	20	in a world where books more than one month old are out of date , this one remains current , __fresh__ , and alive .
Contexts for target fresh are: ['conjI_current']
Contexts in vocabulary for target fresh are: ['conjI_current']
Top most similar embeddings: fresh 0.48565	up-coming 0.35360	freshest 0.34999	non-current 0.34779	prospective 0.34408	near-market 0.33913	topical 0.33805	new 0.33782	up-to-the-minute 0.33743	fresher 0.33672

Generated lemmatized results
***************
GENERATED	fresh.a 955 ::: prospective;topical;new;recent;innovative;unprocessed;emerging;relevant;imminent;refreshed

Filtered results
***************
RANKED	fresh.a 955	new 0.33782	recent 0.33665	unprocessed 0.32974	relevant 0.32791	refreshing 0.32436	raw 0.32421	bright 0.31837	clean 0.31503	original 0.31192	vivid 0.31000	undimmed 0.30416	pure 0.29712	modern 0.29481	clear 0.29479	uncontaminated 0.28852	different 0.28308	airy 0.27051	novel 0.27048	forward 0.26795	impertinent 0.25919	another 0.22309

Test context:
***************
fresh.a	956	31	though many adults work hard to sustain a relationship , this is mostly a compromise after having already invested too much time in someone and being too weary to make a __fresh__ attempt with someone else .
Contexts for target fresh are: ['amodI_attempt']
Contexts in vocabulary for target fresh are: ['amodI_attempt']
Top most similar embeddings: fresh 0.50985	multi-pronged 0.37806	half-arsed 0.37182	cack-handed 0.36803	last-ditch 0.36704	ill-starred 0.36658	full-blooded 0.36645	three-pronged 0.36607	vigourous 0.36460	tragi-comic 0.36380

Generated lemmatized results
***************
GENERATED	fresh.a 956 ::: vigourous;geniune;zesty;surreptitious;unsubtle;ballsy;mere;yearlong;timeous;unpublicised

Filtered results
***************
RANKED	fresh.a 956	unprocessed 0.33558	refreshing 0.33431	raw 0.32972	new 0.32951	vivid 0.32801	recent 0.32203	original 0.31903	clear 0.31630	bright 0.31601	pure 0.31215	impertinent 0.31023	modern 0.30935	clean 0.30716	different 0.29856	undimmed 0.29650	airy 0.29576	uncontaminated 0.28859	relevant 0.28682	novel 0.28069	forward 0.25883	another 0.23831

Test context:
***************
fresh.a	957	5	yet he creates a compellingly __fresh__ vision of good business in both a material and spiritual sense .
Contexts for target fresh are: ['amodI_vision']
Contexts in vocabulary for target fresh are: ['amodI_vision']
Top most similar embeddings: fresh 0.51589	zesty 0.37251	wholistic 0.36928	beatific 0.36911	clear-eyed 0.36696	yeasty 0.36529	tragi-comic 0.36512	youthful 0.36273	multi-pronged 0.36223	neo-platonic 0.36216

Generated lemmatized results
***************
GENERATED	fresh.a 957 ::: zesty;wholistic;beatific;yeasty;youthful;vaporous;panoptic;coruscating;foucauldian;vivid

Filtered results
***************
RANKED	fresh.a 957	vivid 0.35752	refreshing 0.35022	new 0.34930	clear 0.34353	raw 0.34142	unprocessed 0.34002	bright 0.33844	original 0.33834	pure 0.33606	different 0.32484	undimmed 0.32467	clean 0.32012	modern 0.31344	uncontaminated 0.30888	airy 0.30391	recent 0.29543	relevant 0.29433	novel 0.28665	forward 0.28205	impertinent 0.27950	another 0.22055

Test context:
***************
fresh.a	958	3	when preparing a __fresh__ uniform for the next shift look it over closely .
Contexts for target fresh are: ['amodI_uniform']
Contexts in vocabulary for target fresh are: ['amodI_uniform']
Top most similar embeddings: fresh 0.50371	well-fitting 0.37312	tight-fitting 0.36832	loose-fitting 0.36070	dayglo 0.36035	brightly-coloured 0.35819	super-soft 0.35775	short-sleeved 0.35708	close-fitting 0.35707	silver-grey 0.35686

Generated lemmatized results
***************
GENERATED	fresh.a 958 ::: dayglo;georgeous;zesty;traditonal;distinctive;new;crisp;yellowy;authentic;filmy

Filtered results
***************
RANKED	fresh.a 958	new 0.35094	clean 0.34292	bright 0.33974	unprocessed 0.33493	raw 0.33445	vivid 0.33194	original 0.32163	refreshing 0.32082	different 0.31597	modern 0.31087	uncontaminated 0.30866	pure 0.30847	clear 0.30060	airy 0.29442	relevant 0.29420	recent 0.28562	undimmed 0.28283	impertinent 0.27445	novel 0.26992	forward 0.24549	another 0.23342

Test context:
***************
fresh.a	959	1	a __fresh__ group of students will head to college this fall , and the consumer finance classes they took in high school might not be enough to prevent them from making some serious financial mistakes .
Contexts for target fresh are: ['amodI_group']
Contexts in vocabulary for target fresh are: ['amodI_group']
Top most similar embeddings: fresh 0.47925	seven-strong 0.39984	six-strong 0.39311	20-strong 0.39022	pharmacotherapeutic 0.39004	five-strong 0.38773	french-based 0.38597	40-strong 0.38486	cross-generational 0.38383	short-life 0.38335

Generated lemmatized results
***************
GENERATED	fresh.a 959 ::: pharmacotherapeutic;biggish;vigourous;zesty;lively;brasilian;traditonal;ufological;geniune;new

Filtered results
***************
RANKED	fresh.a 959	new 0.35051	unprocessed 0.34259	original 0.32884	refreshing 0.32417	different 0.32408	clean 0.32254	raw 0.32047	relevant 0.31804	vivid 0.31787	pure 0.31738	bright 0.31334	uncontaminated 0.30737	recent 0.30315	modern 0.30094	clear 0.29016	undimmed 0.27865	airy 0.27781	novel 0.27439	impertinent 0.27278	forward 0.26787	another 0.22603

Test context:
***************
fresh.a	960	15	the species highest in mercury include swordfish , shark , tilefish , king mackerel and __fresh__ tuna .
Contexts for target fresh are: ['amodI_tuna']
Contexts in vocabulary for target fresh are: ['amodI_tuna']
Top most similar embeddings: fresh 0.55353	char-grilled 0.43334	well-cooked 0.40772	ready-to-eat 0.40567	deep-fried 0.40179	slow-cooked 0.40021	zesty 0.40010	unsweetened 0.39971	sun-dried 0.39861	stir-fried 0.39709

Generated lemmatized results
***************
GENERATED	fresh.a 960 ::: zesty;unsweetened;flavorful;breaded;uncooked;crispy;floury;undercooked;tangy;broiled

Filtered results
***************
RANKED	fresh.a 960	raw 0.37005	unprocessed 0.36796	refreshing 0.33152	bright 0.32619	clean 0.32139	pure 0.31969	uncontaminated 0.31585	vivid 0.31092	original 0.30672	new 0.30392	modern 0.28795	different 0.28643	clear 0.28535	recent 0.28022	airy 0.27525	impertinent 0.26520	novel 0.26502	relevant 0.26417	undimmed 0.26054	another 0.23973	forward 0.23272

Test context:
***************
go.v	961	2	we have __gone__ through it all -- the collapse of soviet communism , the consolidation of new democracies , and the chilling dawn of a post-september 11 world .
Contexts for target gone are: ['nsubj_we', 'aux_have', 'rootI_*root*', 'prep:through_it', 'dobj_all', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target gone are: ['nsubj_we', 'aux_have', 'rootI_*root*', 'prep:through_it', 'dobj_all', 'punct_.']
Top most similar embeddings: gone 0.01600	slogged 0.01263	trawled 0.01252	traipsed 0.01251	tiptoed 0.01245	blagged 0.01243	slept 0.01236	walked 0.01235	crawled 0.01232	boated 0.01232

Generated lemmatized results
***************
GENERATED	go.v 961 ::: slog;trawl;traipse;tiptoe;blagged;sleep;walk;crawl;boat;get

Filtered results
***************
RANKED	go.v 961	walk 0.01235	pass 0.01164	work 0.01156	travel 0.01149	journey 0.01118	endure 0.01085	move 0.01080	try 0.01062	proceed 0.00999	reach 0.00978	start 0.00973	run 0.00972	approach 0.00934	take 0.00924	attempt 0.00898	rest 0.00856	release 0.00852	undertake 0.00846	attack 0.00838	operate 0.00838	leave 0.00826	running 0.00823	free 0.00819	loose 0.00803	aim 0.00776	be 0.00717	relax 0.00713

Test context:
***************
go.v	962	13	matthew carey reported , ' many never walked on the footpath , but __went__ into the middle of the streets , to avoid being infected in passing houses wherein people had died .
Contexts for target went are: ['conjI_reported', 'prep:into_middle']
Contexts in vocabulary for target went are: ['conjI_reported', 'prep:into_middle']
Top most similar embeddings: went 0.22978	drove 0.19335	drifted 0.18843	careered 0.18569	scooted 0.18564	jinked 0.18498	threw 0.18460	walked 0.18441	ran 0.18373	spiraled 0.18322

Generated lemmatized results
***************
GENERATED	go.v 962 ::: drive;drift;career;scoot;jinked;throw;walk;run;spiral;traipse

Filtered results
***************
RANKED	go.v 962	walk 0.18441	run 0.18373	proceed 0.17661	take 0.17527	move 0.16641	journey 0.16453	travel 0.16201	undertake 0.15073	pass 0.15026	reach 0.14291	attempt 0.14106	approach 0.13773	try 0.13727	attack 0.13577	work 0.13415	endure 0.13386	leave 0.13104	start 0.13090	be 0.12929	operate 0.12857	release 0.12842	rest 0.12781	loose 0.12623	relax 0.12568	running 0.12485	aim 0.11877	free 0.11563

Test context:
***************
go.v	963	3	people will often __go__ on long and arduous journeys just to see things , or will buy recording equipment , radios , or television just to provide themselves with stimulation .
Contexts for target go are: ['nsubj_people', 'aux_will', 'advmod_often', 'rootI_*root*', 'prep:on_journeys', 'xcomp_see', 'punct_,', 'cc_or', 'conj_buy', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target go are: ['nsubj_people', 'aux_will', 'advmod_often', 'rootI_*root*', 'prep:on_journeys', 'xcomp_see', 'punct_,', 'cc_or', 'conj_buy', 'punct_.']
Top most similar embeddings: go 0.00086	wander 0.00065	congregate 0.00061	loiter 0.00060	come 0.00058	stumble 0.00057	stampeded 0.00057	yearn 0.00056	try 0.00056	tend 0.00056

Generated lemmatized results
***************
GENERATED	go.v 963 ::: wander;congregate;loiter;come;stumble;stampede;yearn;try;tend;procrastinate

Filtered results
***************
RANKED	go.v 963	try 0.00056	take 0.00055	travel 0.00048	walk 0.00047	proceed 0.00047	leave 0.00046	endure 0.00046	journey 0.00045	relax 0.00044	pass 0.00044	operate 0.00042	start 0.00041	run 0.00041	move 0.00040	approach 0.00037	reach 0.00036	undertake 0.00036	attack 0.00035	free 0.00034	work 0.00034	loose 0.00034	attempt 0.00033	rest 0.00033	aim 0.00032	running 0.00031	release 0.00031	be 0.00019

Test context:
***************
go.v	964	2	if you __go__ that route , two additional open source tools , password safe and keepass , will help you manage and use your password with minimal hassle and confusion .
Contexts for target go are: ['mark_if', 'nsubj_you', 'rootI_*root*', 'ccomp_help', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target go are: ['mark_if', 'nsubj_you', 'rootI_*root*', 'ccomp_help', 'punct_.']
Top most similar embeddings: go 0.02820	think 0.02721	find 0.02478	believe 0.02469	feel 0.02406	let 0.02394	know 0.02375	want 0.02359	see 0.02333	decide 0.02328

Generated lemmatized results
***************
GENERATED	go.v 964 ::: think;find;believe;feel;let;know;want;see;decide;agree

Filtered results
***************
RANKED	go.v 964	try 0.02248	take 0.01934	leave 0.01891	be 0.01872	proceed 0.01864	start 0.01848	aim 0.01828	reach 0.01805	work 0.01799	move 0.01787	travel 0.01754	relax 0.01749	walk 0.01746	approach 0.01707	run 0.01705	attempt 0.01686	operate 0.01683	pass 0.01666	journey 0.01664	undertake 0.01629	attack 0.01628	endure 0.01558	rest 0.01556	loose 0.01534	running 0.01527	free 0.01503	release 0.01478

Test context:
***************
go.v	965	17	but it 's not much trouble to assemble - all you have to do to get it __going__ is build up the road wheel sets , pop on the tracks , and stick in some batteries .
Contexts for target going are: ['nsubj_it', 'csubjI_build']
Contexts in vocabulary for target going are: ['nsubj_it', 'csubjI_build']
Top most similar embeddings: going 0.23760	gon 0.17969	transpiring 0.17446	happening 0.17177	goes 0.17067	behooves 0.17046	goign 0.16878	portends 0.16780	ought 0.16662	behoved 0.16605

Generated lemmatized results
***************
GENERATED	go.v 965 ::: gon;transpire;happen;behoove;goign;portend;ought;behove;do;verge

Filtered results
***************
RANKED	go.v 965	try 0.16224	take 0.15966	move 0.15773	work 0.15671	aim 0.15326	run 0.15273	start 0.15171	attempt 0.15157	running 0.14988	free 0.14865	proceed 0.14653	travel 0.14204	relax 0.14122	rest 0.14067	operate 0.14053	loose 0.14052	release 0.13902	approach 0.13874	pass 0.13826	walk 0.13806	undertake 0.13790	reach 0.13763	attack 0.13709	leave 0.13238	endure 0.13090	journey 0.12781	be 0.12728

Test context:
***************
go.v	966	2	some teams __go__ abroad to build churches , hospitals , camps , parsonages , houses or barns , which may be needed because of fires , floods , hurricanes or poverty .
Contexts for target go are: ['nsubj_teams', 'rootI_*root*', 'advmod_abroad', 'xcomp_build', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target go are: ['nsubj_teams', 'rootI_*root*', 'advmod_abroad', 'xcomp_build', 'punct_.']
Top most similar embeddings: go 0.02702	went 0.02436	struggled 0.02202	traveled 0.02200	worked 0.02188	ventured 0.02182	travelled 0.02175	journeyed 0.02168	trooped 0.02147	going 0.02144

Generated lemmatized results
***************
GENERATED	go.v 966 ::: struggle;travel;work;venture;journey;troop;continue;strive;battle;compete

Filtered results
***************
RANKED	go.v 966	travel 0.02200	work 0.02188	journey 0.02168	take 0.02046	proceed 0.02039	undertake 0.02038	start 0.01996	move 0.01977	aim 0.01903	try 0.01893	operate 0.01794	run 0.01784	attempt 0.01746	walk 0.01681	approach 0.01679	endure 0.01634	be 0.01620	leave 0.01588	rest 0.01573	reach 0.01572	pass 0.01564	release 0.01502	free 0.01496	attack 0.01487	running 0.01400	loose 0.01397	relax 0.01315

Test context:
***************
go.v	967	16	to make these techniques work well , explain the basic concept and purpose and get it __going__ with minimal briefing .
Contexts for target going are: ['nsubj_it', 'xcompI_get', 'prep:with_briefing']
Contexts in vocabulary for target going are: ['nsubj_it', 'xcompI_get', 'prep:with_briefing']
Top most similar embeddings: going 0.11708	started 0.08486	wrong 0.08474	begin 0.08156	goin 0.08108	pissing 0.07860	starts 0.07856	happening 0.07851	ready 0.07778	go 0.07754

Generated lemmatized results
***************
GENERATED	go.v 967 ::: start;wrong;begin;goin;piss;happen;ready;come;dovetail;goign

Filtered results
***************
RANKED	go.v 967	start 0.08486	move 0.07320	run 0.07161	running 0.07075	proceed 0.07061	travel 0.06942	work 0.06866	try 0.06770	aim 0.06645	take 0.06585	attempt 0.06561	approach 0.06478	walk 0.06309	pass 0.06306	free 0.06271	release 0.06241	reach 0.06175	rest 0.06140	leave 0.06108	operate 0.06059	relax 0.06007	attack 0.05890	undertake 0.05815	journey 0.05754	loose 0.05720	endure 0.05697	be 0.05135

Test context:
***************
go.v	968	20	when carving up the pie , to say , maybe we should leave some dollars out there , because in __going__ for the last dollar , it does n't look right .
Contexts for target going are: ['pcompI_in', 'prep:for_dollar']
Contexts in vocabulary for target going are: ['pcompI_in', 'prep:for_dollar']
Top most similar embeddings: going 0.21322	getting 0.18245	recouping 0.17853	skimping 0.17849	plumping 0.17797	capitulating 0.17751	paying 0.17711	pushing 0.17660	doing 0.17623	whetting 0.17518

Generated lemmatized results
***************
GENERATED	go.v 968 ::: get;recoup;skimp;plump;capitulate;pay;push;do;whet;depreciate

Filtered results
***************
RANKED	go.v 968	reach 0.16924	work 0.16906	try 0.16706	run 0.15887	journey 0.15784	take 0.15759	move 0.15643	attempt 0.15623	running 0.15598	aim 0.15404	release 0.14848	approach 0.14821	proceed 0.14732	attack 0.14729	start 0.14712	loose 0.14690	free 0.14660	travel 0.14546	pass 0.14160	walk 0.14099	leave 0.14056	rest 0.13507	undertake 0.13282	endure 0.13031	operate 0.12702	relax 0.12429	be 0.12303

Test context:
***************
go.v	969	2	newbies sometimes __go__ at their new workout programs like veteran exercisers .
Contexts for target go are: ['nsubj_newbies', 'advmod_sometimes', 'rootI_*root*', 'prep:at_programs', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target go are: ['nsubj_newbies', 'advmod_sometimes', 'rootI_*root*', 'prep:at_programs', 'punct_.']
Top most similar embeddings: go 0.02272	look 0.02143	balk 0.01893	scoff 0.01888	salivate 0.01888	sneered 0.01869	marveled 0.01867	sniggered 0.01860	looked 0.01848	feel 0.01842

Generated lemmatized results
***************
GENERATED	go.v 969 ::: look;balk;scoff;salivate;sneer;marvel;snigger;feel;cringe;appear

Filtered results
***************
RANKED	go.v 969	try 0.01787	take 0.01554	start 0.01533	aim 0.01519	run 0.01503	relax 0.01466	proceed 0.01417	work 0.01407	walk 0.01397	move 0.01379	operate 0.01371	attempt 0.01369	travel 0.01357	leave 0.01356	be 0.01348	reach 0.01323	approach 0.01289	journey 0.01289	free 0.01289	attack 0.01286	pass 0.01277	release 0.01271	undertake 0.01270	rest 0.01261	endure 0.01255	loose 0.01234	running 0.01204

Test context:
***************
go.v	970	13	it woke him up in the mornings and would hardly let his brain __go__ at night .
Contexts for target go are: ['nsubj_brain', 'ccompI_let', 'prep:at_night']
Contexts in vocabulary for target go are: ['nsubj_brain', 'ccompI_let', 'prep:at_night']
Top most similar embeddings: go 0.12535	ruminate 0.09107	wander 0.09038	pulsate 0.08996	salivate 0.08917	dehydrate 0.08793	meditate 0.08752	snuggle 0.08694	shrivel 0.08674	mope 0.08668

Generated lemmatized results
***************
GENERATED	go.v 970 ::: ruminate;wander;pulsate;salivate;dehydrate;meditate;snuggle;shrivel;mope;hallucinate

Filtered results
***************
RANKED	go.v 970	take 0.07780	relax 0.07541	endure 0.07317	try 0.07284	walk 0.07272	proceed 0.07224	move 0.07224	operate 0.07222	start 0.07062	run 0.06904	leave 0.06902	loose 0.06873	rest 0.06707	pass 0.06630	travel 0.06591	reach 0.06453	attack 0.06396	work 0.06216	free 0.06206	journey 0.06167	running 0.05862	release 0.05797	approach 0.05716	attempt 0.05655	be 0.05640	aim 0.05444	undertake 0.05391

Test context:
***************
let.v	971	21	now we would n't have been blamed for taking a day off after our great lochaber traverse but we could n't __let__ the other pair off that easily .
Contexts for target let are: ['nsubj_we', 'aux_could', "neg_n't", 'conjI_blamed', 'dobj_pair', 'prep:off_that']
Contexts in vocabulary for target let are: ['nsubj_we', 'aux_could', "neg_n't", 'conjI_blamed', 'dobj_pair', 'prep:off_that']
Top most similar embeddings: let 0.01163	fobbed 0.00990	begrudge 0.00972	nicked 0.00952	catched 0.00943	conned 0.00901	outplay 0.00900	steamrollered 0.00900	suckered 0.00885	flog 0.00881

Generated lemmatized results
***************
GENERATED	let.v 971 ::: fob;begrudge;nick;catch;con;outplay;steamroller;suckered;flog;fool

Filtered results
***************
RANKED	let.v 971	slacken 0.00825	forgive 0.00814	tell 0.00752	rent 0.00722	hire 0.00721	give 0.00719	expel 0.00707	lessen 0.00691	release 0.00671	have 0.00659	diminish 0.00639	free 0.00626	allow 0.00587	advise 0.00576	lease 0.00539	authorise 0.00535	reduce 0.00526	inform 0.00523	permit 0.00502

Test context:
***************
let.v	972	12	anyone who is truly innovating , simply has a burning desire to __let__ his professional colleagues share his discoveries .
Contexts for target let are: ['aux_to', 'infmodI_desire', 'ccomp_share']
Contexts in vocabulary for target let are: ['aux_to', 'infmodI_desire', 'ccomp_share']
Top most similar embeddings: let 0.12861	ensure 0.09318	propitiate 0.09317	re-assure 0.08958	enfranchise 0.08924	civilize 0.08882	mollify 0.08845	gainsay 0.08803	relearn 0.08799	extirpate 0.08756

Generated lemmatized results
***************
GENERATED	let.v 972 ::: ensure;propitiate;enfranchise;civilize;mollify;gainsay;relearn;extirpate;suceed;realize

Filtered results
***************
RANKED	let.v 972	tell 0.07974	expel 0.07949	forgive 0.07894	lessen 0.07879	give 0.07743	allow 0.07563	reduce 0.07495	inform 0.07350	diminish 0.07040	have 0.06831	rent 0.06753	slacken 0.06734	advise 0.06682	permit 0.06524	free 0.06496	hire 0.06339	authorise 0.06208	lease 0.05988	release 0.05775

Test context:
***************
let.v	973	7	learning of the bailiff 's plans to __let__ the scienos search my files i filed a protest .
Contexts for target let are: ['aux_to', 'infmodI_plans', 'dobj_search']
Contexts in vocabulary for target let are: ['aux_to', 'infmodI_plans', 'dobj_search']
Top most similar embeddings: let 0.10832	widen 0.09779	televise 0.09631	re-do 0.09509	refine 0.09391	re-activate 0.09318	sanitise 0.09313	broaden 0.09299	computerise 0.09287	democratize 0.09287

Generated lemmatized results
***************
GENERATED	let.v 973 ::: widen;televise;refine;sanitise;broaden;computerise;democratize;deregulate;revalue;reorganize

Filtered results
***************
RANKED	let.v 973	allow 0.08902	reduce 0.08278	slacken 0.08252	give 0.08191	expel 0.08045	lessen 0.07857	inform 0.07658	authorise 0.07500	permit 0.07349	diminish 0.07244	forgive 0.07196	rent 0.07064	tell 0.06959	hire 0.06784	release 0.06483	advise 0.06364	have 0.06326	lease 0.06114	free 0.05820

Test context:
***************
let.v	974	16	whether it is helping them with a memo verifying their employment for a mortgage company or __letting__ them use a company truck to move from one apartment to another , i always extend a hand .
Contexts for target letting are: ['conjI_verifying', 'ccomp_use']
Contexts in vocabulary for target letting are: ['conjI_verifying', 'ccomp_use']
Top most similar embeddings: letting 0.24384	double-checking 0.17102	stipulating 0.17085	ensuring 0.16725	suggesting 0.16503	mandating 0.16456	acknowledging 0.16342	publicizing 0.16230	deactivating 0.16219	explaining 0.16214

Generated lemmatized results
***************
GENERATED	let.v 974 ::: stipulate;ensure;suggest;mandate;acknowledge;publicize;deactivate;explain;certify;verify

Filtered results
***************
RANKED	let.v 974	authorise 0.15805	allow 0.15260	advise 0.14930	permit 0.14773	inform 0.14437	hire 0.14248	reduce 0.13920	tell 0.13891	rent 0.13783	expel 0.13779	have 0.13769	release 0.13442	lessen 0.13364	give 0.13357	lease 0.13224	free 0.13125	diminish 0.12939	slacken 0.11866	forgive 0.11288

Test context:
***************
let.v	975	8	if you have a property to sell or __let__ for holidays in uk , spain , balearics islands , france , greece , italy , turkey , america , new zealand... indeed anywhere in the world email the webmaster david@antibes.co.uk do not send .zip attachments .
Contexts for target let are: ['conjI_sell']
Contexts in vocabulary for target let are: ['conjI_sell']
Top most similar embeddings: let 0.51688	letting 0.38615	re-sell 0.36975	lets 0.35412	sell 0.35410	sublicense 0.34917	sublet 0.34761	repackage 0.34458	give 0.34417	cannibalise 0.34365

Generated lemmatized results
***************
GENERATED	let.v 975 ::: sell;sublicense;sublet;repackage;give;cannibalise;rent;resell;revalue;expropriate

Filtered results
***************
RANKED	let.v 975	give 0.34417	rent 0.34183	allow 0.32044	tell 0.31597	hire 0.31192	lease 0.30893	advise 0.30175	forgive 0.29942	reduce 0.29905	slacken 0.29804	lessen 0.29768	have 0.29694	expel 0.29482	inform 0.29297	permit 0.28820	diminish 0.28412	release 0.27888	authorise 0.27468	free 0.27435

Test context:
***************
let.v	976	10	epa 's own assessments showed that because the agency would __let__ power companies buy and sell the right to spew out mercury , high levels of mercury pollution would continue for at least two more decades .
Contexts for target let are: ['mark_because', 'nsubj_agency', 'aux_would', 'depI_that', 'ccomp_buy', 'cc_and', 'conj_sell', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target let are: ['mark_because', 'nsubj_agency', 'aux_would', 'depI_that', 'ccomp_buy', 'cc_and', 'conj_sell', 'punct_.']
Top most similar embeddings: let 0.00271	letting 0.00200	lets 0.00195	dare 0.00193	scoff 0.00192	avow 0.00190	bluffing 0.00189	cheaper 0.00189	sell 0.00187	insist 0.00187

Generated lemmatized results
***************
GENERATED	let.v 976 ::: dare;scoff;avow;bluff;cheaper;sell;insist;overcharge;suck;buy

Filtered results
***************
RANKED	let.v 976	advise 0.00163	rent 0.00163	hire 0.00156	permit 0.00155	diminish 0.00153	tell 0.00153	lessen 0.00151	lease 0.00150	slacken 0.00148	forgive 0.00147	give 0.00146	inform 0.00144	authorise 0.00144	expel 0.00142	allow 0.00140	reduce 0.00140	release 0.00139	free 0.00127	have 0.00125

Test context:
***************
let.v	977	17	the as-of-yet-unnamed team orange was ahead 15 to 5 at halftime , and we really didn 't __let__ up the pressure in the second half .
Contexts for target let are: ['nsubj_t', 'conjI_orange', 'prt_up', 'dobj_pressure']
Contexts in vocabulary for target let are: ['nsubj_t', 'conjI_orange', 'prt_up', 'dobj_pressure']
Top most similar embeddings: let 0.04551	soak 0.03791	lighten 0.03749	lets 0.03612	letting 0.03605	heaping 0.03497	suck 0.03486	clears 0.03441	soften 0.03416	thicken 0.03400

Generated lemmatized results
***************
GENERATED	let.v 977 ::: soak;lighten;heap;suck;clear;soften;thicken;step;dampen;add

Filtered results
***************
RANKED	let.v 977	slacken 0.03175	reduce 0.03081	free 0.03050	give 0.02989	lessen 0.02910	release 0.02851	allow 0.02817	expel 0.02799	tell 0.02749	diminish 0.02696	have 0.02664	advise 0.02570	permit 0.02561	rent 0.02535	hire 0.02491	forgive 0.02487	lease 0.02436	inform 0.02256	authorise 0.02251

Test context:
***************
let.v	978	9	anyone who sees that they have been winked at __lets__ out a blood-curdling scream and dies .
Contexts for target lets are: ['prep:atI_winked', 'prt_out', 'dobj_scream', 'cc_and', 'conj_dies']
Contexts in vocabulary for target lets are: ['prep:atI_winked', 'prt_out', 'dobj_scream', 'cc_and', 'conj_dies']
Top most similar embeddings: lets 0.02200	shrieks 0.01753	belches 0.01749	blurts 0.01733	plucks 0.01723	spits 0.01723	teases 0.01709	rips 0.01703	fluffs 0.01673	drowns 0.01668

Generated lemmatized results
***************
GENERATED	let.v 978 ::: shriek;belch;blurt;pluck;spit;tease;rip;fluff;drown;straighten

Filtered results
***************
RANKED	let.v 978	expel 0.01537	forgive 0.01418	hire 0.01308	rent 0.01286	free 0.01206	release 0.01153	have 0.01146	lessen 0.01146	slacken 0.01141	lease 0.01125	give 0.01107	diminish 0.01105	reduce 0.01040	tell 0.00978	permit 0.00973	advise 0.00958	inform 0.00949	authorise 0.00943	allow 0.00924

Test context:
***************
let.v	979	15	i am still here ( from 1999 ) , still on oxygen 24/7 and still __letting__ people know that this is the best heart site on the web .
Contexts for target letting are: ['advmod_still', 'conjI_on', 'ccomp_know']
Contexts in vocabulary for target letting are: ['advmod_still', 'conjI_on', 'ccomp_know']
Top most similar embeddings: letting 0.12574	let 0.09174	lets 0.08107	admitting 0.07789	pretending 0.07740	insisting 0.07728	fancying 0.07464	dont 0.07442	figuring 0.07393	fearing 0.07326

Generated lemmatized results
***************
GENERATED	let.v 979 ::: admit;pretend;insist;fancy;dont;figure;fear;regret;pee;ignore

Filtered results
***************
RANKED	let.v 979	rent 0.07175	permit 0.06658	allow 0.06650	have 0.06565	release 0.06289	tell 0.06145	hire 0.06085	expel 0.05972	forgive 0.05963	give 0.05882	free 0.05845	inform 0.05820	authorise 0.05748	diminish 0.05744	advise 0.05724	slacken 0.05711	lessen 0.05612	lease 0.05598	reduce 0.05239

Test context:
***************
let.v	980	6	he leaned his head back and __let__ out an almost inhumane cry .
Contexts for target let are: ['conjI_leaned', 'prt_out', 'dobj_cry']
Contexts in vocabulary for target let are: ['conjI_leaned', 'prt_out', 'dobj_cry']
Top most similar embeddings: let 0.12339	blurted 0.09812	hissed 0.09764	bawled 0.09395	belched 0.09379	bellowed 0.09356	spurted 0.09310	rasped 0.09261	panted 0.09203	shouted 0.09169

Generated lemmatized results
***************
GENERATED	let.v 980 ::: blurt;hiss;bawl;belch;bellow;spurt;rasp;pant;shout;wring

Filtered results
***************
RANKED	let.v 980	give 0.07821	forgive 0.06721	slacken 0.06634	allow 0.06535	release 0.06375	rent 0.06311	tell 0.06269	hire 0.06069	permit 0.05998	lease 0.05909	free 0.05882	have 0.05869	expel 0.05850	lessen 0.05491	diminish 0.05346	inform 0.05208	reduce 0.04936	advise 0.04913	authorise 0.04649

Test context:
***************
liberal.a	981	3	according to this __liberal__ approach , capital is a source of powe r that should be used by capitalists , just as political power should be used by politicians , for the benefit of society .
Contexts for target liberal are: ['amodI_approach']
Contexts in vocabulary for target liberal are: ['amodI_approach']
Top most similar embeddings: liberal 0.51469	conservative 0.44047	gradualist 0.43414	localist 0.43300	softly-softly 0.43095	vygotskian 0.41792	rights-based 0.41485	socialistic 0.41416	multiculturalist 0.41296	non-interventionist 0.41282

Generated lemmatized results
***************
GENERATED	liberal.a 981 ::: conservative;gradualist;localist;vygotskian;socialistic;multiculturalist;inclusionary;economistic;rationalistic;communitarian

Filtered results
***************
RANKED	liberal.a 981	progressive 0.36411	lenient 0.34960	tolerant 0.34165	generous 0.33919	humanitarian 0.32154	free 0.32094	social 0.31401	open 0.29126	liberated 0.28190	abundant 0.25968	ample 0.25379	plentiful 0.24853

Test context:
***************
liberal.a	982	5	i have heard educated , __liberal__ women talking about how long to wait before calling a man back , or whether the date should be in her neighbourh ood , or how long to wait until sleeping with him , as if there is some secret formula , some mathematical principle to romantic happiness that she has yet to divine .
Contexts for target liberal are: ['amodI_women']
Contexts in vocabulary for target liberal are: ['amodI_women']
Top most similar embeddings: liberal 0.49977	freedom-loving 0.42798	conservative 0.41549	peace-loving 0.41082	lower-class 0.40833	liberal-minded 0.40667	ultra-orthodox 0.40573	pre-menopausal 0.40419	ultra-conservative 0.40227	mexican-american 0.39967

Generated lemmatized results
***************
GENERATED	liberal.a 982 ::: conservative;middleclass;monied;marriageable;premenopausal;rightwing;libidinous;socialistic;multiparous;malawian

Filtered results
***************
RANKED	liberal.a 982	progressive 0.33946	free 0.32562	generous 0.32475	tolerant 0.32269	liberated 0.31315	lenient 0.30320	social 0.29336	humanitarian 0.29325	abundant 0.27013	ample 0.26126	open 0.25971	plentiful 0.25365

Test context:
***************
liberal.a	983	4	the show was a __liberal__ smattering of silly voices , awful puns , and mildly smutty humour , and was totally anarchic , with the audience controlling most of the show in later series .
Contexts for target liberal are: ['amodI_smattering']
Contexts in vocabulary for target liberal are: ['amodI_smattering']
Top most similar embeddings: liberal 0.53264	conservative 0.40353	libertarian 0.36779	egalitarian 0.35978	generous 0.35636	pro-european 0.35477	rightwing 0.35424	populist 0.35330	middle-of-the-road 0.35305	left-wing 0.35056

Generated lemmatized results
***************
GENERATED	liberal.a 983 ::: conservative;libertarian;egalitarian;generous;rightwing;populist;democrat;socialistic;decent;socialist

Filtered results
***************
RANKED	liberal.a 983	generous 0.35636	progressive 0.32545	tolerant 0.31884	lenient 0.31689	free 0.29155	plentiful 0.28957	ample 0.28916	humanitarian 0.28030	abundant 0.27745	social 0.27324	open 0.25354	liberated 0.24019

Test context:
***************
liberal.a	984	10	she is a product of a tremendously unorthodox family with __liberal__ views toward sex , marriage , religion and child-rearing .
Contexts for target liberal are: ['amodI_views']
Contexts in vocabulary for target liberal are: ['amodI_views']
Top most similar embeddings: liberal 0.51753	conservative 0.42738	ultra-conservative 0.41315	pro-nuclear 0.40709	libertarian 0.40600	pro-israeli 0.40567	metaethical 0.40426	fallibilist 0.40348	non-theistic 0.40218	regionalist 0.40082

Generated lemmatized results
***************
GENERATED	liberal.a 984 ::: conservative;libertarian;metaethical;fallibilist;regionalist;nativist;neoconservative;socialistic;leftish;localist

Filtered results
***************
RANKED	liberal.a 984	progressive 0.35268	generous 0.33212	tolerant 0.33186	lenient 0.32293	free 0.31587	humanitarian 0.30556	social 0.30464	open 0.29123	ample 0.28056	liberated 0.27918	abundant 0.27804	plentiful 0.27598

Test context:
***************
liberal.a	985	12	a guide for the scientific novice - concepts are clearly explained with __liberal__ use of careful definitions and analogy .
Contexts for target liberal are: ['amodI_use']
Contexts in vocabulary for target liberal are: ['amodI_use']
Top most similar embeddings: liberal 0.51631	conservative 0.40375	near-universal 0.38212	immoderate 0.37818	injudicious 0.37559	widescale 0.37371	noncommercial 0.37201	non-literal 0.36908	communistic 0.36836	novelistic 0.36574

Generated lemmatized results
***************
GENERATED	liberal.a 985 ::: conservative;immoderate;injudicious;widescale;noncommercial;communistic;novelistic;propagandistic;socialistic;liberatory

Filtered results
***************
RANKED	liberal.a 985	generous 0.34270	progressive 0.34079	free 0.32028	tolerant 0.32017	humanitarian 0.31855	lenient 0.31696	social 0.30928	plentiful 0.29449	abundant 0.29390	ample 0.28998	open 0.26971	liberated 0.26938

Test context:
***************
liberal.a	986	4	municipal housing schemes with __liberal__ aid from the central government will be encouraged for those who do not wish to establish their own houses .
Contexts for target liberal are: ['amodI_aid']
Contexts in vocabulary for target liberal are: ['amodI_aid']
Top most similar embeddings: liberal 0.47272	conservative 0.38915	social-democratic 0.36981	socialist 0.36729	christian 0.36686	socialistic 0.36639	non-labour 0.36551	pre-accession 0.36464	pro-european 0.36267	namby-pamby 0.36232

Generated lemmatized results
***************
GENERATED	liberal.a 986 ::: conservative;socialist;christian;socialistic;neoconservative;redistributive;localist;reformist;rabbinical;jeffersonian

Filtered results
***************
RANKED	liberal.a 986	humanitarian 0.35132	generous 0.34682	progressive 0.32715	free 0.32089	tolerant 0.30933	social 0.30888	lenient 0.29945	abundant 0.28176	ample 0.27937	liberated 0.27730	plentiful 0.27608	open 0.25716

Test context:
***************
liberal.a	987	22	we 're both in our early thirties , both grew up in the suburbs of east coast us cities , raised by __liberal__ parents who pushed us towards soccer , the progressive , globalized , nonviolent sport of choice for seventies and eighties us parents .
Contexts for target liberal are: ['amodI_parents']
Contexts in vocabulary for target liberal are: ['amodI_parents']
Top most similar embeddings: liberal 0.50732	conservative 0.41974	stay-at-home 0.40354	liberal-minded 0.40210	freedom-loving 0.39998	peace-loving 0.39607	middleclass 0.39487	ultra-conservative 0.39366	self-professed 0.39183	public-school 0.38891

Generated lemmatized results
***************
GENERATED	liberal.a 987 ::: conservative;middleclass;puritanical;libidinous;socialist;puritan;malawian;rightwing;youngish;cretinous

Filtered results
***************
RANKED	liberal.a 987	progressive 0.33622	generous 0.33512	tolerant 0.33427	lenient 0.32232	social 0.30021	liberated 0.29272	free 0.29251	humanitarian 0.29134	abundant 0.26768	plentiful 0.25817	ample 0.25799	open 0.24948

Test context:
***************
liberal.a	988	9	patients should limit exposure to the sun and use __liberal__ amounts of sunscreen .
Contexts for target liberal are: ['amodI_amounts']
Contexts in vocabulary for target liberal are: ['amodI_amounts']
Top most similar embeddings: liberal 0.50794	conservative 0.39357	ever-decreasing 0.36926	ever-greater 0.36388	ever-larger 0.36185	much-reduced 0.36018	four-figure 0.35908	democrat 0.35762	non-labour 0.35578	thatcherite 0.35358

Generated lemmatized results
***************
GENERATED	liberal.a 988 ::: conservative;democrat;thatcherite;inordinate;stalinist;generous;moderate;immoderate;miserly;copious

Filtered results
***************
RANKED	liberal.a 988	generous 0.35017	progressive 0.32831	lenient 0.30834	abundant 0.29816	tolerant 0.29735	ample 0.29542	plentiful 0.29433	humanitarian 0.29366	social 0.28044	free 0.27266	liberated 0.27185	open 0.24988

Test context:
***************
liberal.a	989	19	the potatoes were remarkable ... they did n't look like much , but were cooked with herbs and a __liberal__ sprinkling of pepper that made me wish for more after my plate had been cleaned .
Contexts for target liberal are: ['amodI_sprinkling']
Contexts in vocabulary for target liberal are: ['amodI_sprinkling']
Top most similar embeddings: liberal 0.55446	conservative 0.41579	democrat 0.36916	generous 0.36756	libertarian 0.36733	egalitarian 0.36057	rightwing 0.36026	socialistic 0.35892	pro-european 0.35689	socialist 0.35487

Generated lemmatized results
***************
GENERATED	liberal.a 989 ::: conservative;democrat;generous;libertarian;egalitarian;rightwing;socialistic;socialist;centrist;neoconservative

Filtered results
***************
RANKED	liberal.a 989	generous 0.36756	progressive 0.32791	tolerant 0.31473	lenient 0.31451	free 0.30032	plentiful 0.28764	abundant 0.28144	humanitarian 0.28136	ample 0.28057	social 0.27689	open 0.25232	liberated 0.24105

Test context:
***************
liberal.a	990	4	this decision , by __liberal__ judges no less , is so blatantly at odds with the intention of private ownership and the constitution that it makes me , a lifelong democrat , extremely suspicious of what is going on in that court .
Contexts for target liberal are: ['amodI_judges']
Contexts in vocabulary for target liberal are: ['amodI_judges']
Top most similar embeddings: liberal 0.52030	conservative 0.42225	hard-line 0.40385	ultra-conservative 0.40032	pro-israeli 0.39099	left-leaning 0.39060	rabbinical 0.38922	non-labour 0.38711	self-professed 0.38676	rightwing 0.38549

Generated lemmatized results
***************
GENERATED	liberal.a 990 ::: conservative;rabbinical;rightwing;neoconservative;senatorial;stalinist;secularist;oligarchic;whig;hawkish

Filtered results
***************
RANKED	liberal.a 990	progressive 0.34022	lenient 0.33966	generous 0.32654	free 0.32235	tolerant 0.31965	humanitarian 0.31651	social 0.29574	liberated 0.28133	ample 0.27106	abundant 0.26277	open 0.26145	plentiful 0.26039

Test context:
***************
light.a	991	5	classical the musicians usually play __light__ classical background music .
Contexts for target light are: ['amodI_music']
Contexts in vocabulary for target light are: ['amodI_music']
Top most similar embeddings: light 0.50646	guitar-based 0.39601	acousmatic 0.39182	easy-listening 0.38908	unamplified 0.38080	new-wave 0.37777	foot-tapping 0.37601	guitar-driven 0.37493	spoken-word 0.37424	dubby 0.37379

Generated lemmatized results
***************
GENERATED	light.a 991 ::: acousmatic;unamplified;dubby;traditonal;cantorial;podsafe;twangy;tradtional;electroclash;gloopy

Filtered results
***************
RANKED	light.a 991	pale 0.33828	frothy 0.33249	luminous 0.32922	soft 0.32416	faint 0.32180	gentle 0.32119	bright 0.32062	ethereal 0.32034	cheerful 0.31518	upbeat 0.31424	undemanding 0.31131	lightweight 0.30573	slight 0.29979	mild 0.29640	simple 0.29482	portable 0.29414	casual 0.29121	fair 0.28084	small 0.27843	entertaining 0.27575	minor 0.27561	easy 0.27414	facile 0.27329	trivial 0.27312	inconsiderable 0.25537	restricted 0.25525

Test context:
***************
light.a	992	6	vivianna saw that her eyes were __light__ blue and kind .
Contexts for target light are: ['amodI_blue']
Contexts in vocabulary for target light are: ['amodI_blue']
Top most similar embeddings: light 0.52982	palest 0.40651	darkish 0.40064	blue-white 0.39814	flourescent 0.39353	grey-blue 0.38901	florescent 0.38537	light-coloured 0.38429	coppery 0.38302	red-orange 0.38269

Generated lemmatized results
***************
GENERATED	light.a 992 ::: pale;darkish;flourescent;florescent;coppery;pearlescent;bluish;grayish;filmy;purplish

Filtered results
***************
RANKED	light.a 992	pale 0.40651	bright 0.36358	luminous 0.35576	faint 0.34092	frothy 0.34002	gentle 0.33133	soft 0.32917	ethereal 0.32311	lightweight 0.31358	slight 0.31164	cheerful 0.31134	mild 0.29952	small 0.29658	simple 0.29032	undemanding 0.28623	fair 0.28521	upbeat 0.28301	trivial 0.28245	casual 0.28243	easy 0.27238	portable 0.26861	minor 0.26679	facile 0.25991	inconsiderable 0.25380	entertaining 0.25047	restricted 0.24447

Test context:
***************
light.a	993	2	it is __light__ and easy to use .
Contexts for target light are: ['nsubj_it', 'cop_is', 'rootI_*root*', 'cc_and', 'conj_easy', 'xcomp_use', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target light are: ['nsubj_it', 'cop_is', 'rootI_*root*', 'cc_and', 'conj_easy', 'xcomp_use', 'punct_.']
Top most similar embeddings: straighforward 0.00630	straightforward 0.00626	simple 0.00617	recommendable 0.00617	manoeuvrable 0.00607	easy 0.00606	non-greasy 0.00589	hygenic 0.00587	odorless 0.00580	handier 0.00577

Generated lemmatized results
***************
GENERATED	light.a 993 ::: straighforward;straightforward;simple;recommendable;manoeuvrable;easy;hygenic;odorless;handy;convienient

Filtered results
***************
RANKED	light.a 993	simple 0.00617	easy 0.00606	lightweight 0.00547	undemanding 0.00501	facile 0.00462	trivial 0.00461	soft 0.00440	bright 0.00433	portable 0.00418	upbeat 0.00410	pale 0.00397	entertaining 0.00394	cheerful 0.00387	gentle 0.00380	mild 0.00380	faint 0.00380	fair 0.00379	luminous 0.00362	restricted 0.00360	casual 0.00336	slight 0.00334	small 0.00330	frothy 0.00309	inconsiderable 0.00267	ethereal 0.00265	minor 0.00236

Test context:
***************
light.a	994	33	( even in my condition , if i do n't feed bubby , she does n't get fed. ) in the brief moment before my coughing fit started , the temperature and the __light__ breeze made me stop and take it in .
Contexts for target light are: ['amodI_breeze']
Contexts in vocabulary for target light are: ['amodI_breeze']
Top most similar embeddings: light 0.53198	northwesterly 0.38694	n'ly 0.37708	north-easterly 0.37401	southwesterly 0.37381	south-easterly 0.37368	northeasterly 0.37045	wintery 0.36947	gale-force 0.36937	e'ly 0.36677

Generated lemmatized results
***************
GENERATED	light.a 994 ::: northwesterly;southwesterly;northeasterly;wintery;wintry;blustery;gusty;balmy;muggy;unseasonal

Filtered results
***************
RANKED	light.a 994	faint 0.34177	slight 0.34137	gentle 0.34036	frothy 0.33891	pale 0.33719	luminous 0.33103	bright 0.32275	mild 0.32067	lightweight 0.31896	soft 0.31748	cheerful 0.30718	ethereal 0.30065	undemanding 0.29872	casual 0.29526	fair 0.28469	upbeat 0.28390	simple 0.28150	small 0.28130	easy 0.27125	trivial 0.26728	facile 0.26724	minor 0.26607	inconsiderable 0.26477	portable 0.26304	entertaining 0.25354	restricted 0.23127

Test context:
***************
light.a	995	14	researchers are taking a closer look at the more subtle effects of moderate and __light__ drinking during pregnancy .
Contexts for target light are: ['conjI_moderate']
Contexts in vocabulary for target light are: ['conjI_moderate']
Top most similar embeddings: light 0.47791	moderate 0.37722	heavy 0.35540	equable 0.34444	high-intensity 0.34283	wintry 0.34174	healthful 0.34168	mild 0.33964	low-energy 0.33610	diffuse 0.33387

Generated lemmatized results
***************
GENERATED	light.a 995 ::: moderate;heavy;equable;wintry;healthful;mild;diffuse;sunlight;severe;southwesterly

Filtered results
***************
RANKED	light.a 995	mild 0.33964	slight 0.31801	gentle 0.31707	frothy 0.31293	faint 0.30763	bright 0.30654	undemanding 0.30560	pale 0.30074	soft 0.29865	lightweight 0.29863	cheerful 0.29041	luminous 0.29026	trivial 0.28951	simple 0.28866	minor 0.28840	small 0.27991	fair 0.27829	casual 0.27614	easy 0.27506	upbeat 0.27232	portable 0.26912	ethereal 0.26531	restricted 0.26270	facile 0.26232	inconsiderable 0.26230	entertaining 0.25948

Test context:
***************
light.a	996	4	forget shock art and __light__ impressionist fluff .
Contexts for target light are: ['amodI_fluff']
Contexts in vocabulary for target light are: ['amodI_fluff']
Top most similar embeddings: light 0.46545	gloopy 0.37334	light-coloured 0.37169	darkish 0.36897	filmy 0.36469	wispy 0.36392	palest 0.36232	frothy 0.36149	flourescent 0.36124	all-over 0.36059

Generated lemmatized results
***************
GENERATED	light.a 996 ::: gloopy;darkish;filmy;wispy;pale;frothy;flourescent;yellowy;metalic;vaporous

Filtered results
***************
RANKED	light.a 996	pale 0.36232	frothy 0.36149	luminous 0.34671	lightweight 0.32899	soft 0.32472	gentle 0.31938	faint 0.31511	bright 0.31490	slight 0.31301	ethereal 0.31222	undemanding 0.30539	mild 0.30314	cheerful 0.30061	casual 0.28666	trivial 0.28642	facile 0.28155	simple 0.27358	upbeat 0.27263	entertaining 0.27093	small 0.26972	minor 0.26893	portable 0.26461	fair 0.26400	inconsiderable 0.25379	easy 0.24539	restricted 0.22526

Test context:
***************
light.a	997	28	to depict a simple object such as a cube , only a few tonal values might be necessary : the side which receives the most light being the __lightest__ , the side furthest from the light source ( the darkest ) , and one or two middle gray tones for the sides which receive an in-between or indirect amount of light .
Contexts for target lightest are: ['cop_being', 'det_the', 'depI_light']
Contexts in vocabulary for target lightest are: ['cop_being', 'det_the', 'depI_light']
Top most similar embeddings: lightest 0.13434	thinnest 0.10190	heaviest 0.09750	stiffest 0.09653	whitest 0.09582	thickest 0.09477	quietest 0.09433	gentlest 0.09381	brightest 0.09374	palest 0.09267

Generated lemmatized results
***************
GENERATED	light.a 997 ::: thin;heavy;stiff;white;thick;quiet;gentle;bright;pale;noisy

Filtered results
***************
RANKED	light.a 997	gentle 0.09381	bright 0.09374	pale 0.09267	small 0.09084	soft 0.08992	mild 0.08912	faint 0.08736	easy 0.08713	simple 0.08224	fair 0.07938	luminous 0.07653	lightweight 0.07610	slight 0.07129	ethereal 0.06886	portable 0.06852	cheerful 0.06644	frothy 0.06618	undemanding 0.06501	trivial 0.06201	casual 0.06184	inconsiderable 0.06084	upbeat 0.05920	minor 0.05599	entertaining 0.05509	facile 0.05487	restricted 0.04877

Test context:
***************
light.a	998	3	on to a __lighter__ note now : i started trying to build a store recently .
Contexts for target lighter are: ['amodI_note']
Contexts in vocabulary for target lighter are: ['amodI_note']
Top most similar embeddings: lighter 0.53571	heavier 0.42020	darker 0.40406	post-meeting 0.40255	brighter 0.38941	onfirmed 0.38876	softer 0.38866	sadder 0.38342	sportier 0.38162	jazzier 0.37943

Generated lemmatized results
***************
GENERATED	light.a 998 ::: heavy;dark;bright;onfirmed;soft;sad;sporty;jazzy;meaty;poppier

Filtered results
***************
RANKED	light.a 998	bright 0.38941	soft 0.38866	gentle 0.36711	pale 0.35791	simple 0.35219	slight 0.34572	faint 0.34433	small 0.34389	lightweight 0.34106	mild 0.34048	upbeat 0.33810	frothy 0.32783	cheerful 0.32430	easy 0.31901	luminous 0.31734	portable 0.31594	ethereal 0.31068	casual 0.30921	undemanding 0.30628	trivial 0.29925	fair 0.29917	facile 0.29268	inconsiderable 0.29180	minor 0.28037	entertaining 0.27969	restricted 0.27582

Test context:
***************
light.a	999	8	his horse cocked an ear , blew a __light__ snort .
Contexts for target light are: ['amodI_snort']
Contexts in vocabulary for target light are: ['amodI_snort']
Top most similar embeddings: light 0.55938	well-aimed 0.47914	down-home 0.47686	darkish 0.47611	vaporous 0.47535	pitch-black 0.47502	doleful 0.47322	well-shaped 0.47109	drippy 0.47042	somnolent 0.46998

Generated lemmatized results
***************
GENERATED	light.a 999 ::: darkish;vaporous;doleful;drippy;somnolent;eery;clownish;funereal;coquettish;wispy

Filtered results
***************
RANKED	light.a 999	pale 0.43694	frothy 0.43532	luminous 0.40720	gentle 0.40565	faint 0.40249	bright 0.39884	cheerful 0.39689	slight 0.39377	soft 0.38768	undemanding 0.38570	lightweight 0.38337	mild 0.37987	upbeat 0.37598	ethereal 0.37490	simple 0.36959	facile 0.36528	casual 0.36035	trivial 0.35692	small 0.35052	entertaining 0.33892	portable 0.33647	fair 0.33470	inconsiderable 0.33338	easy 0.33105	minor 0.32666	restricted 0.30042

Test context:
***************
light.a	1000	3	it should feel __light__ and comfortable in your hand , and the grip should fit your palm well .
Contexts for target light are: ['dobjI_feel', 'cc_and', 'conj_comfortable']
Contexts in vocabulary for target light are: ['dobjI_feel', 'cc_and', 'conj_comfortable']
Top most similar embeddings: light 0.12304	lighter 0.09353	plasticky 0.09306	roomier 0.09211	tingly 0.09114	homely 0.08973	woozy 0.08964	warmth 0.08918	homey 0.08909	confortable 0.08888

Generated lemmatized results
***************
GENERATED	light.a 1000 ::: plasticky;roomy;tingly;homely;woozy;warmth;homey;confortable;comfy;unstuffy

Filtered results
***************
RANKED	light.a 1000	lightweight 0.08481	bright 0.08365	cheerful 0.08062	soft 0.08006	gentle 0.07837	casual 0.07462	luminous 0.07380	undemanding 0.07373	pale 0.07370	faint 0.07231	ethereal 0.07207	upbeat 0.07075	simple 0.07041	slight 0.06930	mild 0.06896	frothy 0.06859	fair 0.06562	easy 0.06446	facile 0.06419	small 0.06257	portable 0.06136	entertaining 0.06117	trivial 0.06003	inconsiderable 0.05149	minor 0.05149	restricted 0.05042

Test context:
***************
likewise.r	1001	20	1co 7:22 for he who was called in the lord while a slave , is the lord 's freedman ; __likewise__ he who was called while free , is christ 's slave .
Contexts for target likewise are: ['advmodI_slave']
Contexts in vocabulary for target likewise are: ['advmodI_slave']
Top most similar embeddings: likewise 0.51135	similarly 0.39892	moreover 0.38006	everlastingly 0.37631	therefore 0.37461	consequently 0.37278	furthermore 0.37197	however 0.37184	nevertheless 0.36922	unfortunately 0.36826

Generated lemmatized results
***************
GENERATED	likewise.r 1001 ::: similarly;moreover;everlastingly;therefore;consequently;furthermore;however;nevertheless;unfortunately;evidently

Filtered results
***************
RANKED	likewise.r 1001	similarly 0.39892	also 0.35827	additionally 0.35093	correspondingly 0.34438	equally 0.30817

Test context:
***************
likewise.r	1002	6	the minister and his wife were __likewise__ ill-treated , but they steadfastly refused to betray the hiding-place wherein they had disposed the valuable honours .
Contexts for target likewise are: ['advmodI_ill-treated']
Contexts in vocabulary for target likewise are: []
Top most similar embeddings: likewise 1.00000	similarly 0.77202	consequently 0.77044	moreover 0.76359	nevertheless 0.75601	furthermore 0.75488	therefore 0.75108	futhermore 0.74262	evidently 0.74048	however 0.74027

Generated lemmatized results
***************
GENERATED	likewise.r 1002 ::: similarly;consequently;moreover;nevertheless;furthermore;therefore;futhermore;evidently;however;presumably

Filtered results
***************
RANKED	likewise.r 1002	similarly 0.77202	additionally 0.73076	also 0.72790	correspondingly 0.72451	equally 0.65670

Test context:
***************
likewise.r	1003	3	the other could __likewise__ be a constellation of some type , an animal or a map .
Contexts for target likewise are: ['advmodI_constellation']
Contexts in vocabulary for target likewise are: []
Top most similar embeddings: likewise 1.00000	similarly 0.77202	consequently 0.77044	moreover 0.76359	nevertheless 0.75601	furthermore 0.75488	therefore 0.75108	futhermore 0.74262	evidently 0.74048	however 0.74027

Generated lemmatized results
***************
GENERATED	likewise.r 1003 ::: similarly;consequently;moreover;nevertheless;furthermore;therefore;futhermore;evidently;however;presumably

Filtered results
***************
RANKED	likewise.r 1003	similarly 0.77202	additionally 0.73076	also 0.72790	correspondingly 0.72451	equally 0.65670

Test context:
***************
likewise.r	1004	16	in this sense of the word , faith is the essential virtue of science , and __likewise__ of any religion that is not self-deception .
Contexts for target likewise are: ['conjI_virtue', 'prep:of_religion']
Contexts in vocabulary for target likewise are: ['conjI_virtue', 'prep:of_religion']
Top most similar embeddings: likewise 0.19769	nobleness 0.17804	detestation 0.17505	uprightness 0.17245	justness 0.17214	licentiousness 0.16984	sinlessness 0.16974	rectitude 0.16905	piety 0.16884	exclusivism 0.16825

Generated lemmatized results
***************
GENERATED	likewise.r 1004 ::: nobleness;detestation;uprightness;justness;licentiousness;sinlessness;rectitude;piety;exclusivism;nonexistence

Filtered results
***************
RANKED	likewise.r 1004	correspondingly 0.13849	similarly 0.13457	also 0.12635	equally 0.12297	additionally 0.12013

Test context:
***************
likewise.r	1005	6	maybe a journalist 's privilege should __likewise__ be limited .
Contexts for target likewise are: ['advmodI_limited']
Contexts in vocabulary for target likewise are: ['advmodI_limited']
Top most similar embeddings: likewise 0.50513	consequently 0.40708	moreover 0.40224	similarly 0.40019	however 0.39580	nevertheless 0.39578	furthermore 0.39564	therefore 0.39562	unfortunately 0.39404	correspondingly 0.39121

Generated lemmatized results
***************
GENERATED	likewise.r 1005 ::: consequently;moreover;similarly;however;nevertheless;furthermore;therefore;unfortunately;correspondingly;admittedly

Filtered results
***************
RANKED	likewise.r 1005	similarly 0.40019	correspondingly 0.39121	additionally 0.37817	also 0.36912	equally 0.33108

Test context:
***************
likewise.r	1006	4	the canal project would __likewise__ have a high impact , reversing these trends .
Contexts for target likewise are: ['advmodI_have']
Contexts in vocabulary for target likewise are: ['advmodI_have']
Top most similar embeddings: likewise 0.53505	futhermore 0.41772	consequently 0.41629	similarly 0.41527	moreover 0.41516	regretably 0.41200	furthermore 0.41058	therefore 0.40998	proably 0.40660	nevertheless 0.40535

Generated lemmatized results
***************
GENERATED	likewise.r 1006 ::: futhermore;consequently;similarly;moreover;regretably;furthermore;therefore;proably;nevertheless;additionally

Filtered results
***************
RANKED	likewise.r 1006	similarly 0.41527	additionally 0.40481	also 0.40158	correspondingly 0.37500	equally 0.33961

Test context:
***************
likewise.r	1007	10	the cost of providing easy to use access systems is __likewise__ a consideration .
Contexts for target likewise are: ['advmodI_consideration']
Contexts in vocabulary for target likewise are: ['advmodI_consideration']
Top most similar embeddings: likewise 0.52487	consequently 0.40515	moreover 0.40283	therefore 0.40219	nevertheless 0.40068	similarly 0.39966	furthermore 0.39153	however 0.39136	also 0.38800	evidently 0.38653

Generated lemmatized results
***************
GENERATED	likewise.r 1007 ::: consequently;moreover;therefore;nevertheless;similarly;furthermore;however;also;evidently;nonetheless

Filtered results
***************
RANKED	likewise.r 1007	similarly 0.39966	also 0.38800	additionally 0.37968	correspondingly 0.35954	equally 0.33147

Test context:
***************
likewise.r	1008	11	we are also reminding the member states that they should do __likewise__ .
Contexts for target likewise are: ['dobjI_do']
Contexts in vocabulary for target likewise are: ['dobjI_do']
Top most similar embeddings: likewise 0.52951	damnedest 0.36952	handstands 0.36083	ouro 0.35976	deede 0.35918	obeisance 0.35721	upmost 0.35682	whate'er 0.35456	reguarly 0.35228	barreiro 0.34991

Generated lemmatized results
***************
GENERATED	likewise.r 1008 ::: damnedest;handstands;ouro;deede;obeisance;upmost;reguarly;barreiro;carmo;similarly

Filtered results
***************
RANKED	likewise.r 1008	similarly 0.34899	correspondingly 0.32625	additionally 0.29667	equally 0.28283	also 0.28162

Test context:
***************
likewise.r	1009	3	collective penalties and __likewise__ all measures of intimidation or of terrorism are prohibited .
Contexts for target likewise are: ['nnI_measures']
Contexts in vocabulary for target likewise are: ['nnI_measures']
Top most similar embeddings: likewise 0.46761	consequently 0.35879	similarly 0.34611	correspondingly 0.34497	admittedly 0.34015	plumbosolvency 0.33976	presumably 0.33936	non-gaap 0.33813	moreover 0.33743	hrqol 0.33736

Generated lemmatized results
***************
GENERATED	likewise.r 1009 ::: consequently;similarly;correspondingly;admittedly;plumbosolvency;presumably;moreover;hrqol;nevertheless;evidently

Filtered results
***************
RANKED	likewise.r 1009	similarly 0.34611	correspondingly 0.34497	additionally 0.30834	equally 0.29554	also 0.28654

Test context:
***************
likewise.r	1010	22	there are many false beliefs about two-stroke oils and some say that cheap oils do not mix with the expensive stuff and __likewise__ with synthetic and mineral oils .
Contexts for target likewise are: ['conjI_mix', 'prep:with_oils']
Contexts in vocabulary for target likewise are: ['conjI_mix', 'prep:with_oils']
Top most similar embeddings: likewise 0.18938	blended 0.16715	cornflour 0.16603	flavored 0.16484	fragranced 0.16364	mingle 0.16237	knead 0.16165	moisten 0.16155	baste 0.16117	mingles 0.16098

Generated lemmatized results
***************
GENERATED	likewise.r 1010 ::: blended;cornflour;flavored;fragranced;mingle;knead;moisten;baste;mingles;unmixed

Filtered results
***************
RANKED	likewise.r 1010	similarly 0.14039	correspondingly 0.13508	additionally 0.13071	equally 0.12026	also 0.11324

Test context:
***************
now.r	1011	2	these children __now__ receive some education so the position is much more satisfactory than it had been in the past .
Contexts for target now are: ['advmodI_receive']
Contexts in vocabulary for target now are: ['advmodI_receive']
Top most similar embeddings: now 0.52166	then 0.41920	proably 0.41092	also 0.39924	still 0.39643	currently 0.39530	dually 0.39498	futhermore 0.39003	already 0.38918	apprently 0.38879

Generated lemmatized results
***************
GENERATED	now.r 1011 ::: then;proably;also;still;currently;dually;futhermore;already;apprently;unfortuantely

Filtered results
***************
RANKED	now.r 1011	currently 0.39530	nowadays 0.36264	perhaps 0.35793	immediately 0.35686	just 0.35381	so 0.34881	lately 0.34657	presently 0.34526	recently 0.34377	consequently 0.34020	instantly 0.32866	well 0.32861	since 0.30573	today 0.30457	next 0.29600

Test context:
***************
now.r	1012	0	__now__ while the second leg flies around you gently land on your first leg .
Contexts for target now are: ['advmodI_flies']
Contexts in vocabulary for target now are: ['advmodI_flies']
Top most similar embeddings: now 0.50910	then 0.40737	proably 0.38972	currently 0.38492	ocassionally 0.38139	already 0.38073	still 0.38073	bascially 0.38046	temptingly 0.37830	regally 0.37677

Generated lemmatized results
***************
GENERATED	now.r 1012 ::: then;proably;currently;ocassionally;already;still;bascially;temptingly;regally;moodily

Filtered results
***************
RANKED	now.r 1012	currently 0.38492	just 0.36385	presently 0.34693	lately 0.34596	perhaps 0.34247	recently 0.34217	nowadays 0.33968	immediately 0.33365	so 0.33210	well 0.33176	instantly 0.30802	consequently 0.30556	today 0.30485	since 0.30053	next 0.29748

Test context:
***************
now.r	1013	5	most states in the us __now__ base their local standards for teacher licensure on the intasc or praxis models .
Contexts for target now are: ['advmodI_base']
Contexts in vocabulary for target now are: ['advmodI_base']
Top most similar embeddings: now 0.51049	then 0.40209	proably 0.39551	here 0.39077	also 0.39071	dually 0.38779	currently 0.38610	apprently 0.38556	still 0.38548	defintely 0.38485

Generated lemmatized results
***************
GENERATED	now.r 1013 ::: then;proably;here;also;dually;currently;apprently;still;defintely;legislatively

Filtered results
***************
RANKED	now.r 1013	currently 0.38610	just 0.36764	perhaps 0.36465	nowadays 0.36165	recently 0.34981	so 0.34273	lately 0.34111	presently 0.33752	consequently 0.33595	immediately 0.33224	well 0.32674	since 0.31356	today 0.31254	instantly 0.29908	next 0.29608

Test context:
***************
now.r	1014	0	__now__ some hardcore ashtanga folk may criticize me for my attempt to discover if one can learn ashtanga vinyasa via books and videos and not via a teacher .
Contexts for target now are: ['advmodI_criticize']
Contexts in vocabulary for target now are: ['advmodI_criticize']
Top most similar embeddings: now 0.48859	then 0.39103	proably 0.37922	hypocritically 0.37820	often 0.37760	facetiously 0.37478	virtuously 0.37355	good-naturedly 0.37295	sometimes 0.37218	when 0.37183

Generated lemmatized results
***************
GENERATED	now.r 1014 ::: then;proably;hypocritically;often;facetiously;virtuously;sometimes;when;magnanimously;presumptuously

Filtered results
***************
RANKED	now.r 1014	perhaps 0.35015	currently 0.34563	just 0.33732	nowadays 0.33712	recently 0.32747	lately 0.32699	so 0.32645	presently 0.32418	immediately 0.32369	well 0.31518	consequently 0.30966	instantly 0.30437	today 0.29629	since 0.28399	next 0.26828

Test context:
***************
now.r	1015	3	the tax is __now__ being phased out .
Contexts for target now are: ['advmodI_phased']
Contexts in vocabulary for target now are: ['advmodI_phased']
Top most similar embeddings: now 0.52485	then 0.39412	legislatively 0.38798	eventually 0.38734	currently 0.38509	long-since 0.38187	proably 0.37960	soon 0.37773	finally 0.37713	already 0.37510

Generated lemmatized results
***************
GENERATED	now.r 1015 ::: then;legislatively;eventually;currently;proably;soon;finally;already;feasibly;however

Filtered results
***************
RANKED	now.r 1015	currently 0.38509	recently 0.35853	perhaps 0.35712	nowadays 0.34611	just 0.34134	presently 0.34131	immediately 0.34063	lately 0.33985	so 0.33718	consequently 0.32049	since 0.31108	well 0.30949	instantly 0.30658	today 0.30063	next 0.28080

Test context:
***************
now.r	1016	2	markets are __now__ faster and smarter than you are .
Contexts for target now are: ['advmodI_faster']
Contexts in vocabulary for target now are: ['advmodI_faster']
Top most similar embeddings: now 0.50056	slighly 0.39963	then 0.39231	even 0.39072	proably 0.38903	still 0.38208	probaly 0.38143	noticably 0.37911	acutally 0.37745	defintely 0.37706

Generated lemmatized results
***************
GENERATED	now.r 1016 ::: slighly;then;even;proably;still;probaly;noticably;acutally;defintely;probally

Filtered results
***************
RANKED	now.r 1016	perhaps 0.35404	currently 0.35264	nowadays 0.35262	just 0.35218	lately 0.33416	immediately 0.33240	recently 0.33129	so 0.32911	consequently 0.32323	presently 0.31862	well 0.31538	today 0.30443	instantly 0.30300	since 0.29877	next 0.28191

Test context:
***************
now.r	1017	4	continuing problems we are __now__ at a point in t 's education where he is required to give his written answers in complete sentences and to answer more abstract questions .
Contexts for target now are: ['advmodI_are']
Contexts in vocabulary for target now are: ['advmodI_are']
Top most similar embeddings: now 0.54427	proably 0.42020	then 0.41549	still 0.41513	here 0.41359	defintely 0.41111	currently 0.40947	apprently 0.40755	dually 0.40428	unfortuantely 0.40414

Generated lemmatized results
***************
GENERATED	now.r 1017 ::: proably;then;still;here;defintely;currently;apprently;dually;unfortuantely;also

Filtered results
***************
RANKED	now.r 1017	currently 0.40947	nowadays 0.37973	perhaps 0.37277	just 0.36627	so 0.35518	presently 0.35351	lately 0.34697	recently 0.34495	immediately 0.34016	well 0.33880	consequently 0.33858	today 0.33085	instantly 0.30325	next 0.30239	since 0.30093

Test context:
***************
now.r	1018	1	i __now__ have a better understanding of rivers and coasts in reall y quite beautiful locations , especially the sitges coast .
Contexts for target now are: ['advmodI_have']
Contexts in vocabulary for target now are: ['advmodI_have']
Top most similar embeddings: now 0.54967	proably 0.43320	then 0.42710	still 0.41671	apprently 0.41494	unfortuantely 0.41354	already 0.41263	defintely 0.41109	futhermore 0.40993	usally 0.40803

Generated lemmatized results
***************
GENERATED	now.r 1018 ::: proably;then;still;apprently;unfortuantely;already;defintely;futhermore;usally;currently

Filtered results
***************
RANKED	now.r 1018	currently 0.40604	just 0.38393	nowadays 0.38117	perhaps 0.38069	so 0.36300	lately 0.36248	recently 0.35861	presently 0.35840	well 0.34965	consequently 0.34402	immediately 0.34160	today 0.31941	instantly 0.31412	since 0.31306	next 0.30544

Test context:
***************
now.r	1019	11	what do you see yourself doing five or ten years from __now__ ?
Contexts for target now are: ['pcompI_from']
Contexts in vocabulary for target now are: ['pcompI_from']
Top most similar embeddings: now 0.47500	then 0.36986	here 0.36108	ago 0.35459	among 0.35335	over 0.35044	merrily 0.34999	within 0.34842	across 0.34811	around 0.34651

Generated lemmatized results
***************
GENERATED	now.r 1019 ::: then;here;ago;among;over;merrily;within;across;around;behind

Filtered results
***************
RANKED	now.r 1019	lately 0.33368	recently 0.32836	currently 0.31973	perhaps 0.31825	nowadays 0.31766	since 0.30909	immediately 0.30139	just 0.30087	presently 0.29604	today 0.29061	so 0.29005	well 0.27837	next 0.27402	consequently 0.26815	instantly 0.26302

Test context:
***************
now.r	1020	14	in particular , researchers criticized the prohibitions on sales promotion ; these prohibitions are __now__ abolished .
Contexts for target now are: ['advmodI_abolished']
Contexts in vocabulary for target now are: ['advmodI_abolished']
Top most similar embeddings: now 0.51344	then 0.40170	long-since 0.39860	finally 0.39110	already 0.38933	offically 0.38531	legislatively 0.38506	when 0.38190	dually 0.37787	duely 0.37776

Generated lemmatized results
***************
GENERATED	now.r 1020 ::: then;finally;already;offically;legislatively;when;dually;duely;proably;also

Filtered results
***************
RANKED	now.r 1020	recently 0.36731	perhaps 0.35573	currently 0.35280	lately 0.35020	just 0.34786	nowadays 0.34309	immediately 0.34246	presently 0.33136	so 0.33092	consequently 0.32930	since 0.32916	today 0.30818	instantly 0.30658	well 0.30196	next 0.27511

Test context:
***************
order.v	1021	27	the search engine then scans its index looking for web pages that match the visitor 's search criteria and returns a list of matching pages , usually __ordered__ by relevance .
Contexts for target ordered are: ['advmod_usually', 'ccompI_looking', 'prep:by_relevance']
Contexts in vocabulary for target ordered are: ['advmod_usually', 'ccompI_looking', 'prep:by_relevance']
Top most similar embeddings: ordered 0.11792	sorted 0.08358	dispatched 0.07993	despatched 0.07586	arranged 0.07545	determined 0.07478	motivated 0.07395	categorized 0.07354	characterized 0.07336	stacked 0.07222

Generated lemmatized results
***************
GENERATED	order.v 1021 ::: sort;dispatch;despatch;arrange;determine;motivate;categorize;characterize;stack;organize

Filtered results
***************
RANKED	order.v 1021	sort 0.08358	arrange 0.07545	rank 0.07099	organise 0.06786	buy 0.06671	request 0.06620	purchase 0.06610	grade 0.06513	direct 0.06434	instruct 0.06325	command 0.06266	send 0.06174	plan 0.06043	mandate 0.05990	reserve 0.05958	manage 0.05760	tell 0.05697

Test context:
***************
order.v	1022	5	8396 4748 tickets can be __ordered__ through allison at concession price of $ 16 .
Contexts for target ordered are: ['nsubjpass_tickets', 'aux_can', 'auxpass_be', 'rootI_*root*', 'prep:through_allison', 'prep:at_price', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target ordered are: ['nsubjpass_tickets', 'aux_can', 'auxpass_be', 'rootI_*root*', 'prep:at_price', 'punct_.']
Top most similar embeddings: ordered 0.01798	purchased 0.01638	bought 0.01411	obtained 0.01382	pre-ordered 0.01374	arranged 0.01257	sold 0.01237	booked 0.01235	repurchased 0.01234	raffled 0.01224

Generated lemmatized results
***************
GENERATED	order.v 1022 ::: purchase;buy;obtain;arrange;sell;book;repurchase;raffle;retail;dowloaded

Filtered results
***************
RANKED	order.v 1022	purchase 0.01638	buy 0.01411	arrange 0.01257	reserve 0.01145	request 0.01104	send 0.01103	direct 0.00886	sort 0.00885	organise 0.00868	instruct 0.00861	mandate 0.00850	plan 0.00840	command 0.00825	rank 0.00823	grade 0.00818	manage 0.00801	tell 0.00757

Test context:
***************
order.v	1023	22	the first time beverly saw those eyes was after the majority of her patients had been sent away to their quarters and __ordered__ to rest .
Contexts for target ordered are: ['conjI_sent', 'xcomp_rest']
Contexts in vocabulary for target ordered are: ['conjI_sent', 'xcomp_rest']
Top most similar embeddings: ordered 0.25737	entreated 0.17845	instructed 0.17744	enjoined 0.17493	summoned 0.17224	radioed 0.17221	sent 0.17130	proceded 0.17129	begged 0.17007	motioned 0.16997

Generated lemmatized results
***************
GENERATED	order.v 1023 ::: entreat;instruct;enjoin;summon;radio;send;proceded;beg;motion;despatch

Filtered results
***************
RANKED	order.v 1023	instruct 0.17744	send 0.17130	request 0.16725	tell 0.16516	command 0.16152	buy 0.15581	arrange 0.15293	purchase 0.15278	manage 0.14137	direct 0.13680	plan 0.13413	sort 0.13279	mandate 0.13207	reserve 0.13046	grade 0.12389	organise 0.12030	rank 0.11671

Test context:
***************
order.v	1024	23	thus , people who prefer this mental process for receiving information about the world , like to plan and organise , as they __order__ and regulate events. intuiting involves going beyond the information provided by the senses to discover possibilities which might not be immediately obvious from sensory data .
Contexts for target order are: ['mark_as', 'nsubj_they', 'advclI_plan', 'cc_and', 'conj_regulate']
Contexts in vocabulary for target order are: ['mark_as', 'nsubj_they', 'advclI_plan', 'cc_and', 'conj_regulate']
Top most similar embeddings: interrelate 0.01833	regulate 0.01822	unfold 0.01800	dehydrate 0.01787	disperse 0.01773	regroup 0.01770	scavenge 0.01770	decelerate 0.01754	metabolise 0.01746	manage 0.01740

Generated lemmatized results
***************
GENERATED	order.v 1024 ::: interrelate;regulate;unfold;dehydrate;disperse;regroup;scavenge;decelerate;metabolise;manage

Filtered results
***************
RANKED	order.v 1024	manage 0.01740	organise 0.01615	instruct 0.01516	plan 0.01466	direct 0.01410	command 0.01390	request 0.01386	mandate 0.01375	arrange 0.01355	buy 0.01348	purchase 0.01326	sort 0.01292	rank 0.01237	tell 0.01194	send 0.01194	reserve 0.01127	grade 0.01116

Test context:
***************
order.v	1025	5	iraqi bomb disposal officers were __ordered__ into the villages yesterday afternoon to clear the unexploded ordnance .
Contexts for target ordered are: ['nsubjpass_officers', 'auxpass_were', 'rootI_*root*', 'prep:into_villages', 'tmod_afternoon', 'xcomp_clear', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target ordered are: ['nsubjpass_officers', 'auxpass_were', 'rootI_*root*', 'prep:into_villages', 'tmod_afternoon', 'xcomp_clear', 'punct_.']
Top most similar embeddings: ordered 0.00796	marched 0.00568	summoned 0.00564	despatched 0.00552	summonsed 0.00543	re-deployed 0.00542	airlifted 0.00539	craned 0.00538	dispatched 0.00530	parachuted 0.00529

Generated lemmatized results
***************
GENERATED	order.v 1025 ::: march;summon;despatch;summons;airlift;crane;dispatch;parachute;winch;troop

Filtered results
***************
RANKED	order.v 1025	send 0.00523	instruct 0.00518	request 0.00455	arrange 0.00444	tell 0.00429	direct 0.00417	organise 0.00403	buy 0.00397	plan 0.00392	purchase 0.00391	command 0.00381	manage 0.00379	sort 0.00354	mandate 0.00346	reserve 0.00341	rank 0.00336	grade 0.00317

Test context:
***************
order.v	1026	2	if we __order__ our lives well , and carefully manage those placed in our charge , our churches will shine brightly , as lights set on a hill .
Contexts for target order are: ['mark_if', 'nsubj_we', 'advclI_shine', 'dobj_lives', 'advmod_well', 'punct_,', 'cc_and', 'conj_manage']
Contexts in vocabulary for target order are: ['mark_if', 'nsubj_we', 'advclI_shine', 'dobj_lives', 'advmod_well', 'punct_,', 'cc_and', 'conj_manage']
Top most similar embeddings: conceptualize 0.00205	co-create 0.00203	manage 0.00202	conceptualise 0.00199	overdid 0.00198	organize 0.00196	organise 0.00195	fast-forward 0.00194	live 0.00194	visualize 0.00192

Generated lemmatized results
***************
GENERATED	order.v 1026 ::: conceptualize;manage;conceptualise;overdo;organize;organise;live;visualize;conceive;apprehend

Filtered results
***************
RANKED	order.v 1026	manage 0.00202	organise 0.00195	plan 0.00171	arrange 0.00170	instruct 0.00155	direct 0.00154	buy 0.00152	sort 0.00144	command 0.00141	rank 0.00139	tell 0.00133	grade 0.00133	send 0.00130	purchase 0.00129	reserve 0.00123	request 0.00117	mandate 0.00116

Test context:
***************
order.v	1027	3	if you are __ordering__ several of one item , please allow us enough time to compile the order .
Contexts for target ordering are: ['mark_if', 'nsubj_you', 'aux_are', 'advclI_allow', 'dobj_several']
Contexts in vocabulary for target ordering are: ['mark_if', 'nsubj_you', 'aux_are', 'advclI_allow', 'dobj_several']
Top most similar embeddings: ordering 0.03192	resitting 0.02176	buying 0.02173	applying 0.02104	requesting 0.02091	installing 0.02066	purchasing 0.02063	reusing 0.02059	considering 0.02020	enquiring 0.02010

Generated lemmatized results
***************
GENERATED	order.v 1027 ::: resitting;buy;apply;request;instal;purchase;reuse;consider;enquire;search

Filtered results
***************
RANKED	order.v 1027	buy 0.02173	request 0.02091	purchase 0.02063	send 0.01993	reserve 0.01834	plan 0.01768	arrange 0.01757	organise 0.01732	instruct 0.01642	sort 0.01605	direct 0.01586	mandate 0.01561	tell 0.01503	manage 0.01465	command 0.01257	rank 0.01211	grade 0.01096

Test context:
***************
order.v	1028	8	" in the summer of 1941 , roosevelt __ordered__ the navy to escort merchant convoys as far as iceland .
Contexts for target ordered are: ["punct_''", 'prep:in_summer', 'punct_,', 'nsubj_roosevelt', 'rootI_*root*', 'dobj_navy', 'prep:to_convoys', 'prep:as_far', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target ordered are: ['prep:in_summer', 'punct_,', 'nsubj_roosevelt', 'rootI_*root*', 'dobj_navy', 'prep:as_far', 'punct_.']
Top most similar embeddings: ordered 0.00798	oversaw 0.00544	withdrew 0.00533	enlisted 0.00519	marched 0.00519	mutinied 0.00511	inaugurated 0.00507	rejoined 0.00505	undertook 0.00499	counter-attacked 0.00497

Generated lemmatized results
***************
GENERATED	order.v 1028 ::: oversee;withdraw;enlist;march;mutiny;inaugurate;rejoin;undertake;command;retreat

Filtered results
***************
RANKED	order.v 1028	command 0.00497	instruct 0.00458	send 0.00449	organise 0.00438	purchase 0.00438	buy 0.00435	arrange 0.00432	request 0.00414	plan 0.00405	tell 0.00398	manage 0.00386	direct 0.00380	mandate 0.00369	reserve 0.00339	rank 0.00337	sort 0.00330	grade 0.00319

Test context:
***************
order.v	1029	6	with the methods to date and __order__ the prehistoric past , archeologists could use data to systematically categorize the past .
Contexts for target order are: ['conjI_with', 'dep_past']
Contexts in vocabulary for target order are: ['conjI_with', 'dep_past']
Top most similar embeddings: order 0.17554	against 0.14311	without 0.14127	tenses 0.14048	alongside 0.13723	within 0.13698	orders 0.13663	beneath 0.13559	beyond 0.13493	minus 0.13456

Generated lemmatized results
***************
GENERATED	order.v 1029 ::: against;without;tense;alongside;within;beneath;beyond;minus;notwithstanding;direct

Filtered results
***************
RANKED	order.v 1029	direct 0.13432	instruct 0.11946	plan 0.11639	manage 0.11490	request 0.11470	arrange 0.11431	mandate 0.11357	command 0.11248	rank 0.11245	tell 0.11219	purchase 0.11214	organise 0.11142	reserve 0.10984	sort 0.10885	grade 0.10805	buy 0.10596	send 0.10366

Test context:
***************
order.v	1030	3	this must be __ordered__ by the criminal court division located where the competent public prosecutor has his seat .
Contexts for target ordered are: ['nsubjpass_this', 'aux_must', 'auxpass_be', 'rootI_*root*', 'prep:by_division', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target ordered are: ['nsubjpass_this', 'aux_must', 'auxpass_be', 'rootI_*root*', 'prep:by_division', 'punct_.']
Top most similar embeddings: ordered 0.01597	arranged 0.01277	countered 0.01275	purchased 0.01268	overriden 0.01240	recomputed 0.01240	combated 0.01235	provided 0.01230	complemented 0.01230	cross-checked 0.01230

Generated lemmatized results
***************
GENERATED	order.v 1030 ::: arrange;counter;purchase;overriden;recomputed;combat;provide;complement;preceeded;countermand

Filtered results
***************
RANKED	order.v 1030	arrange 0.01277	purchase 0.01268	request 0.01206	send 0.01115	instruct 0.01085	organise 0.01076	direct 0.01068	plan 0.01034	buy 0.01027	manage 0.01022	sort 0.00985	reserve 0.00961	mandate 0.00939	rank 0.00912	command 0.00901	tell 0.00862	grade 0.00827

Test context:
***************
possibly.r	1031	10	however , fine ceramics from iran , china , and __possibly__ yemen , were imported and these enable us to date the occupation .
Contexts for target possibly are: ['advmodI_yemen']
Contexts in vocabulary for target possibly are: []
Top most similar embeddings: possibly 1.00000	perhaps 0.82601	probably 0.82500	maybe 0.78841	conceivably 0.77773	proably 0.76300	sometimes 0.75486	even 0.74865	indeed 0.74789	probally 0.74224

Generated lemmatized results
***************
GENERATED	possibly.r 1031 ::: perhaps;probably;maybe;conceivably;proably;sometimes;even;indeed;probally;ocassionally

Filtered results
***************
RANKED	possibly.r 1031	perhaps 0.82601	maybe 0.78841	conceivably 0.77773	potentially 0.72760	feasibly 0.72533	plausibly 0.70112	necessarily 0.69934	believably 0.69392	ever 0.67266	reasonably 0.65372

Test context:
***************
possibly.r	1032	10	but , what is there of value that satan could __possibly__ hope to win from jesus ?
Contexts for target possibly are: ['advmodI_hope']
Contexts in vocabulary for target possibly are: ['advmodI_hope']
Top most similar embeddings: possibly 0.52677	perhaps 0.42134	probably 0.41409	proably 0.41167	maybe 0.40089	conceivably 0.40003	defintely 0.39908	certainly 0.39662	apprently 0.39431	actaully 0.39056

Generated lemmatized results
***************
GENERATED	possibly.r 1032 ::: perhaps;probably;proably;maybe;conceivably;defintely;certainly;apprently;actaully;deffinately

Filtered results
***************
RANKED	possibly.r 1032	perhaps 0.42134	maybe 0.40089	conceivably 0.40003	feasibly 0.37258	ever 0.35541	believably 0.35339	plausibly 0.35302	potentially 0.34682	necessarily 0.34125	reasonably 0.34009

Test context:
***************
possibly.r	1033	20	bloggers , who sometimes think of themselves as the current big thing of the internet , wondered how this could __possibly__ be .
Contexts for target possibly are: ['advmodI_be']
Contexts in vocabulary for target possibly are: ['advmodI_be']
Top most similar embeddings: possibly 0.53290	probably 0.44448	perhaps 0.43264	proably 0.42031	conceivably 0.41436	maybe 0.41030	probally 0.40916	apprently 0.40748	defintely 0.40460	usally 0.40158

Generated lemmatized results
***************
GENERATED	possibly.r 1033 ::: probably;perhaps;proably;conceivably;maybe;probally;apprently;defintely;usally;sometimes

Filtered results
***************
RANKED	possibly.r 1033	perhaps 0.43264	conceivably 0.41436	maybe 0.41030	feasibly 0.38471	potentially 0.37928	necessarily 0.36545	believably 0.35663	ever 0.35257	plausibly 0.34895	reasonably 0.33225

Test context:
***************
possibly.r	1034	36	( 22 ) general dwight d. eisenhower letter to george patton ( 29th april 1944 ) i have warned you time and again against your impulsiveness and have flatly instructed you to say nothing that could __possibly__ be misinterpreted .
Contexts for target possibly are: ['advmodI_misinterpreted']
Contexts in vocabulary for target possibly are: ['advmodI_misinterpreted']
Top most similar embeddings: possibly 0.52273	perhaps 0.43290	probably 0.42458	conceivably 0.41671	sometimes 0.40789	maybe 0.39665	egregiously 0.39262	often 0.38955	comically 0.38871	occasionally 0.38749

Generated lemmatized results
***************
GENERATED	possibly.r 1034 ::: perhaps;probably;conceivably;sometimes;maybe;egregiously;often;comically;occasionally;inexcusably

Filtered results
***************
RANKED	possibly.r 1034	perhaps 0.43290	conceivably 0.41671	maybe 0.39665	feasibly 0.37365	potentially 0.37045	plausibly 0.36082	believably 0.34535	necessarily 0.33910	reasonably 0.31762	ever 0.31354

Test context:
***************
possibly.r	1035	24	the whole organization is utterly impersonal ; it is hard , mechanical , inhuman , relentless , and must be so , and cannot __possibly__ be otherwise .
Contexts for target possibly are: ['advmodI_otherwise']
Contexts in vocabulary for target possibly are: ['advmodI_otherwise']
Top most similar embeddings: possibly 0.50942	perhaps 0.41556	probably 0.40615	maybe 0.38815	conceivably 0.38809	indeed 0.37948	even 0.37608	apparently 0.37487	sometimes 0.37475	proably 0.37387

Generated lemmatized results
***************
GENERATED	possibly.r 1035 ::: perhaps;probably;maybe;conceivably;indeed;even;apparently;sometimes;proably;unarguably

Filtered results
***************
RANKED	possibly.r 1035	perhaps 0.41556	maybe 0.38815	conceivably 0.38809	potentially 0.36961	feasibly 0.36179	plausibly 0.35922	believably 0.35108	ever 0.34915	necessarily 0.34881	reasonably 0.31669

Test context:
***************
possibly.r	1036	27	on average , bud 's dodging with his 6 combat dice would generate 3 successes , bud will be definitely be shot at least once and would __possibly__ end up getting shot twice .
Contexts for target possibly are: ['advmodI_end']
Contexts in vocabulary for target possibly are: ['advmodI_end']
Top most similar embeddings: possibly 0.52268	probably 0.45136	perhaps 0.42771	conceivably 0.42369	proably 0.41875	maybe 0.41533	probally 0.40473	sometimes 0.40267	apprently 0.40155	usually 0.40076

Generated lemmatized results
***************
GENERATED	possibly.r 1036 ::: probably;perhaps;conceivably;proably;maybe;probally;sometimes;apprently;usually;usally

Filtered results
***************
RANKED	possibly.r 1036	perhaps 0.42771	conceivably 0.42369	maybe 0.41533	feasibly 0.38358	potentially 0.37381	necessarily 0.36716	plausibly 0.35688	believably 0.35612	ever 0.35064	reasonably 0.31681

Test context:
***************
possibly.r	1037	0	__possibly__ in the future i see the elimination of poverty , economic freedom , the repair of the ecosystem , the elimination of war...all possibilities .
Contexts for target possibly are: ['advmodI_in']
Contexts in vocabulary for target possibly are: ['advmodI_in']
Top most similar embeddings: possibly 0.54063	perhaps 0.44239	probably 0.43948	even 0.41534	especially 0.40910	sometimes 0.40455	particularly 0.40100	maybe 0.40048	usually 0.39739	mainly 0.39646

Generated lemmatized results
***************
GENERATED	possibly.r 1037 ::: perhaps;probably;even;especially;sometimes;particularly;maybe;usually;mainly;notably

Filtered results
***************
RANKED	possibly.r 1037	perhaps 0.44239	maybe 0.40048	potentially 0.37503	conceivably 0.37185	necessarily 0.36102	feasibly 0.35378	ever 0.34951	believably 0.33292	plausibly 0.33106	reasonably 0.30832

Test context:
***************
possibly.r	1038	15	yet if you are a seasoned webmaster this website system gives you everything you could __possibly__ want , and saves you time in your busy day !
Contexts for target possibly are: ['advmodI_want']
Contexts in vocabulary for target possibly are: ['advmodI_want']
Top most similar embeddings: possibly 0.53685	probably 0.45074	perhaps 0.43463	maybe 0.42257	proably 0.41137	conceivably 0.40754	probally 0.40446	sometimes 0.40275	apprently 0.40190	defintely 0.40184

Generated lemmatized results
***************
GENERATED	possibly.r 1038 ::: probably;perhaps;maybe;proably;conceivably;probally;sometimes;apprently;defintely;obviously

Filtered results
***************
RANKED	possibly.r 1038	perhaps 0.43463	maybe 0.42257	conceivably 0.40754	necessarily 0.37098	feasibly 0.37085	ever 0.35709	potentially 0.35528	believably 0.35050	plausibly 0.34969	reasonably 0.32436

Test context:
***************
possibly.r	1039	11	he was born at arles in present day southern france and __possibly__ raised as a christian .
Contexts for target possibly are: ['advmodI_raised']
Contexts in vocabulary for target possibly are: ['advmodI_raised']
Top most similar embeddings: possibly 0.50814	probably 0.41594	perhaps 0.41397	conceivably 0.40689	proably 0.39473	also 0.39338	intially 0.39323	ocassionally 0.39187	indeed 0.39155	maybe 0.38774

Generated lemmatized results
***************
GENERATED	possibly.r 1039 ::: probably;perhaps;conceivably;proably;also;intially;ocassionally;indeed;maybe;certainly

Filtered results
***************
RANKED	possibly.r 1039	perhaps 0.41397	conceivably 0.40689	maybe 0.38774	feasibly 0.37885	potentially 0.36546	plausibly 0.36366	believably 0.34807	necessarily 0.34552	ever 0.34325	reasonably 0.32784

Test context:
***************
possibly.r	1040	31	although immunizations may be uncomfortable for your child and for you as a parent , it is one of the best ways to prevent your child from getting a contagious and __possibly__ dangerous disease .
Contexts for target possibly are: ['advmodI_disease']
Contexts in vocabulary for target possibly are: ['advmodI_disease']
Top most similar embeddings: possibly 0.53524	perhaps 0.43242	probably 0.43084	sometimes 0.39908	usually 0.39863	conceivably 0.39752	putatively 0.39461	hormonally 0.39343	maybe 0.39064	heterosexually 0.39062

Generated lemmatized results
***************
GENERATED	possibly.r 1040 ::: perhaps;probably;sometimes;usually;conceivably;putatively;hormonally;maybe;heterosexually;indeed

Filtered results
***************
RANKED	possibly.r 1040	perhaps 0.43242	conceivably 0.39752	maybe 0.39064	potentially 0.38474	feasibly 0.35847	necessarily 0.35181	believably 0.33458	plausibly 0.33315	ever 0.33040	reasonably 0.31660

Test context:
***************
quick.a	1041	6	however , you must be really __quick__ to get the timing right .
Contexts for target quick are: ['advmod_however', 'punct_,', 'nsubj_you', 'aux_must', 'cop_be', 'advmod_really', 'rootI_*root*', 'xcomp_get', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target quick are: ['advmod_however', 'punct_,', 'nsubj_you', 'aux_must', 'cop_be', 'advmod_really', 'rootI_*root*', 'xcomp_get', 'punct_.']
Top most similar embeddings: well-advised 0.00157	quick 0.00155	able 0.00142	careful 0.00138	keen 0.00134	glad 0.00130	unlucky 0.00128	wary 0.00128	lucky 0.00125	desparate 0.00125

Generated lemmatized results
***************
GENERATED	quick.a 1041 ::: able;careful;keen;glad;unlucky;wary;lucky;desparate;happy;leery

Filtered results
***************
RANKED	quick.a 1041	keen 0.00134	hasty 0.00096	hurried 0.00095	fast 0.00091	prompt 0.00085	swift 0.00082	brief 0.00079	short 0.00073	concise 0.00071	speedy 0.00068	rapid 0.00064	cursory 0.00061	express 0.00060	expeditious 0.00057	immediate 0.00047

Test context:
***************
quick.a	1042	7	journalist : can i ask you a __quick__ question about airports ?
Contexts for target quick are: ['amodI_question']
Contexts in vocabulary for target quick are: ['amodI_question']
Top most similar embeddings: quick 0.51434	quick-fire 0.39318	source-based 0.37321	frequently-asked 0.36995	one-line 0.36819	quickfire 0.36658	multi-choice 0.36393	simple 0.36377	researchable 0.36195	easy 0.36156

Generated lemmatized results
***************
GENERATED	quick.a 1042 ::: quickfire;simple;researchable;easy;nother;ticklish;speedy;ungraded;straightforward;rapid

Filtered results
***************
RANKED	quick.a 1042	speedy 0.35143	rapid 0.35052	fast 0.34447	swift 0.33730	immediate 0.33575	hasty 0.33170	cursory 0.32479	short 0.32243	expeditious 0.31219	concise 0.31149	brief 0.31011	hurried 0.30593	prompt 0.30521	keen 0.30345	express 0.24931

Test context:
***************
quick.a	1043	20	as i was writing this follow up and a new version has just been released i decided to take a __quick__ look and see what improvements have been made .
Contexts for target quick are: ['amodI_look']
Contexts in vocabulary for target quick are: ['amodI_look']
Top most similar embeddings: quick 0.54565	breif 0.38585	sidelong 0.38289	quick-fire 0.37944	fuss-free 0.37745	no-fuss 0.37237	quickfire 0.37213	state-by-state 0.37138	speedy 0.37061	lighthearted 0.36946

Generated lemmatized results
***************
GENERATED	quick.a 1043 ::: breif;sidelong;quickfire;speedy;lighthearted;preppy;cursory;slowish;sneaky;agreat

Filtered results
***************
RANKED	quick.a 1043	speedy 0.37061	cursory 0.36755	swift 0.36087	fast 0.35803	rapid 0.35059	hasty 0.34829	brief 0.33273	concise 0.33073	hurried 0.33003	immediate 0.32210	expeditious 0.32090	short 0.31922	keen 0.31747	prompt 0.31269	express 0.22642

Test context:
***************
quick.a	1044	1	in __quick__ succession , inflation rose and purchasing power dropped , reducing consumer demand--especially for meat and dairy products .
Contexts for target quick are: ['amodI_succession']
Contexts in vocabulary for target quick are: ['amodI_succession']
Top most similar embeddings: quick 0.55227	rapid 0.39701	speedy 0.38690	quick-fire 0.38547	swift 0.38335	fast 0.37197	speedier 0.36597	quickfire 0.36373	quicker 0.35705	quickest 0.35460

Generated lemmatized results
***************
GENERATED	quick.a 1044 ::: rapid;speedy;swift;fast;quickfire;seemless;lineal;expeditious;inexorable;instantaneous

Filtered results
***************
RANKED	quick.a 1044	rapid 0.39701	speedy 0.38690	swift 0.38335	fast 0.37197	expeditious 0.35197	hasty 0.34443	immediate 0.32845	short 0.32405	cursory 0.31873	hurried 0.31421	keen 0.30414	brief 0.29692	prompt 0.29484	concise 0.29237	express 0.24181

Test context:
***************
quick.a	1045	13	when you get on the field with him , he 's just so __quick__ and explosive .
Contexts for target quick are: ['advcl_get', 'punct_,', 'nsubj_he', "cop_'s", 'advmod_so', 'depI_<eol>', 'cc_and', 'conj_explosive', 'punct_.']
Contexts in vocabulary for target quick are: ['advcl_get', 'punct_,', 'nsubj_he', "cop_'s", 'advmod_so', 'cc_and', 'conj_explosive', 'punct_.']
Top most similar embeddings: quick 0.00344	nippy 0.00262	funny 0.00258	cocky 0.00255	cute 0.00255	quick-witted 0.00255	short-tempered 0.00252	fast 0.00252	jumpy 0.00251	polite 0.00251

Generated lemmatized results
***************
GENERATED	quick.a 1045 ::: nippy;funny;cocky;cute;fast;jumpy;polite;ornery;pernickety;clingy

Filtered results
***************
RANKED	quick.a 1045	fast 0.00252	keen 0.00209	swift 0.00206	hasty 0.00206	hurried 0.00201	speedy 0.00194	brief 0.00185	short 0.00174	concise 0.00168	rapid 0.00165	prompt 0.00164	expeditious 0.00136	immediate 0.00130	cursory 0.00124	express 0.00113

Test context:
***************
quick.a	1046	27	two other workers at american media , publisher of the national enquirer , the star and others , also became infected , but would survive thanks to __quick__ treatment .
Contexts for target quick are: ['amodI_treatment']
Contexts in vocabulary for target quick are: ['amodI_treatment']
Top most similar embeddings: quick 0.49564	speedy 0.38431	life-prolonging 0.37298	speedier 0.37292	post-exposure 0.37256	pharmacologic 0.37223	pre-harvest 0.37145	noninvasive 0.37099	elevational 0.37092	antithrombotic 0.37008

Generated lemmatized results
***************
GENERATED	quick.a 1046 ::: speedy;pharmacologic;noninvasive;elevational;antithrombotic;rapid;adjunctive;intravesical;fungicidal;fast

Filtered results
***************
RANKED	quick.a 1046	speedy 0.38431	rapid 0.36699	fast 0.36255	expeditious 0.36247	swift 0.35892	cursory 0.34896	immediate 0.34056	hasty 0.33538	prompt 0.32847	concise 0.32036	short 0.31682	hurried 0.31110	brief 0.31055	keen 0.28686	express 0.24887

Test context:
***************
quick.a	1047	5	caught off-guard , beijing was __quick__ to voice its outrage and to engage in a series of overt retaliatory measures .
Contexts for target quick are: ['parataxis_caught', 'nsubj_beijing', 'cop_was', 'rootI_*root*', 'xcomp_voice', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target quick are: ['parataxis_caught', 'nsubj_beijing', 'cop_was', 'rootI_*root*', 'xcomp_voice', 'punct_.']
Top most similar embeddings: quick 0.01369	eager 0.01114	keen 0.01078	abuzz 0.01060	hesitant 0.01056	reluctant 0.01022	afraid 0.01020	adamant 0.00980	anxious 0.00976	unsurprised 0.00973

Generated lemmatized results
***************
GENERATED	quick.a 1047 ::: eager;keen;abuzz;hesitant;reluctant;afraid;adamant;anxious;unsurprised;unapologetic

Filtered results
***************
RANKED	quick.a 1047	keen 0.01078	hurried 0.00847	swift 0.00800	hasty 0.00766	fast 0.00761	rapid 0.00711	prompt 0.00681	short 0.00621	brief 0.00603	speedy 0.00595	immediate 0.00580	expeditious 0.00567	cursory 0.00552	concise 0.00537	express 0.00496

Test context:
***************
quick.a	1048	18	i guess there is no pleasing some people!so i look at the chords i have and do some __quick__ thinking : will it benefit me to transpose this song so i can move it up the neck ?
Contexts for target quick are: ['amodI_thinking']
Contexts in vocabulary for target quick are: ['amodI_thinking']
Top most similar embeddings: quick 0.52458	blue-sky 0.36865	right-brain 0.36654	speedy 0.36581	fast 0.36531	rapid 0.36150	malthusian 0.35930	no-fuss 0.35481	left-brain 0.35446	deconstructive 0.35300

Generated lemmatized results
***************
GENERATED	quick.a 1048 ::: speedy;fast;rapid;malthusian;deconstructive;derridean;intuitive;innovative;creative;deductive

Filtered results
***************
RANKED	quick.a 1048	speedy 0.36581	fast 0.36531	rapid 0.36150	hasty 0.34467	cursory 0.33815	swift 0.33479	expeditious 0.31918	immediate 0.31887	concise 0.31566	short 0.31083	keen 0.30825	hurried 0.30554	prompt 0.30182	brief 0.29286	express 0.24540

Test context:
***************
quick.a	1049	3	people were rather __quick__ to pitch in .
Contexts for target quick are: ['nsubj_people', 'cop_were', 'advmod_rather', 'rootI_*root*', 'xcomp_pitch', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target quick are: ['nsubj_people', 'cop_were', 'advmod_rather', 'rootI_*root*', 'xcomp_pitch', 'punct_.']
Top most similar embeddings: quick 0.01435	hesitant 0.01189	keen 0.01147	eager 0.01145	reluctant 0.01143	reticent 0.01118	nonplussed 0.01082	loath 0.01082	well-advised 0.01077	chary 0.01065

Generated lemmatized results
***************
GENERATED	quick.a 1049 ::: hesitant;keen;eager;reluctant;reticent;nonplussed;loath;chary;aghast;unenthusiastic

Filtered results
***************
RANKED	quick.a 1049	keen 0.01147	hurried 0.00965	hasty 0.00868	swift 0.00857	fast 0.00822	prompt 0.00712	brief 0.00705	short 0.00693	speedy 0.00669	cursory 0.00664	rapid 0.00644	expeditious 0.00631	concise 0.00625	immediate 0.00538	express 0.00519

Test context:
***************
quick.a	1050	1	a __quick__ glance around my office , living room , or web site would probably make that pretty clear .
Contexts for target quick are: ['amodI_glance']
Contexts in vocabulary for target quick are: ['amodI_glance']
Top most similar embeddings: quick 0.54717	swift 0.38480	sidelong 0.38452	speedy 0.37712	cursory 0.37237	rapid 0.36738	fast 0.36514	quick-fire 0.36227	hasty 0.36094	fleeting 0.35473

Generated lemmatized results
***************
GENERATED	quick.a 1050 ::: swift;sidelong;speedy;cursory;rapid;fast;hasty;fleeting;surreptitious;hurried

Filtered results
***************
RANKED	quick.a 1050	swift 0.38480	speedy 0.37712	cursory 0.37237	rapid 0.36738	fast 0.36514	hasty 0.36094	hurried 0.35205	keen 0.32792	brief 0.32546	expeditious 0.32326	short 0.32010	immediate 0.31525	concise 0.30340	prompt 0.29834	express 0.23236

Test context:
***************
see.v	1051	3	" what we __see__ nationwide is states really backing away from their open access laws , " said fred h. cate , an indiana university law professor who studies privacy and technology .
Contexts for target see are: ["punct_''", 'dobj_what', 'nsubj_we', 'csubjI_states', 'acomp_nationwide']
Contexts in vocabulary for target see are: ['dobj_what', 'nsubj_we', 'csubjI_states']
Top most similar embeddings: see 0.10828	seeing 0.09202	perceive 0.09120	envisaging 0.08821	percieve 0.08632	proposing 0.08553	envisage 0.08458	propose 0.08413	witnessing 0.08390	terming 0.08241

Generated lemmatized results
***************
GENERATED	see.v 1051 ::: perceive;envisage;percieve;propose;witness;term;expect;foresee;suggest;do

Filtered results
***************
RANKED	see.v 1051	perceive 0.09120	witness 0.08390	observe 0.07931	consider 0.07910	find 0.07619	understand 0.07561	experience 0.07318	learn 0.07189	discover 0.07152	behold 0.07126	notice 0.07085	watch 0.07060	detect 0.06903	distinguish 0.06790	note 0.06680	ascertain 0.06635	establish 0.06603	visit 0.06557	view 0.06336	undergo 0.06257

Test context:
***************
see.v	1052	10	i love pigeons , and was excited about going to __see__ them .
Contexts for target see are: ['aux_to', 'xcompI_going', 'dobj_them']
Contexts in vocabulary for target see are: ['aux_to', 'xcompI_going', 'dobj_them']
Top most similar embeddings: see 0.13482	embarass 0.11726	out-do 0.10976	disabuse 0.10864	idolise 0.10851	baby-sit 0.10666	manhandle 0.10639	rile 0.10632	extirpate 0.10568	cremate 0.10526

Generated lemmatized results
***************
GENERATED	see.v 1052 ::: embarass;disabuse;idolise;manhandle;rile;extirpate;cremate;televise;dehumanise;harrass

Filtered results
***************
RANKED	see.v 1052	find 0.09842	observe 0.09387	watch 0.09065	understand 0.08812	consider 0.08776	distinguish 0.08666	discover 0.08662	perceive 0.08585	learn 0.08584	establish 0.08382	detect 0.08282	ascertain 0.08022	visit 0.08002	behold 0.07734	undergo 0.07478	witness 0.07299	view 0.07298	notice 0.07037	experience 0.06248	note 0.06060

Test context:
***************
see.v	1053	3	anyway , go __see__ it if you have to , just do n't have a coffee beforehand. freddy gives this movie 7 out of 10 .
Contexts for target see are: ['xcompI_go', 'dobj_it', 'advcl_have']
Contexts in vocabulary for target see are: ['xcompI_go', 'dobj_it', 'advcl_have']
Top most similar embeddings: see 0.12824	seing 0.09667	find 0.09451	overcook 0.09417	see/hear 0.09386	get 0.09337	apreciate 0.09305	descibe 0.09284	proove 0.09246	reword 0.09225

Generated lemmatized results
***************
GENERATED	see.v 1053 ::: find;overcook;get;apreciate;descibe;proove;reword;reseal;unfreeze;recive

Filtered results
***************
RANKED	see.v 1053	find 0.09451	consider 0.08534	watch 0.08318	understand 0.08297	observe 0.08128	perceive 0.08026	discover 0.07895	learn 0.07782	ascertain 0.07696	notice 0.07620	visit 0.07614	detect 0.07507	distinguish 0.07340	establish 0.07243	behold 0.07181	view 0.07040	experience 0.06960	witness 0.06813	undergo 0.06749	note 0.06549

Test context:
***************
see.v	1054	20	in fact , there were parts where there was just so much happening on screen that you could n't possibly __see__ everything that was going on .
Contexts for target see are: ['mark_that', 'nsubj_you', 'aux_could', "neg_n't", 'advmod_possibly', 'ccompI_happening', 'dobj_everything']
Contexts in vocabulary for target see are: ['mark_that', 'nsubj_you', 'aux_could', "neg_n't", 'advmod_possibly', 'ccompI_happening', 'dobj_everything']
Top most similar embeddings: see 0.00640	understand 0.00583	foresee 0.00569	imagine 0.00566	misconstrue 0.00562	misinterpret 0.00552	lose 0.00549	find 0.00547	afford 0.00547	comprehend 0.00545

Generated lemmatized results
***************
GENERATED	see.v 1054 ::: understand;foresee;imagine;misconstrue;misinterpret;lose;find;afford;comprehend;get

Filtered results
***************
RANKED	see.v 1054	understand 0.00583	find 0.00547	perceive 0.00504	detect 0.00429	notice 0.00429	consider 0.00421	discover 0.00417	observe 0.00415	learn 0.00405	witness 0.00403	watch 0.00370	distinguish 0.00367	experience 0.00363	ascertain 0.00344	undergo 0.00336	behold 0.00325	visit 0.00315	view 0.00305	establish 0.00292	note 0.00222

Test context:
***************
see.v	1055	18	if you carefully read our response to " been high and dry " last week , you would __see__ that nowhere did we encourage , endorse or condone drug use .
Contexts for target see are: ['advcl_read', 'punct_,', 'nsubj_you', 'aux_would', 'rootI_*root*', 'ccomp_encourage', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target see are: ['advcl_read', 'punct_,', 'nsubj_you', 'aux_would', 'rootI_*root*', 'ccomp_encourage', 'punct_.']
Top most similar embeddings: see 0.00747	suggest 0.00623	imagine 0.00619	argue 0.00604	think 0.00602	recommend 0.00591	believe 0.00590	consider 0.00577	say 0.00575	appreciate 0.00574

Generated lemmatized results
***************
GENERATED	see.v 1055 ::: suggest;imagine;argue;think;recommend;believe;consider;say;appreciate;remember

Filtered results
***************
RANKED	see.v 1055	consider 0.00577	notice 0.00546	find 0.00527	understand 0.00496	observe 0.00490	learn 0.00474	discover 0.00473	perceive 0.00456	watch 0.00442	note 0.00414	behold 0.00402	visit 0.00402	view 0.00392	witness 0.00377	detect 0.00368	distinguish 0.00359	establish 0.00346	undergo 0.00346	experience 0.00345	ascertain 0.00345

Test context:
***************
see.v	1056	5	it will be interesting to __see__ how the budget unfolds .
Contexts for target see are: ['aux_to', 'xcompI_interesting', 'ccomp_unfolds']
Contexts in vocabulary for target see are: ['aux_to', 'xcompI_interesting', 'ccomp_unfolds']
Top most similar embeddings: see 0.14910	observe 0.10579	hear 0.09731	discover 0.09338	discern 0.09292	find 0.09262	contemplate 0.09241	ponder 0.09224	watch 0.09090	ascertain 0.09070

Generated lemmatized results
***************
GENERATED	see.v 1056 ::: observe;hear;discover;discern;find;contemplate;ponder;watch;ascertain;examine

Filtered results
***************
RANKED	see.v 1056	observe 0.10579	discover 0.09338	find 0.09262	watch 0.09090	ascertain 0.09070	understand 0.08919	consider 0.08589	learn 0.08368	perceive 0.08187	establish 0.08055	detect 0.07926	behold 0.07848	distinguish 0.07789	note 0.07602	undergo 0.07045	witness 0.06928	notice 0.06873	view 0.06807	visit 0.06771	experience 0.05530

Test context:
***************
see.v	1057	5	i was also pleased to __see__ that he did n't go for the typical warm , fuzzy ending with abra 's absolution .
Contexts for target see are: ['aux_to', 'xcompI_pleased', 'ccomp_go']
Contexts in vocabulary for target see are: ['aux_to', 'xcompI_pleased', 'ccomp_go']
Top most similar embeddings: see 0.14206	annouce 0.11341	hear 0.10404	announce 0.10104	say 0.10023	find 0.09663	know 0.09416	see/hear 0.09389	discuss 0.09237	let 0.09221

Generated lemmatized results
***************
GENERATED	see.v 1057 ::: annouce;hear;announce;say;find;know;discuss;let;discover;confirm

Filtered results
***************
RANKED	see.v 1057	find 0.09663	discover 0.09216	observe 0.09162	learn 0.08996	consider 0.08729	watch 0.08639	ascertain 0.08512	understand 0.08417	perceive 0.08170	behold 0.08161	establish 0.08118	detect 0.07652	note 0.07571	notice 0.07456	distinguish 0.07370	visit 0.07133	witness 0.07040	view 0.06961	undergo 0.06777	experience 0.05882

Test context:
***************
see.v	1058	6	as i walked , i could __see__ the eiffel tower get closer and closer .
Contexts for target see are: ['advcl_walked', 'punct_,', 'nsubj_i', 'aux_could', 'rootI_*root*', 'ccomp_closer', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target see are: ['advcl_walked', 'punct_,', 'nsubj_i', 'aux_could', 'rootI_*root*', 'ccomp_closer', 'punct_.']
Top most similar embeddings: see 0.01080	said 0.00907	imagine 0.00888	believe 0.00857	remember 0.00830	marveled 0.00821	argued 0.00811	surmise 0.00805	chorused 0.00801	hypothesize 0.00799

Generated lemmatized results
***************
GENERATED	see.v 1058 ::: say;imagine;believe;remember;marvel;argue;surmise;chorus;hypothesize;tutted

Filtered results
***************
RANKED	see.v 1058	notice 0.00776	find 0.00737	observe 0.00713	perceive 0.00681	watch 0.00676	discover 0.00670	consider 0.00656	understand 0.00647	behold 0.00627	note 0.00622	view 0.00603	detect 0.00595	learn 0.00593	ascertain 0.00579	witness 0.00574	visit 0.00538	distinguish 0.00508	establish 0.00503	experience 0.00468	undergo 0.00466

Test context:
***************
see.v	1059	4	it 's amusing to __see__ ten rows of cars turn around a circle and converge on a road that at most can hold three cars side by side .
Contexts for target see are: ['aux_to', 'xcompI_amusing', 'dobj_rows']
Contexts in vocabulary for target see are: ['aux_to', 'xcompI_amusing', 'dobj_rows']
Top most similar embeddings: see 0.13698	observe 0.09975	overhear 0.09455	hear 0.09453	see/hear 0.09336	enumerate 0.09222	visualise 0.09194	supress 0.09145	re-do 0.09057	visualize 0.09038

Generated lemmatized results
***************
GENERATED	see.v 1059 ::: observe;overhear;hear;enumerate;visualise;supress;visualize;peruse;contemplate;descibe

Filtered results
***************
RANKED	see.v 1059	observe 0.09975	watch 0.08811	find 0.08793	discover 0.08407	detect 0.08177	behold 0.08075	distinguish 0.08025	consider 0.07877	understand 0.07777	perceive 0.07748	ascertain 0.07684	learn 0.07518	note 0.07376	establish 0.07316	witness 0.07201	notice 0.07152	view 0.06968	visit 0.06691	undergo 0.06447	experience 0.05547

Test context:
***************
see.v	1060	2	the mid-1960s __saw__ a dramatic period of growth for aviation warrant officers .
Contexts for target saw are: ['nsubj_mid-1960s', 'rootI_*root*', 'dobj_period', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target saw are: ['rootI_*root*', 'dobj_period', 'punct_.']
Top most similar embeddings: saw 0.13471	sees 0.10999	vg/f 0.10484	2885557 0.10318	began 0.10212	depicts 0.10158	foresees 0.10111	foreshadows 0.10083	syph 0.10074	undertook 0.10041

Generated lemmatized results
***************
GENERATED	see.v 1060 ::: begin;depict;foresee;foreshadow;syph;undertake;show;uring;oversee;include

Filtered results
***************
RANKED	see.v 1060	witness 0.09569	undergo 0.09332	establish 0.09204	observe 0.09193	watch 0.08984	consider 0.08694	notice 0.08680	understand 0.08556	distinguish 0.08384	note 0.08349	discover 0.08204	find 0.08137	experience 0.08000	view 0.07791	visit 0.07782	behold 0.07778	perceive 0.07676	detect 0.07596	learn 0.07560	ascertain 0.07358

Test context:
***************
shortly.r	1061	9	the only detectable effect was psychological stress during and __shortly__ after the accident .
Contexts for target shortly are: ['conjI_during']
Contexts in vocabulary for target shortly are: ['conjI_during']
Top most similar embeddings: shortly 0.52962	immediately 0.40098	soon 0.38163	after 0.37359	subsequently 0.36430	afterwards 0.35500	during 0.35415	sometime 0.35149	afterward 0.34800	biannually 0.34582

Generated lemmatized results
***************
GENERATED	shortly.r 1061 ::: immediately;soon;after;subsequently;afterwards;during;sometime;afterward;biannually;thereafter

Filtered results
***************
RANKED	shortly.r 1061	immediately 0.40098	soon 0.38163	just 0.32665	briefly 0.30620	abruptly 0.29989	quickly 0.29923	curtly 0.28965	brusquely 0.28296	sharply 0.28036	presently 0.27141	little 0.23827

Test context:
***************
shortly.r	1062	16	performance test for a system coupled with a locally manufactured station engine model mwm will start __shortly__ .
Contexts for target shortly are: ['advmodI_start']
Contexts in vocabulary for target shortly are: ['advmodI_start']
Top most similar embeddings: shortly 0.53029	soon 0.40960	immediately 0.40630	eventualy 0.38451	again 0.38438	imediately 0.37910	immediatly 0.37479	proably 0.37379	regularily 0.37058	unfortuantely 0.36946

Generated lemmatized results
***************
GENERATED	shortly.r 1062 ::: soon;immediately;eventualy;again;imediately;immediatly;proably;regularily;unfortuantely;sometime

Filtered results
***************
RANKED	shortly.r 1062	soon 0.40960	immediately 0.40630	just 0.35815	quickly 0.34491	abruptly 0.33947	brusquely 0.33799	briefly 0.32256	curtly 0.31821	sharply 0.31207	presently 0.31075	little 0.26149

Test context:
***************
shortly.r	1063	7	the evidence of wallat was given very __shortly__ .
Contexts for target shortly are: ['advmod_very', 'advmodI_given']
Contexts in vocabulary for target shortly are: ['advmod_very', 'advmodI_given']
Top most similar embeddings: shortly 0.26981	sportingly 0.21439	cannily 0.20786	dexterously 0.20414	soon 0.20253	civilly 0.19998	magnanimously 0.19756	shoddily 0.19405	hospitably 0.19274	good-naturedly 0.19231

Generated lemmatized results
***************
GENERATED	shortly.r 1063 ::: sportingly;cannily;dexterously;soon;civilly;magnanimously;shoddily;hospitably;adeptly;industriously

Filtered results
***************
RANKED	shortly.r 1063	soon 0.20253	quickly 0.17815	immediately 0.17713	brusquely 0.17439	briefly 0.17245	curtly 0.16617	abruptly 0.16210	sharply 0.15917	just 0.15280	presently 0.14858	little 0.14382

Test context:
***************
shortly.r	1064	11	family members went to a neighbor 's house and called 911 __shortly__ before 3:00 a.m. firefighters arrived within minutes to find the home fully involved .
Contexts for target shortly are: ['advmodI_called']
Contexts in vocabulary for target shortly are: ['advmodI_called']
Top most similar embeddings: shortly 0.51020	immediately 0.39566	duely 0.38803	soon 0.38733	sportingly 0.38447	peremptorily 0.38193	derisively 0.38171	coincidently 0.37940	vulgarly 0.37631	also 0.37592

Generated lemmatized results
***************
GENERATED	shortly.r 1064 ::: immediately;duely;soon;sportingly;peremptorily;derisively;coincidently;vulgarly;also;eventualy

Filtered results
***************
RANKED	shortly.r 1064	immediately 0.39566	soon 0.38733	brusquely 0.35555	curtly 0.34709	just 0.34612	briefly 0.33329	quickly 0.33257	abruptly 0.32997	presently 0.32390	sharply 0.31574	little 0.26028

Test context:
***************
shortly.r	1065	0	__shortly__ , he closed his book and raised his eyes upwards , acknowledging them all with a slight nod of the head .
Contexts for target shortly are: ['advmodI_closed']
Contexts in vocabulary for target shortly are: ['advmodI_closed']
Top most similar embeddings: shortly 0.51463	immediately 0.39103	soon 0.38624	sportingly 0.38238	eventualy 0.37845	indefinately 0.37616	peremptorily 0.37610	duely 0.37586	long-since 0.37520	subsequently 0.37471

Generated lemmatized results
***************
GENERATED	shortly.r 1065 ::: immediately;soon;sportingly;eventualy;indefinately;peremptorily;duely;subsequently;finally;offically

Filtered results
***************
RANKED	shortly.r 1065	immediately 0.39103	soon 0.38624	abruptly 0.34860	brusquely 0.34567	just 0.33970	presently 0.33851	quickly 0.33826	briefly 0.33472	curtly 0.32297	sharply 0.32026	little 0.26372

Test context:
***************
shortly.r	1066	9	go to hell! she remembers paul yelling at her __shortly__ after their wedding .
Contexts for target shortly are: ['advmodI_after']
Contexts in vocabulary for target shortly are: ['advmodI_after']
Top most similar embeddings: shortly 0.56479	soon 0.41710	immediately 0.41223	even 0.37643	just 0.37314	sometime 0.37118	especially 0.36260	imediately 0.35628	possibly 0.35413	immediatly 0.35387

Generated lemmatized results
***************
GENERATED	shortly.r 1066 ::: soon;immediately;even;just;sometime;especially;imediately;possibly;immediatly;finally

Filtered results
***************
RANKED	shortly.r 1066	soon 0.41710	immediately 0.41223	just 0.37314	quickly 0.32297	abruptly 0.32090	presently 0.31526	brusquely 0.31434	briefly 0.30506	sharply 0.30461	curtly 0.30177	little 0.25497

Test context:
***************
shortly.r	1067	11	they said to me that he spoke with those patient very __shortly__ without any interest in the patient and many times , i had to say to him -- ' take care about those patients ' or something , you know .
Contexts for target shortly are: ['advmod_very', 'advmodI_spoke']
Contexts in vocabulary for target shortly are: ['advmod_very', 'advmodI_spoke']
Top most similar embeddings: shortly 0.26900	cannily 0.21446	sportingly 0.21425	civilly 0.21307	dexterously 0.20633	good-naturedly 0.20443	animatedly 0.20433	magnanimously 0.20312	lamely 0.20050	soon 0.19968

Generated lemmatized results
***************
GENERATED	shortly.r 1067 ::: cannily;sportingly;civilly;dexterously;animatedly;magnanimously;lamely;soon;sourly;crossly

Filtered results
***************
RANKED	shortly.r 1067	soon 0.19968	brusquely 0.18532	briefly 0.18423	curtly 0.17966	quickly 0.17906	sharply 0.17364	immediately 0.17305	abruptly 0.17202	just 0.14816	little 0.14776	presently 0.14329

Test context:
***************
shortly.r	1068	1	you __shortly__ come upon grassingdon , a picturesque old village with lead mining heritage .
Contexts for target shortly are: ['advmodI_come']
Contexts in vocabulary for target shortly are: ['advmodI_come']
Top most similar embeddings: shortly 0.51943	eventualy 0.40022	soon 0.39840	proably 0.38724	immediately 0.38666	duely 0.38446	unfortuantely 0.38424	coincidently 0.38258	imediately 0.38094	sportingly 0.37921

Generated lemmatized results
***************
GENERATED	shortly.r 1068 ::: eventualy;soon;proably;immediately;duely;unfortuantely;coincidently;imediately;sportingly;regretably

Filtered results
***************
RANKED	shortly.r 1068	soon 0.39840	immediately 0.38666	just 0.35797	quickly 0.34356	brusquely 0.33687	curtly 0.32589	briefly 0.32464	presently 0.32410	abruptly 0.32233	sharply 0.31928	little 0.25816

Test context:
***************
shortly.r	1069	33	hannah will just keep spouting her pat answers. ' how about we all go to copperchino for coffee? ' tyler suggested. ' we can talk there. ' ' can 't, ' said becca __shortly__ , as they reached the bike rack at the edge of the parking lot. ' today 's my mom 's staff meeting at the community center and i promised i 'd be home to watch alvaro. ' hannah nodded approvingly. ' jacie told me about the wonderful things your family is doing for that little alien boy .
Contexts for target shortly are: ['advmodI_becca']
Contexts in vocabulary for target shortly are: []
Top most similar embeddings: shortly 1.00000	soon 0.75983	immediately 0.74993	sportingly 0.71782	coincidently 0.71532	duely 0.71411	magnanimously 0.71058	eventualy 0.71028	sometime 0.70995	unfortuantely 0.70901

Generated lemmatized results
***************
GENERATED	shortly.r 1069 ::: soon;immediately;sportingly;coincidently;duely;magnanimously;eventualy;sometime;unfortuantely;subsequently

Filtered results
***************
RANKED	shortly.r 1069	soon 0.75983	immediately 0.74993	just 0.68291	brusquely 0.67869	curtly 0.67435	quickly 0.66377	briefly 0.64963	abruptly 0.64654	presently 0.63348	sharply 0.62929	little 0.58496

Test context:
***************
shortly.r	1070	8	they were penned by libertarianz founder ian fraser __shortly__ before he left act in disgust .
Contexts for target shortly are: ['advmodI_left']
Contexts in vocabulary for target shortly are: ['advmodI_left']
Top most similar embeddings: shortly 0.53304	immediately 0.40452	eventualy 0.39840	imediately 0.39639	soon 0.39604	sportingly 0.39211	immediatly 0.38805	proably 0.38467	duely 0.38320	unfortuantely 0.38288

Generated lemmatized results
***************
GENERATED	shortly.r 1070 ::: immediately;eventualy;imediately;soon;sportingly;immediatly;proably;duely;unfortuantely;coincidently

Filtered results
***************
RANKED	shortly.r 1070	immediately 0.40452	soon 0.39604	just 0.35735	brusquely 0.35169	abruptly 0.34696	quickly 0.34117	briefly 0.33555	curtly 0.33320	sharply 0.33148	presently 0.32648	little 0.28474

Test context:
***************
skip.v	1071	15	" oh , lord , " he prayed , " i 'm so sorry i __skipped__ church to come out here and hunt .
Contexts for target skipped are: ['nsubj_i', 'ccompI_sorry', 'dobj_church', 'xcomp_come']
Contexts in vocabulary for target skipped are: ['nsubj_i', 'ccompI_sorry', 'dobj_church', 'xcomp_come']
Top most similar embeddings: skipped 0.06982	missed 0.05398	behoved 0.05359	bunked 0.05303	had 0.05296	behooves 0.05264	chose 0.05226	failed 0.05171	expecting 0.05158	horrify 0.05143

Generated lemmatized results
***************
GENERATED	skip.v 1071 ::: miss;behove;bunk;have;behoove;choose;fail;expect;horrify;motion

Filtered results
***************
RANKED	skip.v 1071	miss 0.05398	leave 0.04995	neglect 0.04807	dodge 0.04677	omit 0.04658	ignore 0.04630	reject 0.04574	jump 0.04550	pass 0.04485	bump 0.04329	bounce 0.04251	avoid 0.04219	hop 0.04126	spring 0.04067	shift 0.04066	eschew 0.03955	skitter 0.03904	disregard 0.03763	bound 0.03723	skim 0.03710	prance 0.03564

Test context:
***************
skip.v	1072	16	the little fellow dashed up the street , scampering through the crowds like a smooth stone __skipping__ across blue water .
Contexts for target skipping are: ['partmodI_stone', 'prep:across_water']
Contexts in vocabulary for target skipping are: ['partmodI_stone', 'prep:across_water']
Top most similar embeddings: skipping 0.27237	jutting 0.18846	careening 0.18579	scooting 0.18535	bouncing 0.18488	throwing 0.18463	flinging 0.17989	snaking 0.17857	slinging 0.17827	ricocheting 0.17811

Generated lemmatized results
***************
GENERATED	skip.v 1072 ::: jut;careen;scoot;bounce;throw;fling;snake;sling;ricochet;spit

Filtered results
***************
RANKED	skip.v 1072	bounce 0.18488	skitter 0.17676	jump 0.17333	skim 0.17262	hop 0.17235	prance 0.17120	dodge 0.16449	bound 0.15856	spring 0.15201	avoid 0.14738	miss 0.14632	leave 0.14599	shift 0.14125	bump 0.13824	pass 0.13724	ignore 0.13683	disregard 0.13399	eschew 0.13352	reject 0.13255	neglect 0.12787	omit 0.12707

Test context:
***************
skip.v	1073	26	his brilliant idea is this - if a bomb can be delivered at the correct shallow trajectory and the right high speed , it will ' __skip__ ' along the lake 's surface like a pebble on a pond , strike the dam and slide down the wall .
Contexts for target skip are: ['advcl_delivered', 'punct_,', 'nsubj_it', 'aux_will', "punct_'", 'depI_this', "punct_'", 'prep:along_surface', 'punct_,', 'dep_strike']
Contexts in vocabulary for target skip are: ['advcl_delivered', 'punct_,', 'nsubj_it', 'aux_will', "punct_'", 'depI_this', "punct_'", 'prep:along_surface', 'punct_,', 'dep_strike']
Top most similar embeddings: skip 0.00053	bleed 0.00046	vibrate 0.00045	skipping 0.00045	paralyze 0.00044	skipped 0.00044	implode 0.00044	twitch 0.00044	scuttle 0.00044	murmured 0.00044

Generated lemmatized results
***************
GENERATED	skip.v 1073 ::: bleed;vibrate;paralyze;implode;twitch;scuttle;murmur;flip;plow;oscillate

Filtered results
***************
RANKED	skip.v 1073	bounce 0.00040	hop 0.00039	jump 0.00038	skim 0.00038	bump 0.00034	pass 0.00033	dodge 0.00033	bound 0.00032	miss 0.00031	avoid 0.00031	shift 0.00031	eschew 0.00030	spring 0.00030	prance 0.00029	reject 0.00029	omit 0.00028	disregard 0.00028	ignore 0.00028	skitter 0.00027	leave 0.00024	neglect 0.00024

Test context:
***************
skip.v	1074	8	thus , for rousseau , even running and __skipping__ had a natural developmental function .
Contexts for target skipping are: ['conjI_running']
Contexts in vocabulary for target skipping are: ['conjI_running']
Top most similar embeddings: skipping 0.54015	jumping 0.39488	scooting 0.38842	rollerblading 0.38565	jogging 0.38276	hopping 0.38011	sprinting 0.37933	tobogganing 0.37775	dribbling 0.37766	crabbing 0.37363

Generated lemmatized results
***************
GENERATED	skip.v 1074 ::: jump;scoot;rollerblade;jog;hop;sprint;toboggan;dribble;crab;loop

Filtered results
***************
RANKED	skip.v 1074	jump 0.39488	hop 0.38011	bounce 0.35675	bound 0.35036	skitter 0.34782	prance 0.34682	dodge 0.34239	bump 0.34167	skim 0.33845	avoid 0.33732	ignore 0.33407	reject 0.31749	leave 0.31601	eschew 0.31263	omit 0.31098	spring 0.31081	miss 0.30796	neglect 0.30474	pass 0.30297	disregard 0.30234	shift 0.28627

Test context:
***************
skip.v	1075	14	eat your regular meals too , and do let us know if you 've __skipped__ a meal on the day .
Contexts for target skipped are: ['mark_if', 'nsubj_you', "aux_'ve", 'advclI_know', 'dobj_meal', 'prep:on_day']
Contexts in vocabulary for target skipped are: ['mark_if', 'nsubj_you', "aux_'ve", 'advclI_know', 'dobj_meal', 'prep:on_day']
Top most similar embeddings: skipped 0.01395	missed 0.01191	eaten 0.01138	skied 0.01100	overdosed 0.01091	bunked 0.01048	pre-ordered 0.01035	overslept 0.01032	booked 0.01027	snogged 0.01016

Generated lemmatized results
***************
GENERATED	skip.v 1075 ::: miss;eat;ski;overdose;bunk;oversleep;book;snog;get;taste

Filtered results
***************
RANKED	skip.v 1075	miss 0.01191	bump 0.00880	dodge 0.00814	pass 0.00775	omit 0.00767	jump 0.00763	skim 0.00756	leave 0.00728	avoid 0.00726	hop 0.00719	bounce 0.00715	reject 0.00708	neglect 0.00692	ignore 0.00670	eschew 0.00638	shift 0.00626	disregard 0.00619	spring 0.00596	prance 0.00570	bound 0.00516	skitter 0.00429

Test context:
***************
skip.v	1076	9	well worth buying , well worth reading , but __skip__ the bits you find irrelevant - another type of blended learning !
Contexts for target skip are: ['conjI_worth', 'dobj_bits']
Contexts in vocabulary for target skip are: ['conjI_worth', 'dobj_bits']
Top most similar embeddings: skip 0.23347	skips 0.17701	skipping 0.16718	skipped 0.16332	ignore 0.16125	discard 0.15544	adding 0.15527	discarding 0.15501	snip 0.15483	savor 0.15243

Generated lemmatized results
***************
GENERATED	skip.v 1076 ::: ignore;discard;add;snip;savor;redo;omit;toss;scrunch;delete

Filtered results
***************
RANKED	skip.v 1076	ignore 0.16125	omit 0.15107	skim 0.14587	eschew 0.14365	miss 0.14296	avoid 0.14191	dodge 0.14001	disregard 0.13755	jump 0.13405	bounce 0.13334	reject 0.13132	shift 0.13070	neglect 0.13028	hop 0.12877	bump 0.12796	pass 0.12706	leave 0.12413	spring 0.11945	skitter 0.11730	bound 0.11476	prance 0.11376

Test context:
***************
skip.v	1077	27	i saw a video a while back where someone used a few inches of blackmatch to ignite a sample of bp only to see it a spark __skip__ the entire fuse and ignite the comp instantaneously .
Contexts for target skip are: ['ccompI_spark', 'dobj_fuse', 'cc_and', 'conj_ignite']
Contexts in vocabulary for target skip are: ['ccompI_spark', 'dobj_fuse', 'cc_and', 'conj_ignite']
Top most similar embeddings: ignite 0.05070	skip 0.04804	ignited 0.04480	ignites 0.04199	vaporize 0.04016	kindle 0.03977	burn 0.03913	melt 0.03859	sparks 0.03830	igniting 0.03826

Generated lemmatized results
***************
GENERATED	skip.v 1077 ::: ignite;vaporize;kindle;burn;melt;spark;corrode;vaporise;overheat;detonate

Filtered results
***************
RANKED	skip.v 1077	jump 0.03101	dodge 0.03018	miss 0.02949	bounce 0.02898	omit 0.02886	spring 0.02831	hop 0.02828	skim 0.02825	ignore 0.02813	bump 0.02724	eschew 0.02602	leave 0.02562	avoid 0.02561	shift 0.02508	reject 0.02457	prance 0.02454	pass 0.02420	disregard 0.02417	bound 0.02375	skitter 0.02374	neglect 0.02231

Test context:
***************
skip.v	1078	5	they lie , cheat , __skip__ deodorant and reject the one true path .
Contexts for target skip are: ['conjI_lie', 'dobj_deodorant']
Contexts in vocabulary for target skip are: ['conjI_lie', 'dobj_deodorant']
Top most similar embeddings: skip 0.19841	chew 0.15098	skips 0.14926	skipping 0.14861	guzzle 0.14665	inhale 0.14656	sprinkle 0.14618	mangle 0.14604	flaunt 0.14400	steal 0.14397

Generated lemmatized results
***************
GENERATED	skip.v 1078 ::: chew;guzzle;inhale;sprinkle;mangle;flaunt;steal;rub;bathe;jiggle

Filtered results
***************
RANKED	skip.v 1078	eschew 0.14272	ignore 0.14128	omit 0.13754	skim 0.13550	dodge 0.13319	avoid 0.13243	jump 0.13174	miss 0.12953	reject 0.12621	bump 0.12514	prance 0.12194	bounce 0.12177	neglect 0.12144	hop 0.11878	disregard 0.11856	pass 0.11669	leave 0.11668	shift 0.11653	bound 0.10906	skitter 0.10816	spring 0.10735

Test context:
***************
skip.v	1079	13	we are running windows xp on a p4 1.9ghz and it has n't __skipped__ a beat .
Contexts for target skipped are: ['nsubj_it', 'aux_has', "neg_n't", 'conjI_running', 'dobj_beat']
Contexts in vocabulary for target skipped are: ['nsubj_it', 'aux_has', "neg_n't", 'conjI_running', 'dobj_beat']
Top most similar embeddings: skipped 0.02985	skipping 0.02163	jogged 0.02034	missed 0.01989	slowed 0.01979	snowing 0.01903	stoped 0.01887	rained 0.01878	raining 0.01862	swerved 0.01858

Generated lemmatized results
***************
GENERATED	skip.v 1079 ::: jog;miss;slow;snow;stop;rain;swerve;dissapeared;dribble;crash

Filtered results
***************
RANKED	skip.v 1079	miss 0.01989	bounce 0.01772	jump 0.01707	dodge 0.01693	ignore 0.01643	skim 0.01637	bump 0.01622	hop 0.01622	eschew 0.01615	neglect 0.01591	spring 0.01557	pass 0.01535	shift 0.01514	leave 0.01512	avoid 0.01499	bound 0.01492	omit 0.01478	skitter 0.01455	reject 0.01348	prance 0.01301	disregard 0.01286

Test context:
***************
skip.v	1080	3	so the movie __skips__ happily around from the tragic brutal boys school to the funny and silly actors troupe to the family turmoil and secret revelations without really every settling anywhere , or picking a cohesive tone .
Contexts for target skips are: ['mark_so', 'nsubj_movie', 'rootI_*root*', 'advmod_happily', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target skips are: ['mark_so', 'nsubj_movie', 'rootI_*root*', 'advmod_happily', 'punct_.']
Top most similar embeddings: skips 0.03153	skip 0.02435	trundles 0.02299	ambles 0.02257	flaunts 0.02218	fizzes 0.02210	quietens 0.02201	purrs 0.02199	flits 0.02196	rewinds 0.02180

Generated lemmatized results
***************
GENERATED	skip.v 1080 ::: trundle;amble;flaunt;fizz;quieten;purr;flit;rewinds;backtrack;oscillate

Filtered results
***************
RANKED	skip.v 1080	bounce 0.02066	jump 0.02031	miss 0.02022	eschew 0.01975	skim 0.01963	ignore 0.01949	omit 0.01926	pass 0.01891	avoid 0.01883	prance 0.01823	hop 0.01805	reject 0.01800	dodge 0.01774	spring 0.01702	leave 0.01676	shift 0.01674	bump 0.01598	disregard 0.01508	neglect 0.01499	bound 0.01380	skitter 0.01297

Test context:
***************
solid.a	1081	3	water , and __solid__ bodies , such as glass , or metal , or sonorous wood , convey the modulations with high velocity , and he conceived the plan of transmitting sound-signals , music , or speech to long distances by this means .
Contexts for target solid are: ['amodI_bodies']
Contexts in vocabulary for target solid are: ['amodI_bodies']
Top most similar embeddings: solid 0.50958	grant-awarding 0.38821	structureless 0.37688	gelatinous 0.37479	glass-like 0.36887	jelly-like 0.36875	bikini-clad 0.36706	luminescent 0.36629	disc-shaped 0.36577	touchable 0.36542

Generated lemmatized results
***************
GENERATED	solid.a 1081 ::: structureless;gelatinous;luminescent;touchable;fusible;carbonaceous;rigid;demountable;cartilaginous;vaporous

Filtered results
***************
RANKED	solid.a 1081	solid 0.50958	rigid 0.36433	sturdy 0.34601	substantial 0.33719	strong 0.33594	respectable 0.32526	firm 0.32368	stable 0.32161	concrete 0.31909	substantive 0.31861	sound 0.31803	dependable 0.30700	reliable 0.30401	hard 0.30113	convincing 0.29830	genuine 0.29753	good 0.29024	fixed 0.28885	dry 0.28609	accurate 0.28339	cemented 0.27886	secure 0.27507	valid 0.26213	set 0.23665

Test context:
***************
solid.a	1082	19	we are confident , that by signing the treaty , the friendly relationship between the two countries has become __solid__ .
Contexts for target solid are: ['mark_that', 'punct_,', 'nsubj_relationship', 'aux_has', 'cop_become', 'ccompI_confident']
Contexts in vocabulary for target solid are: ['mark_that', 'punct_,', 'nsubj_relationship', 'aux_has', 'cop_become', 'ccompI_confident']
Top most similar embeddings: solid 0.01191	commoditised 0.01103	politicized 0.01052	under-explored 0.01051	cheapened 0.01051	stable 0.01046	stronger 0.01034	untarnished 0.01033	top-heavy 0.01033	ossified 0.01031

Generated lemmatized results
***************
GENERATED	solid.a 1082 ::: commoditised;politicized;cheapened;stable;strong;untarnished;ossified;tenuous;unstable;maladministrative

Filtered results
***************
RANKED	solid.a 1082	solid 0.01191	stable 0.01046	strong 0.01034	firm 0.00943	cemented 0.00884	rigid 0.00863	reliable 0.00847	accurate 0.00838	dependable 0.00815	hard 0.00792	sturdy 0.00785	valid 0.00778	genuine 0.00774	convincing 0.00763	respectable 0.00762	dry 0.00744	fixed 0.00729	secure 0.00716	good 0.00707	substantial 0.00694	sound 0.00610	concrete 0.00567	set 0.00549	substantive 0.00541

Test context:
***************
solid.a	1083	13	glacius - pour some water into your hand and cause it to freeze __solid__ !
Contexts for target solid are: ['dobjI_freeze']
Contexts in vocabulary for target solid are: ['dobjI_freeze']
Top most similar embeddings: solid 0.50900	semi-solid 0.35764	liquid 0.33872	rubbery 0.33772	rock-hard 0.33166	steady 0.32915	solids 0.32706	stable 0.32683	shaky 0.32638	devilstick 0.32571

Generated lemmatized results
***************
GENERATED	solid.a 1083 ::: liquid;rubbery;steady;solids;stable;shaky;devilstick;glassy;laggy;eutectic

Filtered results
***************
RANKED	solid.a 1083	solid 0.50900	stable 0.32683	sturdy 0.31869	rigid 0.30883	strong 0.30827	concrete 0.30504	firm 0.30037	substantial 0.29428	substantive 0.29190	sound 0.28735	dry 0.28618	respectable 0.28436	dependable 0.28355	reliable 0.28340	hard 0.28238	good 0.28052	convincing 0.27910	secure 0.27460	accurate 0.27202	fixed 0.27134	cemented 0.26523	genuine 0.26146	valid 0.24941	set 0.24542

Test context:
***************
solid.a	1084	19	thus , when she attempts to interact with the world outside the family , she finds herself without a __solid__ identity - this is well expressed in her intuitive desire to hide from the gaze of those who do not understand her by hiding in cupboards or under beds .
Contexts for target solid are: ['amodI_identity']
Contexts in vocabulary for target solid are: ['amodI_identity']
Top most similar embeddings: solid 0.48877	rock-solid 0.38163	post-national 0.36188	strong 0.36060	multilayered 0.35999	cohesive 0.35899	syncretic 0.35598	iron-clad 0.35563	state-based 0.35435	unshakeable 0.35339

Generated lemmatized results
***************
GENERATED	solid.a 1084 ::: strong;multilayered;cohesive;syncretic;unshakeable;multiracial;associational;lockean;coherent;robust

Filtered results
***************
RANKED	solid.a 1084	solid 0.48877	strong 0.36060	stable 0.34542	firm 0.34008	rigid 0.33894	substantive 0.32509	sturdy 0.32481	sound 0.32363	substantial 0.31999	concrete 0.31858	genuine 0.31855	respectable 0.31380	convincing 0.31161	dependable 0.30928	secure 0.30689	fixed 0.30637	reliable 0.30226	accurate 0.29710	valid 0.29648	good 0.28960	cemented 0.28892	hard 0.28150	dry 0.25283	set 0.23735

Test context:
***************
solid.a	1085	45	it is not only necessary ' the internet as a meaningful phenomenon only exists in particular places ' but it is also the only firm basis for building up the bigger generalisations and abstractions : quite simply , one can use this particularism as a __solid__ grounding for comparative ethnography .
Contexts for target solid are: ['amodI_grounding']
Contexts in vocabulary for target solid are: ['amodI_grounding']
Top most similar embeddings: solid 0.55156	rock-solid 0.39257	thorough 0.36874	strong 0.36135	shaky 0.35804	theoretical 0.35736	excellent 0.35498	water-tight 0.35291	well-rounded 0.35144	robust 0.35069

Generated lemmatized results
***************
GENERATED	solid.a 1085 ::: thorough;strong;shaky;theoretical;excellent;robust;good;firm;unshakeable;semantical

Filtered results
***************
RANKED	solid.a 1085	solid 0.55156	strong 0.36135	good 0.35059	firm 0.34952	sound 0.34735	sturdy 0.34484	rigid 0.34394	substantial 0.34320	substantive 0.33757	stable 0.33237	concrete 0.31602	reliable 0.31370	secure 0.30926	respectable 0.30854	dependable 0.30596	genuine 0.30430	convincing 0.30160	accurate 0.30073	valid 0.28648	hard 0.28307	dry 0.27738	cemented 0.27536	fixed 0.26821	set 0.22697

Test context:
***************
solid.a	1086	16	when an abacus is constructed , it is given a certain number of beads , a __solid__ frame , and poles on which the beads slide up and down .
Contexts for target solid are: ['amodI_frame']
Contexts in vocabulary for target solid are: ['amodI_frame']
Top most similar embeddings: solid 0.53807	four-sided 0.39541	y-shaped 0.39298	chrome-plated 0.39284	sturdy 0.39173	extra-wide 0.39151	ten-foot 0.39099	nickel-plated 0.39019	carbon-fibre 0.38922	shock-absorbing 0.38901

Generated lemmatized results
***************
GENERATED	solid.a 1086 ::: sturdy;rubberized;clumpy;darkish;ebonised;vaporous;rubberised;sinewy;fusible;flattish

Filtered results
***************
RANKED	solid.a 1086	solid 0.53807	sturdy 0.39173	rigid 0.37045	strong 0.35523	stable 0.35167	concrete 0.34638	substantial 0.34502	firm 0.33422	sound 0.33409	respectable 0.32040	good 0.31221	substantive 0.31157	fixed 0.30835	dependable 0.30358	genuine 0.30193	accurate 0.29769	convincing 0.29736	hard 0.29702	reliable 0.29598	secure 0.29546	cemented 0.29298	valid 0.29250	dry 0.28309	set 0.26495

Test context:
***************
solid.a	1087	5	huge areas that had been __solid__ enough for camping a day earlier were now saturated with water .
Contexts for target solid are: ['nsubj_that', 'aux_had', 'cop_been', 'rcmodI_areas', 'advmod_enough']
Contexts in vocabulary for target solid are: ['nsubj_that', 'aux_had', 'cop_been', 'rcmodI_areas', 'advmod_enough']
Top most similar embeddings: solid 0.02429	under-explored 0.02092	hard-hit 0.02084	well-studied 0.02076	strong 0.02073	rotted 0.02057	corroded 0.02019	manured 0.02015	heat-treated 0.02010	stable 0.02005

Generated lemmatized results
***************
GENERATED	solid.a 1087 ::: strong;rotted;corroded;manured;stable;bleached;compacted;accreted;unfrozen;stagnant

Filtered results
***************
RANKED	solid.a 1087	solid 0.02429	strong 0.02073	stable 0.02005	good 0.01754	rigid 0.01713	firm 0.01707	hard 0.01693	respectable 0.01667	convincing 0.01658	cemented 0.01641	dry 0.01615	sturdy 0.01595	substantial 0.01591	reliable 0.01549	dependable 0.01503	accurate 0.01498	genuine 0.01360	secure 0.01358	fixed 0.01323	substantive 0.01312	valid 0.01308	sound 0.01271	concrete 0.01199	set 0.01069

Test context:
***************
solid.a	1088	14	clearly , that was not our intent in publishing what we thought was a __solid__ news item .
Contexts for target solid are: ['amodI_item']
Contexts in vocabulary for target solid are: ['amodI_item']
Top most similar embeddings: solid 0.49685	near-identical 0.37075	nickel-plated 0.36898	semi-solid 0.36645	non-perishable 0.36608	semi-finished 0.36493	unlabeled 0.36469	super-duper 0.36351	silver-plated 0.36341	single-line 0.36189

Generated lemmatized results
***************
GENERATED	solid.a 1088 ::: unlabeled;orignal;bimetallic;vaporous;resealable;origional;trivalent;unreferenced;fusible;immoveable

Filtered results
***************
RANKED	solid.a 1088	solid 0.49685	substantial 0.34364	sturdy 0.34243	substantive 0.34226	strong 0.32971	sound 0.32746	rigid 0.32702	stable 0.31914	genuine 0.31613	dependable 0.31514	firm 0.31119	good 0.30915	respectable 0.30720	concrete 0.30423	reliable 0.30373	hard 0.29842	fixed 0.29603	accurate 0.29221	valid 0.28530	convincing 0.28483	secure 0.28144	dry 0.28094	cemented 0.27953	set 0.25729

Test context:
***************
solid.a	1089	12	my advice is to get a working version first , write a __solid__ test suite for it , and then start optimizing if you really want to .
Contexts for target solid are: ['amodI_test']
Contexts in vocabulary for target solid are: ['amodI_test']
Top most similar embeddings: solid 0.48419	two-tailed 0.38731	two-point 0.37762	second-stage 0.37750	triaxial 0.37714	intradermal 0.37702	sub-critical 0.37690	dna-based 0.37572	pharmacogenetic 0.37317	first-stage 0.36969

Generated lemmatized results
***************
GENERATED	solid.a 1089 ::: triaxial;intradermal;pharmacogenetic;audiometric;multistage;subcritical;talar;cytometric;fecal;uniaxial

Filtered results
***************
RANKED	solid.a 1089	solid 0.48419	rigid 0.34079	substantial 0.34017	substantive 0.33539	strong 0.33536	reliable 0.33532	firm 0.33152	good 0.33103	sound 0.33102	stable 0.32418	dependable 0.32393	concrete 0.32367	sturdy 0.32221	accurate 0.32194	convincing 0.31601	respectable 0.31461	genuine 0.31447	hard 0.31345	valid 0.30213	dry 0.29198	secure 0.28727	fixed 0.28363	cemented 0.27362	set 0.25126

Test context:
***************
solid.a	1090	13	so for us it is mainly individual and anecdotal evidence , which is __solid__ , but which i cannot disclose .
Contexts for target solid are: ['nsubj_which', 'cop_is', 'depI_individual', 'punct_,', 'cc_but', 'conj_disclose']
Contexts in vocabulary for target solid are: ['nsubj_which', 'cop_is', 'depI_individual', 'punct_,', 'cc_but', 'conj_disclose']
Top most similar embeddings: unarguable 0.01036	solid 0.00996	self-existent 0.00968	unobjectionable 0.00966	non-binding 0.00962	non-flammable 0.00958	predicable 0.00953	odorless 0.00947	impermanent 0.00944	laudable 0.00943

Generated lemmatized results
***************
GENERATED	solid.a 1090 ::: unarguable;unobjectionable;predicable;odorless;impermanent;laudable;disclosable;perceivable;unknowable;unexceptionable

Filtered results
***************
RANKED	solid.a 1090	solid 0.00996	rigid 0.00816	accurate 0.00807	stable 0.00804	reliable 0.00797	valid 0.00765	hard 0.00757	convincing 0.00741	strong 0.00739	dependable 0.00738	respectable 0.00732	firm 0.00732	cemented 0.00717	sturdy 0.00703	sound 0.00683	genuine 0.00679	dry 0.00665	secure 0.00652	substantial 0.00648	good 0.00635	substantive 0.00575	concrete 0.00558	fixed 0.00533	set 0.00505

Test context:
***************
strong.a	1091	13	follow the process by watering your garden and your grass should grow back __strong__ and green in no time .
Contexts for target strong are: ['advmod_back', 'acompI_grow', 'cc_and', 'conj_green']
Contexts in vocabulary for target strong are: ['advmod_back', 'acompI_grow', 'cc_and', 'conj_green']
Top most similar embeddings: strong 0.05379	stronger 0.04690	weak 0.04367	stiff 0.04228	supple 0.04164	lean 0.04121	weaker 0.04065	stong 0.03967	tall 0.03967	rich 0.03935

Generated lemmatized results
***************
GENERATED	strong.a 1091 ::: weak;stiff;supple;lean;stong;tall;rich;bright;gnarled;yellowy

Filtered results
***************
RANKED	strong.a 1091	healthy 0.03864	vigorous 0.03825	resilient 0.03742	robust 0.03734	dark 0.03728	sturdy 0.03699	bitter 0.03687	powerful 0.03667	durable 0.03661	tough 0.03654	firm 0.03650	heavy 0.03579	resolute 0.03541	forceful 0.03487	intense 0.03450	hardy 0.03347	solid 0.03301	clear 0.03154	dependable 0.03127	pronounced 0.03053	potent 0.03035	high 0.03033	compelling 0.02991	keen 0.02961	good 0.02960	concentrated 0.02909	persuasive 0.02884	distinct 0.02881	secure 0.02787	sound 0.02753	capable 0.02730	effective 0.02719	convincing 0.02701	masterful 0.02640

Test context:
***************
strong.a	1092	6	the chain will only be as __strong__ as its weakest link .
Contexts for target strong are: ['nsubj_chain', 'aux_will', 'advmod_only', 'cop_be', 'advmod_as', 'rootI_*root*', 'prep:as_link', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target strong are: ['nsubj_chain', 'aux_will', 'advmod_only', 'cop_be', 'advmod_as', 'rootI_*root*', 'prep:as_link', 'punct_.']
Top most similar embeddings: strong 0.00354	weak 0.00248	visible 0.00247	avaialble 0.00243	visable 0.00242	stronger 0.00239	available 0.00238	availible 0.00236	pre-populated 0.00229	valid 0.00227

Generated lemmatized results
***************
GENERATED	strong.a 1092 ::: weak;visible;avaialble;visable;available;availible;valid;avilable;evident;discernible

Filtered results
***************
RANKED	strong.a 1092	effective 0.00224	robust 0.00220	tough 0.00209	powerful 0.00206	resilient 0.00203	keen 0.00200	capable 0.00199	good 0.00197	pronounced 0.00194	durable 0.00191	resolute 0.00188	persuasive 0.00186	vigorous 0.00184	convincing 0.00182	forceful 0.00181	sturdy 0.00181	intense 0.00181	clear 0.00176	solid 0.00173	potent 0.00171	concentrated 0.00171	secure 0.00164	distinct 0.00162	compelling 0.00159	firm 0.00159	healthy 0.00153	dependable 0.00152	bitter 0.00149	heavy 0.00143	hardy 0.00143	high 0.00139	dark 0.00135	masterful 0.00128	sound 0.00126

Test context:
***************
strong.a	1093	5	scotland 's long coastline and __strong__ winds , and its experience with offshore developments through the oil industry , make it one of the most attractive locations in europe for wave-power stations .
Contexts for target strong are: ['amodI_winds']
Contexts in vocabulary for target strong are: ['amodI_winds']
Top most similar embeddings: strong 0.54702	stronger 0.43621	gale-force 0.43140	stong 0.42545	strongest 0.41341	northeasterly 0.40541	southwesterly 0.40170	e'ly 0.40051	weak 0.39600	thermospheric 0.39455

Generated lemmatized results
***************
GENERATED	strong.a 1093 ::: stong;northeasterly;southwesterly;weak;thermospheric;northwesterly;geostrophic;fierce;lowish;forceful

Filtered results
***************
RANKED	strong.a 1093	forceful 0.37747	powerful 0.37722	vigorous 0.36069	intense 0.35463	high 0.35367	heavy 0.34967	tough 0.34891	robust 0.34836	potent 0.34322	firm 0.33915	sturdy 0.33848	bitter 0.33197	resilient 0.33166	good 0.33081	resolute 0.32866	solid 0.32814	persuasive 0.32226	sound 0.31853	durable 0.31813	healthy 0.31574	compelling 0.31347	distinct 0.31133	dependable 0.30812	keen 0.30591	dark 0.30532	clear 0.30377	pronounced 0.30048	hardy 0.30020	convincing 0.30002	capable 0.29599	masterful 0.29384	effective 0.29030	concentrated 0.28114	secure 0.25641

Test context:
***************
strong.a	1094	4	however , there is __strong__ anecdotal evidence , from students , to suggest that it is not as valued as it once was by employers .
Contexts for target strong are: ['amodI_evidence']
Contexts in vocabulary for target strong are: ['amodI_evidence']
Top most similar embeddings: strong 0.53265	stronger 0.42027	strongest 0.41768	weak 0.40971	stong 0.40431	extrabiblical 0.40008	palaeo-environmental 0.39895	uncorroborated 0.39551	robust 0.39333	firmest 0.39333

Generated lemmatized results
***************
GENERATED	strong.a 1094 ::: weak;stong;extrabiblical;uncorroborated;robust;firm;corroborative;artifactual;irrefutable;undisputable

Filtered results
***************
RANKED	strong.a 1094	robust 0.39333	firm 0.39333	powerful 0.37535	compelling 0.37224	solid 0.36573	persuasive 0.36544	sound 0.36481	forceful 0.36262	good 0.35261	convincing 0.35145	vigorous 0.34640	potent 0.34599	clear 0.33729	sturdy 0.33650	resilient 0.33470	tough 0.33421	resolute 0.33043	intense 0.32557	durable 0.32327	high 0.32171	dependable 0.32076	healthy 0.31982	distinct 0.31979	heavy 0.31185	effective 0.30709	keen 0.29958	bitter 0.29939	capable 0.29887	masterful 0.29801	dark 0.29410	pronounced 0.29258	secure 0.29063	hardy 0.28228	concentrated 0.27667

Test context:
***************
strong.a	1095	4	the database is particularly __strong__ in american and british families .
Contexts for target strong are: ['nsubj_database', 'cop_is', 'advmod_particularly', 'rootI_*root*', 'prep:in_families', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target strong are: ['nsubj_database', 'cop_is', 'advmod_particularly', 'rootI_*root*', 'prep:in_families', 'punct_.']
Top most similar embeddings: strong 0.01281	well-represented 0.01086	evident 0.01081	well-suited 0.01069	problematic 0.01057	useful 0.01039	weak 0.01033	prevalent 0.01033	well-endowed 0.01031	rife 0.01026

Generated lemmatized results
***************
GENERATED	strong.a 1095 ::: evident;problematic;useful;weak;prevalent;rife;important;noticeable;abundant;noteworthy

Filtered results
***************
RANKED	strong.a 1095	keen 0.00943	resilient 0.00926	robust 0.00913	concentrated 0.00910	pronounced 0.00908	tough 0.00871	powerful 0.00849	intense 0.00839	effective 0.00819	capable 0.00795	potent 0.00794	hardy 0.00789	good 0.00778	persuasive 0.00778	clear 0.00769	durable 0.00755	heavy 0.00754	compelling 0.00751	distinct 0.00746	vigorous 0.00742	sturdy 0.00732	convincing 0.00732	resolute 0.00731	forceful 0.00726	masterful 0.00710	dependable 0.00709	high 0.00706	healthy 0.00699	firm 0.00662	secure 0.00657	bitter 0.00650	dark 0.00629	solid 0.00627	sound 0.00588

Test context:
***************
strong.a	1096	6	that means norway must send a __strong__ signal .
Contexts for target strong are: ['amodI_signal']
Contexts in vocabulary for target strong are: ['amodI_signal']
Top most similar embeddings: strong 0.53496	stronger 0.43055	weak 0.42776	strongest 0.42413	stong 0.42220	weaker 0.39191	powerful 0.38758	receptor-mediated 0.37995	robust 0.37852	mitogenic 0.37850

Generated lemmatized results
***************
GENERATED	strong.a 1096 ::: weak;stong;powerful;robust;mitogenic;thermospheric;lowish;vestigial;undamped;forceful

Filtered results
***************
RANKED	strong.a 1096	powerful 0.38758	robust 0.37852	forceful 0.36448	potent 0.36077	good 0.34965	firm 0.34876	vigorous 0.34789	solid 0.34434	intense 0.34082	sturdy 0.33929	clear 0.33760	high 0.33662	distinct 0.33576	tough 0.33349	resilient 0.33123	compelling 0.33043	persuasive 0.32874	sound 0.32686	healthy 0.32364	resolute 0.32251	heavy 0.32194	durable 0.31364	capable 0.31041	pronounced 0.31008	convincing 0.30893	effective 0.30837	dark 0.30497	dependable 0.30421	concentrated 0.30025	keen 0.29714	bitter 0.29388	secure 0.29119	masterful 0.28400	hardy 0.27790

Test context:
***************
strong.a	1097	5	try a beer with a __strong__ fruity flavor ; raspberry and peach are good choices .
Contexts for target strong are: ['amodI_flavor']
Contexts in vocabulary for target strong are: ['amodI_flavor']
Top most similar embeddings: strong 0.52828	stronger 0.41889	stong 0.41395	strongest 0.40360	malty 0.40068	yeasty 0.39694	weak 0.39491	biscuity 0.39191	full-flavoured 0.39020	zingy 0.38765

Generated lemmatized results
***************
GENERATED	strong.a 1097 ::: stong;malty;yeasty;weak;biscuity;zingy;zesty;plummy;tannic;oaky

Filtered results
***************
RANKED	strong.a 1097	robust 0.37137	powerful 0.36762	intense 0.36191	potent 0.35636	forceful 0.35376	distinct 0.34770	firm 0.34758	solid 0.34601	vigorous 0.34350	good 0.34251	compelling 0.33928	resolute 0.33553	heavy 0.33387	sound 0.33167	tough 0.33066	sturdy 0.32991	persuasive 0.32901	bitter 0.32837	resilient 0.32665	pronounced 0.31958	dark 0.31764	durable 0.31628	masterful 0.31576	healthy 0.30645	convincing 0.30575	high 0.30430	concentrated 0.30087	keen 0.29901	hardy 0.29724	dependable 0.29631	clear 0.29313	effective 0.28971	capable 0.27677	secure 0.26197

Test context:
***************
strong.a	1098	25	this race is about leadership , and i have clearly demonstrated throughout my career that i have the courage and determination needed to be a __strong__ leader .
Contexts for target strong are: ['amodI_leader']
Contexts in vocabulary for target strong are: ['amodI_leader']
Top most similar embeddings: strong 0.51858	weak 0.40316	stronger 0.40163	tory-led 0.39872	stong 0.39680	strongest 0.39421	pro-russian 0.39031	self-professed 0.38842	under-fire 0.38543	powerful 0.38280

Generated lemmatized results
***************
GENERATED	strong.a 1098 ::: weak;stong;powerful;undisputable;forceful;firm;enthusiatic;archetypical;domineering;unshakable

Filtered results
***************
RANKED	strong.a 1098	powerful 0.38280	forceful 0.37879	firm 0.37020	resolute 0.35912	vigorous 0.35144	tough 0.35016	potent 0.35009	resilient 0.34883	good 0.34831	robust 0.34633	sound 0.34018	solid 0.33784	sturdy 0.33651	persuasive 0.33294	effective 0.32725	compelling 0.32558	clear 0.32377	masterful 0.31891	durable 0.31832	capable 0.31817	intense 0.31498	high 0.31461	keen 0.31418	heavy 0.31179	healthy 0.31148	convincing 0.31144	distinct 0.30827	dependable 0.30595	bitter 0.30375	dark 0.29819	hardy 0.29515	pronounced 0.29458	concentrated 0.27944	secure 0.27312

Test context:
***************
strong.a	1099	3	the coffee was __strong__ , had no milk , and as it cooled , large hard flakes began floating to the top like pieces of loose bark .
Contexts for target strong are: ['nsubj_coffee', 'cop_was', 'rootI_*root*', 'punct_,', 'conj_had', 'punct_,', 'cc_and', 'conj_cooled', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target strong are: ['nsubj_coffee', 'cop_was', 'rootI_*root*', 'punct_,', 'conj_had', 'punct_,', 'cc_and', 'conj_cooled', 'punct_.']
Top most similar embeddings: odorless 0.00158	hypo-allergenic 0.00151	uncorked 0.00150	unbolted 0.00147	re-heated 0.00145	strong 0.00141	tingled 0.00139	rationed 0.00138	degreased 0.00138	indestructable 0.00138

Generated lemmatized results
***************
GENERATED	strong.a 1099 ::: odorless;uncorked;unbolted;tingled;rationed;degreased;indestructable;sizzled;odourless;yelped

Filtered results
***************
RANKED	strong.a 1099	heavy 0.00118	tough 0.00117	intense 0.00112	resilient 0.00106	concentrated 0.00106	firm 0.00105	hardy 0.00105	bitter 0.00105	keen 0.00104	pronounced 0.00102	sturdy 0.00102	robust 0.00101	forceful 0.00099	vigorous 0.00098	resolute 0.00096	durable 0.00095	dark 0.00094	clear 0.00092	solid 0.00091	powerful 0.00091	dependable 0.00088	capable 0.00087	persuasive 0.00086	potent 0.00086	masterful 0.00085	good 0.00084	healthy 0.00078	sound 0.00077	convincing 0.00077	compelling 0.00071	effective 0.00070	distinct 0.00065	high 0.00060	secure 0.00057

Test context:
***************
strong.a	1100	5	she had always been the __strong__ one , robert would say , the one who grew up first and who helped him do the same .
Contexts for target strong are: ['amodI_one']
Contexts in vocabulary for target strong are: ['amodI_one']
Top most similar embeddings: strong 0.50099	stronger 0.41511	stong 0.41343	weak 0.40722	strongest 0.39812	weaker 0.39653	fine-looking 0.38357	powerful 0.38115	strange-looking 0.38029	well-tuned 0.37988

Generated lemmatized results
***************
GENERATED	strong.a 1100 ::: stong;weak;powerful;tough;viscious;geniune;fiesty;archetypical;teensy;biggish

Filtered results
***************
RANKED	strong.a 1100	powerful 0.38115	tough 0.37889	robust 0.37052	good 0.36417	forceful 0.36304	firm 0.35869	vigorous 0.35789	sturdy 0.35567	potent 0.35374	solid 0.35073	sound 0.34919	compelling 0.34560	resilient 0.34484	persuasive 0.34452	intense 0.34217	durable 0.33901	resolute 0.33673	heavy 0.33672	healthy 0.33623	distinct 0.32877	dependable 0.32468	high 0.32174	convincing 0.32067	bitter 0.31944	hardy 0.31896	dark 0.31865	capable 0.31657	keen 0.31226	effective 0.31017	masterful 0.30704	clear 0.30520	pronounced 0.29793	secure 0.28498	concentrated 0.28243

Test context:
***************
suffer.v	1101	31	starting a claim the first and most important thing to be aware of is that a negligence claim for physical or psychiatric injuries must be started within three years of you __suffering__ an injury .
Contexts for target suffering are: ['nsubj_you', 'pcompI_of', 'dobj_injury']
Contexts in vocabulary for target suffering are: ['nsubj_you', 'pcompI_of', 'dobj_injury']
Top most similar embeddings: suffering 0.13600	experiencing 0.10136	suffer 0.09590	suffered 0.09581	inflicting 0.09463	receiving 0.09284	staving 0.09279	incurring 0.09083	recieving 0.09019	hurting 0.08818

Generated lemmatized results
***************
GENERATED	suffer.v 1101 ::: experience;inflict;receive;stave;incur;recieving;hurt;perpetrate;aggravate;recover

Filtered results
***************
RANKED	suffer.v 1101	experience 0.10136	encounter 0.08667	have 0.08140	sustain 0.08092	feel 0.07999	accept 0.07992	tolerate 0.07961	endure 0.07878	acquire 0.07701	undergo 0.07504	know 0.07088	bear 0.06406

Test context:
***************
suffer.v	1102	10	opposition political parties like the national league for democracy have __suffered__ even greater restrictions on their activities and any signs of dissent have been ruthlessly crushed .
Contexts for target suffered are: ['nsubj_parties', 'aux_have', 'rootI_*root*', 'dobj_restrictions', 'prep:on_activities', 'cc_and', 'conj_crushed', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target suffered are: ['nsubj_parties', 'aux_have', 'rootI_*root*', 'dobj_restrictions', 'prep:on_activities', 'cc_and', 'conj_crushed', 'punct_.']
Top most similar embeddings: suffered 0.00331	caved 0.00266	endured 0.00261	vacillated 0.00260	survived 0.00242	defied 0.00239	cooperated 0.00236	concentrated 0.00235	clashed 0.00235	faced 0.00235

Generated lemmatized results
***************
GENERATED	suffer.v 1102 ::: cave;endure;vacillate;survive;defy;cooperate;concentrate;clash;face;abdicate

Filtered results
***************
RANKED	suffer.v 1102	endure 0.00261	undergo 0.00213	sustain 0.00200	experience 0.00197	encounter 0.00192	have 0.00191	bear 0.00184	accept 0.00178	acquire 0.00172	tolerate 0.00162	know 0.00143	feel 0.00129

Test context:
***************
suffer.v	1103	21	marianne zammit has a hearing impairment and following a motor vehicle accident in which she fractured her skull she also now __suffers__ short term memory loss and tinitis .
Contexts for target suffers are: ['nsubj_she', 'advmod_also', 'advmod_now', 'rcmodI_skull', 'dobj_loss']
Contexts in vocabulary for target suffers are: ['nsubj_she', 'advmod_also', 'advmod_now', 'rcmodI_skull', 'dobj_loss']
Top most similar embeddings: suffers 0.03480	suffered 0.02641	suffer 0.02521	mourns 0.02361	suffering 0.02189	hastens 0.02178	undergoes 0.02171	feigns 0.02164	eradicates 0.02153	visualises 0.02139

Generated lemmatized results
***************
GENERATED	suffer.v 1103 ::: mourn;hasten;undergo;feign;eradicate;visualise;possess;tolerate;sustain;produce

Filtered results
***************
RANKED	suffer.v 1103	undergo 0.02171	tolerate 0.02129	sustain 0.02127	feel 0.02110	experience 0.02061	endure 0.01998	accept 0.01980	bear 0.01889	know 0.01855	have 0.01797	acquire 0.01634	encounter 0.01622

Test context:
***************
suffer.v	1104	6	these are people who have already __suffered__ a great deal under a repressive regime .
Contexts for target suffered are: ['nsubj_who', 'aux_have', 'advmod_already', 'rcmodI_people', 'dobj_deal', 'prep:under_regime']
Contexts in vocabulary for target suffered are: ['nsubj_who', 'aux_have', 'advmod_already', 'rcmodI_people', 'dobj_deal', 'prep:under_regime']
Top most similar embeddings: suffered 0.01998	endured 0.01556	benefited 0.01467	undergone 0.01319	benefitted 0.01305	suffer 0.01299	overstayed 0.01281	experienced 0.01274	suffering 0.01250	profited 0.01241

Generated lemmatized results
***************
GENERATED	suffer.v 1104 ::: endure;benefit;undergo;overstay;experience;profit;contribute;reap;perish;defraud

Filtered results
***************
RANKED	suffer.v 1104	endure 0.01556	undergo 0.01319	experience 0.01274	sustain 0.01047	have 0.01037	encounter 0.01004	acquire 0.00969	know 0.00854	bear 0.00828	accept 0.00828	tolerate 0.00745	feel 0.00661

Test context:
***************
suffer.v	1105	19	although the mah look family became a strong part of community life in the king valley they had to __suffer__ the occasional racist comments , which must have made life unpleasant at times .
Contexts for target suffer are: ['aux_to', 'xcompI_had', 'dobj_comments']
Contexts in vocabulary for target suffer are: ['aux_to', 'xcompI_had', 'dobj_comments']
Top most similar embeddings: suffer 0.12319	endure 0.10912	abjure 0.09724	re-shoot 0.09611	make 0.09536	retype 0.09315	disavow 0.09312	disgorge 0.09281	conflate 0.09277	retract 0.09209

Generated lemmatized results
***************
GENERATED	suffer.v 1105 ::: endure;abjure;make;retype;disavow;disgorge;conflate;retract;interject;rebut

Filtered results
***************
RANKED	suffer.v 1105	endure 0.10912	undergo 0.08982	tolerate 0.08813	accept 0.08770	have 0.08359	sustain 0.08072	bear 0.07645	acquire 0.07453	know 0.07036	feel 0.06765	experience 0.06757	encounter 0.06436

Test context:
***************
suffer.v	1106	7	in general , these injured workers apparently __suffered__ little or no disruption in their wages .
Contexts for target suffered are: ['prep:in_general', 'punct_,', 'nsubj_workers', 'advmod_apparently', 'rootI_*root*', 'dobj_little', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target suffered are: ['prep:in_general', 'punct_,', 'nsubj_workers', 'advmod_apparently', 'rootI_*root*', 'dobj_little', 'punct_.']
Top most similar embeddings: suffered 0.00754	suffers 0.00623	suffer 0.00600	profited 0.00570	demurred 0.00565	benefited 0.00559	protested 0.00550	declined 0.00542	shrank 0.00540	wavered 0.00540

Generated lemmatized results
***************
GENERATED	suffer.v 1106 ::: profit;demur;benefit;protest;decline;shrink;waver;falter;balk;recoil

Filtered results
***************
RANKED	suffer.v 1106	endure 0.00513	undergo 0.00481	know 0.00462	feel 0.00446	have 0.00446	experience 0.00432	sustain 0.00413	tolerate 0.00411	encounter 0.00403	acquire 0.00397	bear 0.00383	accept 0.00377

Test context:
***************
suffer.v	1107	9	if we deliberately refuse it , then we must __suffer__ the consequence ; and we cannot blame god .
Contexts for target suffer are: ['advcl_refuse', 'advmod_then', 'nsubj_we', 'aux_must', 'rootI_*root*', 'dobj_consequence', 'punct_;', 'cc_and', 'conj_blame', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target suffer are: ['advcl_refuse', 'advmod_then', 'nsubj_we', 'aux_must', 'rootI_*root*', 'dobj_consequence', 'punct_;', 'cc_and', 'conj_blame', 'punct_.']
Top most similar embeddings: suffer 0.00085	bewail 0.00074	deplore 0.00066	abhor 0.00066	confess 0.00063	suffered 0.00062	underrate 0.00061	apologize 0.00060	rejoice 0.00060	vacillate 0.00060

Generated lemmatized results
***************
GENERATED	suffer.v 1107 ::: bewail;deplore;abhor;confess;underrate;apologize;rejoice;vacillate;revile;condemn

Filtered results
***************
RANKED	suffer.v 1107	endure 0.00057	accept 0.00052	tolerate 0.00050	bear 0.00049	undergo 0.00045	feel 0.00045	have 0.00043	know 0.00040	experience 0.00039	encounter 0.00038	sustain 0.00036	acquire 0.00035

Test context:
***************
suffer.v	1108	16	" his cock-sure , sensitive , yet unsentimental voice chronicles the abuses and brutal conditions he __suffers__ in authentic sounding street slang that sounds like the clockwork orange meets one flew over the cuckoo 's nest .
Contexts for target suffers are: ['nsubj_he', 'rcmodI_abuses', 'prep:in_slang']
Contexts in vocabulary for target suffers are: ['nsubj_he', 'rcmodI_abuses', 'prep:in_slang']
Top most similar embeddings: suffers 0.10399	indulges 0.09121	suffered 0.08961	bemoans 0.08685	decries 0.08678	suffer 0.08458	denounces 0.08447	criticizes 0.08373	chides 0.08342	incites 0.08331

Generated lemmatized results
***************
GENERATED	suffer.v 1108 ::: indulge;bemoan;decry;denounce;criticize;chide;incite;speak;complain;confess

Filtered results
***************
RANKED	suffer.v 1108	endure 0.07749	tolerate 0.07544	encounter 0.07189	undergo 0.07108	experience 0.07043	know 0.06897	sustain 0.06838	acquire 0.06495	feel 0.06402	bear 0.06249	accept 0.06200	have 0.05400

Test context:
***************
suffer.v	1109	13	much has been written about the british soldiers of the great war who __suffered__ death by firing squad for the crimes of cowardice or desertion .
Contexts for target suffered are: ['nsubj_who', 'rcmodI_war', 'dobj_death', 'prep:by_squad']
Contexts in vocabulary for target suffered are: ['nsubj_who', 'rcmodI_war', 'dobj_death', 'prep:by_squad']
Top most similar embeddings: suffered 0.06853	endured 0.05204	wreaked 0.05109	suffer 0.05039	fomented 0.05011	inflicted 0.04972	suffers 0.04953	avenged 0.04765	escaped 0.04729	faced 0.04723

Generated lemmatized results
***************
GENERATED	suffer.v 1109 ::: endure;wreak;foment;inflict;avenge;escape;face;risk;witness;mastermind

Filtered results
***************
RANKED	suffer.v 1109	endure 0.05204	undergo 0.04319	sustain 0.04186	experience 0.04170	encounter 0.03760	acquire 0.03466	bear 0.03450	know 0.03412	have 0.03299	tolerate 0.03263	accept 0.03109	feel 0.02879

Test context:
***************
suffer.v	1110	28	when a person buys an insurance policy , the very risks that are insured against make it clear that if a claim is not satisfied the policyholder will __suffer__ financial pressure and emotional distress .
Contexts for target suffer are: ['mark_that', 'advcl_satisfied', 'nsubj_policyholder', 'aux_will', 'ccompI_clear', 'dobj_pressure']
Contexts in vocabulary for target suffer are: ['mark_that', 'advcl_satisfied', 'nsubj_policyholder', 'aux_will', 'ccompI_clear', 'dobj_pressure']
Top most similar embeddings: suffer 0.01452	incur 0.01088	tolerate 0.01040	suffered 0.01029	exert 0.01024	suffers 0.01020	endure 0.01008	prevail 0.01007	reoffend 0.01001	abscond 0.00998

Generated lemmatized results
***************
GENERATED	suffer.v 1110 ::: incur;tolerate;exert;endure;prevail;reoffend;abscond;diminish;jeopardise;withstand

Filtered results
***************
RANKED	suffer.v 1110	tolerate 0.01040	endure 0.01008	accept 0.00931	undergo 0.00922	experience 0.00894	sustain 0.00873	have 0.00829	acquire 0.00777	feel 0.00775	bear 0.00752	encounter 0.00664	know 0.00635

Test context:
***************
tap.v	1111	13	these emotions are difficult to hide , and might reveal themselves in nervous __tapping__ of the feet , or clenched fists .
Contexts for target tapping are: ['amod_nervous', 'prep:inI_reveal', 'prep:of_feet']
Contexts in vocabulary for target tapping are: ['amod_nervous', 'prep:inI_reveal', 'prep:of_feet']
Top most similar embeddings: tapping 0.09876	pattering 0.08439	shuffling 0.08214	pounding 0.07895	whirr 0.07893	jerking 0.07555	pummelling 0.07527	palpation 0.07523	massaging 0.07512	twitches 0.07496

Generated lemmatized results
***************
GENERATED	tap.v 1111 ::: patter;shuffle;pound;whirr;jerk;pummel;palpation;massage;twitch;retch

Filtered results
***************
RANKED	tap.v 1111	pat 0.06762	drum 0.06633	touch 0.06316	rap 0.06266	beat 0.06229	mark 0.05939	knock 0.05696	draw 0.05476	milk 0.05378	strike 0.05281	hit 0.05234	move 0.05124	contact 0.05068	exploit 0.05062	use 0.05056	extract 0.04973	commission 0.04792	syphon 0.04725	approach 0.04643	select 0.04452	choose 0.04368	ask 0.04345	appoint 0.04210	establish 0.04171	utilise 0.04053	recommend 0.03877

Test context:
***************
tap.v	1112	3	george galloway is __tapping__ into the alienation of not just the youth but of many older muslims too and he is using it well .
Contexts for target tapping are: ['nsubj_galloway', 'aux_is', 'rootI_*root*', 'prep:into_alienation', 'cc_but', 'conj_is', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target tapping are: ['nsubj_galloway', 'aux_is', 'rootI_*root*', 'cc_but', 'conj_is', 'punct_.']
Top most similar embeddings: mindblowing 0.01047	concedes 0.01021	tapping 0.01017	admits 0.01008	tapped 0.00987	booming 0.00974	quipped 0.00969	toying 0.00968	digressing 0.00966	hoping 0.00962

Generated lemmatized results
***************
GENERATED	tap.v 1112 ::: mindblowing;concede;admit;boom;quip;toy;digress;hop;exaggerate;champ

Filtered results
***************
RANKED	tap.v 1112	drum 0.00885	rap 0.00881	draw 0.00842	knock 0.00811	hit 0.00804	ask 0.00799	touch 0.00795	pat 0.00780	utilise 0.00774	use 0.00774	strike 0.00768	milk 0.00765	establish 0.00759	recommend 0.00756	approach 0.00745	move 0.00742	beat 0.00741	exploit 0.00739	choose 0.00726	contact 0.00724	mark 0.00718	select 0.00714	appoint 0.00694	extract 0.00686	commission 0.00677	syphon 0.00380

Test context:
***************
tap.v	1113	20	the board is easy to make and resonates , enhancing any sound created by a person lying on it or __tapping__ it .
Contexts for target tapping are: ['conjI_lying', 'dobj_it']
Contexts in vocabulary for target tapping are: ['conjI_lying', 'dobj_it']
Top most similar embeddings: tapping 0.24296	wiggling 0.19981	legging 0.19457	wedging 0.19400	unscrewing 0.19317	waggling 0.19227	hoofing 0.19209	prodding 0.19164	stroking 0.19121	crumpling 0.19048

Generated lemmatized results
***************
GENERATED	tap.v 1113 ::: wiggle;legging;wedge;unscrew;waggle;hoof;prod;stroke;crumple;scrawl

Filtered results
***************
RANKED	tap.v 1113	pat 0.18946	knock 0.17869	touch 0.17430	hit 0.16634	rap 0.16419	use 0.16404	exploit 0.15912	beat 0.15659	milk 0.15515	drum 0.15212	extract 0.14960	move 0.14735	mark 0.14658	utilise 0.14642	select 0.14204	draw 0.14167	approach 0.14139	strike 0.14118	recommend 0.13827	ask 0.13809	choose 0.13224	syphon 0.13171	contact 0.13062	commission 0.12658	appoint 0.12540	establish 0.12282

Test context:
***************
tap.v	1114	27	introduction to the registration scheme resource was launched in april 2000 in order to work with and for museums , archives and libraries within the uk , __tapping__ the potential for collaboration between the sectors .
Contexts for target tapping are: ['partmodI_introduction', 'dobj_potential']
Contexts in vocabulary for target tapping are: ['partmodI_introduction', 'dobj_potential']
Top most similar embeddings: tapping 0.24626	unlocking 0.18737	maximizing 0.17746	harnessing 0.17661	highlighting 0.17575	exemplifying 0.17463	unleashing 0.17426	accenting 0.17394	uncovering 0.17377	examining 0.17352

Generated lemmatized results
***************
GENERATED	tap.v 1114 ::: unlock;maximize;harness;highlight;exemplify;unleash;accent;uncover;examine;underline

Filtered results
***************
RANKED	tap.v 1114	exploit 0.17312	utilise 0.17269	use 0.15765	extract 0.15720	knock 0.15587	draw 0.15452	touch 0.15329	mark 0.15311	drum 0.15168	pat 0.15079	select 0.14712	rap 0.14531	establish 0.14416	hit 0.14116	milk 0.13936	beat 0.13928	approach 0.13833	recommend 0.13617	move 0.13342	choose 0.13200	ask 0.13098	contact 0.13074	commission 0.13014	appoint 0.12911	strike 0.12454	syphon 0.11036

Test context:
***************
tap.v	1115	2	today consumers __tap__ their mortgages through refinancing or more recently through home equity loans .
Contexts for target tap are: ['tmod_today', 'nsubj_consumers', 'rootI_*root*', 'dobj_mortgages', 'prep:through_refinancing', 'advmod_recently', 'prep:through_loans', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target tap are: ['tmod_today', 'nsubj_consumers', 'rootI_*root*', 'dobj_mortgages', 'advmod_recently', 'prep:through_loans', 'punct_.']
Top most similar embeddings: refinanced 0.00505	tap 0.00448	pledged 0.00428	invested 0.00427	remortgaged 0.00424	launched 0.00420	boosted 0.00419	tapped 0.00413	underwrote 0.00410	balked 0.00409

Generated lemmatized results
***************
GENERATED	tap.v 1115 ::: refinance;pledge;invest;remortgaged;launch;boost;underwrite;balk;switch;benefit

Filtered results
***************
RANKED	tap.v 1115	approach 0.00340	contact 0.00339	move 0.00338	choose 0.00338	commission 0.00332	rap 0.00327	ask 0.00322	recommend 0.00318	hit 0.00306	strike 0.00300	drum 0.00299	exploit 0.00296	milk 0.00296	touch 0.00291	draw 0.00290	appoint 0.00290	establish 0.00290	utilise 0.00289	mark 0.00281	use 0.00278	beat 0.00278	pat 0.00273	select 0.00259	knock 0.00256	extract 0.00253	syphon 0.00168

Test context:
***************
tap.v	1116	7	before the hoopla , stephen spielberg had __tapped__ the actor to play the title role in the wwii epic " saving private ryan " ( 1998 ) , which critics heaped with praise for its showy camerawork and impressively staged battle set pieces .
Contexts for target tapped are: ['prep:before_hoopla', 'punct_,', 'nsubj_spielberg', 'aux_had', 'rootI_*root*', 'xcomp_play']
Contexts in vocabulary for target tapped are: ['punct_,', 'nsubj_spielberg', 'aux_had', 'rootI_*root*', 'xcomp_play']
Top most similar embeddings: tapped 0.03215	opted 0.02314	essayed 0.02313	deigned 0.02289	toyed 0.02282	grabbed 0.02277	scouted 0.02259	commandeered 0.02244	dallied 0.02234	proceded 0.02230

Generated lemmatized results
***************
GENERATED	tap.v 1116 ::: opt;essay;deign;toy;grab;scout;commandeer;dally;proceded;juggle

Filtered results
***************
RANKED	tap.v 1116	ask 0.02131	choose 0.01978	approach 0.01970	move 0.01965	knock 0.01938	draw 0.01929	drum 0.01878	rap 0.01868	strike 0.01866	use 0.01866	touch 0.01822	commission 0.01818	select 0.01808	pat 0.01784	beat 0.01765	exploit 0.01764	contact 0.01761	utilise 0.01759	hit 0.01700	establish 0.01632	milk 0.01630	appoint 0.01609	extract 0.01560	recommend 0.01547	mark 0.01506	syphon 0.01043

Test context:
***************
tap.v	1117	4	he 's also been __tapped__ for remixes by franz ferdinand , the organ and grizzly bear ( worth noting here , the grizzly remix appears alongside a remix by my friend phiiliip , who i think works in a very similar vein ) .
Contexts for target tapped are: ['nsubjpass_he', "auxpass_'s", 'advmod_also', 'auxpass_been', 'rootI_*root*', 'prep:for_remixes', 'prep:by_ferdinand', 'punct_,', 'dobj_organ', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target tapped are: ['nsubjpass_he', "auxpass_'s", 'advmod_also', 'auxpass_been', 'rootI_*root*', 'prep:by_ferdinand', 'punct_,', 'dobj_organ', 'punct_.']
Top most similar embeddings: tapped 0.00171	satirized 0.00143	summoned 0.00137	helmed 0.00137	overhauled 0.00137	played 0.00137	knighted 0.00136	courted 0.00136	comissioned 0.00136	criticized 0.00134

Generated lemmatized results
***************
GENERATED	tap.v 1117 ::: satirize;summon;helm;overhaul;play;knight;court;comissioned;criticize;reprise

Filtered results
***************
RANKED	tap.v 1117	touch 0.00126	commission 0.00126	strike 0.00125	approach 0.00122	knock 0.00122	drum 0.00120	beat 0.00114	ask 0.00114	contact 0.00113	move 0.00111	rap 0.00109	hit 0.00109	appoint 0.00108	draw 0.00104	milk 0.00104	establish 0.00103	pat 0.00103	recommend 0.00100	choose 0.00098	use 0.00097	mark 0.00096	select 0.00096	utilise 0.00095	exploit 0.00091	extract 0.00087	syphon 0.00034

Test context:
***************
tap.v	1118	13	if you do n't like gas hydrates , there is energy to be __tapped__ in the ocean 's waves .
Contexts for target tapped are: ['nsubjpass_energy', 'aux_to', 'auxpass_be', 'xcompI_is', 'prep:in_waves']
Contexts in vocabulary for target tapped are: ['nsubjpass_energy', 'aux_to', 'auxpass_be', 'xcompI_is', 'prep:in_waves']
Top most similar embeddings: tapped 0.02923	harnessed 0.02431	funnelled 0.02289	trifled 0.02212	channeled 0.02195	channelled 0.02182	dissipated 0.02157	funneled 0.02141	levered 0.02139	readjusted 0.02116

Generated lemmatized results
***************
GENERATED	tap.v 1118 ::: harness;funnel;trifle;channel;dissipate;lever;readjust;sneeze;disentangle;reabsorb

Filtered results
***************
RANKED	tap.v 1118	utilise 0.01955	exploit 0.01897	use 0.01869	extract 0.01853	draw 0.01813	touch 0.01729	strike 0.01708	knock 0.01690	milk 0.01651	approach 0.01647	drum 0.01621	hit 0.01615	beat 0.01611	select 0.01575	pat 0.01545	move 0.01544	contact 0.01544	establish 0.01539	rap 0.01440	choose 0.01426	mark 0.01393	appoint 0.01376	ask 0.01355	commission 0.01352	recommend 0.01259	syphon 0.01180

Test context:
***************
tap.v	1119	2	if i __tap__ the gas pedal of an ordinary car very hard and release it very quickly , i might get a slight extra buck for a second .
Contexts for target tap are: ['mark_if', 'nsubj_i', 'advclI_get', 'dobj_pedal', 'advmod_hard', 'cc_and', 'conj_release']
Contexts in vocabulary for target tap are: ['mark_if', 'nsubj_i', 'advclI_get', 'dobj_pedal', 'advmod_hard', 'cc_and', 'conj_release']
Top most similar embeddings: tap 0.00843	unclip 0.00770	unhook 0.00737	unbolt 0.00708	pressed 0.00694	exhale 0.00680	wiggled 0.00676	waggle 0.00674	clench 0.00667	unplug 0.00667

Generated lemmatized results
***************
GENERATED	tap.v 1119 ::: unclip;unhook;unbolt;press;exhale;wiggle;waggle;clench;unplug;push

Filtered results
***************
RANKED	tap.v 1119	hit 0.00656	knock 0.00555	touch 0.00508	milk 0.00504	rap 0.00500	drum 0.00498	move 0.00480	beat 0.00479	pat 0.00471	syphon 0.00461	select 0.00460	use 0.00447	strike 0.00446	choose 0.00446	approach 0.00420	draw 0.00415	extract 0.00405	exploit 0.00405	utilise 0.00403	ask 0.00378	contact 0.00350	establish 0.00347	mark 0.00346	appoint 0.00341	commission 0.00335	recommend 0.00324

Test context:
***************
tap.v	1120	3	the gains from __tapping__ the creative potential of the work force are phenomenal .
Contexts for target tapping are: ['pcompI_from', 'dobj_potential']
Contexts in vocabulary for target tapping are: ['pcompI_from', 'dobj_potential']
Top most similar embeddings: tapping 0.25953	unlocking 0.19676	monopolizing 0.19000	actualising 0.18656	harnessing 0.18504	nullifying 0.18450	exploiting 0.18448	unleashing 0.18402	enumerating 0.18307	glimpsing 0.18307

Generated lemmatized results
***************
GENERATED	tap.v 1120 ::: unlock;monopolize;actualise;harness;nullify;exploit;unleash;enumerate;glimpse;overuse

Filtered results
***************
RANKED	tap.v 1120	exploit 0.18448	utilise 0.17339	knock 0.16444	extract 0.16441	hit 0.16394	touch 0.16290	use 0.15783	drum 0.15646	milk 0.15538	pat 0.15522	draw 0.15282	rap 0.15263	mark 0.15128	select 0.15091	establish 0.15008	beat 0.15000	approach 0.14243	move 0.14183	contact 0.14142	strike 0.13739	choose 0.13560	appoint 0.13512	commission 0.13453	recommend 0.13417	ask 0.13323	syphon 0.11576

Test context:
***************
therefore.r	1121	8	the different variables defining the optimal state can __therefore__ be seen as intrinsic needs .
Contexts for target therefore are: ['advmodI_seen']
Contexts in vocabulary for target therefore are: ['advmodI_seen']
Top most similar embeddings: therefore 0.52451	consequently 0.44253	futhermore 0.43801	conversely 0.43228	furthermore 0.43047	secondly 0.42634	moreover 0.42580	thus 0.42559	however 0.41959	regretably 0.41925

Generated lemmatized results
***************
GENERATED	therefore.r 1121 ::: consequently;futhermore;conversely;furthermore;secondly;moreover;thus;however;regretably;proably

Filtered results
***************
RANKED	therefore.r 1121	consequently 0.44253	thus 0.42559	hence 0.40822	accordingly 0.36280	so 0.34595

Test context:
***************
therefore.r	1122	38	this is not a new phenomenon , but one inherent to capitalism itself and recognised by karl marx who pointed out that ' during its time of circulation capital does not perform the functions of productive capital and __therefore__ produces neither commodities nor surplus-value ' 16 and , circulation proceeds in space and time .
Contexts for target therefore are: ['advmodI_produces']
Contexts in vocabulary for target therefore are: ['advmodI_produces']
Top most similar embeddings: therefore 0.51978	consequently 0.44648	conversely 0.42799	thus 0.42765	moreover 0.42689	furthermore 0.42641	also 0.42381	secondly 0.41950	futhermore 0.41910	additionally 0.41796

Generated lemmatized results
***************
GENERATED	therefore.r 1122 ::: consequently;conversely;thus;moreover;furthermore;also;secondly;futhermore;additionally;however

Filtered results
***************
RANKED	therefore.r 1122	consequently 0.44648	thus 0.42765	hence 0.40484	accordingly 0.36486	so 0.34033

Test context:
***************
therefore.r	1123	2	the terms __therefore__ seek to preclude plaxo from complying with a request by an individual for alteration or deletion of their personal data .
Contexts for target therefore are: ['advmodI_seek']
Contexts in vocabulary for target therefore are: ['advmodI_seek']
Top most similar embeddings: therefore 0.54015	consequently 0.44943	secondly 0.43733	futhermore 0.43178	furthermore 0.43069	moreover 0.42829	thirdly 0.42829	conversely 0.42585	thus 0.42175	additionally 0.41894

Generated lemmatized results
***************
GENERATED	therefore.r 1123 ::: consequently;secondly;futhermore;furthermore;moreover;thirdly;conversely;thus;additionally;nevertheless

Filtered results
***************
RANKED	therefore.r 1123	consequently 0.44943	thus 0.42175	hence 0.40867	accordingly 0.38082	so 0.34782

Test context:
***************
therefore.r	1124	5	psychologists are not doctors and __therefore__ they cannot prescribe medication .
Contexts for target therefore are: ['advmodI_prescribe']
Contexts in vocabulary for target therefore are: ['advmodI_prescribe']
Top most similar embeddings: therefore 0.51971	consequently 0.42877	thus 0.42244	furthermore 0.42099	moreover 0.41624	however 0.41263	futhermore 0.40787	secondly 0.40522	nevertheless 0.40428	also 0.40072

Generated lemmatized results
***************
GENERATED	therefore.r 1124 ::: consequently;thus;furthermore;moreover;however;futhermore;secondly;nevertheless;also;therfore

Filtered results
***************
RANKED	therefore.r 1124	consequently 0.42877	thus 0.42244	hence 0.39414	accordingly 0.37731	so 0.34402

Test context:
***************
therefore.r	1125	4	labour market deregulation is __therefore__ instrumental in boosting jobs and reducing unemployment .
Contexts for target therefore are: ['advmodI_instrumental']
Contexts in vocabulary for target therefore are: ['advmodI_instrumental']
Top most similar embeddings: therefore 0.50592	consequently 0.43943	secondly 0.42298	thus 0.41900	moreover 0.41866	conversely 0.41708	furthermore 0.41572	also 0.41540	additionally 0.40698	similarly 0.40467

Generated lemmatized results
***************
GENERATED	therefore.r 1125 ::: consequently;secondly;thus;moreover;conversely;furthermore;also;additionally;similarly;nevertheless

Filtered results
***************
RANKED	therefore.r 1125	consequently 0.43943	thus 0.41900	hence 0.40169	accordingly 0.34795	so 0.34639

Test context:
***************
therefore.r	1126	2	you should __therefore__ report the break-in to the police .
Contexts for target therefore are: ['advmodI_report']
Contexts in vocabulary for target therefore are: ['advmodI_report']
Top most similar embeddings: therefore 0.50791	consequently 0.43354	futhermore 0.42832	furthermore 0.42538	conversely 0.42527	moreover 0.41971	secondly 0.41965	however 0.41077	nevertheless 0.40748	thus 0.40733

Generated lemmatized results
***************
GENERATED	therefore.r 1126 ::: consequently;futhermore;furthermore;conversely;moreover;secondly;however;nevertheless;thus;additionally

Filtered results
***************
RANKED	therefore.r 1126	consequently 0.43354	thus 0.40733	hence 0.40255	accordingly 0.38107	so 0.34026

Test context:
***************
therefore.r	1127	1	we __therefore__ oppose the government 's proposals .
Contexts for target therefore are: ['advmodI_oppose']
Contexts in vocabulary for target therefore are: ['advmodI_oppose']
Top most similar embeddings: therefore 0.53277	consequently 0.44186	secondly 0.43161	furthermore 0.42665	moreover 0.42518	conversely 0.42372	futhermore 0.41791	thus 0.41666	fourthly 0.41399	thirdly 0.41378

Generated lemmatized results
***************
GENERATED	therefore.r 1127 ::: consequently;secondly;furthermore;moreover;conversely;futhermore;thus;fourthly;thirdly;nevertheless

Filtered results
***************
RANKED	therefore.r 1127	consequently 0.44186	thus 0.41666	hence 0.40193	accordingly 0.37036	so 0.33601

Test context:
***************
therefore.r	1128	20	this setting exists to prevent accidental ' panning ' on mouse downs that are intended for other actions ( and __therefore__ , prevent unintended changing of the scaling into manual mode ) .
Contexts for target therefore are: ['punct_-lrb-', 'cc_and', 'depI_prevent']
Contexts in vocabulary for target therefore are: ['cc_and', 'depI_prevent']
Top most similar embeddings: thirdly 0.18069	secondly 0.17764	vegetatively 0.17733	antenatally 0.17554	therefore 0.17531	conversely 0.17511	fifthly 0.17173	prayerfully 0.17061	sixthly 0.17034	organizationally 0.17023

Generated lemmatized results
***************
GENERATED	therefore.r 1128 ::: thirdly;secondly;vegetatively;antenatally;conversely;fifthly;prayerfully;sixthly;organizationally;domestically

Filtered results
***************
RANKED	therefore.r 1128	hence 0.16638	consequently 0.15637	accordingly 0.15467	thus 0.13265	so 0.12452

Test context:
***************
therefore.r	1129	2	you will __therefore__ permit me to repeat , emphatically , that marley was as dead as a door-nail .
Contexts for target therefore are: ['advmodI_permit']
Contexts in vocabulary for target therefore are: ['advmodI_permit']
Top most similar embeddings: therefore 0.52751	furthermore 0.44249	consequently 0.44028	secondly 0.43257	moreover 0.43235	futhermore 0.42981	thus 0.42706	conversely 0.42330	however 0.42243	nevertheless 0.42010

Generated lemmatized results
***************
GENERATED	therefore.r 1129 ::: furthermore;consequently;secondly;moreover;futhermore;thus;conversely;however;nevertheless;additionally

Filtered results
***************
RANKED	therefore.r 1129	consequently 0.44028	thus 0.42706	hence 0.39926	accordingly 0.37214	so 0.34097

Test context:
***************
therefore.r	1130	22	they should take note of darius ' admonitions.-- well i think this is ok because they 're part of your race and __therefore__ part of your extended family .
Contexts for target therefore are: ['advmodI_part']
Contexts in vocabulary for target therefore are: ['advmodI_part']
Top most similar embeddings: therefore 0.53529	consequently 0.45508	futhermore 0.42842	secondly 0.42702	moreover 0.42691	furthermore 0.42617	thus 0.42332	conversely 0.41981	additionally 0.41787	however 0.41621

Generated lemmatized results
***************
GENERATED	therefore.r 1130 ::: consequently;futhermore;secondly;moreover;furthermore;thus;conversely;additionally;however;nevertheless

Filtered results
***************
RANKED	therefore.r 1130	consequently 0.45508	thus 0.42332	hence 0.40683	accordingly 0.36665	so 0.34887

Test context:
***************
touch.v	1131	6	they will now reach out to __touch__ bright interesting objects , and toys that make a noise will be shaken deliberately .
Contexts for target touch are: ['aux_to', 'xcompI_reach', 'dobj_objects']
Contexts in vocabulary for target touch are: ['aux_to', 'xcompI_reach', 'dobj_objects']
Top most similar embeddings: touch 0.13047	retrieve 0.08786	unhook 0.08710	caress 0.08692	fixate 0.08673	entangle 0.08664	levitate 0.08624	impregnate 0.08581	vaporise 0.08581	manipulate 0.08516

Generated lemmatized results
***************
GENERATED	touch.v 1131 ::: retrieve;unhook;caress;fixate;entangle;levitate;impregnate;vaporise;manipulate;retreive

Filtered results
***************
RANKED	touch.v 1131	reach 0.08442	move 0.07901	handle 0.07789	infect 0.07292	brush 0.07236	skim 0.07127	meet 0.07085	mention 0.07071	stir 0.06906	consider 0.06747	affect 0.06638	stroke 0.06599	tinge 0.06521	feel 0.06487	accept 0.06419	finger 0.06357	contact 0.06304	alight 0.06298	influence 0.06253	do 0.06211	undertake 0.06106	study 0.05770	on 0.03086

Test context:
***************
touch.v	1132	21	the motto is " using together instead of consuming individually " : the full extent of its potential has only been __touched__ upon by the projects examined here .
Contexts for target touched are: ['nsubj_extent', 'aux_has', 'advmod_only', 'auxpass_been', 'parataxisI_using', 'prep:by_projects']
Contexts in vocabulary for target touched are: ['nsubj_extent', 'aux_has', 'advmod_only', 'auxpass_been', 'parataxisI_using', 'prep:by_projects']
Top most similar embeddings: touched 0.01359	surpassed 0.01050	equalled 0.01041	superceded 0.01030	rivalled 0.01003	exceeded 0.00999	overtaken 0.00985	equaled 0.00984	achieved 0.00975	acheived 0.00957

Generated lemmatized results
***************
GENERATED	touch.v 1132 ::: surpass;equal;supercede;rival;exceed;overtake;achieve;acheived;trigger;exacerbate

Filtered results
***************
RANKED	touch.v 1132	affect 0.00922	reach 0.00898	influence 0.00895	undertake 0.00870	study 0.00800	skim 0.00788	handle 0.00787	stir 0.00787	do 0.00786	meet 0.00782	infect 0.00757	finger 0.00754	mention 0.00742	brush 0.00741	move 0.00721	accept 0.00698	consider 0.00692	contact 0.00675	stroke 0.00610	alight 0.00461	feel 0.00408	tinge 0.00350	on 0.00332

Test context:
***************
touch.v	1133	5	i never expected to be __touched__ by a weird global media event personally .
Contexts for target touched are: ['aux_to', 'auxpass_be', 'xcompI_expected', 'prep:by_event']
Contexts in vocabulary for target touched are: ['aux_to', 'auxpass_be', 'xcompI_expected', 'prep:by_event']
Top most similar embeddings: touched 0.05718	affected 0.04453	fazed 0.04435	placated 0.04383	overawed 0.04315	triggered 0.04308	recompensed 0.04209	overwhelmed 0.04183	cowed 0.04177	ennobled 0.04166

Generated lemmatized results
***************
GENERATED	touch.v 1133 ::: affect;faze;placate;overawe;trigger;recompense;overwhelm;cow;ennoble;reassure

Filtered results
***************
RANKED	touch.v 1133	affect 0.04453	influence 0.03999	stir 0.03980	handle 0.03675	reach 0.03658	undertake 0.03624	infect 0.03576	contact 0.03537	do 0.03536	meet 0.03500	move 0.03435	stroke 0.03335	study 0.03209	brush 0.03197	consider 0.03133	accept 0.03071	skim 0.03069	finger 0.02973	alight 0.02920	mention 0.02841	feel 0.02535	tinge 0.02226	on 0.01465

Test context:
***************
touch.v	1134	14	of course it 's individual savings account of our line entirely -- we never __touch__ criminal cases .
Contexts for target touch are: ['nsubj_we', 'neg_never', 'parataxisI_account', 'dobj_cases']
Contexts in vocabulary for target touch are: ['nsubj_we', 'neg_never', 'parataxisI_account', 'dobj_cases']
Top most similar embeddings: touch 0.04702	touched 0.03963	encountered 0.03543	hypothesize 0.03503	disclose 0.03469	ingest 0.03451	touching 0.03444	presume 0.03437	totted 0.03409	hear 0.03396

Generated lemmatized results
***************
GENERATED	touch.v 1134 ::: encounter;hypothesize;disclose;ingest;presume;tot;hear;argue;underestimate;saw

Filtered results
***************
RANKED	touch.v 1134	mention 0.03283	reach 0.03222	consider 0.03129	handle 0.03127	study 0.03126	accept 0.03040	undertake 0.02968	infect 0.02962	meet 0.02903	feel 0.02870	stroke 0.02779	skim 0.02751	finger 0.02747	stir 0.02743	move 0.02718	do 0.02709	brush 0.02654	alight 0.02514	affect 0.02498	contact 0.02486	tinge 0.02440	influence 0.02438	on 0.01595

Test context:
***************
touch.v	1135	10	there is much ground to cover , and i will __touch__ on each topic only briefly .
Contexts for target touch are: ['nsubj_i', 'aux_will', 'conjI_is', 'prep:on_topic', 'advmod_briefly']
Contexts in vocabulary for target touch are: ['nsubj_i', 'aux_will', 'conjI_is', 'prep:on_topic', 'advmod_briefly']
Top most similar embeddings: touch 0.03651	touched 0.03003	touching 0.02680	touches 0.02665	ruminate 0.02656	dwell 0.02649	recapitulate 0.02591	commentate 0.02532	examine 0.02516	commiserate 0.02516

Generated lemmatized results
***************
GENERATED	touch.v 1135 ::: ruminate;dwell;recapitulate;commentate;examine;commiserate;summarise;expound;dissapoint;discourse

Filtered results
***************
RANKED	touch.v 1135	consider 0.02255	mention 0.02098	feel 0.02038	alight 0.02007	skim 0.02005	infect 0.01985	undertake 0.01980	meet 0.01973	contact 0.01972	study 0.01952	do 0.01946	move 0.01933	reach 0.01932	stir 0.01923	affect 0.01904	tinge 0.01898	brush 0.01887	handle 0.01886	stroke 0.01809	finger 0.01746	accept 0.01733	influence 0.01702	on 0.01492

Test context:
***************
touch.v	1136	26	they also called upon members of the public to alert vets and the authorities of incidents in which cats or dogs are found dead in areas __touched__ by the virus .
Contexts for target touched are: ['partmodI_areas', 'prep:by_virus']
Contexts in vocabulary for target touched are: ['partmodI_areas', 'prep:by_virus']
Top most similar embeddings: touched 0.24085	affected 0.20299	impacted 0.18613	struck 0.18308	caused 0.18128	devastated 0.18065	scarred 0.17806	infected 0.17768	ravaged 0.17764	damaged 0.17630

Generated lemmatized results
***************
GENERATED	touch.v 1136 ::: affect;impact;strike;cause;devastate;scar;infect;ravage;damage;hit

Filtered results
***************
RANKED	touch.v 1136	affect 0.20299	infect 0.17768	influence 0.16321	mention 0.15135	reach 0.14991	study 0.14743	stir 0.14659	undertake 0.13962	finger 0.13839	stroke 0.13739	handle 0.13694	do 0.13544	meet 0.13405	contact 0.13323	consider 0.13312	brush 0.13191	move 0.12792	skim 0.12275	alight 0.12089	accept 0.12065	feel 0.11667	tinge 0.10277	on 0.10275

Test context:
***************
touch.v	1137	18	here are a few quotations : in scientific explanation , you usually go around and around and never __touch__ the heart of the matter .
Contexts for target touch are: ['neg_never', 'conjI_go', 'dobj_heart']
Contexts in vocabulary for target touch are: ['neg_never', 'conjI_go', 'dobj_heart']
Top most similar embeddings: touch 0.12621	touched 0.09876	touches 0.09202	ravish 0.08756	forsakes 0.08648	fondle 0.08493	touching 0.08454	smite 0.08248	forsake 0.08168	dismember 0.08114

Generated lemmatized results
***************
GENERATED	touch.v 1137 ::: ravish;forsake;fondle;smite;dismember;unburden;kiss;darken;pluck;lose

Filtered results
***************
RANKED	touch.v 1137	reach 0.07609	stir 0.06989	feel 0.06979	stroke 0.06894	skim 0.06696	infect 0.06633	move 0.06535	brush 0.06488	mention 0.06463	meet 0.06412	alight 0.06273	finger 0.06157	do 0.06072	affect 0.06055	tinge 0.05993	consider 0.05879	accept 0.05835	handle 0.05812	contact 0.05721	study 0.05550	influence 0.05345	undertake 0.05233	on 0.04731

Test context:
***************
touch.v	1138	25	using the ring stand and the clamp , suspend the thermometer in the water ( be sure the thermometer is secure , and is not __touching__ the beaker ) .
Contexts for target touching are: ['aux_is', 'neg_not', 'conjI_sure', 'dobj_beaker', 'punct_-rrb-']
Contexts in vocabulary for target touching are: ['aux_is', 'neg_not', 'conjI_sure', 'dobj_beaker']
Top most similar embeddings: touching 0.05904	overpowering 0.04054	gripping 0.04044	relenting 0.04043	grasping 0.03976	spooking 0.03972	knowing 0.03968	touched 0.03922	reassuring 0.03896	imagining 0.03888

Generated lemmatized results
***************
GENERATED	touch.v 1138 ::: overpower;grip;relent;grasp;spook;know;reassure;imagine;butter;forget

Filtered results
***************
RANKED	touch.v 1138	mention 0.03680	stroke 0.03641	stir 0.03564	accept 0.03510	reach 0.03341	infect 0.03323	move 0.03263	affect 0.03252	brush 0.03217	feel 0.03082	handle 0.03049	do 0.03026	consider 0.02998	contact 0.02860	skim 0.02832	finger 0.02804	alight 0.02712	study 0.02687	influence 0.02669	meet 0.02657	undertake 0.02339	on 0.02239	tinge 0.02155

Test context:
***************
touch.v	1139	8	these stripes are are continuous and do not __touch__ each other , because adjacent stripes cannot bond to each other .
Contexts for target touch are: ['aux_do', 'neg_not', 'conjI_continuous', 'dobj_other']
Contexts in vocabulary for target touch are: ['aux_do', 'neg_not', 'conjI_continuous', 'dobj_other']
Top most similar embeddings: touch 0.05528	contradict 0.04179	disturb 0.04131	pre-judge 0.04081	overstep 0.04056	intersect 0.04045	exasperate 0.04020	diffract 0.03966	overfill 0.03962	impinge 0.03931

Generated lemmatized results
***************
GENERATED	touch.v 1139 ::: contradict;disturb;overstep;intersect;exasperate;diffract;overfill;impinge;contaminate;interrupt

Filtered results
***************
RANKED	touch.v 1139	affect 0.03680	infect 0.03471	mention 0.03371	reach 0.03288	accept 0.03285	feel 0.03201	meet 0.03147	brush 0.03040	skim 0.02973	consider 0.02917	handle 0.02912	contact 0.02894	influence 0.02846	do 0.02827	stir 0.02822	stroke 0.02787	undertake 0.02768	tinge 0.02727	move 0.02711	finger 0.02638	alight 0.02405	study 0.02401	on 0.02056

Test context:
***************
touch.v	1140	9	the novel showcases capote 's talent for writing comedy __touched__ with remorse , and a story the is charismatic and filled with emotion .
Contexts for target touched are: ['partmodI_talent', 'prep:with_remorse']
Contexts in vocabulary for target touched are: ['partmodI_talent', 'prep:with_remorse']
Top most similar embeddings: touched 0.23499	caressed 0.18791	assailed 0.18220	gripped 0.18176	maddened 0.18085	wracked 0.18016	ensnared 0.17946	stung 0.17857	mesmerized 0.17802	convulsed 0.17770

Generated lemmatized results
***************
GENERATED	touch.v 1140 ::: caress;assail;grip;madden;wrack;ensnare;sting;mesmerize;convulse;torment

Filtered results
***************
RANKED	touch.v 1140	stir 0.16539	finger 0.15660	stroke 0.15515	brush 0.14995	infect 0.14472	alight 0.14117	reach 0.14078	influence 0.13904	affect 0.13704	skim 0.13701	handle 0.12918	mention 0.12849	move 0.12296	meet 0.12224	do 0.12150	tinge 0.11688	contact 0.11526	accept 0.11464	study 0.11453	feel 0.11229	consider 0.11048	undertake 0.10686	on 0.08546

Test context:
***************
worthy.a	1141	17	the same is true if you are using internet newspaper sites : some media outlets can be __worthy__ sources of information and analysis and others are not .
Contexts for target worthy are: ['amodI_sources']
Contexts in vocabulary for target worthy are: ['amodI_sources']
Top most similar embeddings: worthy 0.48296	deserving 0.40306	worthier 0.38819	non-biblical 0.37907	extra-biblical 0.37439	unworthy 0.37356	non-canonical 0.36784	extrabiblical 0.36683	lexicographical 0.36208	non-sustainable 0.35746

Generated lemmatized results
***************
GENERATED	worthy.a 1141 ::: deserving;unworthy;extrabiblical;lexicographical;unimpeachable;bankable;hagiographical;credible;authorative;corroborative

Filtered results
***************
RANKED	worthy.a 1141	deserving 0.40306	reputable 0.34217	worthwhile 0.33739	respectable 0.33561	suitable 0.33155	good 0.32393	charitable 0.32168	admirable 0.32072	creditable 0.31791	laudable 0.31776	commendable 0.31647	excellent 0.31614	befitting 0.31567	trusted 0.31497	acceptable 0.30901	deserved 0.30897	honourable 0.30850	fitting 0.30325	satisfactory 0.29543	righteous 0.29305	beneficial 0.28577

Test context:
***************
worthy.a	1142	13	we are so profoundly ignorant in these matters , so far from anything __worthy__ of the name of science , that one view is just as permissible and just as untrustworthy as the other .
Contexts for target worthy are: ['amodI_anything', 'prep:of_name']
Contexts in vocabulary for target worthy are: ['amodI_anything', 'prep:of_name']
Top most similar embeddings: worthy 0.28169	deserving 0.22289	unworthy 0.22259	worthier 0.20306	undeserving 0.17929	befitting 0.17150	suspicious 0.17111	disreputable 0.17078	indelicate 0.17043	objectionable 0.16976

Generated lemmatized results
***************
GENERATED	worthy.a 1142 ::: deserving;unworthy;undeserving;befitting;suspicious;disreputable;indelicate;objectionable;boastful;proud

Filtered results
***************
RANKED	worthy.a 1142	deserving 0.22289	befitting 0.17150	worthwhile 0.16573	honourable 0.15537	admirable 0.15406	respectable 0.15085	commendable 0.15013	deserved 0.14919	laudable 0.14676	righteous 0.14382	fitting 0.14265	suitable 0.14079	reputable 0.14030	creditable 0.13840	good 0.13673	acceptable 0.13634	charitable 0.13427	trusted 0.12824	satisfactory 0.12729	beneficial 0.11956	excellent 0.11522

Test context:
***************
worthy.a	1143	36	but there has been a good campaign fought by all the candidates and i would like to think that a person taking his place in this house in the next week or two will be a __worthy__ representative of the residents in north vancouver .
Contexts for target worthy are: ['amodI_representative']
Contexts in vocabulary for target worthy are: ['amodI_representative']
Top most similar embeddings: worthy 0.50651	deserving 0.40301	unworthy 0.40062	worthier 0.38146	media-friendly 0.37190	court-appointed 0.37033	highest-ranking 0.37027	directly-elected 0.36921	much-respected 0.36156	longest-serving 0.36133

Generated lemmatized results
***************
GENERATED	worthy.a 1143 ::: deserving;unworthy;archetypical;capable;pseudonymous;traitorous;beleagured;godlike;ostensible;onetime

Filtered results
***************
RANKED	worthy.a 1143	deserving 0.40301	admirable 0.34152	respectable 0.34143	honourable 0.33780	worthwhile 0.33630	creditable 0.33508	befitting 0.33146	commendable 0.33027	suitable 0.32955	laudable 0.31916	deserved 0.31866	reputable 0.31518	excellent 0.31360	trusted 0.30949	good 0.30892	acceptable 0.30689	charitable 0.30671	satisfactory 0.29849	righteous 0.29829	fitting 0.28837	beneficial 0.27694

Test context:
***************
worthy.a	1144	25	nicolson : 1 do n't think that anyone has suggested that in a good number of these amounts , the money is not going toward __worthy__ causes .
Contexts for target worthy are: ['amodI_causes']
Contexts in vocabulary for target worthy are: ['amodI_causes']
Top most similar embeddings: worthy 0.54081	deserving 0.44996	unworthy 0.41341	worthier 0.41256	worthiest 0.39592	worthwhile 0.38307	undeserving 0.36920	ostensible 0.36636	non-natural 0.36447	meritorious 0.36283

Generated lemmatized results
***************
GENERATED	worthy.a 1144 ::: deserving;unworthy;worthwhile;undeserving;ostensible;meritorious;likeliest;noble;uncaused;laudable

Filtered results
***************
RANKED	worthy.a 1144	deserving 0.44996	worthwhile 0.38307	laudable 0.35220	admirable 0.34733	commendable 0.34458	good 0.34101	charitable 0.34054	honourable 0.32980	respectable 0.32783	deserved 0.32199	befitting 0.31926	righteous 0.30848	reputable 0.30795	suitable 0.30757	excellent 0.30493	acceptable 0.30029	fitting 0.29938	creditable 0.29912	satisfactory 0.29093	beneficial 0.28828	trusted 0.28140

Test context:
***************
worthy.a	1145	16	thirty-three-year-old delahaye was a popular figure in the paris office and was talked about as a __worthy__ successor to robert capa .
Contexts for target worthy are: ['amodI_successor']
Contexts in vocabulary for target worthy are: ['amodI_successor']
Top most similar embeddings: worthy 0.55641	unworthy 0.44471	deserving 0.44208	worthier 0.40286	undeserving 0.37687	capable 0.37217	ostensible 0.37049	likeliest 0.36889	much-praised 0.36530	full-blooded 0.35875

Generated lemmatized results
***************
GENERATED	worthy.a 1145 ::: unworthy;deserving;undeserving;capable;ostensible;likeliest;titular;legitimate;archetypical;rightful

Filtered results
***************
RANKED	worthy.a 1145	deserving 0.44208	befitting 0.34908	admirable 0.34900	worthwhile 0.34496	suitable 0.34220	respectable 0.34186	deserved 0.34110	commendable 0.33848	honourable 0.33650	laudable 0.33165	creditable 0.32014	fitting 0.31937	righteous 0.31850	charitable 0.31119	excellent 0.31060	acceptable 0.30542	good 0.30045	satisfactory 0.29657	reputable 0.29121	trusted 0.28189	beneficial 0.27294

Test context:
***************
worthy.a	1146	15	but i pictured carolyn looking just as slender and elegant , appearing at benefits for __worthy__ causes .
Contexts for target worthy are: ['amodI_causes']
Contexts in vocabulary for target worthy are: ['amodI_causes']
Top most similar embeddings: worthy 0.54081	deserving 0.44996	unworthy 0.41341	worthier 0.41256	worthiest 0.39592	worthwhile 0.38307	undeserving 0.36920	ostensible 0.36636	non-natural 0.36447	meritorious 0.36283

Generated lemmatized results
***************
GENERATED	worthy.a 1146 ::: deserving;unworthy;worthwhile;undeserving;ostensible;meritorious;likeliest;noble;uncaused;laudable

Filtered results
***************
RANKED	worthy.a 1146	deserving 0.44996	worthwhile 0.38307	laudable 0.35220	admirable 0.34733	commendable 0.34458	good 0.34101	charitable 0.34054	honourable 0.32980	respectable 0.32783	deserved 0.32199	befitting 0.31926	righteous 0.30848	reputable 0.30795	suitable 0.30757	excellent 0.30493	acceptable 0.30029	fitting 0.29938	creditable 0.29912	satisfactory 0.29093	beneficial 0.28828	trusted 0.28140

Test context:
***************
worthy.a	1147	6	but overall , it makes for __worthy__ listening on a good sound system .
Contexts for target worthy are: ['amodI_listening']
Contexts in vocabulary for target worthy are: ['amodI_listening']
Top most similar embeddings: worthy 0.49289	deserving 0.41696	unworthy 0.38918	worthier 0.38444	worthwhile 0.36520	worth-while 0.35611	below-par 0.35242	interesting 0.35215	tragi-comic 0.35209	geniune 0.35157

Generated lemmatized results
***************
GENERATED	worthy.a 1147 ::: deserving;unworthy;worthwhile;interesting;geniune;undeserving;compelling;enjoyable;studious;prayerful

Filtered results
***************
RANKED	worthy.a 1147	deserving 0.41696	worthwhile 0.36520	commendable 0.33389	good 0.32913	respectable 0.32230	excellent 0.32059	admirable 0.32054	befitting 0.31353	deserved 0.31021	suitable 0.30818	satisfactory 0.30613	creditable 0.30481	laudable 0.30431	honourable 0.30304	charitable 0.29961	acceptable 0.29916	righteous 0.29843	reputable 0.28972	fitting 0.28642	beneficial 0.28444	trusted 0.27425

Test context:
***************
worthy.a	1148	37	it means knowing and loving ourselves enough to open the doors to allow a higher understanding of what the idle half our minds are capable of doing , disciplining ourselves to use the gifts accurately , for __worthy__ purposes .
Contexts for target worthy are: ['amodI_purposes']
Contexts in vocabulary for target worthy are: ['amodI_purposes']
Top most similar embeddings: worthy 0.49481	deserving 0.40276	unworthy 0.40239	worthier 0.38563	propagandistic 0.37431	ignoble 0.36410	non-educational 0.36368	noncommercial 0.36324	nefarious 0.36283	non-charitable 0.36212

Generated lemmatized results
***************
GENERATED	worthy.a 1148 ::: deserving;unworthy;propagandistic;ignoble;noncommercial;nefarious;illustrative;worthwhile;salvific;meritorious

Filtered results
***************
RANKED	worthy.a 1148	deserving 0.40276	worthwhile 0.35996	charitable 0.34795	admirable 0.34757	laudable 0.34107	commendable 0.33478	honourable 0.32773	respectable 0.32234	suitable 0.31959	befitting 0.31886	righteous 0.31341	good 0.30972	acceptable 0.30958	beneficial 0.30904	fitting 0.30722	reputable 0.30372	creditable 0.30251	deserved 0.29742	excellent 0.29585	satisfactory 0.28548	trusted 0.26980

Test context:
***************
worthy.a	1149	31	if babydaddy says he won 't be around for the kid if you are n't sleeping with him , or you fear he won't , ask yourself if he 's a __worthy__ boyfriend or father .
Contexts for target worthy are: ['amodI_boyfriend']
Contexts in vocabulary for target worthy are: ['amodI_boyfriend']
Top most similar embeddings: worthy 0.46957	unworthy 0.39729	deserving 0.38526	half-witted 0.37481	worthier 0.37119	put-upon 0.36864	76-year-old 0.36560	drug-addicted 0.36433	foppish 0.36402	undeserving 0.36245

Generated lemmatized results
***************
GENERATED	worthy.a 1149 ::: unworthy;deserving;foppish;undeserving;lecherous;lovable;archetypical;roguish;traitorous;libidinous

Filtered results
***************
RANKED	worthy.a 1149	deserving 0.38526	respectable 0.33321	admirable 0.33099	honourable 0.32081	befitting 0.31831	suitable 0.31490	commendable 0.31347	worthwhile 0.31258	good 0.30990	deserved 0.30676	righteous 0.30320	laudable 0.30158	charitable 0.29996	excellent 0.29603	creditable 0.29414	fitting 0.29212	acceptable 0.28843	reputable 0.28751	satisfactory 0.28653	trusted 0.28530	beneficial 0.26688

Test context:
***************
worthy.a	1150	9	we fork over cash for all sorts of less __worthy__ things .
Contexts for target worthy are: ['amodI_things']
Contexts in vocabulary for target worthy are: ['amodI_things']
Top most similar embeddings: worthy 0.49900	unworthy 0.41686	worthier 0.41365	deserving 0.39757	certian 0.37607	detestable 0.37565	churchy 0.37452	not-so-good 0.37422	worth-while 0.37236	out-of-the-ordinary 0.37148

Generated lemmatized results
***************
GENERATED	worthy.a 1150 ::: unworthy;deserving;certian;detestable;churchy;mad;kitschy;wordly;needful;unsavory

Filtered results
***************
RANKED	worthy.a 1150	deserving 0.39757	worthwhile 0.36341	admirable 0.35062	commendable 0.34353	good 0.33922	laudable 0.33461	honourable 0.33120	befitting 0.32705	respectable 0.32658	deserved 0.32257	righteous 0.32016	creditable 0.31536	suitable 0.31174	fitting 0.31123	excellent 0.30685	charitable 0.30124	acceptable 0.30049	beneficial 0.29452	reputable 0.29190	satisfactory 0.28390	trusted 0.27381

Test context:
***************
account.n	1151	20	peter vardy the puzzle of ethics ( fount - harpercollins isbn 0 00 627701 2 ) vardy gives a readable __account__ of the major theories and asks some probing questions without displaying any religous bias .
Contexts for target account are: ['det_a', 'amod_readable', 'dobjI_gives', 'prep:of_theories']
Contexts in vocabulary for target account are: ['det_a', 'amod_readable', 'dobjI_gives', 'prep:of_theories']
Top most similar embeddings: account 0.06855	over-view 0.05322	acount 0.05193	overview 0.05136	refutation 0.04673	explanation 0.04593	critique 0.04477	exposition 0.04411	disquisition 0.04407	explication 0.04387

Generated lemmatized results
***************
GENERATED	account.n 1151 ::: acount;overview;refutation;explanation;critique;exposition;disquisition;explication;conspectus;precis

Filtered results
***************
RANKED	account.n 1151	explanation 0.04593	description 0.04044	narrative 0.03787	synopsis 0.03754	consideration 0.03545	statement 0.03401	balance 0.03311	chronicle 0.03193	ledger 0.02861	report 0.02837	subscriber 0.02708	facility 0.02647	subscription 0.02631	logon 0.02547	asset 0.02524	access 0.02365	fund 0.02342	finance 0.02115

Test context:
***************
account.n	1152	46	( david chaum introduced the term mix to describe a network service that forwards mail after removing standard indications of the source , thus providing anonymous mail. ) the amount of money allows statistical tracing , but this method may be alleviated by establishing a small __account__ at the mix .
Contexts for target account are: ['det_a', 'amod_small', 'dobjI_establishing']
Contexts in vocabulary for target account are: ['det_a', 'amod_small', 'dobjI_establishing']
Top most similar embeddings: account 0.11375	acount 0.10395	exclosure 0.08857	flexaccount 0.08743	toehold 0.08420	sea-port 0.08419	storefront 0.08390	data-base 0.08338	beachhead 0.08331	hot-line 0.08326

Generated lemmatized results
***************
GENERATED	account.n 1152 ::: acount;exclosure;flexaccount;toehold;storefront;beachhead;telecentre;dsfb;foothold;bridgehead

Filtered results
***************
RANKED	account.n 1152	fund 0.07625	facility 0.07499	ledger 0.07320	balance 0.07177	subscription 0.07166	narrative 0.06861	statement 0.06855	explanation 0.06766	consideration 0.06482	description 0.06481	subscriber 0.06461	asset 0.06215	synopsis 0.06118	chronicle 0.06088	logon 0.05936	report 0.05546	finance 0.05490	access 0.05002

Test context:
***************
account.n	1153	14	it is true , of course , that the triangles leave much out of __account__ , but so too--despite their complexity--do the pure theory ' s warped pie-slice figures that are intended to make some allowance for durable capital ( hayek , 1941 : 208 and 211 ) .
Contexts for target account are: ['pcomp:ofI_out']
Contexts in vocabulary for target account are: ['pcomp:ofI_out']
Top most similar embeddings: account 0.49159	acount 0.39665	flexaccount 0.38610	accounts 0.38002	e-savings 0.37813	cityweb 0.36535	e-bond 0.36407	semi-retirement 0.34876	kilter 0.34687	abeyance 0.34579

Generated lemmatized results
***************
GENERATED	account.n 1153 ::: acount;flexaccount;cityweb;kilter;abeyance;famble;cashbook;torpor;mynde;furbs

Filtered results
***************
RANKED	account.n 1153	balance 0.31258	fund 0.31054	consideration 0.30612	ledger 0.30523	narrative 0.29731	explanation 0.29553	subscription 0.29541	asset 0.29105	finance 0.28265	logon 0.27946	statement 0.27932	chronicle 0.27728	subscriber 0.27716	description 0.27567	report 0.27553	facility 0.27265	synopsis 0.27201	access 0.25928

Test context:
***************
account.n	1154	34	a russian oil company said it would halt shipments to a chinese oil company because the russian company is in a tax fight with the russian government , which froze the company 's bank __accounts__ .
Contexts for target accounts are: ['poss_company', 'nn_bank', 'dobjI_froze']
Contexts in vocabulary for target accounts are: ['poss_company', 'nn_bank', 'dobjI_froze']
Top most similar embeddings: accounts 0.15471	account 0.11454	balances 0.09385	acount 0.09024	receivables 0.08914	ledgers 0.08865	borrowings 0.08848	assets 0.08796	e-savings 0.08680	reconciliations 0.08629

Generated lemmatized results
***************
GENERATED	account.n 1154 ::: balance;acount;receivables;ledger;borrowing;asset;reconciliation;payroll;overdraft;atm

Filtered results
***************
RANKED	account.n 1154	balance 0.09385	ledger 0.08865	asset 0.08796	fund 0.08363	finance 0.08319	statement 0.08084	subscription 0.07289	facility 0.06692	report 0.06379	subscriber 0.06170	narrative 0.05911	description 0.05807	explanation 0.05715	consideration 0.05686	logon 0.05378	access 0.05088	synopsis 0.05011	chronicle 0.04945

Test context:
***************
account.n	1155	15	view/download larger image put in shopping basket a nice copy of this fascinating collection of __accounts__ .
Contexts for target accounts are: ['prep:ofI_collection']
Contexts in vocabulary for target accounts are: ['prep:ofI_collection']
Top most similar embeddings: accounts 0.49112	etexts 0.36474	ledgers 0.35819	muniments 0.35782	documentations 0.35757	calotypes 0.35639	newscuttings 0.35565	testimonies 0.35527	handlists 0.35455	autobiographies 0.35429

Generated lemmatized results
***************
GENERATED	account.n 1155 ::: etexts;ledger;muniments;documentation;calotypes;newscuttings;testimony;handlists;autobiography;manuscript

Filtered results
***************
RANKED	account.n 1155	ledger 0.35819	narrative 0.34514	statement 0.34184	report 0.33470	description 0.32323	balance 0.32149	subscription 0.32090	asset 0.31240	explanation 0.30677	fund 0.30554	synopsis 0.30500	finance 0.29239	chronicle 0.29125	facility 0.27509	subscriber 0.26806	access 0.26603	logon 0.26304	consideration 0.26045

Test context:
***************
account.n	1156	5	samba-3 permits use of multiple __account__ database backends .
Contexts for target account are: ['nnI_backends']
Contexts in vocabulary for target account are: []
Top most similar embeddings: account 1.00000	acount 0.83305	accounts 0.80477	flexaccount 0.75760	e-savings 0.74648	e-bond 0.74190	accounted 0.71313	acct 0.70797	cognisance 0.69887	battels 0.69684

Generated lemmatized results
***************
GENERATED	account.n 1156 ::: acount;flexaccount;accounted;acct;cognisance;battels;chatmark;charitycard;cashbook;cwatters

Filtered results
***************
RANKED	account.n 1156	explanation 0.66116	ledger 0.63676	consideration 0.62643	narrative 0.62534	statement 0.62378	fund 0.62181	description 0.62128	balance 0.62069	subscription 0.61658	chronicle 0.60931	subscriber 0.60690	logon 0.60688	report 0.60139	facility 0.60120	asset 0.58898	finance 0.58581	synopsis 0.58327	access 0.57456

Test context:
***************
account.n	1157	11	within a week , scotiabank said that it had frozen some __accounts__ linked to washington 's hit list .
Contexts for target accounts are: ['det_some', 'dobjI_frozen', 'partmod_linked']
Contexts in vocabulary for target accounts are: ['det_some', 'dobjI_frozen', 'partmod_linked']
Top most similar embeddings: accounts 0.12745	account 0.09151	reconciliations 0.08484	ledgers 0.08177	hand-outs 0.08085	budgets 0.08083	tessas 0.08021	payrolls 0.08021	atms 0.07905	funds 0.07859

Generated lemmatized results
***************
GENERATED	account.n 1157 ::: reconciliation;ledger;budget;tessas;payroll;atm;fund;isas;sipps;asset

Filtered results
***************
RANKED	account.n 1157	ledger 0.08177	fund 0.07859	asset 0.07772	balance 0.07309	statement 0.07289	narrative 0.07288	explanation 0.07021	subscription 0.06944	description 0.06866	finance 0.06662	report 0.06482	facility 0.06146	consideration 0.06071	subscriber 0.06025	synopsis 0.05600	access 0.05556	logon 0.05294	chronicle 0.04670

Test context:
***************
account.n	1158	58	effects on social security and the rest of the budget by themselves , the individual accounts in the graham plan would significantly worsen social security 's finances , because the trust fund would lose more from the diversion of payroll taxes to private accounts than it would gain from the reduction in benefits for the holders of those __accounts__ .
Contexts for target accounts are: ['det_those', 'prep:ofI_holders']
Contexts in vocabulary for target accounts are: ['det_those', 'prep:ofI_holders']
Top most similar embeddings: accounts 0.25519	ledgers 0.17749	tessas 0.17525	account 0.17440	cdis 0.17325	certificates 0.17270	benefices 0.17105	authorisations 0.16956	dispensations 0.16928	rectories 0.16912

Generated lemmatized results
***************
GENERATED	account.n 1158 ::: ledger;tessas;cdis;certificate;benefice;authorisation;dispensation;rectory;recognizance;tlds

Filtered results
***************
RANKED	account.n 1158	ledger 0.17749	asset 0.16454	fund 0.16282	statement 0.16245	balance 0.15443	narrative 0.15234	subscription 0.15017	report 0.14794	description 0.14643	finance 0.14592	explanation 0.13609	subscriber 0.13414	facility 0.13396	access 0.12945	consideration 0.12363	synopsis 0.12131	chronicle 0.12086	logon 0.11604

Test context:
***************
account.n	1159	17	q : why do my deposit accounts show current updates as of today , while my loan __accounts__ may show a previous day 's information ?
Contexts for target accounts are: ['poss_my', 'nn_loan', 'nsubjI_show']
Contexts in vocabulary for target accounts are: ['poss_my', 'nn_loan', 'nsubjI_show']
Top most similar embeddings: accounts 0.12236	account 0.09300	ledgers 0.08670	stats 0.08577	e-bond 0.08388	calculations 0.08381	figures 0.08252	e-savings 0.08184	invoices 0.08141	battels 0.08133

Generated lemmatized results
***************
GENERATED	account.n 1159 ::: ledger;stats;calculation;figure;invoice;battels;statistic;acount;paycheck;reconciliation

Filtered results
***************
RANKED	account.n 1159	ledger 0.08670	statement 0.07993	balance 0.07651	finance 0.07586	report 0.07281	description 0.06920	fund 0.06907	explanation 0.06802	asset 0.06524	subscription 0.06511	narrative 0.06389	synopsis 0.06032	facility 0.05990	subscriber 0.05940	consideration 0.05810	chronicle 0.05653	logon 0.05578	access 0.05216

Test context:
***************
account.n	1160	27	in 1986 , the bank again busted sanctions by indirectly lending to pretoria , via the lesotho highlands water project , using a special london trust fund __account__ to accomplish the stunt .
Contexts for target account are: ['det_a', 'amod_special', 'amod_london', 'nn_trust', 'nn_fund', 'dobjI_using']
Contexts in vocabulary for target account are: ['det_a', 'amod_special', 'amod_london', 'nn_trust', 'nn_fund', 'dobjI_using']
Top most similar embeddings: account 0.01391	acount 0.01044	charitycard 0.01042	accounts 0.00967	flexaccount 0.00952	phonecard 0.00931	isa 0.00917	fund 0.00910	chequebook 0.00904	calculator 0.00903

Generated lemmatized results
***************
GENERATED	account.n 1160 ::: acount;charitycard;flexaccount;phonecard;isa;fund;chequebook;calculator;sipp;voucher

Filtered results
***************
RANKED	account.n 1160	fund 0.00910	facility 0.00814	subscription 0.00761	ledger 0.00741	report 0.00715	statement 0.00709	asset 0.00705	consideration 0.00701	description 0.00676	balance 0.00655	subscriber 0.00654	finance 0.00615	explanation 0.00605	logon 0.00604	chronicle 0.00566	synopsis 0.00540	narrative 0.00505	access 0.00498

Test context:
***************
acquire.v	1161	4	thus , the analyst __acquires__ knowledge about the nature of the patient through an awareness of something going on in him .
Contexts for target acquires are: ['advmod_thus', 'punct_,', 'nsubj_analyst', 'rootI_*root*', 'dobj_knowledge', 'prep:through_awareness', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target acquires are: ['advmod_thus', 'punct_,', 'nsubj_analyst', 'rootI_*root*', 'dobj_knowledge', 'prep:through_awareness', 'punct_.']
Top most similar embeddings: acquires 0.00822	assumes 0.00635	develops 0.00622	augments 0.00621	generalizes 0.00615	evinces 0.00607	assimilates 0.00603	furthers 0.00602	extrapolates 0.00599	possesses 0.00597

Generated lemmatized results
***************
GENERATED	acquire.v 1161 ::: assume;develop;augment;generalize;evince;assimilate;further;extrapolate;possess;posit

Filtered results
***************
RANKED	acquire.v 1161	achieve 0.00550	obtain 0.00547	learn 0.00517	procure 0.00486	gain 0.00471	gather 0.00457	receive 0.00431	amass 0.00429	secure 0.00428	find 0.00427	collect 0.00404	get 0.00374	buy 0.00367	purchase 0.00286

Test context:
***************
acquire.v	1162	16	a subsidiary was floated in the uk , tata tea ( gb ) ltd. , which __acquired__ the controlling interest in the tetley group .
Contexts for target acquired are: ['nsubj_which', 'rcmodI_ltd.', 'dobj_interest']
Contexts in vocabulary for target acquired are: ['nsubj_which', 'rcmodI_ltd.', 'dobj_interest']
Top most similar embeddings: acquired 0.12517	acquires 0.10216	aquired 0.09904	underwrites 0.09506	owns 0.09245	acquire 0.09044	demerged 0.08916	pre-dated 0.08913	sells 0.08899	underwrote 0.08853

Generated lemmatized results
***************
GENERATED	acquire.v 1162 ::: aquired;underwrite;own;demerged;sell;retain;rekindle;purchase;repurchase;procure

Filtered results
***************
RANKED	acquire.v 1162	purchase 0.08572	procure 0.08539	buy 0.08467	gain 0.08222	amass 0.07842	secure 0.07838	obtain 0.07654	receive 0.07543	achieve 0.07165	collect 0.07156	gather 0.06767	find 0.06293	get 0.06144	learn 0.06055

Test context:
***************
acquire.v	1163	15	with the offer now completed , 2016091 ontario inc. will proceed with further steps to __acquire__ the remaining ixos shares not owned by it , in accordance with german law .
Contexts for target acquire are: ['aux_to', 'infmodI_steps', 'dobj_shares']
Contexts in vocabulary for target acquire are: ['aux_to', 'infmodI_steps', 'dobj_shares']
Top most similar embeddings: acquire 0.15194	aquire 0.10969	revalue 0.10909	divest 0.10489	enfranchise 0.10234	commercialize 0.10209	obtain 0.10162	expropriate 0.10110	mass-produce 0.10072	rehouse 0.10036

Generated lemmatized results
***************
GENERATED	acquire.v 1163 ::: aquire;revalue;divest;enfranchise;commercialize;obtain;expropriate;rehouse;deregister;remediate

Filtered results
***************
RANKED	acquire.v 1163	obtain 0.10162	procure 0.09352	buy 0.09186	purchase 0.09176	achieve 0.09154	amass 0.09090	gain 0.08815	receive 0.08581	collect 0.08535	secure 0.08459	get 0.08341	learn 0.07881	find 0.07848	gather 0.07552

Test context:
***************
acquire.v	1164	4	teacher education students will __acquire__ the knowledge and skills required to apply current and emerging educational technologies both as teachers in training and as practicing teachers .
Contexts for target acquire are: ['nsubj_students', 'aux_will', 'rootI_*root*', 'dobj_knowledge', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target acquire are: ['nsubj_students', 'aux_will', 'rootI_*root*', 'dobj_knowledge', 'punct_.']
Top most similar embeddings: acquire 0.03392	acquired 0.02704	possess 0.02599	posses 0.02539	demonstrate 0.02491	require 0.02471	have 0.02434	receive 0.02408	apply 0.02406	accumulate 0.02404

Generated lemmatized results
***************
GENERATED	acquire.v 1164 ::: possess;posses;demonstrate;require;have;receive;apply;accumulate;develop;learn

Filtered results
***************
RANKED	acquire.v 1164	receive 0.02408	learn 0.02391	gain 0.02378	obtain 0.02311	find 0.02155	amass 0.02124	gather 0.02102	collect 0.01989	achieve 0.01955	get 0.01779	secure 0.01685	buy 0.01671	procure 0.01646	purchase 0.01596

Test context:
***************
acquire.v	1165	19	how many times have i caught up with those people several years later , to discover that they have __acquired__ a lifestyle , a car and a mortgage to match their salary , and that their initial ideals have faded to the haziest of memories , which they now dismiss as a post-adolescent fantasy ?
Contexts for target acquired are: ['mark_that', 'nsubj_they', 'aux_have', 'ccompI_discover', 'dobj_lifestyle']
Contexts in vocabulary for target acquired are: ['mark_that', 'nsubj_they', 'aux_have', 'ccompI_discover', 'dobj_lifestyle']
Top most similar embeddings: acquired 0.02946	aquired 0.02492	outgrown 0.02325	pilfered 0.02313	originated 0.02200	renounced 0.02200	possessed 0.02195	imbibed 0.02190	evolved 0.02176	relinquished 0.02175

Generated lemmatized results
***************
GENERATED	acquire.v 1165 ::: aquired;outgrow;pilfer;originate;renounce;possess;imbibe;evolve;relinquish;harbour

Filtered results
***************
RANKED	acquire.v 1165	learn 0.02094	gain 0.02046	buy 0.02038	amass 0.01976	achieve 0.01973	purchase 0.01951	secure 0.01895	procure 0.01858	get 0.01844	receive 0.01781	find 0.01719	obtain 0.01678	gather 0.01566	collect 0.01502

Test context:
***************
acquire.v	1166	14	then judge whether you already have these skills in some form or could reasonably __acquire__ them before retirement .
Contexts for target acquire are: ['aux_could', 'advmod_reasonably', 'conjI_have', 'dobj_them', 'prep:before_retirement']
Contexts in vocabulary for target acquire are: ['aux_could', 'advmod_reasonably', 'conjI_have', 'dobj_them', 'prep:before_retirement']
Top most similar embeddings: acquire 0.02396	possess 0.01954	afford 0.01937	attain 0.01919	glean 0.01914	restrain 0.01913	procure 0.01910	recover 0.01897	re-employ 0.01878	re-train 0.01866

Generated lemmatized results
***************
GENERATED	acquire.v 1166 ::: possess;afford;attain;glean;restrain;procure;recover;cultivate;remunerate;repay

Filtered results
***************
RANKED	acquire.v 1166	procure 0.01910	obtain 0.01847	amass 0.01778	buy 0.01694	receive 0.01681	achieve 0.01668	collect 0.01634	secure 0.01620	get 0.01606	gain 0.01544	find 0.01490	purchase 0.01468	learn 0.01464	gather 0.01446

Test context:
***************
acquire.v	1167	35	thank you for having osiris here.' we 've been involved in mesenchymal stem cell , adult stem cell research for about 11 years now.' our technology came out of arnie kaplan 's lab and was __acquired__ from case western at that time , and we 've been solely focused in that area since on several applications .
Contexts for target acquired are: ['auxpass_was', 'conjI_came', 'prep:from_case']
Contexts in vocabulary for target acquired are: ['auxpass_was', 'conjI_came', 'prep:from_case']
Top most similar embeddings: acquired 0.11405	aquired 0.09805	gained 0.08822	purchased 0.08744	extricated 0.08713	learned 0.08710	disjoined 0.08701	rescued 0.08665	picked 0.08629	bought 0.08602

Generated lemmatized results
***************
GENERATED	acquire.v 1167 ::: aquired;gain;purchase;extricate;learn;disjoin;rescue;pick;buy;remove

Filtered results
***************
RANKED	acquire.v 1167	gain 0.08822	purchase 0.08744	learn 0.08710	buy 0.08602	obtain 0.08444	procure 0.08214	gather 0.07752	amass 0.07584	receive 0.07490	collect 0.07461	secure 0.07457	find 0.07263	achieve 0.06769	get 0.06438

Test context:
***************
acquire.v	1168	11	provides counseling , education and advocacy programs which help area residents __acquire__ and retain/maintain safe and affordable housing .
Contexts for target acquire are: ['nsubj_residents', 'ccompI_help', 'cc_and', 'conj_retain/maintain']
Contexts in vocabulary for target acquire are: ['nsubj_residents', 'ccompI_help', 'cc_and']
Top most similar embeddings: acquire 0.12240	develop 0.09689	aquire 0.09204	resettle 0.09147	regain 0.09124	re-discover 0.09093	retain 0.09077	obtain 0.09019	identify 0.09007	conserve 0.08961

Generated lemmatized results
***************
GENERATED	acquire.v 1168 ::: develop;aquire;resettle;regain;retain;obtain;identify;conserve;conceptualize;consolidate

Filtered results
***************
RANKED	acquire.v 1168	obtain 0.09019	learn 0.08749	gain 0.08634	collect 0.08570	achieve 0.08485	gather 0.08323	procure 0.07990	buy 0.07968	get 0.07938	amass 0.07886	secure 0.07883	find 0.07827	receive 0.07740	purchase 0.07615

Test context:
***************
acquire.v	1169	8	more than 200 of the most significant works __acquired__ by the corning museum of glass during the 1990s , to augment its holdings of 35,000 objects , are featured here .
Contexts for target acquired are: ['partmodI_works', 'prep:by_museum', 'prep:during_1990s']
Contexts in vocabulary for target acquired are: ['partmodI_works', 'prep:by_museum', 'prep:during_1990s']
Top most similar embeddings: acquired 0.13645	purchased 0.09796	commissioned 0.09662	aquired 0.09283	co-commissioned 0.09080	commisioned 0.09039	accessioned 0.09000	undertaken 0.08998	owned 0.08998	donated 0.08883

Generated lemmatized results
***************
GENERATED	acquire.v 1169 ::: purchase;commission;aquired;commisioned;accession;undertake;own;donate;curated;loan

Filtered results
***************
RANKED	acquire.v 1169	purchase 0.09796	buy 0.08658	amass 0.08312	procure 0.08127	gather 0.07900	collect 0.07749	gain 0.07749	obtain 0.07432	receive 0.07188	secure 0.07150	achieve 0.07010	learn 0.06482	find 0.05940	get 0.04941

Test context:
***************
acquire.v	1170	15	yet the last four are unattainable , the narrator insists , if you ca n't __acquire__ the personal security--the " inner core , " says covey--that presumably comes from a mastery of the foundation .
Contexts for target acquire are: ['mark_if', 'nsubj_you', 'aux_ca', "neg_n't", 'depI_unattainable', 'dobj_security']
Contexts in vocabulary for target acquire are: ['mark_if', 'nsubj_you', 'aux_ca', "neg_n't", 'dobj_security']
Top most similar embeddings: misplace 0.02665	want/need 0.02601	undersell 0.02534	afford 0.02485	misspell 0.02418	wnat 0.02409	acquire 0.02404	lose 0.02378	get 0.02360	find 0.02351

Generated lemmatized results
***************
GENERATED	acquire.v 1170 ::: misplace;undersell;afford;misspell;wnat;lose;get;find;monetise;proove

Filtered results
***************
RANKED	acquire.v 1170	get 0.02360	find 0.02351	buy 0.02270	obtain 0.01992	achieve 0.01986	receive 0.01926	amass 0.01836	gain 0.01823	procure 0.01805	purchase 0.01788	learn 0.01752	collect 0.01732	secure 0.01544	gather 0.01474

Test context:
***************
acute.a	1171	18	anointing of the sick may be repeated if the person becomes ill again or the danger becomes more __acute__ .
Contexts for target acute are: ['nsubj_danger', 'cop_becomes', 'advmod_more', 'conjI_ill']
Contexts in vocabulary for target acute are: ['nsubj_danger', 'cop_becomes', 'advmod_more', 'conjI_ill']
Top most similar embeddings: acute 0.06598	severe 0.04804	chronic 0.04624	debilitated 0.04367	worrisome 0.04359	intolerable 0.04304	apparent 0.04295	intense 0.04264	painful 0.04239	debilitating 0.04216

Generated lemmatized results
***************
GENERATED	acute.a 1171 ::: severe;chronic;debilitated;worrisome;intolerable;apparent;intense;painful;debilitating;bothersome

Filtered results
***************
RANKED	acute.a 1171	severe 0.04804	intense 0.04264	serious 0.03932	urgent 0.03902	critical 0.03546	sensitive 0.03400	grave 0.03211	sharp 0.03172	sudden 0.03154	heightened 0.03037	keen 0.02987	emergency 0.02775	pn 0.01908

Test context:
***************
acute.a	1172	14	using occasional case studies , cutler defines her terms and provides specific examples of __acute__ and chronic allergens causing asthma and allergic reactions and the genetic , environmental , metabolic , and little-known causes that play roles in asthma onset .
Contexts for target acute are: ['amodI_allergens', 'cc_and', 'conj_chronic']
Contexts in vocabulary for target acute are: ['amodI_allergens', 'cc_and', 'conj_chronic']
Top most similar embeddings: acute 0.14104	chronic 0.10884	sub-acute 0.10204	subacute 0.10108	severe 0.09882	nonspecific 0.09718	serous 0.09709	macrovascular 0.09680	amoebic 0.09679	sub-clinical 0.09664

Generated lemmatized results
***************
GENERATED	acute.a 1172 ::: chronic;subacute;severe;nonspecific;serous;macrovascular;amoebic;neurologic;subclinical;neurotoxic

Filtered results
***************
RANKED	acute.a 1172	severe 0.09882	serious 0.08022	intense 0.07827	sharp 0.07465	urgent 0.07373	sudden 0.07368	grave 0.07318	heightened 0.06765	sensitive 0.06697	critical 0.06539	emergency 0.06067	keen 0.06067	pn 0.04767

Test context:
***************
acute.a	1173	12	patchwork solutions produced by the personality ethic are like painkillers for an __acute__ disease ; the problems might be temporarily hidden , only to return later with a vengeance .
Contexts for target acute are: ['amodI_disease']
Contexts in vocabulary for target acute are: ['amodI_disease']
Top most similar embeddings: acute 0.52899	intercurrent 0.43533	sub-acute 0.43434	chronic 0.43388	granulomatous 0.43296	hemorrhagic 0.43232	immune-mediated 0.42947	early-onset 0.42850	non-communicable 0.42807	diverticular 0.42736

Generated lemmatized results
***************
GENERATED	acute.a 1173 ::: intercurrent;chronic;granulomatous;hemorrhagic;diverticular;decompensated;pustular;valvular;ischemic;lymphoproliferative

Filtered results
***************
RANKED	acute.a 1173	severe 0.39640	serious 0.34250	grave 0.32991	intense 0.32146	sudden 0.31307	sharp 0.31243	critical 0.31156	urgent 0.29914	sensitive 0.29065	heightened 0.28784	emergency 0.28230	keen 0.28091	pn 0.24179

Test context:
***************
acute.a	1174	8	hands , in particular , seem to be __acute__ qi detectors and transmitters .
Contexts for target acute are: ['amodI_detectors']
Contexts in vocabulary for target acute are: ['amodI_detectors']
Top most similar embeddings: acute 0.48531	mains-powered 0.36915	narrow-band 0.36505	low-energy 0.36381	gas-filled 0.36341	silicon-based 0.36227	non-acute 0.36089	mid-infrared 0.36030	single-molecule 0.36025	opto-electronic 0.35934

Generated lemmatized results
***************
GENERATED	acute.a 1174 ::: photoelectric;chronic;neurovascular;biphasic;cryogenic;capacitive;microfluidic;subcortical;interferometric;palatal

Filtered results
***************
RANKED	acute.a 1174	severe 0.34047	sensitive 0.33860	intense 0.32845	sharp 0.32563	critical 0.31391	urgent 0.29849	serious 0.28908	grave 0.28511	heightened 0.28470	emergency 0.28434	sudden 0.28335	keen 0.28215	pn 0.25697

Test context:
***************
acute.a	1175	8	recommendations regards less of inappropriately placed patients in __acute__ hospitals and the difficulties associated in placing these patients we estimate that the equivalent of a fully resourced general hospital ( ' 130million ) is taken up by p atients who have suffered from preventable error .
Contexts for target acute are: ['amodI_hospitals']
Contexts in vocabulary for target acute are: ['amodI_hospitals']
Top most similar embeddings: acute 0.54464	non-acute 0.41735	long-stay 0.39460	chronic 0.39317	petaid 0.39224	consultant-led 0.39129	sub-acute 0.39082	non-nhs 0.38821	lying-in 0.38318	neo-natal 0.38103

Generated lemmatized results
***************
GENERATED	acute.a 1175 ::: chronic;petaid;psychiatric;cardiothoracic;lymphoblastic;paediatric;urologic;inpatient;myelogenous;geriatric

Filtered results
***************
RANKED	acute.a 1175	severe 0.35085	critical 0.32262	sharp 0.31323	serious 0.30132	urgent 0.30038	grave 0.30003	intense 0.29592	emergency 0.28970	sudden 0.28322	heightened 0.28069	sensitive 0.27350	keen 0.26803	pn 0.24653

Test context:
***************
acute.a	1176	7	coronavirus as a possible cause of severe __acute__ respiratory syndrome .
Contexts for target acute are: ['amodI_syndrome']
Contexts in vocabulary for target acute are: ['amodI_syndrome']
Top most similar embeddings: acute 0.54338	chronic 0.43904	uraemic 0.42582	sub-acute 0.42500	myelodysplastic 0.42413	nephrotic 0.41963	granulomatous 0.41716	premenstrual 0.41704	post-poliomyelitis 0.41554	pre-menstrual 0.41449

Generated lemmatized results
***************
GENERATED	acute.a 1176 ::: chronic;uraemic;myelodysplastic;nephrotic;granulomatous;premenstrual;pustular;hemorrhagic;paroxysmal;subacute

Filtered results
***************
RANKED	acute.a 1176	severe 0.38837	sudden 0.33734	serious 0.31849	grave 0.31774	intense 0.31562	critical 0.31551	sharp 0.30643	urgent 0.30513	sensitive 0.29106	heightened 0.28762	keen 0.27390	emergency 0.26376	pn 0.24452

Test context:
***************
acute.a	1177	15	by sheer personal determination he raised the subject of psychic phenomena into the arena of __acute__ controversy -- and kept it there .
Contexts for target acute are: ['amodI_controversy']
Contexts in vocabulary for target acute are: ['amodI_controversy']
Top most similar embeddings: acute 0.50523	chronic 0.38109	centuries-long 0.37297	inter-communal 0.37250	irresolvable 0.37078	much-discussed 0.37015	incipient 0.36987	unresolvable 0.36970	sub-acute 0.36923	decades-long 0.36864

Generated lemmatized results
***************
GENERATED	acute.a 1177 ::: chronic;irresolvable;incipient;unresolvable;serous;rancorous;intense;oedipal;premenstrual;pustular

Filtered results
***************
RANKED	acute.a 1177	intense 0.36492	severe 0.35623	grave 0.33683	sharp 0.33590	serious 0.32587	critical 0.32369	heightened 0.32078	urgent 0.31878	sudden 0.31072	keen 0.29502	sensitive 0.27381	emergency 0.27253	pn 0.23257

Test context:
***************
acute.a	1178	26	isis-3 : a randomised trial of streptokinase vs tissue plasminogen activator vs anistreplase and of aspirin plus heparin vs aspirin alone among 41,299 cases of suspected __acute__ myocardial infarction .
Contexts for target acute are: ['amodI_infarction']
Contexts in vocabulary for target acute are: ['amodI_infarction']
Top most similar embeddings: acute 0.55463	sub-acute 0.42031	nonfatal 0.41435	myelogenous 0.40805	ischemic 0.40350	non-paralytic 0.40187	intraventricular 0.39843	lymphoblastic 0.39799	fulminant 0.39683	hemorrhagic 0.39643

Generated lemmatized results
***************
GENERATED	acute.a 1178 ::: nonfatal;myelogenous;ischemic;intraventricular;lymphoblastic;fulminant;hemorrhagic;intrahepatic;myocardial;promyelocytic

Filtered results
***************
RANKED	acute.a 1178	severe 0.36352	intense 0.31045	sharp 0.30554	sudden 0.30234	serious 0.30227	urgent 0.30018	critical 0.29913	grave 0.29332	emergency 0.28518	sensitive 0.27979	heightened 0.26886	keen 0.25691	pn 0.22063

Test context:
***************
acute.a	1179	56	" generous chinese loans ' the best recovery that money can buy ' for all its fragilities , nothing yet has slowed this fire-breathing dragon - not the asian financial crisis of 1997-'98 ; not the internet and technology crash ; not synchronous global recession of 2001 ; and not this year 's outbreak of severe __acute__ respiratory syndrome , or sars .
Contexts for target acute are: ['amodI_syndrome']
Contexts in vocabulary for target acute are: ['amodI_syndrome']
Top most similar embeddings: acute 0.54338	chronic 0.43904	uraemic 0.42582	sub-acute 0.42500	myelodysplastic 0.42413	nephrotic 0.41963	granulomatous 0.41716	premenstrual 0.41704	post-poliomyelitis 0.41554	pre-menstrual 0.41449

Generated lemmatized results
***************
GENERATED	acute.a 1179 ::: chronic;uraemic;myelodysplastic;nephrotic;granulomatous;premenstrual;pustular;hemorrhagic;paroxysmal;subacute

Filtered results
***************
RANKED	acute.a 1179	severe 0.38837	sudden 0.33734	serious 0.31849	grave 0.31774	intense 0.31562	critical 0.31551	sharp 0.30643	urgent 0.30513	sensitive 0.29106	heightened 0.28762	keen 0.27390	emergency 0.26376	pn 0.24452

Test context:
***************
acute.a	1180	5	does this woman have an __acute__ uncomplicated urinary tract infection ?
Contexts for target acute are: ['amodI_infection']
Contexts in vocabulary for target acute are: ['amodI_infection']
Top most similar embeddings: acute 0.54220	sub-acute 0.43792	community-acquired 0.43089	chronic 0.42997	nosocomial 0.42765	hospital-acquired 0.42690	hemorrhagic 0.42664	mycoplasmal 0.42236	radiation-induced 0.42135	streptococcal 0.42079

Generated lemmatized results
***************
GENERATED	acute.a 1180 ::: chronic;nosocomial;hemorrhagic;mycoplasmal;streptococcal;intercurrent;fulminant;subacute;pustular;candidal

Filtered results
***************
RANKED	acute.a 1180	severe 0.38894	intense 0.34168	serious 0.34154	grave 0.31800	critical 0.31619	sharp 0.31267	urgent 0.31111	sudden 0.30932	heightened 0.30326	emergency 0.29550	sensitive 0.28564	keen 0.27238	pn 0.23332

Test context:
***************
below.r	1181	3	use the postform __below__ to send us your comments .
Contexts for target below are: ['advmodI_use']
Contexts in vocabulary for target below are: ['advmodI_use']
Top most similar embeddings: below 0.52854	above 0.41002	defintely 0.36252	reguarly 0.36223	diagrammatically 0.35612	algebraically 0.35610	proably 0.35595	futhermore 0.35552	bascially 0.35432	intelligibly 0.35394

Generated lemmatized results
***************
GENERATED	below.r 1181 ::: above;defintely;reguarly;diagrammatically;algebraically;proably;futhermore;bascially;intelligibly;legislatively

Filtered results
***************
RANKED	below.r 1181	beneath 0.35264	underneath 0.32467	later 0.30161	following 0.29353	attached 0.26230	included 0.21806

Test context:
***************
below.r	1182	18	the project will be completed by april 30 , 2002 and project results will be disseminated as delineated __below__ .
Contexts for target below are: ['advmodI_delineated']
Contexts in vocabulary for target below are: ['advmodI_delineated']
Top most similar embeddings: below 0.49234	above 0.41036	diagrammatically 0.36168	schematically 0.35924	elaborately 0.35828	algebraically 0.35278	beneath 0.34977	picturesquely 0.34821	colourfully 0.34742	clearly 0.34740

Generated lemmatized results
***************
GENERATED	below.r 1182 ::: above;diagrammatically;schematically;elaborately;algebraically;beneath;picturesquely;colourfully;clearly;evocatively

Filtered results
***************
RANKED	below.r 1182	beneath 0.34977	underneath 0.30988	following 0.27457	later 0.27257	attached 0.25970	included 0.20840

Test context:
***************
below.r	1183	16	amid the crash and glitter of the falling glass , he tumbled into the flagged area __below__ .
Contexts for target below are: ['advmodI_area']
Contexts in vocabulary for target below are: ['advmodI_area']
Top most similar embeddings: below 0.51829	above 0.40105	beneath 0.37536	legislatively 0.35382	diagrammatically 0.35162	lushly 0.34731	algebraically 0.34686	ornately 0.34679	picturesquely 0.34633	here 0.34531

Generated lemmatized results
***************
GENERATED	below.r 1183 ::: above;beneath;legislatively;diagrammatically;lushly;algebraically;ornately;picturesquely;here;territorially

Filtered results
***************
RANKED	below.r 1183	beneath 0.37536	underneath 0.32829	later 0.29324	following 0.26610	attached 0.24845	included 0.21985

Test context:
***************
below.r	1184	51	for example , formal education is a key variable in explaining the increase in the relative influence of someone like salam fayad , the palestinian minister of finance , whereas trust and political intelligence ( a function of ' aptitude ' ) , as will be shown in the case studies __below__ , are the relevant variables to explain the surge in the relative influence of marwan barghouthi .
Contexts for target below are: ['advmodI_studies']
Contexts in vocabulary for target below are: ['advmodI_studies']
Top most similar embeddings: below 0.50320	above 0.40715	here 0.35397	legislatively 0.35278	algebraically 0.34892	diagrammatically 0.34718	beneath 0.34490	cross-culturally 0.34391	speculatively 0.34250	therein 0.34236

Generated lemmatized results
***************
GENERATED	below.r 1184 ::: above;here;legislatively;algebraically;diagrammatically;beneath;speculatively;therein;pictorially;kinetically

Filtered results
***************
RANKED	below.r 1184	beneath 0.34490	underneath 0.30536	later 0.29938	following 0.27668	attached 0.26270	included 0.21802

Test context:
***************
below.r	1185	14	the folks at lake hawk have a super selection of dyes ( see colors __below__ ) for soft plastic baits , spinner bait blades , and for plugs .
Contexts for target below are: ['punct_-rrb-']
Contexts in vocabulary for target below are: []
Top most similar embeddings: below 1.00000	above 0.80541	overleaf 0.74139	beneath 0.73329	diagrammatically 0.69690	schematically 0.68152	behind 0.68102	here 0.68087	algebraically 0.67856	underneath 0.67845

Generated lemmatized results
***************
GENERATED	below.r 1185 ::: above;overleaf;beneath;diagrammatically;schematically;behind;here;algebraically;underneath;beyond

Filtered results
***************
RANKED	below.r 1185	beneath 0.73329	underneath 0.67845	following 0.63194	attached 0.61377	later 0.59405	included 0.57662

Test context:
***************
below.r	1186	0	__below__ , you 'll see a klr 650 that has been lowered 3 " in the rear , and 3 " in the front .
Contexts for target below are: ['advmodI_see']
Contexts in vocabulary for target below are: ['advmodI_see']
Top most similar embeddings: below 0.54161	above 0.42741	beneath 0.36919	here 0.36869	diagrammatically 0.36575	proably 0.36516	defintely 0.36054	futhermore 0.35821	parenthetically 0.35096	bascially 0.35013

Generated lemmatized results
***************
GENERATED	below.r 1186 ::: above;beneath;here;diagrammatically;proably;defintely;futhermore;parenthetically;bascially;reguarly

Filtered results
***************
RANKED	below.r 1186	beneath 0.36919	underneath 0.32205	later 0.31359	following 0.27893	attached 0.26836	included 0.20995

Test context:
***************
below.r	1187	18	listen to this week 's half-hour program of between the lines by clicking on one of the links __below__ .
Contexts for target below are: ['advmodI_links']
Contexts in vocabulary for target below are: ['advmodI_links']
Top most similar embeddings: below 0.56197	above 0.43165	beneath 0.36159	here 0.35673	diagrammatically 0.35635	algebraically 0.35471	overleaf 0.35114	hierarchically 0.34618	therein 0.34380	herewith 0.34365

Generated lemmatized results
***************
GENERATED	below.r 1187 ::: above;beneath;here;diagrammatically;algebraically;overleaf;hierarchically;therein;herewith;intelligibly

Filtered results
***************
RANKED	below.r 1187	beneath 0.36159	underneath 0.31453	later 0.28419	following 0.27596	attached 0.26948	included 0.21957

Test context:
***************
below.r	1188	3	all the rights __below__ apply if you are working permanently or on a shortor fixed-term contract .
Contexts for target below are: []
Contexts in vocabulary for target below are: []
Top most similar embeddings: below 1.00000	above 0.80541	overleaf 0.74139	beneath 0.73329	diagrammatically 0.69690	schematically 0.68152	behind 0.68102	here 0.68087	algebraically 0.67856	underneath 0.67845

Generated lemmatized results
***************
GENERATED	below.r 1188 ::: above;overleaf;beneath;diagrammatically;schematically;behind;here;algebraically;underneath;beyond

Filtered results
***************
RANKED	below.r 1188	beneath 0.73329	underneath 0.67845	following 0.63194	attached 0.61377	later 0.59405	included 0.57662

Test context:
***************
below.r	1189	13	the customer lies down on a plexiglas surface as lights from above and __below__ reach the body .
Contexts for target below are: ['nsubjI_reach']
Contexts in vocabulary for target below are: ['nsubjI_reach']
Top most similar embeddings: below 0.43537	above 0.35359	overleaf 0.32676	they 0.32438	underneath 0.31167	beneath 0.30986	you 0.30928	we 0.30643	stockmarkets 0.30603	smart-1 0.30584

Generated lemmatized results
***************
GENERATED	below.r 1189 ::: above;overleaf;they;underneath;beneath;you;we;stockmarkets;beyond;hereunder

Filtered results
***************
RANKED	below.r 1189	underneath 0.31167	beneath 0.30986	following 0.25972	attached 0.24840	later 0.22488	included 0.20619

Test context:
***************
below.r	1190	0	__below__ are some of the general signs of serious distress : references to suicide .
Contexts for target below are: ['advmodI_some']
Contexts in vocabulary for target below are: ['advmodI_some']
Top most similar embeddings: below 0.49599	above 0.37858	here 0.35632	at 0.34967	diagrammatically 0.34080	defintely 0.34060	beneath 0.33908	legislatively 0.33786	just 0.33758	even 0.33412

Generated lemmatized results
***************
GENERATED	below.r 1190 ::: above;here;at;diagrammatically;defintely;beneath;legislatively;just;even;proably

Filtered results
***************
RANKED	below.r 1190	beneath 0.33908	underneath 0.30655	later 0.29636	following 0.26439	attached 0.24488	included 0.21851

Test context:
***************
bring.v	1191	6	to get neighbors involved and to __bring__ even more attention to the trees , organizers tied huge red ribbons around each trunk and held a rally beneath the trees where they sold t shirts , visors , and refreshments .
Contexts for target bring are: ['aux_to', 'conjI_involved', 'dobj_attention', 'prep:to_trees']
Contexts in vocabulary for target bring are: ['aux_to', 'conjI_involved', 'dobj_attention', 'prep:to_trees']
Top most similar embeddings: bring 0.05531	sensitize 0.04559	attract 0.04354	give 0.04218	lend 0.04199	devote 0.04188	divert 0.04172	dedicate 0.04152	draw 0.04093	bringing 0.03963

Generated lemmatized results
***************
GENERATED	bring.v 1191 ::: sensitize;attract;give;lend;devote;divert;dedicate;draw;entice;heighten

Filtered results
***************
RANKED	bring.v 1191	attract 0.04354	draw 0.04093	deliver 0.03912	introduce 0.03911	get 0.03840	gather 0.03837	carry 0.03795	convey 0.03726	contribute 0.03722	take 0.03570	instigate 0.03570	generate 0.03549	initiate 0.03533	make 0.03469	produce 0.03466	create 0.03350	put 0.03268	move 0.03194	depress 0.03193	return 0.03120	call 0.03079	incorporate 0.03056	ruin 0.03053	bore 0.03047	guide 0.03031	transport 0.02965	present 0.02894	realise 0.02861	topple 0.02854	force 0.02820	shoot 0.02625	institute 0.02588	start 0.02579	file 0.02485

Test context:
***************
bring.v	1192	21	in short , the course 's process of healing consists of two basic steps : getting out of false denial by __bringing__ our illusions into the light of truth .
Contexts for target bringing are: ['pcompI_by', 'dobj_illusions', 'prep:into_light']
Contexts in vocabulary for target bringing are: ['pcompI_by', 'dobj_illusions', 'prep:into_light']
Top most similar embeddings: bringing 0.13419	transmuting 0.10879	brining 0.10553	catapulting 0.10291	annihilating 0.09935	glimpsing 0.09769	inculcating 0.09754	banishing 0.09685	demoting 0.09600	exorcising 0.09598

Generated lemmatized results
***************
GENERATED	bring.v 1192 ::: transmute;brine;catapult;annihilate;glimpse;inculcate;banish;demote;exorcise;diffuse

Filtered results
***************
RANKED	bring.v 1192	create 0.09329	introduce 0.09225	put 0.08683	transport 0.08645	convey 0.08475	force 0.08204	call 0.08158	incorporate 0.08120	produce 0.08097	carry 0.08070	attract 0.08016	initiate 0.08010	draw 0.08008	generate 0.07948	take 0.07927	institute 0.07918	topple 0.07912	present 0.07790	move 0.07715	make 0.07672	instigate 0.07650	deliver 0.07519	guide 0.07344	ruin 0.07267	get 0.07243	return 0.07225	shoot 0.07051	contribute 0.06913	realise 0.06544	gather 0.06507	start 0.06482	file 0.06068	bore 0.05966	depress 0.05560

Test context:
***************
bring.v	1193	29	civil liability when one party believes that another party has harmed property , crops , or animals by the misuse or misapplication of pesticides , the harmed party may __bring__ a civil lawsuit seeking monetary compensation for the harm .
Contexts for target bring are: ['nsubj_liability', 'aux_may', 'rootI_*root*', 'dobj_lawsuit', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target bring are: ['nsubj_liability', 'aux_may', 'rootI_*root*', 'dobj_lawsuit', 'punct_.']
Top most similar embeddings: bring 0.02587	brought 0.02365	include 0.02223	aggravate 0.02199	potentiate 0.02157	triggered 0.02124	invalidate 0.02123	ensue 0.02112	incur 0.02099	vitiate 0.02077

Generated lemmatized results
***************
GENERATED	bring.v 1193 ::: include;aggravate;potentiate;trigger;invalidate;ensue;incur;vitiate;allege;precipitate

Filtered results
***************
RANKED	bring.v 1193	initiate 0.02063	file 0.02004	instigate 0.01989	institute 0.01900	attract 0.01781	depress 0.01773	take 0.01759	return 0.01758	start 0.01737	introduce 0.01737	make 0.01701	contribute 0.01684	force 0.01671	carry 0.01667	produce 0.01654	move 0.01653	present 0.01652	generate 0.01641	call 0.01625	incorporate 0.01611	get 0.01607	draw 0.01603	put 0.01601	create 0.01567	deliver 0.01551	realise 0.01535	topple 0.01508	convey 0.01495	gather 0.01460	ruin 0.01434	guide 0.01384	shoot 0.01372	transport 0.01355	bore 0.01342

Test context:
***************
bring.v	1194	44	28.1 the commission des normes du travail shall contribute to the fund of the commission des relations du travail referred to in section 137.62 of the labour code ( chapter c-27 ) to provide for expenses incurred by the commission in relation to proceedings __brought__ before the commission under divisions ii and iii of chapter v of this act .
Contexts for target brought are: ['partmodI_proceedings', 'prep:before_commission']
Contexts in vocabulary for target brought are: ['partmodI_proceedings', 'prep:before_commission']
Top most similar embeddings: brought 0.28276	bringing 0.19710	taken 0.18520	bring 0.18421	instituted 0.18163	arraigned 0.17982	litigated 0.17753	commenced 0.17719	summoned 0.17454	adjudicated 0.17369

Generated lemmatized results
***************
GENERATED	bring.v 1194 ::: take;institute;arraign;litigate;commence;summon;adjudicate;instigate;testify;lay

Filtered results
***************
RANKED	bring.v 1194	take 0.18520	institute 0.18163	instigate 0.17223	initiate 0.16722	file 0.16077	present 0.15475	make 0.15250	convey 0.15191	introduce 0.15148	gather 0.15022	put 0.14945	draw 0.14718	produce 0.14455	move 0.14312	deliver 0.14310	carry 0.14232	call 0.14229	attract 0.14032	contribute 0.13783	start 0.13555	create 0.13518	return 0.13026	generate 0.13022	get 0.12978	topple 0.12874	transport 0.12864	force 0.12799	incorporate 0.12761	ruin 0.12759	guide 0.11742	bore 0.11722	shoot 0.11282	realise 0.10853	depress 0.10437

Test context:
***************
bring.v	1195	44	before voting on an appropriate replacement floor , we hope the commission will require the applicant to conduct archival and/or on-site physical research so that the design of the new floor can be based on historic conditions and the restaurant 's interior can be __brought__ closer to its historic appearance rather than farther away .
Contexts for target brought are: ['aux_can', 'auxpass_be', 'advclI_hope', 'advmod_closer']
Contexts in vocabulary for target brought are: ['aux_can', 'auxpass_be', 'advclI_hope', 'advmod_closer']
Top most similar embeddings: brought 0.05888	coaxed 0.04260	bought 0.04178	moved 0.04164	dragged 0.04117	relocated 0.04109	bring 0.04108	steamrollered 0.04094	pushed 0.04069	found 0.04026

Generated lemmatized results
***************
GENERATED	bring.v 1195 ::: coax;buy;move;drag;relocate;steamroller;push;find;accommodate;prevent

Filtered results
***************
RANKED	bring.v 1195	move 0.04164	draw 0.03972	put 0.03873	take 0.03858	deliver 0.03813	make 0.03806	get 0.03804	gather 0.03793	return 0.03639	carry 0.03622	introduce 0.03618	transport 0.03565	initiate 0.03496	institute 0.03486	topple 0.03482	force 0.03478	attract 0.03472	convey 0.03433	incorporate 0.03398	instigate 0.03372	produce 0.03293	realise 0.03241	create 0.03207	guide 0.03205	depress 0.03151	present 0.03121	generate 0.03110	bore 0.03107	file 0.03082	call 0.03070	ruin 0.03038	start 0.02985	contribute 0.02892	shoot 0.02679

Test context:
***************
bring.v	1196	12	play with your cat or dog , allowing her elemental energy to __bring__ you back to solid ground .
Contexts for target bring are: ['nsubj_energy', 'aux_to', 'xcompI_allowing', 'dobj_you', 'advmod_back']
Contexts in vocabulary for target bring are: ['nsubj_energy', 'aux_to', 'xcompI_allowing', 'dobj_you', 'advmod_back']
Top most similar embeddings: bring 0.03330	propel 0.02480	manhandle 0.02329	re-invest 0.02316	repatriate 0.02312	entice 0.02309	percolate 0.02261	inject 0.02256	smuggle 0.02240	disgorge 0.02235

Generated lemmatized results
***************
GENERATED	bring.v 1196 ::: propel;manhandle;repatriate;entice;percolate;inject;smuggle;disgorge;infuse;entrap

Filtered results
***************
RANKED	bring.v 1196	take 0.02195	get 0.02184	carry 0.02084	put 0.02069	introduce 0.02068	deliver 0.02017	move 0.02017	attract 0.02014	depress 0.01956	convey 0.01919	draw 0.01905	make 0.01882	transport 0.01867	topple 0.01841	initiate 0.01836	gather 0.01832	shoot 0.01803	create 0.01791	generate 0.01785	contribute 0.01736	incorporate 0.01704	produce 0.01687	instigate 0.01636	return 0.01625	call 0.01602	bore 0.01572	present 0.01543	ruin 0.01465	force 0.01465	guide 0.01428	realise 0.01420	start 0.01409	file 0.01294	institute 0.01104

Test context:
***************
bring.v	1197	8	the fact is , the best way to __bring__ movement into your life is to stop ' exercising ' and start living !
Contexts for target bring are: ['aux_to', 'infmodI_way', 'dobj_movement', 'prep:into_life']
Contexts in vocabulary for target bring are: ['aux_to', 'infmodI_way', 'dobj_movement', 'prep:into_life']
Top most similar embeddings: bring 0.06787	re-integrate 0.05682	reintegrate 0.05611	galvanise 0.05571	instill 0.05415	popularize 0.05341	refashion 0.05268	reawaken 0.05227	integrate 0.05225	democratize 0.05225

Generated lemmatized results
***************
GENERATED	bring.v 1197 ::: reintegrate;galvanise;instill;popularize;refashion;reawaken;integrate;democratize;wheedle;galvanize

Filtered results
***************
RANKED	bring.v 1197	introduce 0.04972	initiate 0.04849	convey 0.04751	incorporate 0.04688	create 0.04553	instigate 0.04475	get 0.04465	generate 0.04404	carry 0.04362	attract 0.04349	make 0.04321	topple 0.04275	deliver 0.04095	gather 0.03996	take 0.03933	draw 0.03913	produce 0.03880	depress 0.03874	put 0.03856	contribute 0.03692	move 0.03671	ruin 0.03566	start 0.03566	shoot 0.03273	realise 0.03264	present 0.03178	force 0.03077	transport 0.03002	return 0.02996	guide 0.02990	call 0.02983	institute 0.02895	bore 0.02867	file 0.02581

Test context:
***************
bring.v	1198	7	miller says that it was bloggers that __brought__ her down and drove a wedge between her and her editors and peers in the newsroom .
Contexts for target brought are: ['nsubj_that', 'rcmodI_bloggers', 'dobj_her', 'advmod_down', 'cc_and', 'conj_drove']
Contexts in vocabulary for target brought are: ['nsubj_that', 'rcmodI_bloggers', 'dobj_her', 'advmod_down', 'cc_and', 'conj_drove']
Top most similar embeddings: brought 0.01296	drove 0.01207	dragged 0.01127	slithered 0.01113	quieted 0.01088	threw 0.01076	slowed 0.01060	pushed 0.01059	tore 0.01056	took 0.01054

Generated lemmatized results
***************
GENERATED	bring.v 1198 ::: drive;drag;slither;quiet;throw;slow;push;tear;take;calm

Filtered results
***************
RANKED	bring.v 1198	take 0.01054	topple 0.00969	move 0.00915	draw 0.00903	put 0.00876	get 0.00874	gather 0.00854	bore 0.00850	depress 0.00849	force 0.00836	attract 0.00831	ruin 0.00814	guide 0.00779	carry 0.00757	transport 0.00749	start 0.00731	shoot 0.00731	make 0.00705	instigate 0.00704	return 0.00703	contribute 0.00692	convey 0.00673	deliver 0.00668	call 0.00656	initiate 0.00651	create 0.00649	introduce 0.00619	institute 0.00618	file 0.00613	generate 0.00607	produce 0.00606	present 0.00573	incorporate 0.00549	realise 0.00515

Test context:
***************
bring.v	1199	1	he __brought__ the unit to his office and again it behaved the same .
Contexts for target brought are: ['nsubj_he', 'rootI_*root*', 'dobj_unit', 'prep:to_office', 'cc_and', 'conj_behaved', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target brought are: ['nsubj_he', 'rootI_*root*', 'dobj_unit', 'prep:to_office', 'cc_and', 'conj_behaved', 'punct_.']
Top most similar embeddings: brought 0.00675	radioed 0.00556	moved 0.00555	doffed 0.00551	summoned 0.00549	co-founded 0.00549	took 0.00545	rallied 0.00543	oversaw 0.00535	marched 0.00535

Generated lemmatized results
***************
GENERATED	bring.v 1199 ::: radio;move;doff;summon;take;rally;oversee;march;decamp;come

Filtered results
***************
RANKED	bring.v 1199	move 0.00555	take 0.00545	return 0.00527	draw 0.00459	get 0.00458	introduce 0.00456	attract 0.00447	convey 0.00446	make 0.00442	present 0.00441	institute 0.00437	instigate 0.00437	initiate 0.00426	start 0.00425	contribute 0.00423	create 0.00422	deliver 0.00422	call 0.00420	carry 0.00419	produce 0.00418	gather 0.00406	transport 0.00387	put 0.00387	incorporate 0.00386	topple 0.00382	guide 0.00376	bore 0.00361	file 0.00358	depress 0.00351	shoot 0.00335	generate 0.00330	realise 0.00326	force 0.00323	ruin 0.00305

Test context:
***************
bring.v	1200	37	now moving back over to main st. at lincoln , the old erb lumber site is being reborn thanks to the vision of sam and toby haberman , long time merchants , who are eventually going to __bring__ in approximately 70,000 additional square feet of retail space and the relocation of their famous fabric store .
Contexts for target bring are: ['aux_to', 'xcompI_going', 'prt_in', 'dobj_feet']
Contexts in vocabulary for target bring are: ['aux_to', 'xcompI_going', 'prt_in', 'dobj_feet']
Top most similar embeddings: bring 0.06659	manhandle 0.05302	put 0.05020	get 0.04927	keep 0.04856	shoehorn 0.04812	wheedle 0.04781	take 0.04752	give 0.04697	pressurize 0.04683

Generated lemmatized results
***************
GENERATED	bring.v 1200 ::: manhandle;put;get;keep;shoehorn;wheedle;take;give;pressurize;engross

Filtered results
***************
RANKED	bring.v 1200	put 0.05020	get 0.04927	take 0.04752	deliver 0.04189	move 0.04152	topple 0.04112	make 0.04060	draw 0.04043	shoot 0.04042	carry 0.04022	introduce 0.03986	gather 0.03954	depress 0.03913	create 0.03746	attract 0.03647	incorporate 0.03588	ruin 0.03586	produce 0.03575	convey 0.03506	contribute 0.03437	generate 0.03385	bore 0.03378	initiate 0.03366	instigate 0.03364	call 0.03348	start 0.03194	realise 0.03186	transport 0.03147	force 0.03039	return 0.03015	guide 0.02974	file 0.02800	present 0.02765	institute 0.02599

Test context:
***************
burst.v	1201	0	__bursting__ from the bedroom in a fit of passion , they bounced from room to room in a series of energetic embraces , hitting just about every wall in the house .
Contexts for target bursting are: ['partmodI_bounced', 'prep:from_bedroom', 'prep:in_fit']
Contexts in vocabulary for target bursting are: ['prep:from_bedroom', 'prep:in_fit']
Top most similar embeddings: bursting 0.23546	burst 0.18364	overflowing 0.17598	groaning 0.17551	leaping 0.17473	exploding 0.17451	blaring 0.17421	screaming 0.17384	heaving 0.17072	shrieking 0.16978

Generated lemmatized results
***************
GENERATED	burst.v 1201 ::: overflow;groan;leap;explode;blare;scream;heave;shriek;billow;sob

Filtered results
***************
RANKED	burst.v 1201	overflow 0.17598	leap 0.17473	explode 0.17451	erupt 0.16415	rush 0.16111	bristle 0.15901	break 0.15615	pop 0.15528	barge 0.15350	bound 0.15214	bounce 0.15074	rupture 0.14761	run 0.14307	descend 0.14187	split 0.14113	fracture 0.13968	push 0.13240	deflate 0.13218	burgeon 0.12746	laden 0.12440	end 0.12194	cover 0.11649	surprise 0.11123	enthusiastic 0.10808

Test context:
***************
burst.v	1202	18	do n't expect the contract highs to get hit again for along time as the commodity bubble is __bursting__ .
Contexts for target bursting are: ['mark_as', 'nsubj_bubble', 'aux_is', 'depI_time']
Contexts in vocabulary for target bursting are: ['mark_as', 'nsubj_bubble', 'aux_is', 'depI_time']
Top most similar embeddings: bursting 0.06341	exploding 0.04704	overflowing 0.04685	burst 0.04554	brimming 0.04500	buzzing 0.04448	erupting 0.04321	collapsing 0.04315	evaporating 0.04266	swarming 0.04215

Generated lemmatized results
***************
GENERATED	burst.v 1202 ::: explode;overflow;brim;buzz;erupt;collapse;evaporate;swarm;deflate;heave

Filtered results
***************
RANKED	burst.v 1202	explode 0.04704	overflow 0.04685	erupt 0.04321	deflate 0.04207	pop 0.04143	bristle 0.03873	bounce 0.03872	break 0.03704	rush 0.03700	run 0.03659	descend 0.03614	leap 0.03591	barge 0.03457	push 0.03357	rupture 0.03333	bound 0.03326	fracture 0.03210	split 0.03140	burgeon 0.03063	end 0.02870	cover 0.02777	laden 0.02456	surprise 0.02303	enthusiastic 0.02151

Test context:
***************
burst.v	1203	26	he has not yet achieved a victory like those of iban mayo in last year 's midi libre or classique des alpes , but he has __burst__ on to the scene with a string of noticeable results during the first half of the year .
Contexts for target burst are: ['dobjI_has', 'prep:with_string']
Contexts in vocabulary for target burst are: ['dobjI_has', 'prep:with_string']
Top most similar embeddings: burst 0.23513	bursts 0.18811	d-ring 0.16475	spurt 0.16432	drawcord 0.16355	bursting 0.16201	fling 0.16074	crush 0.16058	flings 0.15945	plaits 0.15922

Generated lemmatized results
***************
GENERATED	burst.v 1203 ::: spurt;drawcord;fling;crush;plait;throb;bodice;ovipositor;blast;prickle

Filtered results
***************
RANKED	burst.v 1203	overflow 0.15092	rupture 0.14925	bristle 0.14837	leap 0.14456	break 0.14192	end 0.14023	explode 0.14002	bounce 0.13965	pop 0.13831	erupt 0.13434	rush 0.13344	surprise 0.13338	push 0.13209	fracture 0.13113	barge 0.12905	split 0.12825	laden 0.12785	bound 0.12671	deflate 0.12641	descend 0.12617	burgeon 0.12222	cover 0.11961	run 0.11835	enthusiastic 0.10682

Test context:
***************
burst.v	1204	12	6 ) it was further agreed that a mountain initiative should not __burst__ on the political constituency suddenly but should been seen to be in preparation well in advance , with a demonstrated dimension in popular awareness and concern .
Contexts for target burst are: ['mark_that', 'nsubj_initiative', 'aux_should', 'neg_not', 'ccompI_agreed', 'prep:on_constituency', 'advmod_suddenly', 'cc_but', 'conj_seen']
Contexts in vocabulary for target burst are: ['mark_that', 'nsubj_initiative', 'aux_should', 'neg_not', 'ccompI_agreed', 'advmod_suddenly', 'cc_but', 'conj_seen']
Top most similar embeddings: materialised 0.00251	materialise 0.00250	burst 0.00240	re-occur 0.00238	encroach 0.00233	transpire 0.00231	budged 0.00229	reoccur 0.00229	interfered 0.00224	heeded 0.00221

Generated lemmatized results
***************
GENERATED	burst.v 1204 ::: materialise;encroach;transpire;budge;reoccur;interfere;heed;materialize;tokenistic;disappear

Filtered results
***************
RANKED	burst.v 1204	erupt 0.00209	explode 0.00201	rush 0.00194	push 0.00175	leap 0.00173	overflow 0.00173	bounce 0.00171	break 0.00168	descend 0.00162	rupture 0.00161	pop 0.00161	end 0.00156	split 0.00156	cover 0.00151	bound 0.00149	surprise 0.00148	run 0.00146	fracture 0.00144	bristle 0.00142	deflate 0.00141	barge 0.00134	enthusiastic 0.00133	burgeon 0.00131	laden 0.00092

Test context:
***************
burst.v	1205	3	a branch , __bursting__ with red blossoms , hung over the doorway .
Contexts for target bursting are: ['partmodI_branch', 'prep:with_blossoms']
Contexts in vocabulary for target bursting are: ['partmodI_branch', 'prep:with_blossoms']
Top most similar embeddings: bursting 0.24197	festooned 0.19816	bristling 0.19731	overflowing 0.19212	brimming 0.19009	garlanded 0.18933	teemed 0.18748	teeming 0.18690	flecked 0.18575	bedecked 0.18556

Generated lemmatized results
***************
GENERATED	burst.v 1205 ::: festoon;bristle;overflow;brim;garland;teem;fleck;bedeck;drip;ooze

Filtered results
***************
RANKED	burst.v 1205	bristle 0.19731	overflow 0.19212	erupt 0.15775	explode 0.15764	descend 0.14867	leap 0.14865	bound 0.14679	pop 0.14518	break 0.14292	laden 0.14031	rupture 0.13839	cover 0.13654	burgeon 0.13639	rush 0.13606	bounce 0.13601	split 0.13525	deflate 0.13135	fracture 0.13027	end 0.12693	run 0.12641	push 0.12137	barge 0.12077	surprise 0.10339	enthusiastic 0.10100

Test context:
***************
burst.v	1206	4	in seconds , they __burst__ out onto the open stony space before the muskeg .
Contexts for target burst are: ['prep:in_seconds', 'punct_,', 'nsubj_they', 'rootI_*root*', 'prt_out', 'prep:onto_space', 'prep:before_muskeg', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target burst are: ['prep:in_seconds', 'punct_,', 'nsubj_they', 'rootI_*root*', 'prt_out', 'prep:onto_space', 'punct_.']
Top most similar embeddings: burst 0.00713	leapt 0.00576	jutted 0.00569	peeked 0.00562	clanged 0.00559	darted 0.00558	sputtered 0.00556	squelched 0.00554	bulged 0.00550	taxied 0.00547

Generated lemmatized results
***************
GENERATED	burst.v 1206 ::: leap;jut;peek;clang;dart;sputter;squelch;bulge;taxi;scamper

Filtered results
***************
RANKED	burst.v 1206	leap 0.00576	break 0.00526	overflow 0.00507	pop 0.00504	barge 0.00501	rush 0.00498	explode 0.00497	run 0.00483	erupt 0.00465	bounce 0.00452	push 0.00447	bristle 0.00438	split 0.00422	descend 0.00399	deflate 0.00396	bound 0.00366	rupture 0.00363	end 0.00331	fracture 0.00330	cover 0.00317	burgeon 0.00300	surprise 0.00289	enthusiastic 0.00252	laden 0.00245

Test context:
***************
burst.v	1207	14	a small number of residents also had to be evacuated when the river wharfe __burst__ its banks and flooded the a65 at ilkley and otley on friday night .
Contexts for target burst are: ['det_the', 'nn_river', 'nn_wharfe', 'depI_when', 'dep_banks', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target burst are: ['det_the', 'nn_river', 'nn_wharfe', 'depI_when', 'dep_banks', 'punct_.']
Top most similar embeddings: burst 0.01289	bursts 0.01045	wades 0.00926	swells 0.00906	tributary 0.00900	wissey 0.00876	ouse 0.00873	stort 0.00863	confluence 0.00860	doon 0.00857

Generated lemmatized results
***************
GENERATED	burst.v 1207 ::: wad;swell;tributary;wissey;ouse;stort;confluence;doon;piddle;dart

Filtered results
***************
RANKED	burst.v 1207	barge 0.00765	overflow 0.00764	rupture 0.00689	rush 0.00674	explode 0.00652	break 0.00631	erupt 0.00604	descend 0.00599	leap 0.00598	bound 0.00579	run 0.00569	end 0.00568	split 0.00567	bristle 0.00558	fracture 0.00538	pop 0.00528	surprise 0.00514	bounce 0.00506	laden 0.00488	deflate 0.00449	burgeon 0.00443	cover 0.00427	push 0.00423	enthusiastic 0.00321

Test context:
***************
burst.v	1208	11	and from what he 's seen , buckley is not exactly __bursting__ at the seams to support the knoxville church or the international churches of christ .
Contexts for target bursting are: ['cc_and', 'punct_,', 'nsubj_buckley', 'aux_is', 'neg_not', 'advmod_exactly', 'rootI_*root*', 'prep:at_seams', 'xcomp_support', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target bursting are: ['cc_and', 'punct_,', 'nsubj_buckley', 'aux_is', 'neg_not', 'advmod_exactly', 'rootI_*root*', 'prep:at_seams', 'xcomp_support', 'punct_.']
Top most similar embeddings: bursting 0.00087	brimming 0.00070	overflowing 0.00068	bristling 0.00055	heaving 0.00055	bulging 0.00053	buzzing 0.00052	booming 0.00051	teeming 0.00051	springing 0.00049

Generated lemmatized results
***************
GENERATED	burst.v 1208 ::: brim;overflow;bristle;heave;bulge;buzz;boom;teem;spring;line

Filtered results
***************
RANKED	burst.v 1208	overflow 0.00068	bristle 0.00055	pop 0.00046	explode 0.00045	break 0.00045	rush 0.00044	erupt 0.00044	leap 0.00042	push 0.00039	bounce 0.00039	split 0.00038	bound 0.00036	deflate 0.00036	cover 0.00035	barge 0.00034	rupture 0.00034	descend 0.00034	burgeon 0.00033	enthusiastic 0.00033	run 0.00033	surprise 0.00031	fracture 0.00030	end 0.00029	laden 0.00027

Test context:
***************
burst.v	1209	12	one evening , while he and jan were talking , the children __burst__ into the living room arguing about something .
Contexts for target burst are: ['advcl_talking', 'punct_,', 'nsubj_children', 'rcmodI_evening', 'prep:into_room', 'xcomp_arguing']
Contexts in vocabulary for target burst are: ['advcl_talking', 'punct_,', 'nsubj_children', 'rcmodI_evening', 'prep:into_room', 'xcomp_arguing']
Top most similar embeddings: burst 0.01362	sidled 0.01018	sauntered 0.01015	bustled 0.01000	walked 0.00997	swaggered 0.00987	spluttered 0.00980	barged 0.00975	chattered 0.00969	rushed 0.00967

Generated lemmatized results
***************
GENERATED	burst.v 1209 ::: sidle;saunter;bustle;walk;swagger;splutter;barge;chatter;rush;scurry

Filtered results
***************
RANKED	burst.v 1209	barge 0.00975	rush 0.00967	leap 0.00958	break 0.00899	erupt 0.00893	explode 0.00842	pop 0.00827	run 0.00813	bounce 0.00778	push 0.00770	overflow 0.00760	bristle 0.00758	descend 0.00735	split 0.00658	bound 0.00649	enthusiastic 0.00647	deflate 0.00643	end 0.00627	surprise 0.00588	rupture 0.00554	fracture 0.00543	burgeon 0.00529	laden 0.00447	cover 0.00446

Test context:
***************
burst.v	1210	7	( he begins to hysterically and uncontrollably __burst__ out laughing with a fiendish sound ) , that you want me as much as i do you , as a life-long mate .
Contexts for target burst are: ['aux_to', 'advmod_hysterically', 'xcompI_begins', 'prt_out', 'xcomp_laughing']
Contexts in vocabulary for target burst are: ['aux_to', 'advmod_hysterically', 'xcompI_begins', 'prt_out', 'xcomp_laughing']
Top most similar embeddings: burst 0.03297	bawl 0.02461	blurt 0.02413	wriggle 0.02240	scream 0.02221	yell 0.02205	writhe 0.02174	cry 0.02143	splutter 0.02127	sputter 0.02123

Generated lemmatized results
***************
GENERATED	burst.v 1210 ::: bawl;blurt;wriggle;scream;yell;writhe;cry;splutter;sputter;shriek

Filtered results
***************
RANKED	burst.v 1210	erupt 0.02089	explode 0.02004	break 0.01798	bounce 0.01732	push 0.01723	deflate 0.01717	pop 0.01625	rush 0.01591	leap 0.01586	run 0.01586	bristle 0.01526	rupture 0.01526	descend 0.01468	overflow 0.01442	bound 0.01433	barge 0.01410	split 0.01399	end 0.01148	cover 0.01135	fracture 0.01101	surprise 0.01088	burgeon 0.01054	laden 0.01051	enthusiastic 0.01025

Test context:
***************
call.v	1211	4	this week he 's __calling__ his company of two part-time party planners the " san francisco underground urban dance party circuit. " " you know , what we 're doing , it 's not being done, " confides the goateed professional host , " in new york , they 've let the tunnels go to the homeless .
Contexts for target calling are: ['tmod_week', 'nsubj_he', "aux_'s", 'ccompI_confides', 'dobj_company', 'dobj_circuit', 'punct_.', "punct_''", "punct_''", 'parataxis_know']
Contexts in vocabulary for target calling are: ['tmod_week', 'nsubj_he', "aux_'s", 'ccompI_confides', 'dobj_company', 'dobj_circuit', 'punct_.', 'parataxis_know']
Top most similar embeddings: calling 0.00291	dreading 0.00227	prepping 0.00221	bigging 0.00219	skiving 0.00219	dissing 0.00218	suing 0.00217	blaming 0.00215	expecting 0.00214	blames 0.00213

Generated lemmatized results
***************
GENERATED	call.v 1211 ::: dread;prepping;bigging;skive;diss;sue;blame;expect;pester;quit

Filtered results
***************
RANKED	call.v 1211	phone 0.00207	ring 0.00194	telephone 0.00179	dub 0.00165	describe 0.00162	contact 0.00159	dial 0.00157	summon 0.00152	request 0.00151	name 0.00140	designate 0.00138	address 0.00136	label 0.00125	term 0.00122	entitle 0.00112

Test context:
***************
call.v	1212	29	the article quoted richard c. darnell , president of the society , as saying that dr. j. b. rhine , director of the parapsychology laboratory at duke university , __called__ the so-called haunting the ' most impressive manifestation he has heard of in the poltergeist field. ' the article ended with the minister saying that things had been calm in the household for about the last two months .
Contexts for target called are: ['mark_that', 'nsubj_rhine', 'ccompI_saying', 'dep_haunting']
Contexts in vocabulary for target called are: ['mark_that', 'nsubj_rhine', 'ccompI_saying', 'dep_haunting']
Top most similar embeddings: called 0.04815	nicknamed 0.03874	dubbed 0.03818	nick-named 0.03632	termed 0.03628	owes 0.03585	meets 0.03511	eludes 0.03486	named 0.03473	diverges 0.03452

Generated lemmatized results
***************
GENERATED	call.v 1212 ::: nickname;dub;term;owe;meet;elude;name;diverge;evoke;flow

Filtered results
***************
RANKED	call.v 1212	dub 0.03818	term 0.03628	name 0.03473	entitle 0.03401	label 0.03273	summon 0.02983	ring 0.02955	designate 0.02833	telephone 0.02581	phone 0.02539	dial 0.02514	describe 0.02506	address 0.02494	contact 0.02451	request 0.02423

Test context:
***************
call.v	1213	33	the night i saw the play , his three guests were arthur helton , the director of peace and conflict studies for the council on foreign relations ; a female asylum-seeker from somalia __called__ ayisha ; and a serbian woman from the former yugoslavia who 'd emigrated to the us after suffering during the balkan wars .
Contexts for target called are: ['partmodI_somalia', 'dep_ayisha']
Contexts in vocabulary for target called are: []
Top most similar embeddings: called 1.00000	termed 0.81091	dubbed 0.76191	named 0.74962	titled 0.74860	nicknamed 0.74656	renamed 0.73798	nick-named 0.72438	entitled 0.71696	summoned 0.71264

Generated lemmatized results
***************
GENERATED	call.v 1213 ::: term;dub;name;title;nickname;rename;entitle;summon;refer;label

Filtered results
***************
RANKED	call.v 1213	term 0.81091	dub 0.76191	name 0.74962	entitle 0.71696	summon 0.71264	label 0.71234	phone 0.68052	describe 0.67854	dial 0.65418	designate 0.65080	contact 0.64941	address 0.63654	ring 0.63634	request 0.63013	telephone 0.62815

Test context:
***************
call.v	1214	15	launched an additional service with net2phone that lets users access information on the internet by __calling__ an 800-number .
Contexts for target calling are: ['pcompI_by', 'dobj_800-number']
Contexts in vocabulary for target calling are: ['pcompI_by']
Top most similar embeddings: calling 0.54951	terming 0.39826	phoning 0.39585	telephoning 0.39509	censuring 0.38788	abbreviating 0.38205	chastising 0.38016	castigating 0.37987	concatenating 0.37985	reprimanding 0.37951

Generated lemmatized results
***************
GENERATED	call.v 1214 ::: term;phone;telephone;censure;abbreviate;chastise;castigate;concatenate;reprimand;email

Filtered results
***************
RANKED	call.v 1214	term 0.39826	phone 0.39585	telephone 0.39509	contact 0.36937	dial 0.36709	ring 0.35575	summon 0.34683	request 0.34147	designate 0.33939	describe 0.33712	name 0.33312	address 0.33188	dub 0.32232	label 0.31299	entitle 0.30395

Test context:
***************
call.v	1215	3	eventually , someone __called__ a federal bomb squad , which arrived more than an hour after the discovery .
Contexts for target called are: ['advmod_eventually', 'punct_,', 'nsubj_someone', 'rootI_*root*', 'dobj_squad', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target called are: ['advmod_eventually', 'punct_,', 'nsubj_someone', 'rootI_*root*', 'dobj_squad', 'punct_.']
Top most similar embeddings: called 0.01399	quipped 0.01191	yelled 0.01154	told 0.01145	named 0.01124	panted 0.01123	shouted 0.01121	phoned 0.01118	joins 0.01114	dubbed 0.01112

Generated lemmatized results
***************
GENERATED	call.v 1215 ::: quip;yell;tell;name;pant;shout;phone;join;dub;rejoin

Filtered results
***************
RANKED	call.v 1215	name 0.01124	phone 0.01118	dub 0.01112	summon 0.01080	ring 0.01052	contact 0.00972	telephone 0.00958	term 0.00933	dial 0.00896	designate 0.00896	describe 0.00876	request 0.00857	label 0.00843	entitle 0.00801	address 0.00722

Test context:
***************
call.v	1216	1	we __called__ the marriott marquis hotel .
Contexts for target called are: ['nsubj_we', 'rootI_*root*', 'dep_hotel', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target called are: ['nsubj_we', 'rootI_*root*', 'dep_hotel', 'punct_.']
Top most similar embeddings: called 0.06102	honeymooned 0.04898	renamed 0.04837	www.tripadvisor.co.uk 0.04686	nick-named 0.04660	dubbed 0.04651	detoured 0.04590	named 0.04567	termed 0.04530	nicknamed 0.04530

Generated lemmatized results
***************
GENERATED	call.v 1216 ::: honeymoon;rename;dub;detour;name;term;nickname;say;chorus;specialize

Filtered results
***************
RANKED	call.v 1216	dub 0.04651	name 0.04567	term 0.04530	phone 0.03990	ring 0.03873	summon 0.03818	contact 0.03796	entitle 0.03769	describe 0.03731	telephone 0.03632	label 0.03600	request 0.03498	dial 0.03442	address 0.03421	designate 0.03402

Test context:
***************
call.v	1217	15	in text , speech marks ( ' ' ' or " ' " ' also __called__ inverted commas or quotes ) mark the beginning and end of direct speech : helen said , ' i 'm going home ' .
Contexts for target called are: ['advmod_also', 'partmodI_marks', 'dep_commas']
Contexts in vocabulary for target called are: ['advmod_also', 'partmodI_marks', 'dep_commas']
Top most similar embeddings: called 0.11808	termed 0.08336	named 0.08163	labeled 0.07985	titled 0.07875	nicknamed 0.07873	inscribed 0.07707	dubbed 0.07666	blazoned 0.07646	inverted 0.07594

Generated lemmatized results
***************
GENERATED	call.v 1217 ::: term;name;label;title;nickname;inscribe;dub;blazon;invert;insert

Filtered results
***************
RANKED	call.v 1217	term 0.08336	name 0.08163	label 0.07985	dub 0.07666	entitle 0.07191	designate 0.06773	dial 0.06513	describe 0.06345	ring 0.06298	summon 0.06118	request 0.06112	address 0.05906	contact 0.05819	telephone 0.05712	phone 0.05691

Test context:
***************
call.v	1218	3	for more information __call__ 1800 620 420. | back to top practical and financial help a serious illness often causes practical and financial difficulties .
Contexts for target call are: ['amod_more', 'nn_information', 'prep:forI_|', 'num_1800\xc2\xa0620\xc2\xa0420']
Contexts in vocabulary for target call are: ['amod_more', 'nn_information', 'prep:forI_|']
Top most similar embeddings: call 0.10143	informtion 0.08926	rmation 0.08707	infomration 0.08444	inforamtion 0.08419	infromation 0.08398	skaife 0.08290	informaton 0.08205	informatio 0.08192	calls 0.08190

Generated lemmatized results
***************
GENERATED	call.v 1218 ::: informtion;rmation;infomration;inforamtion;infromation;skaife;informaton;informatio;information;telephone

Filtered results
***************
RANKED	call.v 1218	telephone 0.08011	request 0.07978	contact 0.07916	ring 0.07301	phone 0.06759	dial 0.06360	address 0.06066	term 0.06060	label 0.06021	dub 0.05813	summon 0.05756	name 0.05641	designate 0.04445	entitle 0.03986	describe 0.03761

Test context:
***************
call.v	1219	28	and lo , i recently went into gap in oxford street , and they seemed to have an entire department devoted to non-street wear , including something they __call__ gap body , which seems to be an adult romper suit in two parts ( top and bottom ) .
Contexts for target call are: ['nsubj_they', 'rcmodI_something', 'dobj_body']
Contexts in vocabulary for target call are: ['nsubj_they', 'rcmodI_something', 'dobj_body']
Top most similar embeddings: call 0.10971	want/need 0.08973	perceive 0.08437	percieve 0.08363	disfigure 0.08320	desecrate 0.08281	craved 0.08260	calling 0.08249	possess 0.08172	nourish 0.08158

Generated lemmatized results
***************
GENERATED	call.v 1219 ::: perceive;percieve;disfigure;desecrate;crave;possess;nourish;inhabit;entangle;impel

Filtered results
***************
RANKED	call.v 1219	term 0.07525	summon 0.07487	describe 0.07154	dub 0.07116	dial 0.06859	designate 0.06792	ring 0.06790	phone 0.06644	entitle 0.06486	request 0.06336	telephone 0.06305	address 0.06270	contact 0.06258	label 0.06176	name 0.05723

Test context:
***************
call.v	1220	7	for more information about drug interactions , __call__ project inform 's hotline .
Contexts for target call are: ['nnI_project']
Contexts in vocabulary for target call are: ['nnI_project']
Top most similar embeddings: call 0.43392	camtoo 0.39096	fdtl3 0.38693	impee 0.38416	acets 0.38101	l2l 0.37397	opencourseware 0.36795	era-age 0.36526	spaceguard 0.36504	e-innovation 0.36243

Generated lemmatized results
***************
GENERATED	call.v 1220 ::: camtoo;impee;acets;opencourseware;spaceguard;disabilitycpd;achieveability;virtualis;honeynet;yamamah

Filtered results
***************
RANKED	call.v 1220	ring 0.31923	phone 0.30333	dial 0.30002	contact 0.29874	telephone 0.29517	dub 0.29126	term 0.28866	summon 0.27906	request 0.27338	name 0.26906	label 0.26800	designate 0.25422	address 0.25121	describe 0.24264	entitle 0.24031

Test context:
***************
caravan.n	1221	3	wherever the azt __caravan__ stopped , it presented physicians from important metropolitan centres like london and new york .
Contexts for target caravan are: ['det_the', 'nn_azt', 'nsubjI_stopped']
Contexts in vocabulary for target caravan are: ['det_the', 'nn_azt', 'nsubjI_stopped']
Top most similar embeddings: caravan 0.09196	truck 0.07771	mtx 0.07714	ramipril 0.07630	jeep 0.07542	lorry 0.07541	meds 0.07504	van 0.07458	trailer 0.07451	tractor 0.07436

Generated lemmatized results
***************
GENERATED	caravan.n 1221 ::: truck;mtx;ramipril;jeep;lorry;med;van;trailer;tractor;respirator

Filtered results
***************
RANKED	caravan.n 1221	trailer 0.07451	camper 0.07225	vehicle 0.06956	convoy 0.06947	roadshow 0.06706	traveller 0.06667	cavalcade 0.06502	troop 0.06220	group 0.06178	train 0.06085	crocodile 0.06032	camping 0.05955	band 0.05951	party 0.05756	company 0.05514	convey 0.02959

Test context:
***************
caravan.n	1222	3	your trailer or __caravan__ must be fitted with an approved style number plate .
Contexts for target caravan are: ['conjI_trailer']
Contexts in vocabulary for target caravan are: ['conjI_trailer']
Top most similar embeddings: caravan 0.53973	trailer 0.46034	horsebox 0.42955	caravans 0.42836	trailers 0.41695	motorhome 0.40521	campervan 0.39309	lorry 0.39298	camper 0.37900	truck 0.37486

Generated lemmatized results
***************
GENERATED	caravan.n 1222 ::: trailer;horsebox;motorhome;campervan;lorry;camper;truck;car;van;sidecar

Filtered results
***************
RANKED	caravan.n 1222	trailer 0.46034	camper 0.37900	vehicle 0.36791	camping 0.35662	cavalcade 0.32301	roadshow 0.31537	traveller 0.29720	convoy 0.29643	crocodile 0.28445	train 0.27063	troop 0.26706	party 0.26500	company 0.26367	group 0.25844	band 0.25799	convey 0.25031

Test context:
***************
caravan.n	1223	25	if you sat facing cologne you could n't see the chimney stacks further up the river , if you squinted you could n't see the __caravan__ park on the other side , if you drank enough weisse weijn the thronging day-trippers greyed-themselves out .
Contexts for target caravan are: ['nnI_park']
Contexts in vocabulary for target caravan are: ['nnI_park']
Top most similar embeddings: caravan 0.54440	brookmans 0.42012	plitvice 0.41494	chelston 0.41184	glanford 0.41078	stradey 0.40818	lucknam 0.40808	kaziranga 0.40743	pritchatts 0.40725	crawfordsburn 0.40651

Generated lemmatized results
***************
GENERATED	caravan.n 1223 ::: brookmans;plitvice;chelston;glanford;stradey;lucknam;kaziranga;pritchatts;crawfordsburn;keoladeo

Filtered results
***************
RANKED	caravan.n 1223	trailer 0.37488	camping 0.37441	camper 0.35345	vehicle 0.33179	roadshow 0.31727	cavalcade 0.29835	convoy 0.29507	crocodile 0.29442	traveller 0.29201	troop 0.27487	company 0.27113	group 0.27042	party 0.26615	band 0.26464	train 0.26443	convey 0.24036

Test context:
***************
caravan.n	1224	2	tent , __caravan__ or campervan. ' make sure of your future work plans before you move on from your present location .
Contexts for target caravan are: ['conjI_tent']
Contexts in vocabulary for target caravan are: ['conjI_tent']
Top most similar embeddings: caravan 0.55343	tent 0.44000	caravans 0.43056	motorhome 0.41384	tents 0.41368	camping 0.39949	tipi 0.39845	horsebox 0.39569	campervan 0.38724	trailer 0.38619

Generated lemmatized results
***************
GENERATED	caravan.n 1224 ::: tent;motorhome;camping;tipi;horsebox;campervan;trailer;camper;marquee;yurt

Filtered results
***************
RANKED	caravan.n 1224	camping 0.39949	trailer 0.38619	camper 0.38364	vehicle 0.33250	roadshow 0.32817	cavalcade 0.31022	convoy 0.30141	troop 0.28934	band 0.28897	traveller 0.28631	party 0.27885	crocodile 0.27812	company 0.26106	train 0.25382	group 0.25250	convey 0.24178

Test context:
***************
caravan.n	1225	5	you might think of several __caravans__ of trucks all using the same road system to carry materials .
Contexts for target caravans are: ['amod_several', 'prep:ofI_think', 'prep:of_trucks']
Contexts in vocabulary for target caravans are: ['amod_several', 'prep:ofI_think', 'prep:of_trucks']
Top most similar embeddings: caravans 0.10485	bmws 0.08783	mpvs 0.08521	hearses 0.08481	vans 0.08476	cars 0.08303	motorcars 0.08273	waggons 0.08253	hatchbacks 0.08253	rickshaws 0.08211

Generated lemmatized results
***************
GENERATED	caravan.n 1225 ::: bmws;mpvs;hearse;van;car;motorcar;waggon;hatchback;rickshaw;sinking

Filtered results
***************
RANKED	caravan.n 1225	camper 0.07940	vehicle 0.07853	convoy 0.07788	trailer 0.07610	band 0.07094	crocodile 0.07084	train 0.06927	traveller 0.06849	group 0.06356	camping 0.06230	cavalcade 0.06096	company 0.06077	troop 0.05996	party 0.05717	roadshow 0.05025	convey 0.03499

Test context:
***************
caravan.n	1226	13	the town is also well known as a transit point for the camel __caravans__ bringing salt up from the arid lands of the dankal depression .
Contexts for target caravans are: ['det_the', 'nn_camel', 'prep:forI_point', 'partmod_bringing']
Contexts in vocabulary for target caravans are: ['det_the', 'nn_camel', 'prep:forI_point', 'partmod_bringing']
Top most similar embeddings: caravans 0.05668	caravan 0.04566	lorries 0.04449	tourers 0.04429	convoys 0.04399	yachts 0.04361	barges 0.04313	campers 0.04282	stagecoaches 0.04254	narrowboats 0.04186

Generated lemmatized results
***************
GENERATED	caravan.n 1226 ::: lorry;tourer;convoy;yacht;barge;camper;stagecoach;narrowboat;boat;waggon

Filtered results
***************
RANKED	caravan.n 1226	convoy 0.04399	camper 0.04282	train 0.03886	vehicle 0.03823	cavalcade 0.03751	traveller 0.03682	roadshow 0.03656	trailer 0.03630	troop 0.03385	crocodile 0.03258	camping 0.03243	band 0.03126	company 0.02976	group 0.02946	party 0.02841	convey 0.01539

Test context:
***************
caravan.n	1227	11	in his distress of mind at being left behind by the __caravan__ , he had not noticed where he had thrown the load .
Contexts for target caravan are: ['det_the', 'prep:byI_left']
Contexts in vocabulary for target caravan are: ['det_the', 'prep:byI_left']
Top most similar embeddings: caravan 0.24889	caravans 0.19262	lorry 0.19167	bucketload 0.18920	road-side 0.18822	land-rover 0.18726	motor-car 0.18685	dustcart 0.18484	horsebox 0.18470	grundys 0.18464

Generated lemmatized results
***************
GENERATED	caravan.n 1227 ::: lorry;bucketload;dustcart;horsebox;grundys;roundhead;landrover;ferryboat;gregory;car

Filtered results
***************
RANKED	caravan.n 1227	trailer 0.17430	camper 0.17163	convoy 0.16758	vehicle 0.16727	cavalcade 0.15653	traveller 0.15591	troop 0.15578	camping 0.15557	train 0.15193	roadshow 0.15193	crocodile 0.14642	party 0.14630	band 0.14489	company 0.13951	group 0.13820	convey 0.08591

Test context:
***************
caravan.n	1228	17	about the time that ross , trudo , and benware were beating tipton senseless , the three-vehicle __caravan__ , led by the blazer , with defendant as the driver and harris as a passenger , pulled into the parking lot .
Contexts for target caravan are: ['det_the', 'amod_three-vehicle', 'nsubjI_pulled', 'punct_,', 'partmod_led', 'punct_,', 'prep:with_defendant', 'prep:as_driver', 'prep:as_passenger', 'punct_,']
Contexts in vocabulary for target caravan are: ['det_the', 'nsubjI_pulled', 'punct_,', 'partmod_led', 'punct_,', 'prep:with_defendant', 'prep:as_driver', 'prep:as_passenger', 'punct_,']
Top most similar embeddings: caravan 0.00099	kdg 0.00096	waggons 0.00095	lancers 0.00094	ronin 0.00093	loane 0.00090	stevedores 0.00090	jeeps 0.00090	dakotas 0.00089	kirton 0.00089

Generated lemmatized results
***************
GENERATED	caravan.n 1228 ::: kdg;waggon;lancer;ronin;loane;stevedore;jeep;dakota;kirton;fangio

Filtered results
***************
RANKED	caravan.n 1228	trailer 0.00082	convoy 0.00079	camper 0.00078	cavalcade 0.00074	troop 0.00069	train 0.00069	band 0.00068	camping 0.00067	traveller 0.00064	crocodile 0.00061	vehicle 0.00061	roadshow 0.00061	party 0.00051	company 0.00050	group 0.00043	convey 0.00035

Test context:
***************
caravan.n	1229	10	lazy lizard caravan park , pine creek small and nondescript __caravan__ park behind the pine creek tavern , off the stuart highway .
Contexts for target caravan are: ['nnI_park']
Contexts in vocabulary for target caravan are: ['nnI_park']
Top most similar embeddings: caravan 0.54440	brookmans 0.42012	plitvice 0.41494	chelston 0.41184	glanford 0.41078	stradey 0.40818	lucknam 0.40808	kaziranga 0.40743	pritchatts 0.40725	crawfordsburn 0.40651

Generated lemmatized results
***************
GENERATED	caravan.n 1229 ::: brookmans;plitvice;chelston;glanford;stradey;lucknam;kaziranga;pritchatts;crawfordsburn;keoladeo

Filtered results
***************
RANKED	caravan.n 1229	trailer 0.37488	camping 0.37441	camper 0.35345	vehicle 0.33179	roadshow 0.31727	cavalcade 0.29835	convoy 0.29507	crocodile 0.29442	traveller 0.29201	troop 0.27487	company 0.27113	group 0.27042	party 0.26615	band 0.26464	train 0.26443	convey 0.24036

Test context:
***************
caravan.n	1230	5	directly away from where the __caravan__ was headed. : : : yang watched the exchange with interest .
Contexts for target caravan are: ['det_the', 'nsubjpassI_headed']
Contexts in vocabulary for target caravan are: ['det_the', 'nsubjpassI_headed']
Top most similar embeddings: caravan 0.22969	motorcade 0.18623	cortege 0.18542	caravans 0.18238	convoy 0.17680	motorhome 0.17663	trailer 0.17577	car 0.17462	lrdg 0.17403	jeep 0.17391

Generated lemmatized results
***************
GENERATED	caravan.n 1230 ::: motorcade;cortege;convoy;motorhome;trailer;car;lrdg;jeep;windcheetah;rhib

Filtered results
***************
RANKED	caravan.n 1230	convoy 0.17680	trailer 0.17577	vehicle 0.16934	cavalcade 0.16062	roadshow 0.15835	camper 0.15696	group 0.15656	company 0.15207	troop 0.15122	band 0.14958	train 0.14693	party 0.14418	traveller 0.14391	camping 0.14356	crocodile 0.13083	convey 0.09086

Test context:
***************
carry.v	1231	21	the fifeshire under the command of under captain arnold was wrecked while leaving nelson on 27 february 1842 when the tide __carried__ her onto arrow reef named after a vessel that was part of the survey expedition .
Contexts for target carried are: ['advmod_when', 'nsubj_tide', 'advclI_leaving', 'dep_her']
Contexts in vocabulary for target carried are: ['advmod_when', 'nsubj_tide', 'advclI_leaving', 'dep_her']
Top most similar embeddings: carried 0.04571	refloated 0.04257	turned 0.04160	drowns 0.04126	recedes 0.04125	abates 0.04100	wanes 0.04082	topples 0.04063	waked 0.04046	scuttles 0.04041

Generated lemmatized results
***************
GENERATED	carry.v 1231 ::: refloat;turn;drown;recede;abate;wan;topple;wake;scuttle;slacken

Filtered results
***************
RANKED	carry.v 1231	drag 0.03865	bring 0.03567	take 0.03438	lug 0.03436	convey 0.03429	transport 0.03389	do 0.03309	clutch 0.03309	bear 0.03308	complete 0.03307	send 0.03210	undertake 0.03083	accomplish 0.03045	perform 0.03042	fulfil 0.03005	conclude 0.02991	execute 0.02986	hold 0.02902	transmit 0.02837	deploy 0.02818	pack 0.02799	contain 0.02638	use 0.02473

Test context:
***************
carry.v	1232	21	beside which , these needles dull quickly , and can develop barbs and hooks which not only mangle the skin but __carry__ microrust , which can cause infection .
Contexts for target carry are: ['conjI_mangle', 'dobj_microrust']
Contexts in vocabulary for target carry are: []
Top most similar embeddings: carry 1.00000	carrying 0.84190	carries 0.83580	carried 0.79913	undertake 0.75828	carring 0.75099	take 0.72366	carryout 0.72173	mass-produce 0.71950	invigilate 0.71258

Generated lemmatized results
***************
GENERATED	carry.v 1232 ::: undertake;carring;take;carryout;invigilate;perform;disgorge;revalidate;manhandle;fulfill

Filtered results
***************
RANKED	carry.v 1232	undertake 0.75828	take 0.72366	perform 0.71215	convey 0.70233	bring 0.69946	lug 0.68708	do 0.68671	fulfil 0.68469	contain 0.67851	accomplish 0.67532	execute 0.67375	transport 0.66872	send 0.66712	hold 0.66268	bear 0.65526	transmit 0.65238	deploy 0.64845	use 0.64138	drag 0.63766	complete 0.63274	conclude 0.63064	clutch 0.62890	pack 0.60779

Test context:
***************
carry.v	1233	12	government sources tell nbc news that federal investigators recently were able to __carry__ materials needed to make a similar homemade bomb through security screening at 21 airports .
Contexts for target carry are: ['aux_to', 'xcompI_able', 'dobj_materials']
Contexts in vocabulary for target carry are: ['aux_to', 'xcompI_able', 'dobj_materials']
Top most similar embeddings: carry 0.13618	mass-produce 0.11866	repurpose 0.10825	commercialize 0.10796	re-distribute 0.10767	reprocess 0.10624	retreive 0.10615	recondition 0.10438	reprogramme 0.10433	monetise 0.10411

Generated lemmatized results
***************
GENERATED	carry.v 1233 ::: repurpose;commercialize;reprocess;retreive;recondition;reprogramme;monetise;decontaminate;sanitize;utilise

Filtered results
***************
RANKED	carry.v 1233	undertake 0.10054	bring 0.09491	convey 0.09485	deploy 0.09380	transmit 0.09167	perform 0.09138	take 0.09055	use 0.08675	send 0.08605	fulfil 0.08554	hold 0.08452	execute 0.08399	contain 0.08346	accomplish 0.08310	do 0.07951	bear 0.07623	drag 0.07571	complete 0.07515	conclude 0.07235	lug 0.07176	transport 0.07109	pack 0.06565	clutch 0.06006

Test context:
***************
carry.v	1234	4	the alsep on a-17 __carried__ different instruments once the networks had been established by earlier flights .
Contexts for target carried are: ['nsubj_alsep', 'rootI_*root*', 'dobj_instruments', 'advcl_established', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target carried are: ['rootI_*root*', 'dobj_instruments', 'advcl_established', 'punct_.']
Top most similar embeddings: carried 0.05875	carries 0.04826	conducted 0.04564	undertaken 0.04519	pioneered 0.04433	developed 0.04383	incorporates 0.04349	developped 0.04307	carry 0.04293	adopted 0.04279

Generated lemmatized results
***************
GENERATED	carry.v 1234 ::: conduct;undertake;pioneer;develop;incorporate;developped;adopt;strengthen;initiate;play

Filtered results
***************
RANKED	carry.v 1234	undertake 0.04519	use 0.04220	take 0.04173	perform 0.04156	bring 0.04152	hold 0.04060	contain 0.04018	bear 0.04006	conclude 0.03936	send 0.03821	complete 0.03818	convey 0.03756	deploy 0.03741	execute 0.03731	transport 0.03697	lug 0.03659	accomplish 0.03537	transmit 0.03502	do 0.03492	fulfil 0.03462	drag 0.03460	pack 0.03356	clutch 0.03177

Test context:
***************
carry.v	1235	23	" 2 dr. borlaug cannot afford to wait : there is an important cause weighing on his mind , something that must be __carried__ out and must be carried out now .
Contexts for target carried are: ['nsubjpass_that', 'aux_must', 'auxpass_be', 'rcmodI_something', 'prt_out', 'cc_and', 'conj_carried']
Contexts in vocabulary for target carried are: ['nsubjpass_that', 'aux_must', 'auxpass_be', 'rcmodI_something', 'prt_out', 'cc_and', 'conj_carried']
Top most similar embeddings: carried 0.00835	borne 0.00599	worn 0.00584	ironed 0.00578	weighed 0.00564	checked 0.00554	bulked 0.00548	costed 0.00545	taken 0.00545	baled 0.00544

Generated lemmatized results
***************
GENERATED	carry.v 1235 ::: bear;wear;iron;weigh;check;bulk;cost;take;bale;prick

Filtered results
***************
RANKED	carry.v 1235	bear 0.00599	take 0.00545	undertake 0.00535	drag 0.00512	do 0.00509	lug 0.00507	bring 0.00499	transport 0.00487	convey 0.00472	send 0.00449	complete 0.00448	perform 0.00442	hold 0.00439	pack 0.00435	accomplish 0.00435	fulfil 0.00433	transmit 0.00429	execute 0.00428	use 0.00400	deploy 0.00393	contain 0.00371	clutch 0.00367	conclude 0.00300

Test context:
***************
carry.v	1236	6	2001 february - britain , us __carry__ out bombing raids to try to disable iraq 's air defence network .
Contexts for target carry are: ['nsubj_us', 'rcmodI_february', 'prt_out', 'dobj_raids', 'xcomp_try']
Contexts in vocabulary for target carry are: ['nsubj_us', 'rcmodI_february', 'prt_out', 'dobj_raids', 'xcomp_try']
Top most similar embeddings: carry 0.02771	carrying 0.02375	carried 0.02201	carries 0.02001	carring 0.02000	scurrying 0.01963	bombed 0.01843	flew 0.01813	scuttled 0.01802	smuggle 0.01762

Generated lemmatized results
***************
GENERATED	carry.v 1236 ::: carring;scurry;bomb;fly;scuttle;smuggle;sallied;ferry;dissect;step

Filtered results
***************
RANKED	carry.v 1236	lug 0.01694	send 0.01692	undertake 0.01643	perform 0.01642	take 0.01611	bear 0.01530	drag 0.01513	execute 0.01508	hold 0.01491	clutch 0.01488	bring 0.01486	pack 0.01386	deploy 0.01382	transport 0.01376	transmit 0.01354	fulfil 0.01345	do 0.01344	conclude 0.01340	accomplish 0.01317	convey 0.01312	complete 0.01246	use 0.01135	contain 0.01110

Test context:
***************
carry.v	1237	15	2 " in our changing society , many people who dine in our restaurant dislike __carrying__ money .
Contexts for target carrying are: ['partmodI_dislike', 'dobj_money']
Contexts in vocabulary for target carrying are: ['dobj_money']
Top most similar embeddings: carrying 0.48717	carry 0.40831	stashing 0.39771	disbursing 0.39667	siphoning 0.39609	extorting 0.39483	embezzling 0.39284	carring 0.38599	pocketing 0.38094	carries 0.37612

Generated lemmatized results
***************
GENERATED	carry.v 1237 ::: stash;disburse;siphon;extort;embezzle;carring;pocket;transport;reallocate;doling

Filtered results
***************
RANKED	carry.v 1237	transport 0.37431	lug 0.36824	take 0.36210	send 0.35947	bring 0.34511	hold 0.34259	use 0.33856	clutch 0.33834	convey 0.33138	transmit 0.32796	drag 0.32655	contain 0.32391	deploy 0.31598	bear 0.31005	do 0.30109	perform 0.29963	pack 0.29936	execute 0.29883	fulfil 0.29670	undertake 0.29664	accomplish 0.29595	complete 0.29361	conclude 0.25761

Test context:
***************
carry.v	1238	1	they __carried__ with them their carefully wrapped torah scrolls .
Contexts for target carried are: ['nsubj_they', 'rootI_*root*', 'prep:with_them', 'dobj_scrolls', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target carried are: ['nsubj_they', 'rootI_*root*', 'prep:with_them', 'dobj_scrolls', 'punct_.']
Top most similar embeddings: carried 0.02815	carry 0.02401	quarreled 0.02239	brought 0.02227	gossiped 0.02218	loitered 0.02209	rummaged 0.02180	took 0.02179	lugged 0.02174	honeymooned 0.02145

Generated lemmatized results
***************
GENERATED	carry.v 1238 ::: quarrel;bring;gossip;loiter;rummage;take;lug;honeymoon;blazon;seethe

Filtered results
***************
RANKED	carry.v 1238	bring 0.02227	take 0.02179	lug 0.02174	undertake 0.02068	conclude 0.01987	hold 0.01937	bear 0.01932	perform 0.01902	drag 0.01881	contain 0.01876	do 0.01823	transport 0.01819	convey 0.01808	send 0.01801	pack 0.01725	complete 0.01722	clutch 0.01716	execute 0.01701	accomplish 0.01668	use 0.01625	deploy 0.01557	fulfil 0.01549	transmit 0.01482

Test context:
***************
carry.v	1239	26	in 1889 he won a huge contract to supply ammunition and founded in 1889 the " rheinische metallwaaren und maschinenfabrik " with the explicit purpose to __carry__ out this contract and establish himself as a military supplier .
Contexts for target carry are: ['aux_to', 'infmodI_purpose', 'prt_out', 'dobj_contract', 'cc_and', 'conj_establish']
Contexts in vocabulary for target carry are: ['aux_to', 'infmodI_purpose', 'prt_out', 'dobj_contract', 'cc_and', 'conj_establish']
Top most similar embeddings: carry 0.01575	formalize 0.01166	wheedle 0.01141	oversee 0.01112	consolidate 0.01106	dissect 0.01102	revalidate 0.01101	extend 0.01092	centralize 0.01092	reorganize 0.01087

Generated lemmatized results
***************
GENERATED	carry.v 1239 ::: formalize;wheedle;oversee;consolidate;dissect;revalidate;extend;centralize;reorganize;mete

Filtered results
***************
RANKED	carry.v 1239	undertake 0.01057	fulfil 0.01034	bring 0.01024	execute 0.00937	take 0.00928	perform 0.00915	hold 0.00906	transmit 0.00849	convey 0.00848	deploy 0.00825	send 0.00807	accomplish 0.00807	complete 0.00798	conclude 0.00779	drag 0.00724	lug 0.00706	bear 0.00695	contain 0.00677	transport 0.00602	do 0.00596	pack 0.00567	use 0.00561	clutch 0.00509

Test context:
***************
carry.v	1240	12	even if item-level information remains generic , identifying items people wear or __carry__ could associate them with , for example , particular events like political rallies .
Contexts for target carry are: ['conjI_wear']
Contexts in vocabulary for target carry are: ['conjI_wear']
Top most similar embeddings: carry 0.51306	carries 0.40529	carrying 0.40280	wear 0.38221	tie-dye 0.36085	embroider 0.36016	carried 0.35757	reseal 0.35754	vandalise 0.35613	tear 0.35497

Generated lemmatized results
***************
GENERATED	carry.v 1240 ::: wear;embroider;reseal;vandalise;tear;bring;accessorise;recondition;discolour;undertake

Filtered results
***************
RANKED	carry.v 1240	bring 0.35439	undertake 0.35036	perform 0.34398	take 0.34243	lug 0.32859	convey 0.31935	transport 0.31804	execute 0.30843	do 0.30730	bear 0.30714	transmit 0.30596	fulfil 0.30095	hold 0.29863	use 0.29863	accomplish 0.29607	clutch 0.29558	deploy 0.29416	drag 0.29414	send 0.29134	contain 0.28872	pack 0.28693	complete 0.28282	conclude 0.28115

Test context:
***************
clear.a	1241	39	peter orszag , brookings institution : and just briefly , for example , on preferred stock , at least according to initial reports , dividends paid on preferred stock are treated as interest income , and it 's not __clear__ whether they would be exempted or not under this proposal .
Contexts for target clear are: ['nsubj_it', "cop_'s", 'neg_not', 'conjI_treated', 'ccomp_exempted']
Contexts in vocabulary for target clear are: ['nsubj_it', "cop_'s", 'neg_not', 'conjI_treated', 'ccomp_exempted']
Top most similar embeddings: clear 0.03214	surprising 0.02351	arguable 0.02325	obvious 0.02316	probable 0.02218	unclear 0.02199	apparent 0.02162	possible 0.02151	inconceivable 0.02112	evident 0.02070

Generated lemmatized results
***************
GENERATED	clear.a 1241 ::: surprising;arguable;obvious;probable;unclear;apparent;possible;inconceivable;evident;unreasonable

Filtered results
***************
RANKED	clear.a 1241	obvious 0.02316	apparent 0.02162	evident 0.02070	true 0.01991	understandable 0.01836	transparent 0.01655	plain 0.01614	unambiguous 0.01590	certain 0.01576	unmistakable 0.01492	clean 0.01480	definite 0.01441	distinct 0.01346	pure 0.01332	lucid 0.01292	sharp 0.01266	fresh 0.01234	unobscured 0.01144	distinctly 0.01129	patent 0.00984

Test context:
***************
clear.a	1242	30	on the way ahead , it was proposed that canada simultaneously pursue incremental approaches and outright abolition , on the grounds that incrementalism on its own was pointless without a __clear__ sense of the final destination , but also that it was important not to force others to choose between the two because this would simply lose canada allies .
Contexts for target clear are: ['amodI_sense']
Contexts in vocabulary for target clear are: ['amodI_sense']
Top most similar embeddings: clear 0.51025	clearer 0.41831	crystal-clear 0.40507	clearest 0.39581	non-literal 0.38391	undisguised 0.38076	obvious 0.37847	clear-cut 0.37675	universalistic 0.37607	loosest 0.37546

Generated lemmatized results
***************
GENERATED	clear.a 1242 ::: undisguised;obvious;universalistic;loose;incontestable;categoric;unarguable;indubitable;apparent;commonsensical

Filtered results
***************
RANKED	clear.a 1242	obvious 0.37847	apparent 0.37082	unambiguous 0.36992	unmistakable 0.36843	evident 0.36326	plain 0.36113	definite 0.35755	true 0.35092	certain 0.34498	distinct 0.34278	understandable 0.33570	lucid 0.33271	sharp 0.33019	pure 0.32875	transparent 0.32583	clean 0.31913	fresh 0.31796	unobscured 0.30542	distinctly 0.30291	patent 0.23420

Test context:
***************
clear.a	1243	10	in this regard , neither ink appears to have a __clear__ advantage over the other .
Contexts for target clear are: ['amodI_advantage']
Contexts in vocabulary for target clear are: ['amodI_advantage']
Top most similar embeddings: clear 0.50992	obvious 0.38616	clearest 0.37976	one-point 0.37791	eight-point 0.37484	clearer 0.37481	clear-cut 0.37413	nine-point 0.37274	apparent 0.37035	incontestable 0.37034

Generated lemmatized results
***************
GENERATED	clear.a 1243 ::: obvious;apparent;incontestable;indisputable;evident;undisputable;unarguable;unquestionable;unambiguous;definite

Filtered results
***************
RANKED	clear.a 1243	obvious 0.38616	apparent 0.37035	evident 0.36285	unambiguous 0.35976	definite 0.35936	distinct 0.35916	unmistakable 0.34899	certain 0.32413	understandable 0.32145	transparent 0.31897	plain 0.31882	true 0.31821	clean 0.31116	sharp 0.30436	fresh 0.30186	pure 0.29517	distinctly 0.29311	lucid 0.28805	unobscured 0.28189	patent 0.25526

Test context:
***************
clear.a	1244	2	what is __clear__ is that we should consider a company like microsoft to potentially be able to wield the same kind of power as the foundation .
Contexts for target clear are: ['nsubj_what', 'cop_is', 'csubjI_is']
Contexts in vocabulary for target clear are: ['nsubj_what', 'cop_is', 'csubjI_is']
Top most similar embeddings: clear 0.13859	unclear 0.10382	apparant 0.10315	incontestable 0.10217	indisputable 0.10191	evident 0.10180	apparent 0.10045	obvious 0.10024	undeniable 0.09930	undisputable 0.09769

Generated lemmatized results
***************
GENERATED	clear.a 1244 ::: unclear;apparant;incontestable;indisputable;evident;apparent;obvious;undeniable;undisputable;unarguable

Filtered results
***************
RANKED	clear.a 1244	evident 0.10180	apparent 0.10045	obvious 0.10024	certain 0.08930	true 0.08715	unambiguous 0.08497	understandable 0.08345	unmistakable 0.08097	definite 0.07791	distinct 0.07489	plain 0.07425	clean 0.07153	transparent 0.07091	lucid 0.07022	sharp 0.06589	fresh 0.06497	pure 0.06416	unobscured 0.05900	patent 0.05267	distinctly 0.05164

Test context:
***************
clear.a	1245	17	after opening a few files in the sample project the concept of projects and file usage is __clear__ .
Contexts for target clear are: ['mark_after', 'dep_opening', 'nsubj_concept', 'cop_is', 'rootI_*root*', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target clear are: ['mark_after', 'dep_opening', 'nsubj_concept', 'cop_is', 'rootI_*root*', 'punct_.']
Top most similar embeddings: clear 0.01323	unclear 0.01216	evident 0.01133	apparant 0.01126	clearer 0.01112	two-fold 0.01105	clear-cut 0.01036	self-evident 0.01023	incontestable 0.01023	apparent 0.01020

Generated lemmatized results
***************
GENERATED	clear.a 1245 ::: unclear;evident;apparant;incontestable;apparent;debateable;uncertain;debatable;clarified;fraught

Filtered results
***************
RANKED	clear.a 1245	evident 0.01133	apparent 0.01020	obvious 0.00981	understandable 0.00931	unmistakable 0.00879	true 0.00868	unambiguous 0.00798	plain 0.00777	lucid 0.00762	transparent 0.00753	sharp 0.00751	clean 0.00701	distinct 0.00695	unobscured 0.00674	definite 0.00637	fresh 0.00627	pure 0.00613	certain 0.00602	distinctly 0.00461	patent 0.00461

Test context:
***************
clear.a	1246	1	the __clear__ cool breeze is on your face first thing in the morning , and the children have new energy and interest in the season .
Contexts for target clear are: ['amodI_breeze']
Contexts in vocabulary for target clear are: ['amodI_breeze']
Top most similar embeddings: clear 0.47187	crystal-clear 0.39132	clearer 0.39049	clearest 0.37367	balmy 0.36672	limpid 0.36450	wintery 0.36308	gusty 0.36163	blustery 0.36072	e'ly 0.36071

Generated lemmatized results
***************
GENERATED	clear.a 1246 ::: balmy;limpid;wintery;gusty;blustery;hazy;southwesterly;northwesterly;northeasterly;cloudless

Filtered results
***************
RANKED	clear.a 1246	apparent 0.35160	fresh 0.34573	unmistakable 0.34532	definite 0.34201	evident 0.34156	obvious 0.33312	unambiguous 0.33132	clean 0.32976	transparent 0.32403	plain 0.32256	lucid 0.32142	distinct 0.31454	sharp 0.31095	certain 0.31038	pure 0.30021	understandable 0.29836	true 0.29810	unobscured 0.29052	distinctly 0.28005	patent 0.23106

Test context:
***************
clear.a	1247	7	the reaction from one of them was __clear__ : 'yappari , towel desu '(again a towel ) .
Contexts for target clear are: ['nsubj_reaction', 'cop_was', 'rootI_*root*', 'punct_:', 'punct_`', 'dep_yappari', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target clear are: ['nsubj_reaction', 'cop_was', 'rootI_*root*', 'punct_:', 'punct_`', 'punct_.']
Top most similar embeddings: clear 0.01205	ho-hum 0.01137	unequivocal 0.01134	wutch 0.01133	two-fold 0.01125	unforgiveable 0.01106	doct 0.01102	csk 0.01093	unprintable 0.01070	emphatic 0.01068

Generated lemmatized results
***************
GENERATED	clear.a 1247 ::: unequivocal;wutch;unforgiveable;doct;csk;unprintable;emphatic;evident;indisputable;twofold

Filtered results
***************
RANKED	clear.a 1247	evident 0.01066	understandable 0.01017	unmistakable 0.00982	obvious 0.00971	unambiguous 0.00919	apparent 0.00908	true 0.00870	plain 0.00806	sharp 0.00752	lucid 0.00723	transparent 0.00706	clean 0.00704	definite 0.00675	pure 0.00654	distinct 0.00653	certain 0.00634	unobscured 0.00602	fresh 0.00589	patent 0.00474	distinctly 0.00418

Test context:
***************
clear.a	1248	17	the iraqis were sitting on the desert floor in groups of three or four ; it was __clear__ that they were tired , cold , and hungry .
Contexts for target clear are: ['nsubj_it', 'cop_was', 'parataxisI_sitting', 'ccomp_tired']
Contexts in vocabulary for target clear are: ['nsubj_it', 'cop_was', 'parataxisI_sitting', 'ccomp_tired']
Top most similar embeddings: clear 0.05808	obvious 0.04580	apparent 0.04450	unclear 0.04439	evident 0.04359	apparant 0.04343	clearer 0.04317	snowed 0.04213	foggy 0.04149	inconceivable 0.04060

Generated lemmatized results
***************
GENERATED	clear.a 1248 ::: obvious;apparent;unclear;evident;apparant;snowed;foggy;inconceivable;ironical;arguable

Filtered results
***************
RANKED	clear.a 1248	obvious 0.04580	apparent 0.04450	evident 0.04359	understandable 0.03774	true 0.03666	plain 0.03609	unmistakable 0.03394	clean 0.03358	certain 0.03119	sharp 0.03095	unambiguous 0.02993	pure 0.02885	transparent 0.02863	fresh 0.02846	lucid 0.02787	definite 0.02773	distinct 0.02681	unobscured 0.02638	distinctly 0.02427	patent 0.01970

Test context:
***************
clear.a	1249	5	i made that point perfectly __clear__ to those of you who i discussed that with on thursday .
Contexts for target clear are: ['advmod_perfectly', 'acompI_made', 'prep:to_those']
Contexts in vocabulary for target clear are: ['advmod_perfectly', 'acompI_made', 'prep:to_those']
Top most similar embeddings: clear 0.13546	comprehensible 0.10129	evident 0.09684	intelligible 0.09646	clearer 0.09640	obvious 0.09540	apparent 0.09495	crystal-clear 0.09481	perspicuous 0.09340	apparant 0.09295

Generated lemmatized results
***************
GENERATED	clear.a 1249 ::: comprehensible;evident;intelligible;obvious;apparent;perspicuous;apparant;calculable;understandable;transparent

Filtered results
***************
RANKED	clear.a 1249	evident 0.09684	obvious 0.09540	apparent 0.09495	understandable 0.09244	transparent 0.09219	unambiguous 0.08797	plain 0.08425	unmistakable 0.07812	distinct 0.07678	true 0.07322	clean 0.07269	fresh 0.07172	lucid 0.07125	definite 0.07072	certain 0.07062	pure 0.06990	unobscured 0.06681	sharp 0.06630	distinctly 0.05733	patent 0.04918

Test context:
***************
clear.a	1250	34	i 've bumped it a few times and it never rips or breaks. if you could give us some idea , the pics are n't the greatest , but i 'm hoping they are __clear__ enough to give you some kind of idea what he is .
Contexts for target clear are: ['nsubj_they', 'cop_are', 'ccompI_hoping', 'dep_enough']
Contexts in vocabulary for target clear are: ['nsubj_they', 'cop_are', 'ccompI_hoping', 'dep_enough']
Top most similar embeddings: clear 0.05323	clearer 0.04349	lucky 0.04205	confident 0.04097	overconfident 0.04029	teachable 0.03981	open-minded 0.03949	clear-headed 0.03947	sober 0.03925	capable 0.03923

Generated lemmatized results
***************
GENERATED	clear.a 1250 ::: lucky;confident;overconfident;teachable;sober;capable;invulnerable;watertight;fixable;clever

Filtered results
***************
RANKED	clear.a 1250	obvious 0.03775	apparent 0.03711	clean 0.03707	evident 0.03597	unambiguous 0.03587	sharp 0.03540	understandable 0.03534	unmistakable 0.03476	true 0.03463	transparent 0.03435	fresh 0.03394	lucid 0.03379	plain 0.03301	definite 0.03280	certain 0.03191	pure 0.03063	distinct 0.02962	distinctly 0.02296	unobscured 0.02291	patent 0.02248

Test context:
***************
close.r	1251	34	well , she finally deigned to bring my basin , and even though i swear i did n't plan it , i projectiled all over the front of her as soon as she got __close__ to my bed .
Contexts for target close are: ['advmodI_got', 'prep:to_bed']
Contexts in vocabulary for target close are: ['advmodI_got', 'prep:to_bed']
Top most similar embeddings: close 0.25108	closer 0.19681	nearer 0.17525	sleepily 0.17154	jauntily 0.17009	closest 0.16995	eventualy 0.16897	unsteadily 0.16791	belly-up 0.16791	tamely 0.16784

Generated lemmatized results
***************
GENERATED	close.r 1251 ::: closer;nearer;sleepily;jauntily;closest;eventualy;unsteadily;tamely;dejectedly;back

Filtered results
***************
RANKED	close.r 1251	adjacent 0.15605	near 0.15433	next 0.15308	almost 0.12994	contiguous 0.12620	about 0.12540	proximate 0.10701	neighbouring 0.09823	local 0.09609

Test context:
***************
close.r	1252	12	the control of government spending has improved , tax rates have stayed __close__ to the low levels set in the early 1980s , regulatory pressure has eased , and monetary policy has been superb and steady .
Contexts for target close are: ['advmodI_stayed', 'prep:to_levels']
Contexts in vocabulary for target close are: ['advmodI_stayed', 'prep:to_levels']
Top most similar embeddings: close 0.25612	closer 0.19143	perpendicularly 0.17556	closest 0.17343	nearer 0.16797	sluggishly 0.15982	spasmodically 0.15869	adjacent 0.15810	distally 0.15476	inefficiently 0.15429

Generated lemmatized results
***************
GENERATED	close.r 1252 ::: closer;perpendicularly;closest;nearer;sluggishly;spasmodically;adjacent;distally;inefficiently;awake

Filtered results
***************
RANKED	close.r 1252	adjacent 0.15810	near 0.15048	contiguous 0.13872	next 0.13796	proximate 0.11915	almost 0.11718	about 0.11397	neighbouring 0.10558	local 0.10427

Test context:
***************
close.r	1253	11	the application was opposed by a substantial number of residents living __close__ to the property .
Contexts for target close are: ['amodI_living', 'prep:to_property']
Contexts in vocabulary for target close are: ['amodI_living', 'prep:to_property']
Top most similar embeddings: close 0.25279	adjacent 0.18517	closest 0.18505	closer 0.17881	next-door 0.16868	nearest 0.16301	nearer 0.16189	near 0.16097	relative 0.16073	near-by 0.16049

Generated lemmatized results
***************
GENERATED	close.r 1253 ::: adjacent;closest;closer;nearest;nearer;near;relative;contiguous;adjoining;uncongenial

Filtered results
***************
RANKED	close.r 1253	adjacent 0.18517	near 0.16097	contiguous 0.15577	next 0.14915	proximate 0.14701	local 0.12571	neighbouring 0.12491	about 0.11498	almost 0.11167

Test context:
***************
close.r	1254	10	quite the biter , do n't get your fingers too __close__ .
Contexts for target close are: ['advmod_too', 'advmodI_get']
Contexts in vocabulary for target close are: ['advmod_too', 'advmodI_get']
Top most similar embeddings: close 0.27134	tiddly 0.18773	easilly 0.18690	shallowly 0.18570	closer 0.18517	tight 0.18219	straggly 0.18171	frugally 0.18092	often 0.18043	dexterously 0.17977

Generated lemmatized results
***************
GENERATED	close.r 1254 ::: tiddly;easilly;shallowly;closer;tight;straggly;frugally;often;dexterously;ineffectually

Filtered results
***************
RANKED	close.r 1254	near 0.17470	adjacent 0.13737	next 0.12918	about 0.12806	almost 0.12485	contiguous 0.12194	proximate 0.12085	local 0.10419	neighbouring 0.10130

Test context:
***************
close.r	1255	15	m ' riel , always the planner , added , " yes--if we get get __close__ enough and you can inflict enough damage on it to prevent it from flying , then just keep pounding on it !
Contexts for target close are: ['advmodI_enough']
Contexts in vocabulary for target close are: ['advmodI_enough']
Top most similar embeddings: close 0.52791	closer 0.35842	dexterously 0.35224	sportingly 0.35153	spookily 0.34959	temptingly 0.34871	tranquilly 0.34845	easilly 0.34773	inconspicuously 0.34721	funnily 0.34668

Generated lemmatized results
***************
GENERATED	close.r 1255 ::: closer;dexterously;sportingly;spookily;temptingly;tranquilly;easilly;inconspicuously;funnily;frugally

Filtered results
***************
RANKED	close.r 1255	near 0.34074	almost 0.30382	adjacent 0.30201	next 0.28703	about 0.28592	contiguous 0.27676	proximate 0.26691	neighbouring 0.22900	local 0.22550

Test context:
***************
close.r	1256	9	provided that the humps or ramps are spaced sufficiently __close__ together , an 85 percentile speed of less than 30kph is achievable .
Contexts for target close are: ['advmod_sufficiently', 'depI_spaced', 'advmod_together', 'punct_,', 'dep_speed']
Contexts in vocabulary for target close are: ['advmod_sufficiently', 'depI_spaced', 'advmod_together', 'punct_,', 'dep_speed']
Top most similar embeddings: close 0.02687	spaced 0.01862	closer 0.01861	tight 0.01828	knit 0.01820	multiplexed 0.01772	bunched 0.01757	closest 0.01751	near 0.01741	soldered 0.01740

Generated lemmatized results
***************
GENERATED	close.r 1256 ::: spaced;closer;tight;knit;multiplexed;bunched;closest;near;soldered;taut

Filtered results
***************
RANKED	close.r 1256	near 0.01741	contiguous 0.01361	proximate 0.01349	adjacent 0.01260	about 0.01024	neighbouring 0.00875	next 0.00872	local 0.00820	almost 0.00695

Test context:
***************
close.r	1257	34	the sitting liberal mp is john day , a former dentist who first won this seat in 1993 , served as health minister in the second term of the court government , and came __close__ to losing his seat in 2001 .
Contexts for target close are: ['advmodI_came']
Contexts in vocabulary for target close are: ['advmodI_came']
Top most similar embeddings: close 0.52529	closer 0.39868	closest 0.38252	onstream 0.36833	eventualy 0.36412	nearer 0.36274	sportingly 0.35314	unstuck 0.35242	belly-up 0.35200	dexterously 0.35154

Generated lemmatized results
***************
GENERATED	close.r 1257 ::: closer;closest;onstream;eventualy;nearer;sportingly;unstuck;dexterously;imediately;serendipitously

Filtered results
***************
RANKED	close.r 1257	near 0.34549	next 0.32445	adjacent 0.32043	about 0.29935	almost 0.29894	contiguous 0.29196	proximate 0.25840	local 0.23881	neighbouring 0.22477

Test context:
***************
close.r	1258	10	note some of the perches are new and are positioned __close__ to the original perches .
Contexts for target close are: ['advmodI_positioned', 'prep:to_perches']
Contexts in vocabulary for target close are: ['advmodI_positioned']
Top most similar embeddings: close 0.52097	closer 0.38967	idyllically 0.37844	perpendicularly 0.37273	picturesquely 0.36987	idealy 0.36857	enviably 0.36836	closest 0.36805	adjacent 0.36160	temptingly 0.35915

Generated lemmatized results
***************
GENERATED	close.r 1258 ::: closer;idyllically;perpendicularly;picturesquely;idealy;enviably;closest;adjacent;temptingly;orthogonally

Filtered results
***************
RANKED	close.r 1258	adjacent 0.36160	near 0.32473	next 0.32077	contiguous 0.30933	proximate 0.28607	almost 0.27580	neighbouring 0.25961	about 0.24477	local 0.23241

Test context:
***************
close.r	1259	31	major smog occurrences are often linked to heavy motor vehicle traffic , sunshine , high temperatures and calm winds or temperature inversion ( weather condition in which warm air is trapped __close__ to the ground instead of rising ) .
Contexts for target close are: ['advmodI_trapped', 'prep:to_ground']
Contexts in vocabulary for target close are: ['advmodI_trapped', 'prep:to_ground']
Top most similar embeddings: close 0.25551	perpendicularly 0.19304	closer 0.18943	closest 0.17843	invitingly 0.17807	harmlessly 0.17609	adjacent 0.17534	protectively 0.17079	orthogonally 0.17023	jauntily 0.16979

Generated lemmatized results
***************
GENERATED	close.r 1259 ::: perpendicularly;closer;closest;invitingly;harmlessly;adjacent;protectively;orthogonally;jauntily;stealthily

Filtered results
***************
RANKED	close.r 1259	adjacent 0.17534	near 0.15877	next 0.15332	contiguous 0.14177	proximate 0.12544	almost 0.12450	about 0.11253	neighbouring 0.10977	local 0.10642

Test context:
***************
close.r	1260	12	by not slowing down at the end , i at least come __close__ to making back the lost time .
Contexts for target close are: ['advmodI_come']
Contexts in vocabulary for target close are: ['advmodI_come']
Top most similar embeddings: close 0.51977	closer 0.39816	onstream 0.37846	closest 0.37409	eventualy 0.35914	nearer 0.35831	unstuck 0.35314	proably 0.35213	toe-to-toe 0.35140	near 0.35072

Generated lemmatized results
***************
GENERATED	close.r 1260 ::: closer;onstream;closest;eventualy;nearer;unstuck;proably;near;prosperously;usally

Filtered results
***************
RANKED	close.r 1260	near 0.35072	adjacent 0.31942	next 0.31301	about 0.29731	contiguous 0.29600	almost 0.29518	proximate 0.26579	local 0.23515	neighbouring 0.23333

Test context:
***************
closely.r	1261	14	to understand why this should have been so , we need to look more __closely__ at the nature of the style and its origins .
Contexts for target closely are: ['advmod_more', 'advmodI_look']
Contexts in vocabulary for target closely are: ['advmod_more', 'advmodI_look']
Top most similar embeddings: closely 0.29221	incisively 0.21545	pessimistically 0.21386	trenchantly 0.21182	complexly 0.21168	intently 0.21167	tenaciously 0.21085	attentively 0.21029	stringently 0.21017	maturely 0.20901

Generated lemmatized results
***************
GENERATED	closely.r 1261 ::: incisively;pessimistically;trenchantly;complexly;intently;tenaciously;attentively;stringently;maturely;dexterously

Filtered results
***************
RANKED	closely.r 1261	intently 0.21167	attentively 0.21029	carefully 0.20268	intimately 0.19245	narrowly 0.18700	directly 0.18083	strongly 0.16905	scrupulously 0.16738	neatly 0.15583	together 0.15392	nearly 0.14660	jointly 0.14523	collectively 0.13752	approximately 0.13260	alongside 0.12418

Test context:
***************
closely.r	1262	8	some people have guessed that this radiation is __closely__ related to a period of intense cold and a high level of ice cover occurring around 600 mya ; perhaps environmental stresses wiped out competitors and created opportunities for a ( relatively ) clever animal to succeed and proliferate .
Contexts for target closely are: ['advmodI_related']
Contexts in vocabulary for target closely are: ['advmodI_related']
Top most similar embeddings: closely 0.55532	integrally 0.41927	tenuously 0.41859	inseparably 0.41545	intimately 0.41378	mechanistically 0.40901	compositionally 0.40130	indissolubly 0.40006	dialectically 0.39458	tangentially 0.38853

Generated lemmatized results
***************
GENERATED	closely.r 1262 ::: integrally;tenuously;inseparably;intimately;mechanistically;compositionally;indissolubly;dialectically;tangentially;directly

Filtered results
***************
RANKED	closely.r 1262	intimately 0.41378	directly 0.38669	narrowly 0.36022	carefully 0.35915	strongly 0.35749	intently 0.35547	attentively 0.34485	scrupulously 0.33542	nearly 0.32999	neatly 0.32340	together 0.31896	jointly 0.31246	approximately 0.30423	collectively 0.28692	alongside 0.25874

Test context:
***************
closely.r	1263	3	they are working __closely__ with natural tunnel state park , where the staff , eager to have additional housing nearby , have assured the bakers that they will be booked on a regular basis since the demand for housing outweighs supply .
Contexts for target closely are: ['advmodI_working']
Contexts in vocabulary for target closely are: ['advmodI_working']
Top most similar embeddings: closely 0.55330	industriously 0.41166	cohesively 0.41106	harmoniously 0.40740	intensively 0.40590	cooperatively 0.40122	cross-culturally 0.39993	co-operatively 0.39148	integrally 0.39136	assiduously 0.39031

Generated lemmatized results
***************
GENERATED	closely.r 1263 ::: industriously;cohesively;harmoniously;intensively;cooperatively;integrally;assiduously;ecumenically;tenaciously;fruitfully

Filtered results
***************
RANKED	closely.r 1263	intently 0.38137	intimately 0.37733	together 0.36827	directly 0.36768	attentively 0.36410	carefully 0.35961	jointly 0.34394	strongly 0.33009	scrupulously 0.32903	narrowly 0.32743	neatly 0.31171	collectively 0.30978	nearly 0.30724	alongside 0.28940	approximately 0.28683

Test context:
***************
closely.r	1264	5	the department is also working __closely__ with hm customs and excise who are in the lead on developing the national lorry road user charging scheme .
Contexts for target closely are: ['advmodI_working']
Contexts in vocabulary for target closely are: ['advmodI_working']
Top most similar embeddings: closely 0.55330	industriously 0.41166	cohesively 0.41106	harmoniously 0.40740	intensively 0.40590	cooperatively 0.40122	cross-culturally 0.39993	co-operatively 0.39148	integrally 0.39136	assiduously 0.39031

Generated lemmatized results
***************
GENERATED	closely.r 1264 ::: industriously;cohesively;harmoniously;intensively;cooperatively;integrally;assiduously;ecumenically;tenaciously;fruitfully

Filtered results
***************
RANKED	closely.r 1264	intently 0.38137	intimately 0.37733	together 0.36827	directly 0.36768	attentively 0.36410	carefully 0.35961	jointly 0.34394	strongly 0.33009	scrupulously 0.32903	narrowly 0.32743	neatly 0.31171	collectively 0.30978	nearly 0.30724	alongside 0.28940	approximately 0.28683

Test context:
***************
closely.r	1265	10	retail : in the u.s. , analysts will be looking __closely__ at third-quarter results .
Contexts for target closely are: ['advmodI_looking']
Contexts in vocabulary for target closely are: ['advmodI_looking']
Top most similar embeddings: closely 0.52787	intently 0.41012	enviously 0.40221	askance 0.38685	longingly 0.38504	dexterously 0.38492	avidly 0.38339	industriously 0.38278	unconventionally 0.37948	fixedly 0.37947

Generated lemmatized results
***************
GENERATED	closely.r 1265 ::: intently;enviously;askance;longingly;dexterously;avidly;industriously;unconventionally;fixedly;worriedly

Filtered results
***************
RANKED	closely.r 1265	intently 0.41012	attentively 0.37739	carefully 0.37705	intimately 0.36675	narrowly 0.35832	directly 0.35683	together 0.32659	strongly 0.32270	jointly 0.32226	scrupulously 0.32160	nearly 0.30332	neatly 0.30265	approximately 0.29227	collectively 0.29116	alongside 0.26799

Test context:
***************
closely.r	1266	4	their academic careers are __closely__ intertwined with social and political developments such as secularisation and antisemitism .
Contexts for target closely are: ['advmodI_intertwined']
Contexts in vocabulary for target closely are: ['advmodI_intertwined']
Top most similar embeddings: closely 0.55491	inseparably 0.43058	indissolubly 0.40649	inextricably 0.40582	tenuously 0.40310	tightly 0.40209	integrally 0.40175	intimately 0.40049	potently 0.39878	tenaciously 0.39857

Generated lemmatized results
***************
GENERATED	closely.r 1266 ::: inseparably;indissolubly;inextricably;tenuously;tightly;integrally;intimately;potently;tenaciously;intricately

Filtered results
***************
RANKED	closely.r 1266	intimately 0.40049	intently 0.36717	carefully 0.36538	narrowly 0.36173	scrupulously 0.35368	strongly 0.34859	attentively 0.34367	neatly 0.33730	directly 0.33570	together 0.32563	nearly 0.31196	jointly 0.31006	collectively 0.28055	approximately 0.27676	alongside 0.25964

Test context:
***************
closely.r	1267	11	" the baby has developed very normally and has been followed __closely__ .
Contexts for target closely are: ['advmodI_followed']
Contexts in vocabulary for target closely are: ['advmodI_followed']
Top most similar embeddings: closely 0.55637	avidly 0.40848	slavishly 0.39577	dexterously 0.39551	assiduously 0.39372	stringently 0.39131	intently 0.38941	industriously 0.38925	zealously 0.38746	tenaciously 0.38627

Generated lemmatized results
***************
GENERATED	closely.r 1267 ::: avidly;slavishly;dexterously;assiduously;stringently;intently;industriously;zealously;tenaciously;carefully

Filtered results
***************
RANKED	closely.r 1267	intently 0.38941	carefully 0.38385	attentively 0.37820	scrupulously 0.36384	intimately 0.36164	narrowly 0.35893	directly 0.35452	strongly 0.33285	neatly 0.33161	together 0.32716	jointly 0.31865	nearly 0.31589	approximately 0.30084	collectively 0.28143	alongside 0.27627

Test context:
***************
closely.r	1268	9	to prevent asthma episodes you will have to work __closely__ with your doctor to : develop a medicine plan that keeps you from getting symptoms .
Contexts for target closely are: ['advmodI_work']
Contexts in vocabulary for target closely are: ['advmodI_work']
Top most similar embeddings: closely 0.55507	cohesively 0.42444	harmoniously 0.40708	cross-culturally 0.40486	cooperatively 0.40393	industriously 0.40390	intensively 0.40138	tenaciously 0.39353	co-operatively 0.39313	ecumenically 0.39287

Generated lemmatized results
***************
GENERATED	closely.r 1268 ::: cohesively;harmoniously;cooperatively;industriously;intensively;tenaciously;ecumenically;unconventionally;fruitfully;seemlessly

Filtered results
***************
RANKED	closely.r 1268	intimately 0.37421	together 0.37040	carefully 0.36821	attentively 0.36695	intently 0.36638	directly 0.36534	jointly 0.34469	narrowly 0.34464	scrupulously 0.33310	strongly 0.33117	neatly 0.32822	nearly 0.31922	collectively 0.31116	approximately 0.30003	alongside 0.29011

Test context:
***************
closely.r	1269	7	problems are flagged quickly and , working __closely__ with your staff , we propose solutions .
Contexts for target closely are: ['advmodI_working']
Contexts in vocabulary for target closely are: ['advmodI_working']
Top most similar embeddings: closely 0.55330	industriously 0.41166	cohesively 0.41106	harmoniously 0.40740	intensively 0.40590	cooperatively 0.40122	cross-culturally 0.39993	co-operatively 0.39148	integrally 0.39136	assiduously 0.39031

Generated lemmatized results
***************
GENERATED	closely.r 1269 ::: industriously;cohesively;harmoniously;intensively;cooperatively;integrally;assiduously;ecumenically;tenaciously;fruitfully

Filtered results
***************
RANKED	closely.r 1269	intently 0.38137	intimately 0.37733	together 0.36827	directly 0.36768	attentively 0.36410	carefully 0.35961	jointly 0.34394	strongly 0.33009	scrupulously 0.32903	narrowly 0.32743	neatly 0.31171	collectively 0.30978	nearly 0.30724	alongside 0.28940	approximately 0.28683

Test context:
***************
closely.r	1270	35	what women want on a first date ( updated thursday , dec 5 , 2002 , 02:06:55 pm to reflect the 100 most recent valid responses. ) assuming you are a woman , which most __closely__ matches your idea of a great first date ?
Contexts for target closely are: ['advmod_most', 'advmodI_matches']
Contexts in vocabulary for target closely are: ['advmod_most', 'advmodI_matches']
Top most similar embeddings: closely 0.28331	potently 0.21569	advantageously 0.20656	stringently 0.20003	intimately 0.19868	believably 0.19843	fruitfully 0.19789	tenaciously 0.19754	tenuously 0.19731	trenchantly 0.19728

Generated lemmatized results
***************
GENERATED	closely.r 1270 ::: potently;advantageously;stringently;intimately;believably;fruitfully;tenaciously;tenuously;trenchantly;adeptly

Filtered results
***************
RANKED	closely.r 1270	intimately 0.19868	carefully 0.18638	attentively 0.18490	intently 0.17905	scrupulously 0.17530	narrowly 0.17260	directly 0.17155	strongly 0.16939	neatly 0.16395	nearly 0.15375	together 0.14360	jointly 0.13956	approximately 0.13472	collectively 0.12852	alongside 0.11976

Test context:
***************
decline.v	1271	42	but that last statistic is misleading , because a variety of studies shows that about 40 % of the workers who don 't take up healthcare offers have coverage through a spouse , and another 20 % ( likely younger workers ) __decline__ coverage to save money .
Contexts for target decline are: ['depI_shows', 'dobj_coverage', 'xcomp_save']
Contexts in vocabulary for target decline are: ['depI_shows', 'dobj_coverage', 'xcomp_save']
Top most similar embeddings: decline 0.09230	declines 0.08399	trebling 0.07480	decrease 0.07461	increase 0.07416	tripling 0.07331	declining 0.07278	declined 0.07125	slowing 0.07026	weakening 0.07009

Generated lemmatized results
***************
GENERATED	decline.v 1271 ::: treble;decrease;increase;triple;slow;weaken;drop;narrow;rise;downgrade

Filtered results
***************
RANKED	decline.v 1271	decrease 0.07461	weaken 0.07009	drop 0.06947	refuse 0.06528	fall 0.06113	reduce 0.05994	lessen 0.05880	reject 0.05721	deteriorate 0.05665

Test context:
***************
decline.v	1272	24	in an interview for this survey , gordon brown , the british chancellor and himself a scotsman , said that support for the snp __declined__ as the election neared because the party failed to give convincing answers to big questions about how it would run scotland 's economy .
Contexts for target declined are: ['mark_that', 'nsubj_support', 'ccompI_said', 'advcl_neared']
Contexts in vocabulary for target declined are: ['mark_that', 'nsubj_support', 'ccompI_said', 'advcl_neared']
Top most similar embeddings: declined 0.06447	plummeted 0.05133	declining 0.05059	dwindled 0.04999	soared 0.04829	plateaued 0.04817	diminished 0.04656	overreacted 0.04643	skyrocketed 0.04639	waned 0.04630

Generated lemmatized results
***************
GENERATED	decline.v 1272 ::: plummet;dwindle;soar;plateaued;diminish;overreact;skyrocket;wan;rise;peak

Filtered results
***************
RANKED	decline.v 1272	decrease 0.04528	drop 0.04455	fall 0.04438	refuse 0.04390	deteriorate 0.04374	weaken 0.04192	lessen 0.04149	reduce 0.03629	reject 0.03562

Test context:
***************
decline.v	1273	12	st. lawrence cement increased domestic cement deliveries , but on balance volumes __declined__ owing to delivery bottlenecks in the northeastern us .
Contexts for target declined are: ['prep:on_volumes', 'conjI_increased', 'xcomp_owing']
Contexts in vocabulary for target declined are: ['prep:on_volumes', 'conjI_increased', 'xcomp_owing']
Top most similar embeddings: declined 0.12039	decreased 0.10305	risen 0.09653	fluctuated 0.09435	increased 0.09405	plummeted 0.09379	soared 0.09196	dwindled 0.09077	declining 0.08986	rocketed 0.08977

Generated lemmatized results
***************
GENERATED	decline.v 1273 ::: decrease;rise;fluctuate;increase;plummet;soar;dwindle;rocket;skyrocket;stagnate

Filtered results
***************
RANKED	decline.v 1273	decrease 0.10305	fall 0.08628	reduce 0.08459	drop 0.08266	deteriorate 0.08012	lessen 0.07526	weaken 0.07435	refuse 0.07202	reject 0.06604

Test context:
***************
decline.v	1274	27	the air force has experienced low levels of equipment availability in the last five years , and availability of the hercules and the aurora fleets continues to __decline__ .
Contexts for target decline are: ['aux_to', 'xcompI_continues']
Contexts in vocabulary for target decline are: ['aux_to', 'xcompI_continues']
Top most similar embeddings: decline 0.26136	rise 0.20580	increase 0.19992	decrease 0.19949	dwindle 0.19618	under-perform 0.19523	undershoot 0.19181	underperform 0.19148	deteriorate 0.19083	industrialise 0.19073

Generated lemmatized results
***************
GENERATED	decline.v 1274 ::: rise;increase;decrease;dwindle;undershoot;underperform;deteriorate;industrialise;wane;plummet

Filtered results
***************
RANKED	decline.v 1274	decrease 0.19949	deteriorate 0.19083	fall 0.18708	drop 0.17437	refuse 0.17072	weaken 0.16900	reject 0.16845	reduce 0.15642	lessen 0.14955

Test context:
***************
decline.v	1275	6	high school non-completion rates continue to __decline__ 5 and an increasing number of young people are pursuing post-secondary education 6 .
Contexts for target decline are: ['aux_to', 'xcompI_continue', 'dobj_5']
Contexts in vocabulary for target decline are: ['aux_to', 'xcompI_continue', 'dobj_5']
Top most similar embeddings: decline 0.11483	rise 0.09430	underperform 0.09005	decrease 0.08877	uprate 0.08761	under-perform 0.08751	undershoot 0.08692	plummet 0.08645	deteriorate 0.08630	underachieve 0.08628

Generated lemmatized results
***************
GENERATED	decline.v 1275 ::: rise;underperform;decrease;uprate;undershoot;plummet;deteriorate;underachieve;increase;dwindle

Filtered results
***************
RANKED	decline.v 1275	decrease 0.08877	deteriorate 0.08630	drop 0.08159	fall 0.08015	reject 0.07890	refuse 0.07659	weaken 0.07062	reduce 0.06944	lessen 0.06532

Test context:
***************
decline.v	1276	14	whenever there is a condition with results in cardiac dysfunction stroke volume will eventually __declined__ .
Contexts for target declined are: ['csubj_is', 'aux_will', 'advmod_eventually', 'rootI_*root*', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target declined are: ['csubj_is', 'aux_will', 'advmod_eventually', 'rootI_*root*', 'punct_.']
Top most similar embeddings: declined 0.02827	disappear 0.02319	depend 0.02200	refused 0.02181	dropped 0.02144	deteriorate 0.02123	dwindled 0.02121	dwindle 0.02116	plummeted 0.02106	skyrocketed 0.02095

Generated lemmatized results
***************
GENERATED	decline.v 1276 ::: disappear;depend;refuse;drop;deteriorate;dwindle;plummet;skyrocket;vary;prompt

Filtered results
***************
RANKED	decline.v 1276	refuse 0.02181	drop 0.02144	deteriorate 0.02123	reject 0.02062	decrease 0.02002	weaken 0.01988	lessen 0.01976	reduce 0.01943	fall 0.01778

Test context:
***************
decline.v	1277	16	the productivity of crops and pastures , as well as the health of other vegetation , __declines__ as the saline watertable reaches their root zones .
Contexts for target declines are: ['nsubj_productivity', 'rootI_*root*', 'advcl_reaches', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target declines are: ['nsubj_productivity', 'rootI_*root*', 'advcl_reaches', 'punct_.']
Top most similar embeddings: declines 0.06849	decreases 0.05674	plummets 0.05361	rises 0.05346	increases 0.05013	stagnates 0.05004	continues 0.04976	declined 0.04974	skyrocketed 0.04932	wanes 0.04932

Generated lemmatized results
***************
GENERATED	decline.v 1277 ::: decrease;plummet;rise;increase;stagnate;continue;skyrocket;wan;fluctuate;soar

Filtered results
***************
RANKED	decline.v 1277	decrease 0.05674	drop 0.04721	deteriorate 0.04662	fall 0.04416	lessen 0.04387	weaken 0.04331	reduce 0.04322	refuse 0.03945	reject 0.03681

Test context:
***************
decline.v	1278	7	unhappy with being called to task for __declining__ scores , political educators complained that the tests were unfair to some , so they watered them down - - as if 2+2=4 was being challenged as unfair on racial , gender or other social-oriented measures .
Contexts for target declining are: ['amodI_scores']
Contexts in vocabulary for target declining are: ['amodI_scores']
Top most similar embeddings: declining 0.49556	below-average 0.38203	above-average 0.38201	dwindling 0.37766	decreasing 0.37553	plummeting 0.37484	age-standardised 0.37472	deteriorating 0.37342	lowish 0.37187	single-digit 0.37106

Generated lemmatized results
***************
GENERATED	decline.v 1278 ::: dwindle;decrease;plummet;deteriorate;lowish;diminish;rise;increase;fluctuate;shrink

Filtered results
***************
RANKED	decline.v 1278	decrease 0.37553	deteriorate 0.37342	fall 0.35173	reduce 0.32603	weaken 0.30724	drop 0.30414	lessen 0.29762	refuse 0.29105	reject 0.27536

Test context:
***************
decline.v	1279	9	in particular , per capita incomes in africa have __declined__ relative to the industrial countries and in some countries have declined in absolute terms .
Contexts for target declined are: ['prep:in_particular', 'punct_,', 'prep:per_capita', 'nsubj_incomes', 'aux_have', 'csubjI_declined', 'acomp_relative', 'cc_and', 'conj_in', 'conj:in_countries']
Contexts in vocabulary for target declined are: ['prep:in_particular', 'punct_,', 'prep:per_capita', 'nsubj_incomes', 'aux_have', 'csubjI_declined', 'acomp_relative', 'cc_and', 'conj_in', 'conj:in_countries']
Top most similar embeddings: declined 0.00110	declining 0.00083	stagnated 0.00074	decreased 0.00067	plummeted 0.00067	fluctuated 0.00066	rocketed 0.00066	risen 0.00066	soared 0.00065	skyrocketed 0.00062

Generated lemmatized results
***************
GENERATED	decline.v 1279 ::: stagnate;decrease;plummet;fluctuate;rocket;rise;soar;skyrocket;fall;increase

Filtered results
***************
RANKED	decline.v 1279	decrease 0.00067	fall 0.00061	deteriorate 0.00050	drop 0.00050	reduce 0.00045	weaken 0.00043	refuse 0.00042	lessen 0.00038	reject 0.00036

Test context:
***************
decline.v	1280	12	the garch model is an infinite order arch model with a geometrically __declining__ set of weights .
Contexts for target declining are: ['amodI_set']
Contexts in vocabulary for target declining are: ['amodI_set']
Top most similar embeddings: declining 0.47564	dwindling 0.38930	singsational 0.37468	ever-decreasing 0.37346	diminishing 0.36597	shrinking 0.36407	decreasing 0.36390	much-reduced 0.36262	deteriorating 0.36129	ever-increasing 0.35967

Generated lemmatized results
***************
GENERATED	decline.v 1280 ::: dwindle;singsational;diminish;shrink;decrease;deteriorate;rise;lowish;increase;fluctuate

Filtered results
***************
RANKED	decline.v 1280	decrease 0.36390	deteriorate 0.36129	fall 0.33698	reduce 0.31769	weaken 0.31327	refuse 0.28363	drop 0.27556	lessen 0.27481	reject 0.26328

Test context:
***************
drop.v	1281	3	" " i __dropped__ her off six hours ago , " the young monk says .
Contexts for target dropped are: ["punct_''", "punct_''", 'nsubj_i', 'depI_says', 'dobj_her', 'advmod_off', 'advmod_ago', 'punct_,', "punct_''"]
Contexts in vocabulary for target dropped are: ['nsubj_i', 'depI_says', 'dobj_her', 'advmod_off', 'advmod_ago', 'punct_,']
Top most similar embeddings: dropped 0.01862	dropping 0.01549	wheezed 0.01496	loitered 0.01480	snogged 0.01478	catched 0.01460	plopped 0.01447	texted 0.01447	shooed 0.01442	rocketed 0.01441

Generated lemmatized results
***************
GENERATED	drop.v 1281 ::: wheeze;loiter;snog;catch;plop;texted;shoo;rocket;fondle;chuck

Filtered results
***************
RANKED	drop.v 1281	dump 0.01410	throw 0.01378	ditch 0.01327	stop 0.01277	write 0.01183	lower 0.01179	abandon 0.01163	fall 0.01130	send 0.01129	decline 0.01107	weigh 0.01045	relinquish 0.01042	pause 0.01041	leave 0.01038	email 0.00988	release 0.00976	unload 0.00933	omit 0.00926	discontinue 0.00899	deliver 0.00852	terminate 0.00815	deselect 0.00745	text 0.00572

Test context:
***************
drop.v	1282	13	anyway , i saw your ad on the net and just wanted to __drop__ you a line to say hello .
Contexts for target drop are: ['aux_to', 'xcompI_wanted', 'iobj_you', 'dobj_line']
Contexts in vocabulary for target drop are: ['aux_to', 'xcompI_wanted', 'iobj_you', 'dobj_line']
Top most similar embeddings: drop 0.07310	give 0.04465	off-load 0.04391	re-book 0.04321	re-send 0.04220	write 0.04195	electrify 0.04187	baby-sit 0.04165	re-sign 0.04129	jettison 0.04116

Generated lemmatized results
***************
GENERATED	drop.v 1282 ::: give;write;electrify;jettison;disabuse;throw;flog;send;disgorge;abandon

Filtered results
***************
RANKED	drop.v 1282	write 0.04195	throw 0.04104	send 0.04091	abandon 0.04047	leave 0.03862	dump 0.03768	unload 0.03695	deliver 0.03667	discontinue 0.03638	relinquish 0.03535	stop 0.03513	fall 0.03463	weigh 0.03415	terminate 0.03406	deselect 0.03338	omit 0.03286	decline 0.03178	ditch 0.03109	pause 0.03054	email 0.02976	release 0.02870	lower 0.02788	text 0.02202

Test context:
***************
drop.v	1283	3	instead , she __dropped__ the man to the ground at her feet .
Contexts for target dropped are: ['advmod_instead', 'punct_,', 'nsubj_she', 'rootI_*root*', 'dobj_man', 'prep:to_ground', 'prep:at_feet', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target dropped are: ['advmod_instead', 'punct_,', 'nsubj_she', 'rootI_*root*', 'dobj_man', 'prep:to_ground', 'prep:at_feet', 'punct_.']
Top most similar embeddings: dropped 0.00381	scowled 0.00330	panted 0.00330	threw 0.00322	yelped 0.00319	fell 0.00319	whimpered 0.00318	crouches 0.00316	tumbled 0.00314	plunged 0.00312

Generated lemmatized results
***************
GENERATED	drop.v 1283 ::: scowl;pant;throw;yelp;fell;whimper;crouch;tumble;plunge;bawl

Filtered results
***************
RANKED	drop.v 1283	throw 0.00322	lower 0.00261	fall 0.00256	abandon 0.00254	dump 0.00251	pause 0.00249	stop 0.00242	send 0.00234	ditch 0.00228	unload 0.00224	leave 0.00213	write 0.00212	weigh 0.00210	decline 0.00210	relinquish 0.00207	deliver 0.00190	terminate 0.00176	omit 0.00173	release 0.00162	email 0.00156	discontinue 0.00151	deselect 0.00117	text 0.00067

Test context:
***************
drop.v	1284	12	7 ) true or false : the 2000 u. s. census will __drop__ the question on marital status on the universal form .
Contexts for target drop are: ['nsubj_census', 'aux_will', 'parataxisI_true', 'dobj_question']
Contexts in vocabulary for target drop are: ['nsubj_census', 'aux_will', 'parataxisI_true', 'dobj_question']
Top most similar embeddings: drop 0.04327	ask 0.03567	dropping 0.03506	over-write 0.03478	reopen 0.03466	asked 0.03462	ignore 0.03421	answered 0.03407	pose 0.03334	drops 0.03332

Generated lemmatized results
***************
GENERATED	drop.v 1284 ::: ask;reopen;ignore;answer;pose;overwrite;reveal;prejudge;diminish;fall

Filtered results
***************
RANKED	drop.v 1284	fall 0.03274	omit 0.03265	throw 0.03131	weigh 0.03069	send 0.03052	leave 0.02962	lower 0.02960	abandon 0.02958	write 0.02940	decline 0.02908	pause 0.02879	email 0.02844	deselect 0.02827	release 0.02826	stop 0.02778	discontinue 0.02713	relinquish 0.02699	unload 0.02683	dump 0.02682	deliver 0.02594	ditch 0.02536	terminate 0.02528	text 0.02072

Test context:
***************
drop.v	1285	22	such an agreement states that the local authority will start to make a financial contribution towards costs once the person 's savings __drop__ to below a certain amount .
Contexts for target drop are: ['advmod_once', 'poss_person', 'nn_savings', 'depI_start']
Contexts in vocabulary for target drop are: ['advmod_once', 'poss_person', 'nn_savings', 'depI_start']
Top most similar embeddings: drop 0.04243	drops 0.03465	til 0.03218	subsides 0.03147	drop-off 0.03144	plummet 0.03065	untill 0.03053	declines 0.03005	right-click 0.02986	jump 0.02985

Generated lemmatized results
***************
GENERATED	drop.v 1285 ::: til;subside;plummet;untill;decline;jump;fall;preferences;straightaway;remarry

Filtered results
***************
RANKED	drop.v 1285	decline 0.03005	fall 0.02983	pause 0.02787	stop 0.02759	dump 0.02696	ditch 0.02603	terminate 0.02592	leave 0.02541	throw 0.02516	lower 0.02458	abandon 0.02431	relinquish 0.02361	unload 0.02323	deselect 0.02314	release 0.02279	discontinue 0.02241	weigh 0.02202	email 0.02201	deliver 0.02197	write 0.02172	text 0.02105	omit 0.01994	send 0.01962

Test context:
***************
drop.v	1286	24	the economy expanded by over 10 per cent , the number of people at work increased by 5 per cent and the unemployment rate __dropped__ below 4 per cent for the first time .
Contexts for target dropped are: ['nsubj_rate', 'conjI_increased', 'prep:below_4', 'prep:for_time']
Contexts in vocabulary for target dropped are: ['nsubj_rate', 'conjI_increased', 'prep:for_time']
Top most similar embeddings: dropped 0.12804	plateaued 0.11539	plummeted 0.10685	skyrocketed 0.10048	fallen 0.10036	slowed 0.09999	decreased 0.09966	stagnated 0.09939	dropping 0.09921	risen 0.09828

Generated lemmatized results
***************
GENERATED	drop.v 1286 ::: plateaued;plummet;skyrocket;fall;slow;decrease;stagnate;rise;soar;slump

Filtered results
***************
RANKED	drop.v 1286	fall 0.10036	decline 0.09572	lower 0.09279	stop 0.07757	discontinue 0.07194	pause 0.07103	throw 0.06989	dump 0.06932	ditch 0.06747	abandon 0.06665	omit 0.06562	weigh 0.06418	terminate 0.06319	unload 0.06173	relinquish 0.06171	deliver 0.06170	leave 0.05930	release 0.05735	email 0.05606	write 0.05601	send 0.05571	deselect 0.04622	text 0.04120

Test context:
***************
drop.v	1287	8	i 'm especially surprised to see le nain __dropped__ - not that i ever was such a fan or him or his brothers , but i would have thought that in light of aspects of the revision - using art " as a way to discuss race , class , and gender " - he would have been useful .
Contexts for target dropped are: ['nsubj_nain', 'ccompI_see', 'punct_-', 'dep_useful']
Contexts in vocabulary for target dropped are: ['ccompI_see', 'punct_-', 'dep_useful']
Top most similar embeddings: dropped 0.09315	dropping 0.08161	drop 0.07742	drops 0.07667	explode 0.07620	hotmail.com 0.07539	cached 0.07485	dipped 0.07384	shelved 0.07346	halved 0.07323

Generated lemmatized results
***************
GENERATED	drop.v 1287 ::: explode;cache;dip;shelve;halve;translate;plummet;rub;fied;disappear

Filtered results
***************
RANKED	drop.v 1287	dump 0.07119	fall 0.07050	discontinue 0.06973	omit 0.06715	ditch 0.06657	throw 0.06583	lower 0.06492	decline 0.06448	write 0.06386	stop 0.06369	unload 0.06306	abandon 0.06246	weigh 0.06121	pause 0.05924	email 0.05836	release 0.05823	terminate 0.05757	deliver 0.05749	leave 0.05747	deselect 0.05729	send 0.05699	relinquish 0.05305	text 0.05064

Test context:
***************
drop.v	1288	18	reichen/chip having plenty of time to kill ( like 9hrs ) decide to do their signature move of __dropping__ anchors and cementing themselves to the floor to keep a spot in line .
Contexts for target dropping are: ['pcompI_of', 'dobj_anchors', 'cc_and', 'conj_cementing']
Contexts in vocabulary for target dropping are: ['pcompI_of', 'dobj_anchors', 'cc_and', 'conj_cementing']
Top most similar embeddings: dropping 0.06493	jettisoning 0.05232	unscrewing 0.05099	overshooting 0.04967	extruding 0.04955	dislodging 0.04874	ditching 0.04871	dislocating 0.04807	disassembling 0.04765	rupturing 0.04726

Generated lemmatized results
***************
GENERATED	drop.v 1288 ::: jettison;unscrew;overshoot;extrude;dislodge;ditch;dislocate;disassemble;rupture;lower

Filtered results
***************
RANKED	drop.v 1288	ditch 0.04871	lower 0.04720	dump 0.04557	throw 0.04446	abandon 0.04407	relinquish 0.04113	fall 0.04091	unload 0.03999	terminate 0.03899	leave 0.03704	omit 0.03679	stop 0.03678	discontinue 0.03595	weigh 0.03586	send 0.03569	release 0.03559	pause 0.03547	deliver 0.03513	write 0.03431	decline 0.03254	email 0.02900	deselect 0.02386	text 0.02119

Test context:
***************
drop.v	1289	19	managers like to believe that the union is n't really all that keen on pursuing most grievances and will __drop__ most of them somewhere along the way .
Contexts for target drop are: ['aux_will', 'conjI_keen', 'dobj_most', 'advmod_somewhere', 'prep:along_way']
Contexts in vocabulary for target drop are: ['aux_will', 'conjI_keen', 'dobj_most', 'advmod_somewhere', 'prep:along_way']
Top most similar embeddings: drop 0.02339	dropping 0.02065	dropped 0.01923	popping 0.01709	stumble 0.01707	squeeze 0.01674	disappear 0.01657	forgo 0.01649	enjoy 0.01645	dump 0.01645

Generated lemmatized results
***************
GENERATED	drop.v 1289 ::: pop;stumble;squeeze;disappear;forgo;enjoy;dump;meet;offload;miss

Filtered results
***************
RANKED	drop.v 1289	dump 0.01645	fall 0.01595	stop 0.01573	throw 0.01572	abandon 0.01447	unload 0.01442	pause 0.01432	relinquish 0.01426	ditch 0.01412	write 0.01363	leave 0.01357	weigh 0.01348	release 0.01317	send 0.01316	email 0.01310	omit 0.01308	deliver 0.01270	discontinue 0.01263	decline 0.01244	terminate 0.01238	lower 0.01161	deselect 0.01002	text 0.00798

Test context:
***************
drop.v	1290	14	in addition to making and maintaining the bubble nest , replacing eggs that may __drop__ from the nest , rounding up the straggling young , and mouthing the young at intervals , he is constantly on the alert to protect the eggs and young from intruders that may devour them .
Contexts for target drop are: ['nsubj_that', 'aux_may', 'rcmodI_eggs', 'prep:from_nest']
Contexts in vocabulary for target drop are: ['nsubj_that', 'aux_may', 'rcmodI_eggs', 'prep:from_nest']
Top most similar embeddings: drop 0.05150	dangle 0.04457	protrude 0.04307	emerge 0.04276	dropped 0.04148	fall 0.04115	ripen 0.03978	sprout 0.03964	curdle 0.03935	dislodged 0.03929

Generated lemmatized results
***************
GENERATED	drop.v 1290 ::: dangle;protrude;emerge;fall;ripen;sprout;curdle;dislodge;seep;hatch

Filtered results
***************
RANKED	drop.v 1290	fall 0.04115	dump 0.03422	throw 0.03399	weigh 0.03325	lower 0.03147	unload 0.03094	decline 0.03050	leave 0.03021	abandon 0.02967	ditch 0.02949	stop 0.02908	omit 0.02892	terminate 0.02875	pause 0.02846	relinquish 0.02742	send 0.02740	release 0.02728	deliver 0.02667	discontinue 0.02642	deselect 0.02400	email 0.02323	write 0.02194	text 0.01673

Test context:
***************
easy.a	1291	6	if they are looking for an __easier__ language than c++ , c# should have been their option , but i would even prefer c++ to java .
Contexts for target easier are: ['amodI_language']
Contexts in vocabulary for target easier are: ['amodI_language']
Top most similar embeddings: easier 0.47698	simpler 0.43215	difficult 0.38818	easy 0.38587	harder 0.38454	object-orientated 0.37663	clearer 0.37348	xml-based 0.37309	plainer 0.37275	easy-to-learn 0.37140

Generated lemmatized results
***************
GENERATED	easy.a 1291 ::: simple;difficult;hard;clear;plain;tough;snappy;straightforward;untyped;tricky

Filtered results
***************
RANKED	easy.a 1291	simple 0.43215	straightforward 0.37077	uncomplicated 0.34835	convenient 0.33652	undemanding 0.32840	possible 0.32751	common 0.32467	accessible 0.32408	less 0.30875	carefree 0.29576

Test context:
***************
easy.a	1292	3	just fill out __easy__ form to enter , no other restrictions listed .
Contexts for target easy are: ['amodI_form']
Contexts in vocabulary for target easy are: ['amodI_form']
Top most similar embeddings: easy 0.47623	simple 0.40195	straightforward 0.39620	easy-to-navigate 0.38697	simple-to-use 0.38606	easier 0.38430	non-electronic 0.38134	straight-forward 0.38090	menu-based 0.37968	fill-out 0.37815

Generated lemmatized results
***************
GENERATED	easy.a 1292 ::: simple;straightforward;definative;convenient;acurate;periphrastic;unreferenced;straighforward;quick;scannable

Filtered results
***************
RANKED	easy.a 1292	simple 0.40195	straightforward 0.39620	convenient 0.37413	uncomplicated 0.36101	undemanding 0.35180	accessible 0.34031	common 0.32774	possible 0.32194	carefree 0.32097	less 0.28151

Test context:
***************
easy.a	1293	4	i 've never been __easier__ for callers to reach , or had greater freedom with less hassle while being assured of getting all important calls and messages .
Contexts for target easier are: ['nsubj_i', "aux_'ve", 'neg_never', 'cop_been', 'rootI_*root*', 'advcl_reach', 'punct_,', 'cc_or', 'conj_freedom', 'advcl_assured', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target easier are: ['nsubj_i', "aux_'ve", 'neg_never', 'cop_been', 'rootI_*root*', 'advcl_reach', 'punct_,', 'cc_or', 'conj_freedom', 'advcl_assured', 'punct_.']
Top most similar embeddings: easier 0.00043	happier 0.00036	surprized 0.00036	flinched 0.00035	wavered 0.00034	shirked 0.00033	unbolted 0.00033	imprudent 0.00033	dieted 0.00033	mollified 0.00033

Generated lemmatized results
***************
GENERATED	easy.a 1293 ::: happy;surprized;flinched;wavered;shirked;unbolted;imprudent;dieted;mollified;true

Filtered results
***************
RANKED	easy.a 1293	simple 0.00032	straightforward 0.00029	possible 0.00026	uncomplicated 0.00024	undemanding 0.00024	convenient 0.00021	common 0.00018	carefree 0.00017	accessible 0.00017	less 0.00015

Test context:
***************
easy.a	1294	9	remember that the delegates ' life is not always __easy__ .
Contexts for target easy are: ['mark_that', 'nsubj_life', 'cop_is', 'neg_not', 'advmod_always', 'ccompI_remember']
Contexts in vocabulary for target easy are: ['mark_that', 'nsubj_life', 'cop_is', 'neg_not', 'advmod_always', 'ccompI_remember']
Top most similar embeddings: easy 0.01684	difficult 0.01288	easier 0.01283	dificult 0.01281	straightforward 0.01234	sacrosanct 0.01212	unproblematic 0.01196	salvageable 0.01193	reducible 0.01183	be-all 0.01174

Generated lemmatized results
***************
GENERATED	easy.a 1294 ::: difficult;dificult;straightforward;sacrosanct;unproblematic;salvageable;reducible;predicable;falsifiable;necesary

Filtered results
***************
RANKED	easy.a 1294	straightforward 0.01234	possible 0.01098	simple 0.01004	convenient 0.00954	undemanding 0.00929	uncomplicated 0.00913	accessible 0.00894	less 0.00705	common 0.00703	carefree 0.00689

Test context:
***************
easy.a	1295	9	in particular , the fact that it is quite __easy__ for media students to be reasonably slick media producers in the online environment , means that we are all more actively engaged with questions of creation , distribution and audience .
Contexts for target easy are: ['mark_that', 'nsubj_it', 'cop_is', 'advmod_quite', 'ccompI_fact', 'advcl_producers']
Contexts in vocabulary for target easy are: ['mark_that', 'nsubj_it', 'cop_is', 'advmod_quite', 'ccompI_fact']
Top most similar embeddings: easy 0.03405	difficult 0.02863	impossible 0.02826	fixable 0.02697	dificult 0.02690	straighforward 0.02667	straightforward 0.02650	bug-free 0.02647	worth-while 0.02645	doable 0.02598

Generated lemmatized results
***************
GENERATED	easy.a 1295 ::: difficult;impossible;fixable;dificult;straighforward;straightforward;doable;stressfull;unhistorical;feasible

Filtered results
***************
RANKED	easy.a 1295	straightforward 0.02650	possible 0.02385	simple 0.02316	convenient 0.02173	undemanding 0.02141	uncomplicated 0.02019	accessible 0.01955	common 0.01828	carefree 0.01427	less 0.01396

Test context:
***************
easy.a	1296	8	the guardian uses the example that it 's __easier__ to create uk maps using the american google maps than our own ordnance survey .
Contexts for target easier are: ['mark_that', 'nsubj_it', "cop_'s", 'ccompI_uses', 'xcomp_create']
Contexts in vocabulary for target easier are: ['mark_that', 'nsubj_it', "cop_'s", 'ccompI_uses', 'xcomp_create']
Top most similar embeddings: easier 0.03273	easy 0.02703	impossible 0.02670	harder 0.02575	difficult 0.02511	cheaper 0.02447	simpler 0.02434	dificult 0.02429	possible 0.02410	feasible 0.02397

Generated lemmatized results
***************
GENERATED	easy.a 1296 ::: impossible;hard;difficult;cheap;simple;dificult;possible;feasible;necesary;infeasible

Filtered results
***************
RANKED	easy.a 1296	simple 0.02434	possible 0.02410	convenient 0.02067	straightforward 0.02061	undemanding 0.01668	uncomplicated 0.01551	accessible 0.01547	less 0.01340	common 0.01331	carefree 0.01074

Test context:
***************
easy.a	1297	22	apache is designed as a set of modules , enabling administrators to choose which features they wish to use and making it __easy__ to add features to meet specific needs inlcuding handling protocols other than the web-standard http .
Contexts for target easy are: ['nsubj_it', 'xcompI_making', 'xcomp_add']
Contexts in vocabulary for target easy are: ['nsubj_it', 'xcompI_making', 'xcomp_add']
Top most similar embeddings: easy 0.14451	easier 0.12061	difficult 0.10804	dificult 0.10740	impossible 0.10376	cinch 0.10149	near-impossible 0.09826	straightforward 0.09777	inadvisable 0.09746	possible 0.09628

Generated lemmatized results
***************
GENERATED	easy.a 1297 ::: difficult;dificult;impossible;cinch;straightforward;inadvisable;possible;simple;convenient;recommendable

Filtered results
***************
RANKED	easy.a 1297	straightforward 0.09777	possible 0.09628	simple 0.09615	convenient 0.09549	accessible 0.07981	uncomplicated 0.07752	undemanding 0.07460	common 0.06376	carefree 0.05658	less 0.05397

Test context:
***************
easy.a	1298	10	the black cowboy walked across african square stepping slow and __easy__ under his wide-brimmed hat , his boots clicking on the pavement .
Contexts for target easy are: ['conjI_slow']
Contexts in vocabulary for target easy are: ['conjI_slow']
Top most similar embeddings: easy 0.49542	difficult 0.39830	painless 0.39378	straightforward 0.38678	dificult 0.38513	slow 0.38475	unchallenging 0.38159	effortless 0.38054	laborious 0.37922	straighforward 0.37912

Generated lemmatized results
***************
GENERATED	easy.a 1298 ::: difficult;painless;straightforward;dificult;slow;unchallenging;effortless;laborious;straighforward;repetative

Filtered results
***************
RANKED	easy.a 1298	straightforward 0.38678	undemanding 0.37010	simple 0.36367	uncomplicated 0.36206	convenient 0.34510	carefree 0.32497	accessible 0.30340	possible 0.30077	common 0.28220	less 0.26242

Test context:
***************
easy.a	1299	7	the basics are very well expressed and __easy__ to understand .
Contexts for target easy are: ['conjI_expressed', 'ccomp_understand']
Contexts in vocabulary for target easy are: ['conjI_expressed', 'ccomp_understand']
Top most similar embeddings: easy 0.23750	easier 0.19757	difficult 0.19092	straightforward 0.17106	simple 0.16430	hard 0.16400	harder 0.15983	impossible 0.15597	insisted 0.15531	helped 0.15513

Generated lemmatized results
***************
GENERATED	easy.a 1299 ::: difficult;straightforward;simple;hard;impossible;insisted;helped;daresay;uncomplicated;helps

Filtered results
***************
RANKED	easy.a 1299	straightforward 0.17106	simple 0.16430	uncomplicated 0.15382	undemanding 0.14924	convenient 0.14191	possible 0.13404	accessible 0.12911	carefree 0.12258	common 0.11940	less 0.11642

Test context:
***************
easy.a	1300	19	by rick warren there are so many books and tapes on goal setting and establishing objectives that it 's __easy__ to get bored with them .
Contexts for target easy are: ['mark_that', 'nsubj_it', "cop_'s", 'ccompI_warren', 'xcomp_bored']
Contexts in vocabulary for target easy are: ['mark_that', 'nsubj_it', "cop_'s", 'xcomp_bored']
Top most similar embeddings: easy 0.07176	impossible 0.05729	difficult 0.05599	dificult 0.05574	easier 0.05542	hard 0.05159	nigh-on 0.05132	unlikely 0.04986	harder 0.04870	unlikley 0.04825

Generated lemmatized results
***************
GENERATED	easy.a 1300 ::: impossible;difficult;dificult;hard;unlikely;unlikley;doable;unwise;tempting;addicting

Filtered results
***************
RANKED	easy.a 1300	possible 0.04376	straightforward 0.04287	convenient 0.04260	simple 0.04102	undemanding 0.03963	uncomplicated 0.03371	accessible 0.03277	common 0.03198	carefree 0.02718	less 0.02699

Test context:
***************
endure.v	1301	3	i will not __endure__ the laughter of the court .
Contexts for target endure are: ['nsubj_i', 'aux_will', 'neg_not', 'rootI_*root*', 'dobj_laughter', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target endure are: ['nsubj_i', 'aux_will', 'neg_not', 'rootI_*root*', 'dobj_laughter', 'punct_.']
Top most similar embeddings: endure 0.02093	tolerate 0.01821	overemphasise 0.01759	re-occur 0.01751	chasten 0.01730	exasperate 0.01707	include 0.01675	fynde 0.01665	contain 0.01659	cheapen 0.01649

Generated lemmatized results
***************
GENERATED	endure.v 1301 ::: tolerate;overemphasise;chasten;exasperate;include;fynde;contain;cheapen;bewail;deaden

Filtered results
***************
RANKED	endure.v 1301	tolerate 0.01821	suffer 0.01635	have 0.01498	undergo 0.01409	continue 0.01379	persist 0.01350	bear 0.01275	experience 0.01216	last 0.01192

Test context:
***************
endure.v	1302	6	and this combined annual incidence-rate will __endure__ indefinitely too , until the annual production-rate is altered .
Contexts for target endure are: ['cc_and', 'nsubj_incidence-rate', 'aux_will', 'rootI_*root*', 'advmod_indefinitely', 'punct_,', 'advcl_altered', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target endure are: ['cc_and', 'aux_will', 'rootI_*root*', 'advmod_indefinitely', 'punct_,', 'advcl_altered', 'punct_.']
Top most similar embeddings: endure 0.00647	persist 0.00626	survive 0.00606	continue 0.00587	reverberate 0.00548	re-occur 0.00548	retained 0.00542	survived 0.00536	persisted 0.00536	tolerate 0.00534

Generated lemmatized results
***************
GENERATED	endure.v 1302 ::: persist;survive;continue;reverberate;retain;tolerate;fluctuate;proliferate;linger;withstand

Filtered results
***************
RANKED	endure.v 1302	persist 0.00626	continue 0.00587	tolerate 0.00534	last 0.00503	undergo 0.00494	suffer 0.00491	bear 0.00403	experience 0.00359	have 0.00331

Test context:
***************
endure.v	1303	10	positive attitude overcomes pelvic pain former athlete janet h has __endured__ 20 operations and has been reduced to surviving on a special liquid diet after being stricken 24 years ago with endometriosis .
Contexts for target endured are: ['nsubj_h', 'aux_has', 'rcmodI_pain', 'dobj_operations', 'cc_and', 'conj_reduced']
Contexts in vocabulary for target endured are: ['nsubj_h', 'aux_has', 'rcmodI_pain', 'dobj_operations', 'cc_and', 'conj_reduced']
Top most similar embeddings: endured 0.01503	suffered 0.01230	undergone 0.01050	decreased 0.01029	intensified 0.01025	sustained 0.01002	withstood 0.01001	survived 0.00999	worsened 0.00987	underwent 0.00985

Generated lemmatized results
***************
GENERATED	endure.v 1303 ::: suffer;undergo;decrease;intensify;sustain;withstand;survive;worsen;last;stave

Filtered results
***************
RANKED	endure.v 1303	suffer 0.01230	undergo 0.01050	last 0.00984	persist 0.00964	experience 0.00924	continue 0.00879	have 0.00798	tolerate 0.00792	bear 0.00683

Test context:
***************
endure.v	1304	11	what was n't my fault was the ordeal i had to __endure__ to fix it .
Contexts for target endure are: ['aux_to', 'xcompI_had', 'xcomp_fix']
Contexts in vocabulary for target endure are: ['aux_to', 'xcompI_had', 'xcomp_fix']
Top most similar embeddings: endure 0.13398	withstand 0.09884	relearn 0.09736	forgo 0.09674	manhandle 0.09619	invent 0.09540	baby-sit 0.09379	re-learn 0.09297	traipse 0.09291	surmount 0.09267

Generated lemmatized results
***************
GENERATED	endure.v 1304 ::: withstand;relearn;forgo;manhandle;invent;traipse;surmount;negotiate;undergo;readjust

Filtered results
***************
RANKED	endure.v 1304	undergo 0.09235	suffer 0.08621	tolerate 0.08271	continue 0.07786	bear 0.07743	have 0.07202	persist 0.07139	last 0.06415	experience 0.06191

Test context:
***************
endure.v	1305	5	developers are routinely asked to __endure__ the hardships of design extremes , such as a low-memory footprint , in order to reduce total system cost .
Contexts for target endure are: ['aux_to', 'xcompI_asked', 'dobj_hardships', 'advcl_reduce']
Contexts in vocabulary for target endure are: ['aux_to', 'xcompI_asked', 'dobj_hardships', 'advcl_reduce']
Top most similar embeddings: endure 0.07038	undergo 0.04981	withstand 0.04781	inflict 0.04729	suffer 0.04596	endured 0.04521	forego 0.04515	forgo 0.04515	alleviate 0.04503	postpone 0.04499

Generated lemmatized results
***************
GENERATED	endure.v 1305 ::: undergo;withstand;inflict;suffer;forego;forgo;alleviate;postpone;feign;expiate

Filtered results
***************
RANKED	endure.v 1305	undergo 0.04981	suffer 0.04596	tolerate 0.04341	bear 0.03986	continue 0.03538	persist 0.03282	experience 0.03248	have 0.02723	last 0.02689

Test context:
***************
endure.v	1306	6	the white sox , who are __enduring__ what i call the curse of the 1919 black sox ?
Contexts for target enduring are: ['nsubj_who', 'aux_are', 'rcmodI_sox', 'ccomp_call']
Contexts in vocabulary for target enduring are: ['nsubj_who', 'aux_are', 'ccomp_call']
Top most similar embeddings: enduring 0.11114	experiencing 0.09362	perishing 0.08654	perpetrating 0.08614	bankrolling 0.08467	propounding 0.08413	suffering 0.08363	rediscovering 0.08336	wiling 0.08264	espousing 0.08264

Generated lemmatized results
***************
GENERATED	endure.v 1306 ::: experience;perish;perpetrate;bankroll;propound;suffer;rediscover;wiling;espouse;contemplate

Filtered results
***************
RANKED	endure.v 1306	experience 0.09362	suffer 0.08363	undergo 0.08006	continue 0.07669	tolerate 0.07636	have 0.07528	persist 0.07475	last 0.07087	bear 0.06172

Test context:
***************
endure.v	1307	31	and , to a large extent i have harvard to thank for that ' for the extraordinary role models i studied and studied under and the friendships i made that have __endured__ .
Contexts for target endured are: ['nsubj_that', 'aux_have', 'ccompI_made']
Contexts in vocabulary for target endured are: ['nsubj_that', 'aux_have', 'ccompI_made']
Top most similar embeddings: endured 0.13168	withstood 0.10031	suffered 0.09930	survived 0.09699	subsisted 0.09648	befallen 0.09589	smouldered 0.09582	rankled 0.09437	lasted 0.09333	eluded 0.09299

Generated lemmatized results
***************
GENERATED	endure.v 1307 ::: withstand;suffer;survive;subsist;befall;smoulder;rankle;last;elude;outlast

Filtered results
***************
RANKED	endure.v 1307	suffer 0.09930	last 0.09333	undergo 0.08962	persist 0.08952	experience 0.08366	have 0.08276	continue 0.07717	bear 0.07684	tolerate 0.07187

Test context:
***************
endure.v	1308	13	now here he is , gowned and on a gurney , forced to __endure__ a medical procedure all because of some soup .
Contexts for target endure are: ['aux_to', 'xcompI_forced', 'dobj_procedure', 'dep_all']
Contexts in vocabulary for target endure are: ['aux_to', 'xcompI_forced', 'dobj_procedure', 'dep_all']
Top most similar embeddings: endure 0.06622	undergo 0.05103	re-do 0.04668	forgo 0.04658	withstand 0.04572	forego 0.04564	concoct 0.04531	abandon 0.04517	disavow 0.04511	adopt 0.04494

Generated lemmatized results
***************
GENERATED	endure.v 1308 ::: undergo;forgo;withstand;forego;concoct;abandon;disavow;adopt;confront;postpone

Filtered results
***************
RANKED	endure.v 1308	undergo 0.05103	suffer 0.04384	tolerate 0.04255	bear 0.03558	continue 0.03540	persist 0.03460	have 0.03303	experience 0.02960	last 0.02838

Test context:
***************
endure.v	1309	4	however , people often __endured__ inadequate at because of the lack of a viable alternative .
Contexts for target endured are: ['advmod_however', 'punct_,', 'nsubj_people', 'advmod_often', 'rootI_*root*', 'acomp_inadequate', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target endured are: ['advmod_however', 'punct_,', 'nsubj_people', 'advmod_often', 'rootI_*root*', 'acomp_inadequate', 'punct_.']
Top most similar embeddings: endured 0.00648	felt 0.00638	proved 0.00603	seem 0.00572	feel 0.00553	proves 0.00543	balked 0.00540	suffer 0.00536	feels 0.00536	suffered 0.00536

Generated lemmatized results
***************
GENERATED	endure.v 1309 ::: felt;prove;seem;feel;balk;suffer;tend;doubt;bemoan;persist

Filtered results
***************
RANKED	endure.v 1309	suffer 0.00536	persist 0.00525	tolerate 0.00438	continue 0.00437	experience 0.00437	undergo 0.00418	last 0.00418	bear 0.00417	have 0.00360

Test context:
***************
endure.v	1310	17	the campaign should challenge the notion that prostate problems are an inevitable part of ageing to be __endured__ rather than investigated .
Contexts for target endured are: ['aux_to', 'auxpass_be', 'infmodI_ageing']
Contexts in vocabulary for target endured are: ['aux_to', 'auxpass_be']
Top most similar embeddings: endured 0.23985	revenged 0.19853	trifled 0.19606	pitied 0.19456	savoured 0.19307	overcome 0.19069	endure 0.18627	fullfilled 0.18623	combated 0.18163	euthanased 0.18073

Generated lemmatized results
***************
GENERATED	endure.v 1310 ::: revenge;trifle;pity;savour;overcome;fullfilled;combat;euthanased;inflict;avoid

Filtered results
***************
RANKED	endure.v 1310	suffer 0.17484	bear 0.17335	tolerate 0.16907	experience 0.16735	undergo 0.15818	continue 0.15403	persist 0.15370	last 0.14879	have 0.13401

Test context:
***************
extended.a	1311	27	the hispanic family : an untapped resource one step that schools can take is to understand and tap into an important and underutilized source of strength--the hispanic __extended__ family .
Contexts for target extended are: ['amodI_family']
Contexts in vocabulary for target extended are: ['amodI_family']
Top most similar embeddings: extended 0.54016	one-parent 0.39551	multi-generational 0.38560	extending 0.38469	two-parent 0.38071	expanded 0.37898	lone-parent 0.37517	extend 0.37020	slimmed-down 0.36271	two-car 0.36177

Generated lemmatized results
***************
GENERATED	extended.a 1311 ::: extending;expanded;extend;lengthened;extends;agnatic;wizarding;dysfunctional;expanding;enlarged

Filtered results
***************
RANKED	extended.a 1311	expanded 0.37898	lengthened 0.35911	enlarged 0.34838	prolonged 0.34407	wide 0.33804	extensive 0.33223	broad 0.32274	elongated 0.32228	increased 0.32105	augmented 0.32023	additional 0.31177	comprehensive 0.30093	protracted 0.29940	expansive 0.29797	lengthy 0.29546	long 0.29256

Test context:
***************
extended.a	1312	4	) and recording an __extended__ soundcheck on a little tape machine that may end up playing a big role on our next record .
Contexts for target extended are: ['amodI_soundcheck']
Contexts in vocabulary for target extended are: []
Top most similar embeddings: extended 1.00000	extend 0.81711	extending 0.80780	extends 0.78567	expanded 0.78422	widened 0.75258	lengthened 0.75149	broadened 0.74300	resited 0.72232	stretched 0.71963

Generated lemmatized results
***************
GENERATED	extended.a 1312 ::: extend;extending;extends;expanded;widened;lengthened;broadened;resited;stretched;shortened

Filtered results
***************
RANKED	extended.a 1312	expanded 0.78422	lengthened 0.75149	increased 0.70584	prolonged 0.70494	enlarged 0.68922	augmented 0.67740	extensive 0.66394	elongated 0.65138	lengthy 0.64483	wide 0.64109	protracted 0.63920	additional 0.63388	broad 0.63305	expansive 0.63200	comprehensive 0.61820	long 0.61794

Test context:
***************
extended.a	1313	31	discussion top in this study , we have shown that recombinant gp120 increases the permeability of brain endothelium cultures to albumin , most likely by altering the cell morphology and inducing __extended__ intercellular gaps that allow passage of macromolecules and probably facilitate cell transmigration across the bbb .
Contexts for target extended are: ['amodI_gaps']
Contexts in vocabulary for target extended are: ['amodI_gaps']
Top most similar embeddings: extended 0.46476	widened 0.36129	ever-widening 0.36094	extending 0.35931	clearly-defined 0.35554	extra-long 0.35327	short/long 0.35311	two-second 0.35261	lengthened 0.35000	longish 0.34955

Generated lemmatized results
***************
GENERATED	extended.a 1313 ::: widened;extending;lengthened;longish;unbridgeable;expanded;prolonged;signficant;unpublicised;generalised

Filtered results
***************
RANKED	extended.a 1313	lengthened 0.35000	expanded 0.34037	prolonged 0.34000	enlarged 0.32958	lengthy 0.32853	wide 0.32413	increased 0.32306	extensive 0.32240	elongated 0.31774	protracted 0.31582	long 0.30928	additional 0.30800	broad 0.30648	expansive 0.29515	augmented 0.29186	comprehensive 0.27795

Test context:
***************
extended.a	1314	28	nuclear family this unit observes and assesses the effectiveness of childcare in the nuclear family home environment , looking at the childrens ' experience with their parents and __extended__ family .
Contexts for target extended are: ['amodI_family']
Contexts in vocabulary for target extended are: ['amodI_family']
Top most similar embeddings: extended 0.54016	one-parent 0.39551	multi-generational 0.38560	extending 0.38469	two-parent 0.38071	expanded 0.37898	lone-parent 0.37517	extend 0.37020	slimmed-down 0.36271	two-car 0.36177

Generated lemmatized results
***************
GENERATED	extended.a 1314 ::: extending;expanded;extend;lengthened;extends;agnatic;wizarding;dysfunctional;expanding;enlarged

Filtered results
***************
RANKED	extended.a 1314	expanded 0.37898	lengthened 0.35911	enlarged 0.34838	prolonged 0.34407	wide 0.33804	extensive 0.33223	broad 0.32274	elongated 0.32228	increased 0.32105	augmented 0.32023	additional 0.31177	comprehensive 0.30093	protracted 0.29940	expansive 0.29797	lengthy 0.29546	long 0.29256

Test context:
***************
extended.a	1315	15	at work : calling in sick , coming in late , leaving early , taking __extended__ breaks , giving up your territory ( " why do n't you let mary take over that assignment for you " ) .
Contexts for target extended are: ['amodI_breaks']
Contexts in vocabulary for target extended are: ['amodI_breaks']
Top most similar embeddings: extended 0.49614	3-night 0.38520	two-centre 0.38287	four-night 0.38128	extending 0.38066	three-night 0.37994	4-night 0.37869	recuperative 0.37790	short/long 0.37565	seven-night 0.36689

Generated lemmatized results
***************
GENERATED	extended.a 1315 ::: extending;recuperative;expanded;lengthened;prolonged;shortish;extendible;extend;longish;shortened

Filtered results
***************
RANKED	extended.a 1315	expanded 0.36575	lengthened 0.35533	prolonged 0.35408	lengthy 0.33224	increased 0.32607	extensive 0.32496	additional 0.32121	protracted 0.32094	elongated 0.31727	enlarged 0.31304	augmented 0.31270	long 0.30959	wide 0.30606	expansive 0.30436	broad 0.29686	comprehensive 0.28161

Test context:
***************
extended.a	1316	21	( grieve 1927a , 19 ) [ 9 ] this book therefore marked the beginning of what was to be an __extended__ battle between macdiarmid , as well as the other celticist fundamentalists in the nps , and the conservative nationalists of the scottish party .
Contexts for target extended are: ['amodI_battle']
Contexts in vocabulary for target extended are: ['amodI_battle']
Top most similar embeddings: extended 0.48568	race-long 0.38574	season-long 0.37882	yearlong 0.37515	36-hour 0.37430	five-game 0.37344	eight-month 0.37189	decades-long 0.37164	five-month 0.37139	6-hour 0.37131

Generated lemmatized results
***************
GENERATED	extended.a 1316 ::: yearlong;prolonged;lengthened;extending;expanded;daylong;sanguinary;protracted;neverending;extend

Filtered results
***************
RANKED	extended.a 1316	prolonged 0.36697	lengthened 0.36473	expanded 0.35790	protracted 0.35066	lengthy 0.34419	wide 0.31925	extensive 0.31872	enlarged 0.31658	long 0.31589	broad 0.31307	increased 0.31200	augmented 0.30816	elongated 0.30785	expansive 0.30151	additional 0.29815	comprehensive 0.28895

Test context:
***************
extended.a	1317	16	not surprisingly , ellison spends a considerable amount of time describing the results of his own __extended__ fieldwork among efe hunter-gatherers and lese horticulturalists living in the rainforests of the democratic republic of congo .
Contexts for target extended are: ['amodI_fieldwork']
Contexts in vocabulary for target extended are: ['amodI_fieldwork']
Top most similar embeddings: extended 0.48511	library-based 0.36346	questionnaire-based 0.35962	yearlong 0.35868	drama-based 0.35734	self-initiated 0.35680	inter-laboratory 0.35626	desk-based 0.35584	extensive 0.35523	ahrc-funded 0.35444

Generated lemmatized results
***************
GENERATED	extended.a 1317 ::: yearlong;extensive;expanded;prolonged;phenomenographic;explorative;geoarchaeological;ethnobotanical;extending;urodynamic

Filtered results
***************
RANKED	extended.a 1317	extensive 0.35523	expanded 0.35361	prolonged 0.35080	increased 0.32585	lengthened 0.32532	lengthy 0.32306	additional 0.32158	augmented 0.31754	protracted 0.31349	enlarged 0.31232	comprehensive 0.30652	wide 0.30232	expansive 0.29923	broad 0.29818	long 0.29117	elongated 0.28507

Test context:
***************
extended.a	1318	0	__extended__ warranties for desktop computers tend to be rip-offs , because you would usually pay an independent technician much less in repair costs over the same period that a typical extended warranty costs to provide repair cover .
Contexts for target extended are: ['amodI_warranties']
Contexts in vocabulary for target extended are: ['amodI_warranties']
Top most similar embeddings: extended 0.53989	extend 0.40010	extending 0.38500	expanded 0.37608	insurance-backed 0.37242	extends 0.37071	extendable 0.35869	24-month 0.35625	lengthened 0.35522	widened 0.35256

Generated lemmatized results
***************
GENERATED	extended.a 1318 ::: extend;extending;expanded;extends;extendable;lengthened;widened;generalized;extendible;generalised

Filtered results
***************
RANKED	extended.a 1318	expanded 0.37608	lengthened 0.35522	extensive 0.33698	prolonged 0.33009	enlarged 0.32507	additional 0.32267	lengthy 0.32018	comprehensive 0.31710	increased 0.31499	augmented 0.30966	broad 0.30818	expansive 0.29975	long 0.29930	wide 0.29636	protracted 0.28423	elongated 0.27352

Test context:
***************
extended.a	1319	14	i 've always been kind of at loose ends whenever i 'm given an __extended__ period of free time .
Contexts for target extended are: ['amodI_period']
Contexts in vocabulary for target extended are: ['amodI_period']
Top most similar embeddings: extended 0.53031	fourteen-day 0.41978	eighteen-month 0.41662	13-week 0.41543	2-month 0.41530	nine-week 0.41498	40-day 0.41399	16-week 0.41226	twelve-week 0.40618	24-month 0.40280

Generated lemmatized results
***************
GENERATED	extended.a 1319 ::: lengthened;prolonged;yearlong;recuperative;extending;intertestamental;maccabean;extend;longish;hasmonean

Filtered results
***************
RANKED	extended.a 1319	lengthened 0.38783	prolonged 0.38619	expanded 0.35875	lengthy 0.35024	protracted 0.34923	extensive 0.33706	increased 0.33065	long 0.32527	augmented 0.32485	elongated 0.32079	additional 0.32033	enlarged 0.31741	expansive 0.31340	wide 0.31187	broad 0.30884	comprehensive 0.29511

Test context:
***************
extended.a	1320	8	i was taking a prescription medication over an __extended__ length of time under the supervision of a physician who specializes in the management of pain .
Contexts for target extended are: ['amodI_length']
Contexts in vocabulary for target extended are: ['amodI_length']
Top most similar embeddings: extended 0.50569	lengthened 0.39467	extra-long 0.37905	extending 0.37591	50-metre 0.36854	expanded 0.36808	user-specified 0.36771	15-mile 0.36727	200-mile 0.36421	40-mile 0.36420

Generated lemmatized results
***************
GENERATED	extended.a 1320 ::: lengthened;extending;expanded;extendible;longish;shortened;shortish;proportionable;extend;increased

Filtered results
***************
RANKED	extended.a 1320	lengthened 0.39467	expanded 0.36808	increased 0.35281	prolonged 0.34649	enlarged 0.33736	elongated 0.32890	additional 0.32038	long 0.31981	lengthy 0.31692	protracted 0.31516	extensive 0.31453	wide 0.31146	augmented 0.30597	broad 0.30156	expansive 0.29840	comprehensive 0.28162

Test context:
***************
external.a	1321	1	this __external__ communication could be with external trading partners or within the organization .
Contexts for target external are: ['amodI_communication']
Contexts in vocabulary for target external are: ['amodI_communication']
Top most similar embeddings: external 0.51511	internal 0.43370	internal/external 0.43046	inter-process 0.41316	human-human 0.40800	multi-way 0.39621	human-to-human 0.39510	cell-to-cell 0.39416	inter-organisational 0.39356	in-cab 0.39274

Generated lemmatized results
***************
GENERATED	external.a 1321 ::: internal;phatic;interdimensional;intercellular;interlingual;telephonic;nonverbal;intersectoral;intersubjective;spacial

Filtered results
***************
RANKED	external.a 1321	nonlocal 0.34560	outward 0.33524	outer 0.32288	outside 0.32069	foreign 0.31531	exterior 0.30285	link 0.22928

Test context:
***************
external.a	1322	15	that is , we can be glad so long as we do not believe in __external__ authority ( for example , the testimony of others ) alone for our religious beliefs .
Contexts for target external are: ['amodI_authority']
Contexts in vocabulary for target external are: ['amodI_authority']
Top most similar embeddings: external 0.50672	internal 0.39551	internal/external 0.39333	prosecutorial 0.39297	precepting 0.38302	order-making 0.38136	government-appointed 0.37747	grant-awarding 0.37512	national/local 0.37306	non-legal 0.37119

Generated lemmatized results
***************
GENERATED	external.a 1322 ::: internal;prosecutorial;precepting;local;synodical;ostensible;extraterritorial;cial;decisional;corporative

Filtered results
***************
RANKED	external.a 1322	outside 0.33199	nonlocal 0.32530	outward 0.32465	foreign 0.32455	outer 0.31525	exterior 0.28684	link 0.23144

Test context:
***************
external.a	1323	1	the __external__ appearance of each type of extinguisher maybe different and each carries its own instructions for use .
Contexts for target external are: ['amodI_appearance']
Contexts in vocabulary for target external are: ['amodI_appearance']
Top most similar embeddings: external 0.53339	internal 0.40635	internal/external 0.38614	now-familiar 0.37052	mirror-like 0.36872	sonographic 0.36821	inital 0.36611	ultrasonographic 0.36447	hollywood-style 0.36339	no-compromise 0.36281

Generated lemmatized results
***************
GENERATED	external.a 1323 ::: internal;sonographic;inital;ultrasonographic;outward;cyclopean;scleral;macroscopic;diegetic;scrotal

Filtered results
***************
RANKED	external.a 1323	outward 0.36011	outer 0.34624	exterior 0.34281	outside 0.33759	nonlocal 0.32593	foreign 0.30927	link 0.22756

Test context:
***************
external.a	1324	0	__external__ resources : assess external resources and the community 's institutional , political , technical , legal and fiscal capability to engage in hazard mitigation and response .
Contexts for target external are: ['amodI_resources']
Contexts in vocabulary for target external are: ['amodI_resources']
Top most similar embeddings: external 0.51828	internal 0.42573	www.englishresources.co.uk 0.41873	internal/external 0.40003	non-arts 0.39856	education-related 0.39718	customer-specific 0.39543	publicly-available 0.39486	course-specific 0.39176	www-based 0.39175

Generated lemmatized results
***************
GENERATED	external.a 1324 ::: internal;additonal;lexicographical;terminological;nonmilitary;geoscientific;nonfinancial;addtional;prosecutorial;electonic

Filtered results
***************
RANKED	external.a 1324	nonlocal 0.34065	outside 0.33050	outer 0.32193	foreign 0.31843	outward 0.31562	exterior 0.29984	link 0.23894

Test context:
***************
external.a	1325	14	q can you kindly advise if team roles change with different team members and __external__ factors e.g. company setting , cultural context ?
Contexts for target external are: ['amodI_factors']
Contexts in vocabulary for target external are: ['amodI_factors']
Top most similar embeddings: external 0.54006	internal 0.42601	internal/external 0.42194	neurotrophic 0.42023	etiological 0.41839	non-genetic 0.41428	etiologic 0.41299	non-price 0.41015	extra-linguistic 0.40506	individual-level 0.40392

Generated lemmatized results
***************
GENERATED	external.a 1325 ::: internal;neurotrophic;etiological;etiologic;clinicopathological;angiogenic;abiotic;exogenous;taphonomic;steric

Filtered results
***************
RANKED	external.a 1325	nonlocal 0.37111	outside 0.33772	outward 0.32335	outer 0.31792	foreign 0.31189	exterior 0.30959	link 0.22479

Test context:
***************
external.a	1326	0	__external__ links to other internet sites should not be construed as an endorsement of the views or privacy policies contained therein .
Contexts for target external are: ['amodI_links']
Contexts in vocabulary for target external are: ['amodI_links']
Top most similar embeddings: external 0.54850	internal 0.42655	internal/external 0.42545	in-bound 0.40847	people-to-people 0.40084	non-reciprocal 0.39483	public-facing 0.39086	non-related 0.39064	home-school 0.38981	intra-regional 0.38698

Generated lemmatized results
***************
GENERATED	external.a 1326 ::: internal;addtional;multipage;intertextual;mutiple;intersectoral;cial;intensional;additonal;nomenclatural

Filtered results
***************
RANKED	external.a 1326	nonlocal 0.34936	outside 0.33309	outer 0.32787	outward 0.32347	exterior 0.31611	foreign 0.31221	link 0.24595

Test context:
***************
external.a	1327	14	when careful measurements are taken of current flows in the generator and in the __external__ circuit , evidence suggests that electric charges are appearing at the periphery of the generator and disappearing at the center of the generator that do not actually pass through the generator .
Contexts for target external are: ['amodI_circuit']
Contexts in vocabulary for target external are: ['amodI_circuit']
Top most similar embeddings: external 0.51420	internal 0.41949	internal/external 0.40274	3-stage 0.37927	all-optical 0.37714	single-channel 0.37613	high-gain 0.37511	high-voltage 0.37471	thermoelectric 0.37386	four-way 0.37252

Generated lemmatized results
***************
GENERATED	external.a 1327 ::: internal;thermoelectric;multiband;fibreoptic;extracorporeal;subcortical;ufological;ultrafast;multistage;capacitive

Filtered results
***************
RANKED	external.a 1327	nonlocal 0.35500	outer 0.34461	outward 0.33085	outside 0.32807	foreign 0.31605	exterior 0.31177	link 0.23999

Test context:
***************
external.a	1328	55	many spiritual traditions still eschew technological techniques in favor of more " authentic " ones ; so unassisted meditation is said to be better than use of mind machines , electronic biofeedback , or psychotropic chemicals , and the use of technology as a sign of attachment to " worldly " things or reliance on __external__ crutches rather than " self-realization .
Contexts for target external are: ['amodI_crutches']
Contexts in vocabulary for target external are: []
Top most similar embeddings: external 1.00000	internal 0.81304	internal/external 0.78725	public-facing 0.72370	non-arts 0.72357	customer-specific 0.71822	extra-linguistic 0.71753	user-controlled 0.71699	15-pin 0.71614	analogue-to-digital 0.71547

Generated lemmatized results
***************
GENERATED	external.a 1328 ::: internal;ultrasonographic;neurotrophic;allosteric;thermoelectric;thermographic;extrinsic;subcortical;anastomotic;luminal

Filtered results
***************
RANKED	external.a 1328	nonlocal 0.68358	outside 0.67509	outer 0.66597	outward 0.66345	exterior 0.66136	foreign 0.64963	link 0.56616

Test context:
***************
external.a	1329	15	" nothing came to our attention indicating evidence of influence or pressure from internal or __external__ sources , " he wrote .
Contexts for target external are: ['conjI_internal']
Contexts in vocabulary for target external are: ['conjI_internal']
Top most similar embeddings: external 0.57774	internal/external 0.42503	internal 0.42371	extra-linguistic 0.36856	inter-governmental 0.36213	third-party 0.35905	extrinsic 0.35859	project-specific 0.35423	externally 0.35266	efferent 0.34695

Generated lemmatized results
***************
GENERATED	external.a 1329 ::: internal;extrinsic;externally;efferent;nonmilitary;interdepartmental;urethral;conjunctural;intergovernmental;untrusted

Filtered results
***************
RANKED	external.a 1329	outside 0.33647	outward 0.33182	foreign 0.32600	exterior 0.32508	outer 0.32496	nonlocal 0.32044	link 0.23525

Test context:
***************
external.a	1330	23	the end of the cold war could not but sharply increase its international isolation and legitimacy deficit ; bartering its anti-communist credentials for __external__ assistance was no longer a feasible option .
Contexts for target external are: ['amodI_assistance']
Contexts in vocabulary for target external are: ['amodI_assistance']
Top most similar embeddings: external 0.52331	internal 0.40015	internal/external 0.39761	on-the-ground 0.39488	concessional 0.39328	telephone-based 0.38769	host-nation 0.38077	pre-accession 0.37682	much-valued 0.37635	court-ordered 0.37628

Generated lemmatized results
***************
GENERATED	external.a 1330 ::: internal;concessional;additonal;prosecutorial;nonmilitary;finacial;addtional;aeromedical;adminstrative;cial

Filtered results
***************
RANKED	external.a 1330	outside 0.34895	foreign 0.33779	outward 0.33685	nonlocal 0.33116	outer 0.32238	exterior 0.30295	link 0.23259

Test context:
***************
field.n	1331	12	negative values indicate west of the prime meridian. pdate 8 character text __field__ consisting of numeric digits .
Contexts for target field are: ['nn_pdate', 'num_8', 'nn_character', 'nn_text', 'depI_west', 'partmod_consisting']
Contexts in vocabulary for target field are: ['num_8', 'nn_character', 'nn_text', 'depI_west', 'partmod_consisting']
Top most similar embeddings: field 0.02377	fields 0.02046	string 0.01906	sts 0.01727	strings 0.01716	arcmin 0.01671	textarea 0.01652	octet 0.01651	chars 0.01650	nodes 0.01632

Generated lemmatized results
***************
GENERATED	field.n 1331 ::: string;sts;arcmin;textarea;octet;char;node;intron;exon;bitset

Filtered results
***************
RANKED	field.n 1331	area 0.01609	region 0.01539	box 0.01533	section 0.01505	pitch 0.01424	domain 0.01370	battleground 0.01261	sphere 0.01228	subject 0.01206	land 0.01196	province 0.01194	resource 0.01187	acreage 0.01177	ground 0.01156	discipline 0.01143	licence 0.01109	environment 0.01094	community 0.01073	holder 0.01051	speciality 0.01032	activity 0.00993	investigative 0.00860	geographical 0.00858

Test context:
***************
field.n	1332	14	close co-ordination with the cept fora would support the emergence of pan-european solutions in __fields__ such as frequencies and numbering ( see the following section ) allowing a coverage of the 43 european member countries of the cept .
Contexts for target fields are: ['prep:inI_solutions', 'prep:as_frequencies']
Contexts in vocabulary for target fields are: ['prep:inI_solutions']
Top most similar embeddings: fields 0.50623	field 0.41432	subfields 0.37002	sub-fields 0.36973	spheres 0.36743	areas 0.35996	sectors 0.35314	sub-areas 0.34948	disciplines 0.34876	arenas 0.34836

Generated lemmatized results
***************
GENERATED	field.n 1332 ::: subfields;sphere;area;sector;discipline;arena;cf;waveband;feild;industry

Filtered results
***************
RANKED	field.n 1332	sphere 0.36743	area 0.35996	discipline 0.34876	domain 0.33523	environment 0.33084	region 0.31185	community 0.30324	box 0.30282	subject 0.30269	province 0.30033	acreage 0.29792	ground 0.29186	speciality 0.28593	battleground 0.28364	section 0.28311	land 0.28297	pitch 0.27407	activity 0.27282	resource 0.27024	holder 0.26724	geographical 0.25728	licence 0.25298	investigative 0.24680

Test context:
***************
field.n	1333	11	this community is one of those that share the yorla oil __field__ operated by shell petroleum development company ( spdc ) .
Contexts for target field are: ['det_the', 'nn_yorla', 'nn_oil', 'dobjI_share', 'partmod_operated']
Contexts in vocabulary for target field are: ['det_the', 'nn_oil', 'dobjI_share', 'partmod_operated']
Top most similar embeddings: field 0.05641	fields 0.04951	oilfields 0.04252	feild 0.04225	oilfield 0.04044	pipe-line 0.04025	refinery 0.04006	pipeline 0.03952	rigs 0.03906	refineries 0.03864

Generated lemmatized results
***************
GENERATED	field.n 1333 ::: oilfield;feild;refinery;pipeline;rig;platform;boma;depot;wagon;evaporator

Filtered results
***************
RANKED	field.n 1333	acreage 0.03684	ground 0.03407	region 0.03362	sphere 0.03344	resource 0.03327	land 0.03322	province 0.03304	pitch 0.03293	area 0.03271	box 0.03261	domain 0.03133	battleground 0.03063	holder 0.03039	environment 0.03008	subject 0.02962	activity 0.02934	licence 0.02932	speciality 0.02924	discipline 0.02909	community 0.02857	section 0.02727	geographical 0.02022	investigative 0.01906

Test context:
***************
field.n	1334	8	students learned about employment and opportunities in the __fields__ of science and technology and gained an understanding of the realities of workplace responsibilities .
Contexts for target fields are: ['det_the', 'prep:inI_learned', 'prep:of_science']
Contexts in vocabulary for target fields are: ['det_the', 'prep:inI_learned', 'prep:of_science']
Top most similar embeddings: fields 0.13523	field 0.11218	sub-fields 0.09730	sub-disciplines 0.09536	interstices 0.09423	spheres 0.09326	subfields 0.09303	popularization 0.08932	feild 0.08745	realm 0.08733

Generated lemmatized results
***************
GENERATED	field.n 1334 ::: interstice;sphere;subfields;popularization;feild;realm;sociology;schoolyard;discipline;problematics

Filtered results
***************
RANKED	field.n 1334	sphere 0.09326	discipline 0.08578	area 0.08559	domain 0.07862	province 0.07561	battleground 0.07498	subject 0.07300	section 0.07171	land 0.07076	acreage 0.06908	community 0.06904	environment 0.06900	region 0.06887	ground 0.06814	activity 0.06333	speciality 0.06279	pitch 0.06083	box 0.06080	holder 0.05985	resource 0.05704	licence 0.05076	geographical 0.04741	investigative 0.04425

Test context:
***************
field.n	1335	1	receptive __fields__ , binocular interaction and functional architecture in the cat 's visual cortex .
Contexts for target fields are: ['amod_receptive', 'rootI_*root*', 'punct_,', 'conj_interaction', 'cc_and', 'conj_architecture', 'prep:in_cortex', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target fields are: ['amod_receptive', 'rootI_*root*', 'punct_,', 'conj_interaction', 'cc_and', 'conj_architecture', 'prep:in_cortex', 'punct_.']
Top most similar embeddings: bioenergetics 0.00255	fields 0.00248	palaeogeography 0.00244	ferroelectrics 0.00240	whitehand 0.00239	cognition 0.00239	ontogeny 0.00234	biostratigraphy 0.00230	plasticity 0.00230	geomorphology 0.00229

Generated lemmatized results
***************
GENERATED	field.n 1335 ::: bioenergetics;palaeogeography;ferroelectrics;whitehand;cognition;ontogeny;biostratigraphy;plasticity;geomorphology;psychophysiology

Filtered results
***************
RANKED	field.n 1335	domain 0.00188	sphere 0.00147	discipline 0.00138	environment 0.00136	subject 0.00134	activity 0.00131	speciality 0.00131	battleground 0.00129	pitch 0.00122	region 0.00119	land 0.00119	section 0.00118	acreage 0.00109	province 0.00108	box 0.00108	ground 0.00108	area 0.00107	community 0.00104	resource 0.00104	licence 0.00098	geographical 0.00091	holder 0.00087	investigative 0.00082

Test context:
***************
field.n	1336	22	decimal precision will , in turn , determine the amount of disk space that is allocated to the data stored in that __field__ .
Contexts for target field are: ['det_that', 'prep:inI_stored']
Contexts in vocabulary for target field are: ['det_that', 'prep:inI_stored']
Top most similar embeddings: field 0.25251	fields 0.18486	feild 0.18394	mol-item 0.18017	subentry 0.17367	subfield 0.17277	makefile.in 0.17231	area 0.17034	subarray 0.17004	wastebasket 0.16937

Generated lemmatized results
***************
GENERATED	field.n 1336 ::: feild;subentry;subfield;area;subarray;wastebasket;tablespace;waveband;subform;subview

Filtered results
***************
RANKED	field.n 1336	area 0.17034	domain 0.15635	box 0.15058	sphere 0.14923	region 0.14835	ground 0.14747	discipline 0.14379	section 0.14340	environment 0.14115	land 0.14024	pitch 0.13837	acreage 0.13735	province 0.13604	community 0.13396	holder 0.13223	resource 0.13042	subject 0.12822	battleground 0.12559	activity 0.12388	speciality 0.12022	licence 0.11577	geographical 0.10184	investigative 0.09546

Test context:
***************
field.n	1337	13	some of today 's fishing " boats " are longer than a football __field__ !
Contexts for target field are: ['det_a', 'nn_football', 'prep:thanI_longer']
Contexts in vocabulary for target field are: ['det_a', 'nn_football', 'prep:thanI_longer']
Top most similar embeddings: field 0.11269	feild 0.09253	pitch 0.08270	fields 0.07896	shuttlecock 0.07795	racket 0.07767	cup-tie 0.07651	game 0.07621	linebacker 0.07581	stadium 0.07577

Generated lemmatized results
***************
GENERATED	field.n 1337 ::: feild;pitch;shuttlecock;racket;game;linebacker;stadium;match;outfield;layby

Filtered results
***************
RANKED	field.n 1337	pitch 0.08270	ground 0.07148	battleground 0.06867	area 0.06636	box 0.06448	discipline 0.06445	sphere 0.06426	holder 0.06336	section 0.06328	activity 0.06275	community 0.06244	acreage 0.06210	domain 0.06176	region 0.06104	province 0.06061	licence 0.06016	speciality 0.05968	subject 0.05854	land 0.05802	environment 0.05676	resource 0.05648	geographical 0.04603	investigative 0.04568

Test context:
***************
field.n	1338	14	while these officers are completing this enormous task , effective law enforcement in the __field__ will suffer .
Contexts for target field are: ['det_the', 'prep:inI_enforcement']
Contexts in vocabulary for target field are: ['det_the', 'prep:inI_enforcement']
Top most similar embeddings: field 0.25700	fields 0.20328	feild 0.19627	pipe-line 0.17891	area 0.17866	arena 0.17812	context 0.17365	market-place 0.17356	sphere 0.17341	countie 0.17255

Generated lemmatized results
***************
GENERATED	field.n 1338 ::: feild;area;arena;context;sphere;countie;workplace;subregion;rhizosphere;negeb

Filtered results
***************
RANKED	field.n 1338	area 0.17866	sphere 0.17341	region 0.16006	domain 0.15778	community 0.15647	province 0.15445	acreage 0.15021	ground 0.14930	environment 0.14860	discipline 0.14834	land 0.14715	section 0.14589	battleground 0.14452	box 0.14324	pitch 0.13807	subject 0.13080	holder 0.12938	speciality 0.12654	activity 0.12557	licence 0.12285	resource 0.12058	investigative 0.11287	geographical 0.10778

Test context:
***************
field.n	1339	31	' all of these provisions of the trips agreement should be adequately brought into wipo 's framework. ' technical assistance wipo is the main multilateral provider of technical assistance in the __field__ of intellectual property .
Contexts for target field are: ['det_the', 'prep:inI_assistance', 'prep:of_property']
Contexts in vocabulary for target field are: ['det_the', 'prep:inI_assistance', 'prep:of_property']
Top most similar embeddings: field 0.12863	fields 0.10353	feild 0.09530	rateability 0.08672	area 0.08618	furtherance 0.08596	realm 0.08419	acquirement 0.08401	curtilage 0.08329	pipe-line 0.08311

Generated lemmatized results
***************
GENERATED	field.n 1339 ::: feild;rateability;area;furtherance;realm;acquirement;curtilage;commercialization;vicinity;operationalisation

Filtered results
***************
RANKED	field.n 1339	area 0.08618	sphere 0.07982	region 0.07873	province 0.07570	ground 0.07520	domain 0.07386	acreage 0.07143	discipline 0.06829	section 0.06727	land 0.06705	community 0.06659	environment 0.06658	holder 0.06633	box 0.06573	speciality 0.06251	pitch 0.06220	subject 0.06219	battleground 0.06144	resource 0.05964	activity 0.05892	licence 0.05440	investigative 0.05073	geographical 0.04740

Test context:
***************
field.n	1340	33	in order to assess the nature of the tsunami that struck this isolated stretch of coast , and to determine the cause of the large waves , the international tsunami community conducted a __field__ survey of the area .
Contexts for target field are: ['nnI_survey']
Contexts in vocabulary for target field are: ['nnI_survey']
Top most similar embeddings: field 0.50633	nilt 0.41389	shbdep 0.39444	fields 0.37691	all-sky 0.37615	supercosmos 0.37240	gradiometer 0.37228	elais 0.36995	feild 0.36745	cadastral 0.36490

Generated lemmatized results
***************
GENERATED	field.n 1340 ::: nilt;shbdep;supercosmos;gradiometer;elais;feild;cadastral;antartic;ukst;waxcap

Filtered results
***************
RANKED	field.n 1340	area 0.31394	discipline 0.30920	acreage 0.30763	land 0.30717	ground 0.30638	pitch 0.30191	community 0.30169	domain 0.29673	environment 0.29367	activity 0.28547	resource 0.28225	geographical 0.28002	region 0.27991	box 0.27766	battleground 0.27452	subject 0.27266	investigative 0.27125	sphere 0.27111	section 0.26842	speciality 0.26605	province 0.26065	holder 0.25486	licence 0.25097

Test context:
***************
flat.a	1341	20	he talked knowledgeably about the braille overlays for the control buttons and genuinely understood the accessibility problems inherent in the __flat__ cooking surfaces .
Contexts for target flat are: ['amodI_surfaces']
Contexts in vocabulary for target flat are: ['amodI_surfaces']
Top most similar embeddings: flat 0.52953	flattish 0.40256	anti-skid 0.39590	unshaded 0.39265	mirror-like 0.39062	nickel-plated 0.38783	non-porous 0.38712	orthotropic 0.38621	hummocky 0.38374	shock-absorbing 0.38348

Generated lemmatized results
***************
GENERATED	flat.a 1341 ::: flattish;unshaded;orthotropic;hummocky;dimpled;clumpy;rubberized;uninsulated;cartilaginous;unventilated

Filtered results
***************
RANKED	flat.a 1341	smooth 0.35506	lifeless 0.33162	horizontal 0.32965	uniform 0.31649	straight 0.31546	thin 0.31071	shallow 0.31046	plain 0.30283	gently 0.30215	flush 0.29681	fixed 0.28730	deflated 0.27691	plane 0.27595	absolute 0.27074	outright 0.26995	total 0.26989	categoric 0.26918	downright 0.25503	even 0.24727	level 0.24213

Test context:
***************
flat.a	1342	18	keep upright posture : keep chest up and out , head tilted slightly upwards , and maintain a __flat__ back .
Contexts for target flat are: ['amodI_back']
Contexts in vocabulary for target flat are: ['amodI_back']
Top most similar embeddings: flat 0.52065	flattish 0.37660	v-shaped 0.36502	straight-sided 0.36364	three-inch 0.35703	half-round 0.35432	well-shaped 0.35398	strapless 0.35255	four-inch 0.35176	fan-shaped 0.35110

Generated lemmatized results
***************
GENERATED	flat.a 1342 ::: flattish;strapless;unshaded;steepish;dimpled;hummocky;lowish;rumpled;pebbled;heathery

Filtered results
***************
RANKED	flat.a 1342	straight 0.32757	smooth 0.32690	lifeless 0.32215	thin 0.31714	horizontal 0.29978	plain 0.29883	shallow 0.29494	uniform 0.28379	flush 0.28126	outright 0.28107	fixed 0.28102	total 0.27774	gently 0.27650	plane 0.27287	absolute 0.27210	deflated 0.27179	categoric 0.25227	downright 0.24335	level 0.22934	even 0.22846

Test context:
***************
flat.a	1343	26	the molten glass literally floats on the tin , spreading and seeking a controlled level in the same manner as water poured onto a smooth , __flat__ surface .
Contexts for target flat are: ['amodI_surface']
Contexts in vocabulary for target flat are: ['amodI_surface']
Top most similar embeddings: flat 0.54783	flattish 0.42158	anti-skid 0.39806	mirror-like 0.39755	unshaded 0.39216	hummocky 0.39027	fan-shaped 0.38866	rubberized 0.38789	straight-sided 0.38714	dimpled 0.38405

Generated lemmatized results
***************
GENERATED	flat.a 1343 ::: flattish;unshaded;hummocky;rubberized;dimpled;clumpy;orthotropic;floured;ellipsoidal;tessellated

Filtered results
***************
RANKED	flat.a 1343	smooth 0.35684	lifeless 0.34001	thin 0.32783	horizontal 0.32707	uniform 0.32456	straight 0.31916	shallow 0.31771	plain 0.30814	gently 0.30623	total 0.29076	flush 0.29025	fixed 0.28917	deflated 0.28660	categoric 0.28139	plane 0.27606	outright 0.27492	absolute 0.27190	level 0.26626	downright 0.26175	even 0.24809

Test context:
***************
flat.a	1344	4	the spin 's are __flat__ .
Contexts for target flat are: ['nsubj_spin', 'cop_are', 'rootI_*root*', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target flat are: ['nsubj_spin', 'cop_are', 'rootI_*root*', 'punct_.']
Top most similar embeddings: flat 0.04973	interchangable 0.04657	ho-hum 0.04505	unforgiveable 0.04488	phenominal 0.04458	unpaved 0.04445	implementation-dependent 0.04429	two-fold 0.04422	uncoloured 0.04413	non-absorbent 0.04408

Generated lemmatized results
***************
GENERATED	flat.a 1344 ::: interchangable;unforgiveable;phenominal;unpaved;uncoloured;hillarious;irrelevent;forgivable;debateable;unphased

Filtered results
***************
RANKED	flat.a 1344	smooth 0.03517	categoric 0.03452	deflated 0.03385	thin 0.03330	lifeless 0.03320	shallow 0.03290	straight 0.03282	plain 0.03222	uniform 0.03080	flush 0.03068	fixed 0.02892	absolute 0.02722	horizontal 0.02706	gently 0.02335	plane 0.02235	total 0.02214	outright 0.02154	level 0.01911	downright 0.01886	even 0.01267

Test context:
***************
flat.a	1345	16	the other evidence occurred after i asked to do research this summer with him and his __flat__ refusal ( well , he said he 'd be out of town a lot , but that was just being polite i 'm sure ) .
Contexts for target flat are: ['amodI_refusal']
Contexts in vocabulary for target flat are: ['amodI_refusal']
Top most similar embeddings: flat 0.51819	maisonette 0.36183	apartment 0.34470	injudicious 0.34110	undisguised 0.33704	callous 0.33661	flattish 0.33458	blatent 0.33399	vituperative 0.33158	rigid 0.33000

Generated lemmatized results
***************
GENERATED	flat.a 1345 ::: maisonette;apartment;injudicious;undisguised;callous;flattish;blatent;vituperative;rigid;flagrant

Filtered results
***************
RANKED	flat.a 1345	outright 0.32327	lifeless 0.31389	uniform 0.31252	smooth 0.31078	straight 0.30795	categoric 0.30562	absolute 0.30367	plain 0.29977	shallow 0.29685	total 0.29345	horizontal 0.29317	fixed 0.28262	thin 0.27837	downright 0.27397	gently 0.27371	plane 0.27150	flush 0.26273	deflated 0.25754	even 0.24363	level 0.24355

Test context:
***************
flat.a	1346	15	these are used to create finest transistor structures on display glass for pc monitors and __flat__ screens .
Contexts for target flat are: ['amodI_screens']
Contexts in vocabulary for target flat are: ['amodI_screens']
Top most similar embeddings: flat 0.53172	flat-screen 0.39394	frameless 0.39345	flip-up 0.39205	flat-panel 0.38797	30-inch 0.38561	2-inch 0.38473	21-inch 0.38348	12.1-inch 0.38107	19-inch 0.37923

Generated lemmatized results
***************
GENERATED	flat.a 1346 ::: frameless;flattish;traceried;louvred;latticed;slatted;hemispherical;dockable;rubberized;polygonal

Filtered results
***************
RANKED	flat.a 1346	thin 0.32227	horizontal 0.31086	smooth 0.30978	lifeless 0.30838	plain 0.30366	shallow 0.30331	straight 0.30119	fixed 0.29426	uniform 0.29032	flush 0.28538	gently 0.28327	outright 0.27576	total 0.27322	absolute 0.27107	deflated 0.26853	plane 0.26665	categoric 0.25856	downright 0.25597	level 0.23951	even 0.23825

Test context:
***************
flat.a	1347	8	natural geological processes have often conspired to create __flat__ and fertile land near to the present sea level , to which people are drawn or driven to settle because the living is usually agreeable .
Contexts for target flat are: ['amodI_land', 'cc_and', 'conj_fertile']
Contexts in vocabulary for target flat are: ['amodI_land', 'cc_and', 'conj_fertile']
Top most similar embeddings: flat 0.13225	uncultivated 0.10773	well-watered 0.10650	undulated 0.10617	fertile 0.10552	flattish 0.10370	well-wooded 0.10319	treeless 0.10186	cultivable 0.10128	ungrazed 0.10101

Generated lemmatized results
***************
GENERATED	flat.a 1347 ::: uncultivated;undulated;fertile;flattish;treeless;cultivable;ungrazed;trackless;parched;pathless

Filtered results
***************
RANKED	flat.a 1347	lifeless 0.08325	smooth 0.08249	shallow 0.08023	thin 0.07533	straight 0.07482	gently 0.07469	horizontal 0.07241	plain 0.07050	uniform 0.06993	flush 0.06511	deflated 0.06416	outright 0.06211	fixed 0.05938	absolute 0.05778	categoric 0.05412	total 0.05352	plane 0.05331	level 0.05107	downright 0.04628	even 0.03633

Test context:
***************
flat.a	1348	30	" virtually all defenses of the fairness of a flat tax reduce to this tautology -- which is , in any case , the wrong tautology , since under a __flat__ tax people pay taxes in direct proportion to consumption , not income .
Contexts for target flat are: ['amodI_people']
Contexts in vocabulary for target flat are: ['amodI_people']
Top most similar embeddings: flat 0.45533	middleclass 0.36338	non-english-speaking 0.36320	right-minded 0.36102	average-sized 0.35349	200-plus 0.35327	messed-up 0.35242	likeminded 0.35218	strange-looking 0.35088	freedom-loving 0.34983

Generated lemmatized results
***************
GENERATED	flat.a 1348 ::: middleclass;likeminded;certian;scummy;frail;flattish;peacefull;youngish;unchurched;indiginous

Filtered results
***************
RANKED	flat.a 1348	lifeless 0.31408	straight 0.30714	thin 0.30263	plain 0.29346	smooth 0.29013	shallow 0.28920	uniform 0.28491	horizontal 0.27936	gently 0.27856	total 0.27845	flush 0.27251	outright 0.27058	fixed 0.26287	downright 0.26246	deflated 0.26244	absolute 0.25927	categoric 0.25457	even 0.24992	plane 0.23969	level 0.22096

Test context:
***************
flat.a	1349	5	( 4 ) on a __flat__ slope of 5 % or less to minimize construction problems .
Contexts for target flat are: ['amodI_slope']
Contexts in vocabulary for target flat are: ['amodI_slope']
Top most similar embeddings: flat 0.50050	steepish 0.40424	flattish 0.39791	near-vertical 0.39672	tree-covered 0.38682	hummocky 0.38104	west-facing 0.38022	north-facing 0.37815	east-facing 0.37659	steep 0.37631

Generated lemmatized results
***************
GENERATED	flat.a 1349 ::: steepish;flattish;hummocky;steep;slabby;pebbly;heathery;lowish;pebbled;unshaded

Filtered results
***************
RANKED	flat.a 1349	smooth 0.33791	straight 0.33121	shallow 0.33011	lifeless 0.31720	uniform 0.31540	horizontal 0.31479	gently 0.31228	thin 0.29617	plain 0.28815	flush 0.28393	absolute 0.28011	fixed 0.27860	total 0.27517	deflated 0.27444	categoric 0.27337	outright 0.26743	plane 0.26403	downright 0.24986	level 0.23957	even 0.23922

Test context:
***************
flat.a	1350	3	push all the __flat__ lego pieces together tightly .
Contexts for target flat are: ['amodI_pieces']
Contexts in vocabulary for target flat are: ['amodI_pieces']
Top most similar embeddings: flat 0.50568	flattish 0.38707	straight-sided 0.37586	three-inch 0.37334	nickel-plated 0.37051	half-round 0.36449	hand-cut 0.36442	two-inch 0.36400	fan-shaped 0.36350	extra-long 0.36307

Generated lemmatized results
***************
GENERATED	flat.a 1350 ::: flattish;undecorated;jeweled;kitschy;hemispherical;frameless;scummy;touchable;rectangular;cubical

Filtered results
***************
RANKED	flat.a 1350	lifeless 0.32871	thin 0.32284	smooth 0.32222	straight 0.31424	horizontal 0.31133	plain 0.30487	uniform 0.30203	shallow 0.29908	fixed 0.28628	gently 0.28555	flush 0.28000	categoric 0.27681	outright 0.27381	total 0.27092	deflated 0.26820	absolute 0.26771	downright 0.26204	even 0.25570	plane 0.24940	level 0.23688

Test context:
***************
forward.r	1351	4	i 'm quite looking __forward__ to this !
Contexts for target forward are: ['advmodI_looking']
Contexts in vocabulary for target forward are: ['advmodI_looking']
Top most similar embeddings: forward 0.56691	forwards 0.41498	backward 0.38217	foward 0.38093	worriedly 0.37715	skyward 0.37127	vacantly 0.36820	quizzically 0.36772	longingly 0.36737	outwards 0.36522

Generated lemmatized results
***************
GENERATED	forward.r 1351 ::: forwards;backward;foward;worriedly;skyward;vacantly;quizzically;longingly;outwards;defintely

Filtered results
***************
RANKED	forward.r 1351	ahead 0.35840	onward 0.32798	out 0.30687	forth 0.30501	earlier 0.29668	along 0.29394	over 0.27808	on 0.27127	front 0.26076	advance 0.25184	anticipate 0.22873	expect 0.22477

Test context:
***************
forward.r	1352	6	the cheerful spirit that carried him __forward__ was more than a disposition ; it was the optimism of a faithful soul who trusted in god 's purposes and knew those purposes to be right and true .
Contexts for target forward are: ['advmodI_carried']
Contexts in vocabulary for target forward are: ['advmodI_carried']
Top most similar embeddings: forward 0.54320	forwards 0.40208	sleekly 0.36158	upfield 0.36147	dexterously 0.36069	nimbly 0.35910	backward 0.35622	acrobatically 0.35417	away 0.35335	unconventionally 0.35271

Generated lemmatized results
***************
GENERATED	forward.r 1352 ::: forwards;sleekly;upfield;dexterously;nimbly;backward;acrobatically;away;unconventionally;duely

Filtered results
***************
RANKED	forward.r 1352	onward 0.33715	ahead 0.33150	along 0.31629	earlier 0.31118	forth 0.30903	out 0.30463	over 0.27899	on 0.27679	advance 0.26450	front 0.25137	expect 0.21901	anticipate 0.20652

Test context:
***************
forward.r	1353	24	i could tell why this pedal was called " powershifter " right away as the natural direction of the beater and drive were weighted __forward__ , smooth and in sync with the " power " of my foot .
Contexts for target forward are: ['advmodI_weighted']
Contexts in vocabulary for target forward are: ['advmodI_weighted']
Top most similar embeddings: forward 0.46311	forwards 0.36338	asymmetrically 0.35675	sleekly 0.35371	rotationally 0.35305	oppositely 0.35264	electrostatically 0.35134	elastically 0.34691	unsuitably 0.34643	temptingly 0.34433

Generated lemmatized results
***************
GENERATED	forward.r 1353 ::: forwards;asymmetrically;sleekly;rotationally;oppositely;electrostatically;elastically;unsuitably;temptingly;orthogonally

Filtered results
***************
RANKED	forward.r 1353	ahead 0.31224	onward 0.30144	forth 0.28763	along 0.28453	earlier 0.27613	over 0.27530	out 0.27024	on 0.25199	front 0.23894	advance 0.23687	anticipate 0.21297	expect 0.20639

Test context:
***************
forward.r	1354	3	so keep looking __forward__ to more bomberblitz.com exclusive interviews in the weeks and months to come !
Contexts for target forward are: ['advmodI_looking']
Contexts in vocabulary for target forward are: ['advmodI_looking']
Top most similar embeddings: forward 0.56691	forwards 0.41498	backward 0.38217	foward 0.38093	worriedly 0.37715	skyward 0.37127	vacantly 0.36820	quizzically 0.36772	longingly 0.36737	outwards 0.36522

Generated lemmatized results
***************
GENERATED	forward.r 1354 ::: forwards;backward;foward;worriedly;skyward;vacantly;quizzically;longingly;outwards;defintely

Filtered results
***************
RANKED	forward.r 1354	ahead 0.35840	onward 0.32798	out 0.30687	forth 0.30501	earlier 0.29668	along 0.29394	over 0.27808	on 0.27127	front 0.26076	advance 0.25184	anticipate 0.22873	expect 0.22477

Test context:
***************
forward.r	1355	35	" what calls to the heart -- and the heart has heard , speaks , and the soul has obeyed the word , summons , and all the years advance , and the world goes __forward__ with france -- with france ?
Contexts for target forward are: ['advmodI_goes']
Contexts in vocabulary for target forward are: ['advmodI_goes']
Top most similar embeddings: forward 0.51530	forwards 0.39457	beserk 0.39083	belly-up 0.39040	defintely 0.36131	toe-to-toe 0.36097	sleekly 0.36032	backward 0.36026	nimbly 0.35927	ahead 0.35890

Generated lemmatized results
***************
GENERATED	forward.r 1355 ::: forwards;beserk;defintely;sleekly;backward;nimbly;ahead;proably;sneakily;ponderously

Filtered results
***************
RANKED	forward.r 1355	ahead 0.35890	onward 0.33881	along 0.32300	forth 0.31906	out 0.31864	on 0.31594	earlier 0.29420	over 0.28869	front 0.26639	advance 0.25801	expect 0.23042	anticipate 0.22040

Test context:
***************
forward.r	1356	21	within this context , a first phase of community policy was initiated in 1984 with the aim to move the sector __forward__ to establish common development lines .
Contexts for target forward are: ['advmodI_move']
Contexts in vocabulary for target forward are: ['advmodI_move']
Top most similar embeddings: forward 0.55637	forwards 0.42237	nimbly 0.37712	backward 0.37644	foward 0.37346	sideways 0.37081	shoreward 0.37038	rearward 0.37004	medially 0.36846	skyward 0.36830

Generated lemmatized results
***************
GENERATED	forward.r 1356 ::: forwards;nimbly;backward;foward;sideways;shoreward;rearward;medially;skyward;upward

Filtered results
***************
RANKED	forward.r 1356	ahead 0.35335	onward 0.34791	along 0.32243	out 0.31615	forth 0.31513	earlier 0.30050	on 0.29410	over 0.29149	advance 0.26460	front 0.25846	expect 0.22769	anticipate 0.22642

Test context:
***************
forward.r	1357	3	the only way __forward__ therefore is to accept these differences and go forward on the basis of a fully agreed partnership which accepts the traditions and attitudes of people as they are and without seeking to coerce them .
Contexts for target forward are: ['advmodI_way']
Contexts in vocabulary for target forward are: ['advmodI_way']
Top most similar embeddings: forward 0.55984	forwards 0.41038	defintely 0.36929	backward 0.36799	proably 0.36334	ahead 0.36026	tortuously 0.35939	upfield 0.35574	backwards 0.35375	nimbly 0.35306

Generated lemmatized results
***************
GENERATED	forward.r 1357 ::: forwards;defintely;backward;proably;ahead;tortuously;upfield;backwards;nimbly;westward

Filtered results
***************
RANKED	forward.r 1357	ahead 0.36026	onward 0.33028	out 0.32559	along 0.30538	forth 0.30266	earlier 0.29561	over 0.28070	advance 0.26074	on 0.25898	front 0.25700	expect 0.21861	anticipate 0.21154

Test context:
***************
forward.r	1358	7	when it comes to moving tax cuts __forward__ to 2003 , rather than waiting until 2006 or 2009 , the president 's critics have been saying things that make no sense at all .
Contexts for target forward are: ['advmodI_cuts', 'prep:to_2003']
Contexts in vocabulary for target forward are: ['advmodI_cuts', 'prep:to_2003']
Top most similar embeddings: forward 0.23501	forwards 0.17682	back 0.16362	sideways 0.16146	downward 0.15928	upfield 0.15820	biennially 0.15789	ahead 0.15696	prior 0.15624	ten-fold 0.15565

Generated lemmatized results
***************
GENERATED	forward.r 1358 ::: forwards;back;sideways;downward;upfield;biennially;ahead;prior;medially;rhythmically

Filtered results
***************
RANKED	forward.r 1358	ahead 0.15696	onward 0.15420	forth 0.14574	along 0.14226	earlier 0.13706	over 0.13154	out 0.12150	on 0.11509	advance 0.11403	front 0.11242	expect 0.09232	anticipate 0.08851

Test context:
***************
forward.r	1359	21	a significant part of the recommendations for change and the establishment of new standards either originated from or have been taken __forward__ by the imf , the world bank and the committees of national experts working under the aegis of the g10 and the bis .
Contexts for target forward are: ['advmodI_taken']
Contexts in vocabulary for target forward are: ['advmodI_taken']
Top most similar embeddings: forward 0.54265	forwards 0.39060	imediately 0.36251	duely 0.35922	proably 0.35736	sleekly 0.35686	upfield 0.35630	aback 0.35596	dexterously 0.35559	apprently 0.35430

Generated lemmatized results
***************
GENERATED	forward.r 1359 ::: forwards;imediately;duely;proably;sleekly;upfield;aback;dexterously;apprently;sneakily

Filtered results
***************
RANKED	forward.r 1359	ahead 0.33259	onward 0.32142	earlier 0.31643	out 0.30526	along 0.30309	forth 0.29839	over 0.27953	on 0.25941	advance 0.25303	front 0.25008	expect 0.20782	anticipate 0.20687

Test context:
***************
forward.r	1360	2	investment is __forward__ looking , and the most long-term investment concerns itself with future unborn generations .
Contexts for target forward are: ['advmodI_looking']
Contexts in vocabulary for target forward are: ['advmodI_looking']
Top most similar embeddings: forward 0.56691	forwards 0.41498	backward 0.38217	foward 0.38093	worriedly 0.37715	skyward 0.37127	vacantly 0.36820	quizzically 0.36772	longingly 0.36737	outwards 0.36522

Generated lemmatized results
***************
GENERATED	forward.r 1360 ::: forwards;backward;foward;worriedly;skyward;vacantly;quizzically;longingly;outwards;defintely

Filtered results
***************
RANKED	forward.r 1360	ahead 0.35840	onward 0.32798	out 0.30687	forth 0.30501	earlier 0.29668	along 0.29394	over 0.27808	on 0.27127	front 0.26076	advance 0.25184	anticipate 0.22873	expect 0.22477

Test context:
***************
fundamental.a	1361	24	the emancipation of women can only be completed when a fundamental transformation of living is effected ; and life-styles will change only with the __fundamental__ transformation of all production and the establishment of a communist economy .
Contexts for target fundamental are: ['amodI_transformation']
Contexts in vocabulary for target fundamental are: ['amodI_transformation']
Top most similar embeddings: fundamental 0.52504	fundemental 0.42947	psycho-spiritual 0.41552	psycho-physical 0.40325	life-altering 0.40308	profound 0.40175	foundational 0.39921	mereological 0.39896	long-overdue 0.39848	much-discussed 0.39799

Generated lemmatized results
***************
GENERATED	fundamental.a 1361 ::: fundemental;profound;foundational;mereological;sociopolitical;ineluctable;liberatory;paradigmatic;crucial;configurational

Filtered results
***************
RANKED	fundamental.a 1361	foundational 0.39921	intrinsic 0.37444	radical 0.36601	significant 0.36501	basic 0.36463	vital 0.36258	essential 0.35676	important 0.34853	elementary 0.33597	necessary 0.33012	underlying 0.32911	elemental 0.32831	major 0.32791	central 0.32631	primary 0.31494

Test context:
***************
fundamental.a	1362	18	but as the approach moves into the commercial realm , especially the software business , it 's challenging __fundamental__ notions about who owns ideas and how best to foster innovation .
Contexts for target fundamental are: ['amodI_notions']
Contexts in vocabulary for target fundamental are: ['amodI_notions']
Top most similar embeddings: fundamental 0.52743	fundemental 0.44953	commonly-held 0.43478	universalistic 0.43136	foundational 0.42545	lockean 0.41969	pre-conceived 0.41828	set-theoretic 0.41529	positivistic 0.41277	ecclesiological 0.41235

Generated lemmatized results
***************
GENERATED	fundamental.a 1362 ::: fundemental;universalistic;foundational;lockean;positivistic;ecclesiological;deontological;metaethical;essentialist;eurocentric

Filtered results
***************
RANKED	fundamental.a 1362	foundational 0.42545	basic 0.39909	elementary 0.37254	intrinsic 0.37201	important 0.35781	vital 0.35406	essential 0.35149	central 0.34604	radical 0.34354	elemental 0.34098	underlying 0.33829	significant 0.32907	primary 0.30962	necessary 0.29405	major 0.28911

Test context:
***************
fundamental.a	1363	8	the occasion is often a personal failure of __fundamental__ understanding , where understanding transcends the grammar of associative consciousness .
Contexts for target fundamental are: ['amodI_understanding']
Contexts in vocabulary for target fundamental are: ['amodI_understanding']
Top most similar embeddings: fundamental 0.53050	fundemental 0.42819	foundational 0.41757	universalistic 0.41118	lockean 0.40622	commonly-held 0.40528	metalinguistic 0.40212	cross-discipline 0.39991	basic 0.39872	profound 0.39759

Generated lemmatized results
***************
GENERATED	fundamental.a 1363 ::: fundemental;foundational;universalistic;lockean;metalinguistic;basic;profound;ecclesiological;historiographic;semantical

Filtered results
***************
RANKED	fundamental.a 1363	foundational 0.41757	basic 0.39872	intrinsic 0.37359	elementary 0.36917	vital 0.36053	essential 0.35699	important 0.34159	significant 0.33991	underlying 0.33352	necessary 0.33080	radical 0.32859	central 0.32682	elemental 0.32421	primary 0.30718	major 0.28217

Test context:
***************
fundamental.a	1364	15	first , he clearly distinguishes norms or values within the social network as having a __fundamental__ impact on the development of social capital .
Contexts for target fundamental are: ['amodI_impact']
Contexts in vocabulary for target fundamental are: ['amodI_impact']
Top most similar embeddings: fundamental 0.50836	fundemental 0.42866	profound 0.41274	wide-reaching 0.40994	far-reaching 0.40389	economy-wide 0.39874	signficant 0.39437	crucial 0.39288	significant 0.39230	far-ranging 0.39114

Generated lemmatized results
***************
GENERATED	fundamental.a 1364 ::: fundemental;profound;signficant;crucial;significant;liberatory;ineradicable;historiographic;nonlocal;baneful

Filtered results
***************
RANKED	fundamental.a 1364	significant 0.39230	foundational 0.37109	intrinsic 0.36710	important 0.36468	vital 0.36341	basic 0.34977	radical 0.34244	essential 0.34096	major 0.33718	elemental 0.32895	elementary 0.32268	central 0.32128	underlying 0.32127	primary 0.31719	necessary 0.30888

Test context:
***************
fundamental.a	1365	23	' we 're trying to build things that work and to prove theorems about why they work.we 're trying to articulate the more __fundamental__ concepts of the field. ' koditschek mentions alan turing , who in the early 20th century first envisioned machines capable of methodical , goal-directed computation .
Contexts for target fundamental are: ['advmod_more', 'amodI_concepts']
Contexts in vocabulary for target fundamental are: ['advmod_more', 'amodI_concepts']
Top most similar embeddings: fundamental 0.29210	fundemental 0.24505	universalistic 0.22156	foundational 0.21977	human-centred 0.21172	deontological 0.21153	basic 0.20921	commonsensical 0.20576	profound 0.20553	abstruse 0.20466

Generated lemmatized results
***************
GENERATED	fundamental.a 1365 ::: fundemental;universalistic;foundational;deontological;basic;commonsensical;profound;abstruse;formalistic;recondite

Filtered results
***************
RANKED	fundamental.a 1365	foundational 0.21977	basic 0.20921	important 0.20024	elementary 0.19062	radical 0.18522	intrinsic 0.18519	vital 0.18123	essential 0.18090	significant 0.17888	central 0.17690	elemental 0.17540	underlying 0.16346	necessary 0.15377	major 0.14804	primary 0.14604

Test context:
***************
fundamental.a	1366	3	two of the __fundamental__ limitations of northern eias are the lack of adequate ecological baseline data and the lack of an adequate framework or method to link ecological and social components of the environment .
Contexts for target fundamental are: ['amodI_limitations']
Contexts in vocabulary for target fundamental are: ['amodI_limitations']
Top most similar embeddings: fundamental 0.52783	fundemental 0.44715	inherent 0.40841	interpretational 0.39983	foundational 0.39750	non-economic 0.39646	socio-psychological 0.39494	quantum-mechanical 0.39428	intrinsic 0.39208	set-theoretic 0.39034

Generated lemmatized results
***************
GENERATED	fundamental.a 1366 ::: fundemental;inherent;interpretational;foundational;intrinsic;definitional;researchable;universalistic;crucial;semantical

Filtered results
***************
RANKED	fundamental.a 1366	foundational 0.39750	intrinsic 0.39208	basic 0.37083	significant 0.37076	important 0.36439	central 0.35763	essential 0.35389	elementary 0.34802	vital 0.34756	underlying 0.33165	elemental 0.32848	radical 0.32789	necessary 0.32296	major 0.32033	primary 0.31960

Test context:
***************
fundamental.a	1367	19	we generally do not permit transferral into the second year due to the unique nature of our course and __fundamental__ skills that are learnt in the first year , but you are welcome to discuss your case with the admissions tutor .
Contexts for target fundamental are: ['amodI_skills']
Contexts in vocabulary for target fundamental are: ['amodI_skills']
Top most similar embeddings: fundamental 0.52166	discipline-related 0.44386	fundemental 0.42795	module-specific 0.42768	meta-cognitive 0.42215	career-related 0.41458	foundational 0.41317	interpretational 0.41283	basic 0.41220	job-specific 0.40703

Generated lemmatized results
***************
GENERATED	fundamental.a 1367 ::: fundemental;foundational;interpretational;basic;metalinguistic;communicational;metacognitive;crucial;essential;vital

Filtered results
***************
RANKED	fundamental.a 1367	foundational 0.41317	basic 0.41220	essential 0.39484	vital 0.39389	intrinsic 0.36753	important 0.36617	elementary 0.36418	necessary 0.35642	significant 0.34378	underlying 0.33475	central 0.33306	elemental 0.32354	primary 0.31714	radical 0.30571	major 0.30252

Test context:
***************
fundamental.a	1368	24	would you rather have made the camera that shot citizen kane , or make citizen kane? ' silicon alley is unique , but the __fundamental__ processes that have facilitated its emergence are not .
Contexts for target fundamental are: ['amodI_processes']
Contexts in vocabulary for target fundamental are: ['amodI_processes']
Top most similar embeddings: fundamental 0.53124	fundemental 0.45411	taphonomic 0.42220	interpretational 0.41913	psycho-physical 0.41913	socio-psychological 0.41702	inclusionary 0.41696	homeostatic 0.41648	set-theoretic 0.41393	post-depositional 0.41327

Generated lemmatized results
***************
GENERATED	fundamental.a 1368 ::: fundemental;taphonomic;interpretational;inclusionary;homeostatic;pathophysiological;communicational;neurocognitive;derivational;diagenetic

Filtered results
***************
RANKED	fundamental.a 1368	foundational 0.39560	basic 0.38958	intrinsic 0.38364	vital 0.38020	essential 0.37094	elementary 0.36801	important 0.36380	underlying 0.35607	significant 0.34581	central 0.34257	elemental 0.33708	necessary 0.33185	primary 0.32699	radical 0.32459	major 0.31689

Test context:
***************
fundamental.a	1369	5	they will also support two __fundamental__ instructional objectives .
Contexts for target fundamental are: ['amodI_objectives']
Contexts in vocabulary for target fundamental are: ['amodI_objectives']
Top most similar embeddings: fundamental 0.52090	fundemental 0.42776	clearly-defined 0.41237	health-based 0.40548	micro-economic 0.40349	non-economic 0.39900	overarching 0.39757	over-arching 0.39743	socio-psychological 0.39420	superordinate 0.39402

Generated lemmatized results
***************
GENERATED	fundamental.a 1369 ::: fundemental;overarching;superordinate;soteriological;foundational;ecclesiological;communicational;universalistic;deontological;crucial

Filtered results
***************
RANKED	fundamental.a 1369	foundational 0.39022	basic 0.37904	vital 0.36409	important 0.36344	essential 0.36232	intrinsic 0.35613	central 0.34929	underlying 0.34365	elementary 0.33990	primary 0.33985	significant 0.33474	radical 0.33153	elemental 0.32396	major 0.32231	necessary 0.31931

Test context:
***************
fundamental.a	1370	44	the training demands outlined above ; the needs of governors for trained , well-led , and appropriately organized forces to defend against terrorist threats ; and possible political pressures not to deploy some arng units during times of heightened terrorist threats will demand a __fundamental__ reexamination of army organization .
Contexts for target fundamental are: ['amodI_reexamination']
Contexts in vocabulary for target fundamental are: []
Top most similar embeddings: fundamental 1.00000	fundemental 0.85622	crucial 0.78876	foundational 0.78332	commonly-held 0.76106	vital 0.75790	universalistic 0.75529	near-market 0.75491	non-moral 0.74979	ineradicable 0.74776

Generated lemmatized results
***************
GENERATED	fundamental.a 1370 ::: fundemental;crucial;foundational;vital;universalistic;ineradicable;basic;profound;intrinsic;irresolvable

Filtered results
***************
RANKED	fundamental.a 1370	foundational 0.78332	vital 0.75790	basic 0.74758	intrinsic 0.74342	essential 0.74138	important 0.74119	significant 0.70875	elementary 0.70593	central 0.69623	radical 0.67181	necessary 0.66828	underlying 0.66747	elemental 0.66298	primary 0.65016	major 0.62796

Test context:
***************
get.v	1371	9	half-naked women and muscular barbarians are very good for __getting__ teenaged readers to at least take a look .
Contexts for target getting are: ['pcompI_for', 'dobj_readers', 'xcomp_take']
Contexts in vocabulary for target getting are: ['pcompI_for', 'dobj_readers', 'xcomp_take']
Top most similar embeddings: getting 0.12180	pressuring 0.10096	coercing 0.09848	re-educating 0.09823	persuading 0.09805	pressurising 0.09707	geting 0.09650	tricking 0.09594	hypnotising 0.09589	dissuading 0.09575

Generated lemmatized results
***************
GENERATED	get.v 1371 ::: pressure;coerce;persuade;pressurise;trick;hypnotise;dissuade;orientate;attract;gettting

Filtered results
***************
RANKED	get.v 1371	persuade 0.09805	have 0.09010	reach 0.08792	gain 0.08675	bring 0.08647	obtain 0.08607	give 0.08469	acquire 0.08056	procure 0.07868	achieve 0.07757	receive 0.07725	go 0.07722	become 0.07631	travel 0.07463	convince 0.07433	buy 0.07417	fetch 0.07112	be 0.06369

Test context:
***************
get.v	1372	25	by the time my family was settled in the new place , it was too late for me , almost six years old , to __get__ admitted to a kindergarten class at dong khanh .
Contexts for target get are: ['auxpassI_admitted']
Contexts in vocabulary for target get are: ['auxpassI_admitted']
Top most similar embeddings: get 0.43432	be 0.37878	getting 0.37548	gets 0.36763	was 0.36032	were 0.35383	been 0.35236	gotten 0.34923	are 0.34698	got 0.34256

Generated lemmatized results
***************
GENERATED	get.v 1372 ::: be;beeen;wre;gettting;hve;beeing;willbe;werent;ahve;wasnt

Filtered results
***************
RANKED	get.v 1372	be 0.37878	obtain 0.28912	become 0.28851	persuade 0.28551	convince 0.28175	procure 0.27558	receive 0.27154	achieve 0.26474	give 0.26412	bring 0.26154	fetch 0.26023	acquire 0.25973	have 0.25902	reach 0.25897	go 0.25881	buy 0.25679	gain 0.25325	travel 0.24763

Test context:
***************
get.v	1373	1	manatees __get__ safer waterways federal and state water managers have worked for more than a decade to make water gates and navigation locks safer for manatees , and signed an agreement last week for the final round of their $ 13.8 million manatee protection effort .
Contexts for target get are: ['nsubj_manatees', 'rootI_*root*', 'ccomp_worked', 'punct_,', 'cc_and', 'conj_signed', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target get are: ['rootI_*root*', 'ccomp_worked', 'punct_,', 'cc_and', 'conj_signed', 'punct_.']
Top most similar embeddings: tutted 0.01255	sigill 0.01155	sighed 0.01104	rallied 0.01101	grunted 0.01094	co-founded 0.01089	came 0.01087	double-checked 0.01081	went 0.01078	recalled 0.01076

Generated lemmatized results
***************
GENERATED	get.v 1373 ::: tutted;sigill;sigh;rally;grunt;come;go;recall;demur;show

Filtered results
***************
RANKED	get.v 1373	go 0.01078	travel 0.00980	give 0.00941	buy 0.00913	receive 0.00895	persuade 0.00893	fetch 0.00886	have 0.00871	reach 0.00866	convince 0.00860	gain 0.00840	bring 0.00837	obtain 0.00834	achieve 0.00824	procure 0.00822	acquire 0.00790	become 0.00788	be 0.00666

Test context:
***************
get.v	1374	8	from here , there are two options for __getting__ to champery .
Contexts for target getting are: ['pcompI_for', 'prep:to_champery']
Contexts in vocabulary for target getting are: ['pcompI_for']
Top most similar embeddings: getting 0.53007	gettting 0.43195	geting 0.43102	aquiring 0.40831	carring 0.40304	spooking 0.39709	obtaining 0.39042	recieving 0.39040	makeing 0.38889	putting 0.38781

Generated lemmatized results
***************
GENERATED	get.v 1374 ::: gettting;aquiring;carring;spook;obtain;recieving;make;put;acheiving;decrypt

Filtered results
***************
RANKED	get.v 1374	obtain 0.39042	have 0.38030	achieve 0.37482	bring 0.37308	gain 0.36880	receive 0.36471	give 0.36360	acquire 0.36339	reach 0.36009	procure 0.35305	go 0.34635	buy 0.34446	become 0.34202	persuade 0.34187	fetch 0.33303	travel 0.33143	be 0.32635	convince 0.28904

Test context:
***************
get.v	1375	15	posted by : david 's thong at january 23 , 2005 11:56 am can i __get__ them in a medium ?
Contexts for target get are: ['nsubj_11:56', 'aux_am', 'aux_can', 'nsubj_i', 'rcmodI_january', 'dobj_them', 'prep:in_medium']
Contexts in vocabulary for target get are: ['nsubj_11:56', 'aux_am', 'aux_can', 'nsubj_i', 'rcmodI_january', 'dobj_them', 'prep:in_medium']
Top most similar embeddings: recive 0.00556	get 0.00554	add 0.00533	reproduce 0.00526	entrapped 0.00519	recieve 0.00519	upload 0.00499	join 0.00498	geting 0.00496	engross 0.00494

Generated lemmatized results
***************
GENERATED	get.v 1375 ::: recive;add;reproduce;entrap;recieve;upload;join;engross;outbid;publish

Filtered results
***************
RANKED	get.v 1375	receive 0.00491	buy 0.00460	convince 0.00445	persuade 0.00444	bring 0.00443	obtain 0.00441	procure 0.00418	fetch 0.00413	give 0.00407	acquire 0.00401	achieve 0.00392	travel 0.00381	gain 0.00375	reach 0.00359	go 0.00349	have 0.00329	become 0.00328	be 0.00256

Test context:
***************
get.v	1376	30	coyw [ post a reply to this message ][ edit ] new coffee shop -- hbb , tuesday , march 21 , 11:42:46am just been up to the ground to __get__ tickets for villa ( loads left - was n't anymore specific than that btw !
Contexts for target get are: ['aux_to', 'xcompI_been', 'dobj_tickets']
Contexts in vocabulary for target get are: ['aux_to', 'xcompI_been', 'dobj_tickets']
Top most similar embeddings: get 0.13318	rebook 0.10634	wheedle 0.10560	obtain 0.10176	aquire 0.10081	mass-produce 0.09974	re-book 0.09971	wangle 0.09908	manhandle 0.09704	collect 0.09646

Generated lemmatized results
***************
GENERATED	get.v 1376 ::: rebook;wheedle;obtain;aquire;wangle;manhandle;collect;buy;scrounge;revalue

Filtered results
***************
RANKED	get.v 1376	obtain 0.10176	buy 0.09603	procure 0.09378	acquire 0.09328	give 0.09258	receive 0.09080	bring 0.09049	achieve 0.08426	convince 0.08231	fetch 0.08168	persuade 0.08075	gain 0.08070	go 0.07860	have 0.07751	reach 0.07693	travel 0.07344	become 0.05868	be 0.05352

Test context:
***************
get.v	1377	24	we could not investigate jenin and now the fox media wants to tell this country with the israeli spokesclown representing israel that they either __get__ tried in israel or face exile ?
Contexts for target get are: ['auxpassI_tried']
Contexts in vocabulary for target get are: ['auxpassI_tried']
Top most similar embeddings: get 0.40116	be 0.37429	been 0.36421	gets 0.35433	were 0.35189	was 0.34918	getting 0.34597	gotten 0.32900	are 0.32866	being 0.32334

Generated lemmatized results
***************
GENERATED	get.v 1377 ::: be;beeen;gettting;wre;hve;beeing;ahve;willbe;shoulda;gatecrash

Filtered results
***************
RANKED	get.v 1377	be 0.37429	obtain 0.28478	become 0.28152	persuade 0.27042	bring 0.26903	convince 0.26774	receive 0.26739	go 0.26460	give 0.26369	procure 0.26266	achieve 0.26204	fetch 0.26193	have 0.26124	acquire 0.25590	buy 0.25409	travel 0.25306	gain 0.25274	reach 0.25092

Test context:
***************
get.v	1378	7	in these examples , some hints for __getting__ better simulation results are given .
Contexts for target getting are: ['pcompI_for', 'ccomp_given']
Contexts in vocabulary for target getting are: ['pcompI_for', 'ccomp_given']
Top most similar embeddings: getting 0.24054	ensuring 0.19094	geting 0.18401	intimating 0.18082	insisting 0.18012	suspecting 0.17881	recieving 0.17873	decreeing 0.17839	gettting 0.17827	presupposing 0.17783

Generated lemmatized results
***************
GENERATED	get.v 1378 ::: ensure;intimate;insist;suspect;recieving;decree;gettting;presuppose;discover;realise

Filtered results
***************
RANKED	get.v 1378	have 0.17587	obtain 0.17105	achieve 0.16945	gain 0.16551	procure 0.16425	receive 0.16349	acquire 0.16017	give 0.15963	become 0.15882	bring 0.15852	reach 0.15782	persuade 0.15731	fetch 0.15042	travel 0.14950	buy 0.14821	go 0.14661	be 0.14644	convince 0.13689

Test context:
***************
get.v	1379	2	let me __get__ it for you .
Contexts for target get are: ['nsubj_me', 'ccompI_let', 'dobj_it', 'prep:for_you']
Contexts in vocabulary for target get are: ['nsubj_me', 'ccompI_let', 'dobj_it', 'prep:for_you']
Top most similar embeddings: get 0.06129	rephrase 0.05399	manhandle 0.05226	unfreeze 0.04979	re-do 0.04978	do 0.04904	slosh 0.04867	baby-sit 0.04862	wheedle 0.04804	knw 0.04779

Generated lemmatized results
***************
GENERATED	get.v 1379 ::: rephrase;manhandle;unfreeze;do;slosh;wheedle;knw;unpack;weepe;drinke

Filtered results
***************
RANKED	get.v 1379	fetch 0.04281	go 0.04129	bring 0.04077	buy 0.04047	give 0.04042	obtain 0.04014	procure 0.03879	achieve 0.03609	convince 0.03521	acquire 0.03500	have 0.03495	reach 0.03485	persuade 0.03413	receive 0.03397	gain 0.03277	travel 0.02958	be 0.02768	become 0.02636

Test context:
***************
get.v	1380	2	the couple __got__ engage in 1988 , but prison regulations delayed the wedding until 1996 .
Contexts for target got are: ['auxI_engage']
Contexts in vocabulary for target got are: ['auxI_engage']
Top most similar embeddings: got 0.35363	did 0.34348	to 0.33775	can 0.32763	does 0.32728	could 0.32663	should 0.32236	'll 0.31723	would 0.31617	couldnae 0.31613

Generated lemmatized results
***************
GENERATED	get.v 1380 ::: do;to;can;could;should;would;couldnae;must;oughta;coud

Filtered results
***************
RANKED	get.v 1380	have 0.27581	be 0.25891	become 0.25671	buy 0.25441	fetch 0.24703	go 0.24694	travel 0.24684	reach 0.24547	give 0.24445	receive 0.24254	procure 0.24232	gain 0.24229	persuade 0.24183	convince 0.24111	bring 0.24026	achieve 0.23946	acquire 0.23226	obtain 0.23122

Test context:
***************
hold.v	1381	20	the most famous case of this sort occurred with galileo , who was attacked and prosecuted by the academy for __holding__ ideas that conflicted with aristotle 's explanations of the world .
Contexts for target holding are: ['amodI_ideas']
Contexts in vocabulary for target holding are: ['amodI_ideas']
Top most similar embeddings: holding 0.46466	pre-conceived 0.36854	apache-plusplus 0.36444	commonly-held 0.35454	long-cherished 0.34382	half-formed 0.34227	preconceived 0.33716	newfangled 0.33591	long-held 0.33443	anti-god 0.33429

Generated lemmatized results
***************
GENERATED	hold.v 1381 ::: preconceive;newfangled;serveral;crystallise;outwear;propound;implant;purvey;proffer;indeterminist

Filtered results
***************
RANKED	hold.v 1381	host 0.31867	grasp 0.31781	clutch 0.31691	organise 0.31550	possess 0.31413	clasp 0.30543	grip 0.30449	own 0.30062	carry 0.29780	convene 0.29658	occupy 0.29452	adhere 0.29167	support 0.29047	retain 0.28971	put 0.28875	stand 0.28660	store 0.28657	lift 0.28228	position 0.27755	place 0.27412	contain 0.27310	believe 0.27191	call 0.26743	have 0.26625	handle 0.26564	conduct 0.26444	cache 0.26407	maintain 0.26248	keep 0.25958	take 0.25604

Test context:
***************
hold.v	1382	12	there are no images of starving adults or of toddlers unable to __hold__ themselves up , like those from ethiopia in 1984 or sudan in 1998 .
Contexts for target hold are: ['aux_to', 'xcompI_unable', 'dobj_themselves', 'prt_up']
Contexts in vocabulary for target hold are: ['aux_to', 'xcompI_unable', 'dobj_themselves', 'prt_up']
Top most similar embeddings: hold 0.06732	rearm 0.04986	wheedle 0.04967	baby-sit 0.04883	acclimatize 0.04881	re-attach 0.04870	fatten 0.04854	sieze 0.04768	immunise 0.04705	accommodate 0.04705

Generated lemmatized results
***************
GENERATED	hold.v 1382 ::: rearm;wheedle;acclimatize;fatten;sieze;immunise;accommodate;reprogramme;rehouse;manhandle

Filtered results
***************
RANKED	hold.v 1382	keep 0.04626	take 0.04320	handle 0.04275	put 0.04255	lift 0.04248	organise 0.04202	carry 0.04171	occupy 0.04089	maintain 0.04046	stand 0.03937	grasp 0.03782	conduct 0.03747	retain 0.03691	convene 0.03681	possess 0.03612	contain 0.03589	call 0.03507	support 0.03496	store 0.03399	grip 0.03372	adhere 0.03325	clasp 0.03264	host 0.03096	place 0.02989	believe 0.02932	position 0.02855	clutch 0.02828	own 0.02800	have 0.02668	cache 0.02658

Test context:
***************
hold.v	1383	18	air conduction fans , often made of thin metal and shaped like a partially open fan , were __held__ behind the ear to direct sound into the ear .
Contexts for target held are: ['nsubjpass_fans', 'auxpass_were', 'rootI_*root*', 'prep:behind_ear', 'xcomp_direct', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target held are: ['nsubjpass_fans', 'auxpass_were', 'rootI_*root*', 'prep:behind_ear', 'xcomp_direct', 'punct_.']
Top most similar embeddings: held 0.01360	placed 0.01103	positioned 0.01103	glued 0.01061	stuck 0.01054	housed 0.01054	rivetted 0.01039	cupped 0.01037	craned 0.01035	located 0.01032

Generated lemmatized results
***************
GENERATED	hold.v 1383 ::: place;position;glue;stick;house;rivetted;cup;crane;locate;invite

Filtered results
***************
RANKED	hold.v 1383	place 0.01103	position 0.01103	grip 0.00967	clutch 0.00948	retain 0.00940	keep 0.00929	clasp 0.00883	convene 0.00882	put 0.00881	carry 0.00881	lift 0.00879	conduct 0.00874	stand 0.00853	call 0.00840	take 0.00831	occupy 0.00818	support 0.00815	contain 0.00814	maintain 0.00810	host 0.00808	believe 0.00801	organise 0.00798	store 0.00787	own 0.00776	handle 0.00766	possess 0.00764	grasp 0.00702	adhere 0.00701	cache 0.00641	have 0.00599

Test context:
***************
hold.v	1384	8	a doctor sat in front of me and __held__ my hands .
Contexts for target held are: ['conjI_sat', 'dobj_hands']
Contexts in vocabulary for target held are: ['conjI_sat', 'dobj_hands']
Top most similar embeddings: held 0.23866	cupped 0.21343	clasped 0.20218	wrung 0.19490	clutched 0.19413	shook 0.19250	clenched 0.18987	kissed 0.18968	manacled 0.18895	wagged 0.18504

Generated lemmatized results
***************
GENERATED	hold.v 1384 ::: cup;clasp;wring;clutch;shake;clench;kiss;manacle;wag;twitch

Filtered results
***************
RANKED	hold.v 1384	clasp 0.20218	clutch 0.19413	grip 0.17382	put 0.16702	lift 0.16668	grasp 0.16646	keep 0.16641	stand 0.16383	take 0.16138	place 0.15965	have 0.15483	retain 0.14885	carry 0.14719	conduct 0.14568	host 0.14555	convene 0.14530	occupy 0.14415	position 0.14138	call 0.14046	handle 0.13849	believe 0.13620	possess 0.13491	maintain 0.13488	support 0.13268	contain 0.13267	organise 0.13253	adhere 0.13187	own 0.12809	store 0.12705	cache 0.11382

Test context:
***************
hold.v	1385	8	the first president , miles merwin jr. , __held__ that position till shortly before his death .
Contexts for target held are: ['nsubj_president', 'rootI_*root*', 'ccomp_<eol>']
Contexts in vocabulary for target held are: ['nsubj_president', 'rootI_*root*']
Top most similar embeddings: held 0.24304	co-chaired 0.19889	convened 0.19833	co-organized 0.19447	co-signed 0.19418	said 0.19364	convenes 0.19294	holds 0.18836	affirmed 0.18785	reaffirmed 0.18662

Generated lemmatized results
***************
GENERATED	hold.v 1385 ::: convene;say;affirm;reaffirm;attend;reconvene;denounce;reiterate;emphasize;officiate

Filtered results
***************
RANKED	hold.v 1385	convene 0.19833	host 0.17571	believe 0.17348	take 0.17253	conduct 0.17061	organise 0.16881	retain 0.16876	call 0.16568	maintain 0.16539	stand 0.16391	clutch 0.16330	keep 0.16247	support 0.16080	have 0.15907	grip 0.15787	carry 0.15784	occupy 0.15627	lift 0.15524	possess 0.15506	put 0.15482	clasp 0.15411	handle 0.15403	place 0.15145	own 0.15140	position 0.14891	adhere 0.14772	grasp 0.14736	contain 0.14293	cache 0.13597	store 0.13268

Test context:
***************
hold.v	1386	9	you wo n't think of those applications as just __holding__ their data , and that you have to learn some special method to navigate that data .
Contexts for target holding are: ['advmod_just', 'pcompI_as', 'dobj_data']
Contexts in vocabulary for target holding are: ['advmod_just', 'pcompI_as', 'dobj_data']
Top most similar embeddings: holding 0.12174	plonking 0.08895	concatenating 0.08871	divulging 0.08763	regurgitating 0.08593	stashing 0.08548	restating 0.08538	rehashing 0.08513	aquiring 0.08512	decrypting 0.08496

Generated lemmatized results
***************
GENERATED	hold.v 1386 ::: plonk;concatenate;divulge;regurgitate;stash;restate;rehash;aquiring;decrypt;output

Filtered results
***************
RANKED	hold.v 1386	put 0.08480	store 0.08293	clutch 0.08254	have 0.08096	carry 0.08038	keep 0.08014	possess 0.08010	own 0.07861	grasp 0.07586	lift 0.07506	contain 0.07478	take 0.07404	retain 0.07384	place 0.07319	support 0.07255	maintain 0.07220	host 0.07197	organise 0.07191	clasp 0.07157	stand 0.07090	handle 0.07021	grip 0.06941	conduct 0.06940	call 0.06925	occupy 0.06865	believe 0.06861	convene 0.06560	position 0.06453	cache 0.06296	adhere 0.06054

Test context:
***************
hold.v	1387	4	during 1830 the bpu __held__ a series of meetings in the george street sandpit , which helped bring reform up the political agenda .
Contexts for target held are: ['prep:during_1830', 'nsubj_bpu', 'rootI_*root*', 'dobj_series', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target held are: ['rootI_*root*', 'dobj_series', 'punct_.']
Top most similar embeddings: held 0.13390	co-organized 0.11553	co-presented 0.10954	co-organised 0.10739	2885557 0.10590	co-hosted 0.10544	co-chaired 0.10502	www.hotproperty.co.uk 0.10434	holds 0.10373	co-organising 0.10253

Generated lemmatized results
***************
GENERATED	hold.v 1387 ::: laur;syph;conduct;convene;organise;stag;initiate;produce;cyos;undertake

Filtered results
***************
RANKED	hold.v 1387	conduct 0.09958	convene 0.09937	organise 0.09902	host 0.09731	contain 0.09345	carry 0.09173	take 0.08889	retain 0.08879	maintain 0.08868	occupy 0.08589	support 0.08581	keep 0.08407	have 0.08293	clutch 0.08273	possess 0.08260	place 0.08108	grip 0.08044	put 0.08025	own 0.08023	believe 0.08001	stand 0.07934	call 0.07843	handle 0.07759	lift 0.07665	position 0.07619	clasp 0.07564	store 0.07557	grasp 0.07285	adhere 0.06854	cache 0.06609

Test context:
***************
hold.v	1388	14	( ii ) eligible employees not described in subparagraph ( i ) above , __holding__ the position of vice president may select the moody 's rate as the investment option for up to 15 % of their base salary and bonus for a plan year .
Contexts for target holding are: ['partmodI_employees', 'dobj_position']
Contexts in vocabulary for target holding are: ['partmodI_employees', 'dobj_position']
Top most similar embeddings: holding 0.26038	occupying 0.18796	surrendering 0.17999	held 0.17792	relinquishing 0.17534	regularising 0.17525	taking 0.17494	resigning 0.17268	adopting 0.17218	vacating 0.17149

Generated lemmatized results
***************
GENERATED	hold.v 1388 ::: occupy;surrender;relinquish;regularise;take;resign;adopt;vacate;jeopardize;abuse

Filtered results
***************
RANKED	hold.v 1388	occupy 0.18796	take 0.17494	carry 0.17037	retain 0.16046	maintain 0.15959	possess 0.15955	own 0.15812	grasp 0.15525	put 0.15328	support 0.15322	have 0.15109	clutch 0.15057	place 0.14959	conduct 0.14834	keep 0.14826	organise 0.14772	clasp 0.14763	lift 0.14693	stand 0.14631	host 0.14386	store 0.14309	handle 0.14170	call 0.14138	believe 0.14010	convene 0.13570	contain 0.13411	position 0.13316	grip 0.13197	adhere 0.12892	cache 0.12074

Test context:
***************
hold.v	1389	25	taxable personal property includes ( but is not limited to ) : office machinery and equipment as well as supplies and materials which are not __held__ for sale or do not become an ingredient or component of an article being produced for sale .
Contexts for target held are: ['nsubjpass_which', 'auxpass_are', 'neg_not', 'rcmodI_supplies', 'prep:for_sale', 'cc_or', 'conj_ingredient']
Contexts in vocabulary for target held are: ['nsubjpass_which', 'auxpass_are', 'neg_not', 'rcmodI_supplies', 'prep:for_sale', 'cc_or', 'conj_ingredient']
Top most similar embeddings: prepacked 0.00647	resold 0.00548	re-exported 0.00542	counterfeited 0.00538	misdescribed 0.00524	warehoused 0.00514	bartered 0.00508	re-sold 0.00506	pasteurised 0.00504	held 0.00501

Generated lemmatized results
***************
GENERATED	hold.v 1389 ::: prepacked;resold;counterfeit;misdescribed;warehouse;barter;pasteurise;autoclave;mislabelled;ration

Filtered results
***************
RANKED	hold.v 1389	store 0.00461	own 0.00452	retain 0.00405	maintain 0.00405	keep 0.00400	contain 0.00372	place 0.00368	cache 0.00365	carry 0.00365	occupy 0.00360	handle 0.00354	take 0.00354	convene 0.00348	adhere 0.00346	host 0.00342	call 0.00337	possess 0.00337	position 0.00335	lift 0.00331	put 0.00329	support 0.00320	grasp 0.00320	organise 0.00320	conduct 0.00304	believe 0.00297	clasp 0.00262	grip 0.00261	clutch 0.00258	stand 0.00228	have 0.00204

Test context:
***************
hold.v	1390	10	his present to her will be the book he is __holding__ - a sad story about a young hedonistic woman who suffered a tragic ending : armand : a beautiful girl who lived for love and pleasure .
Contexts for target holding are: ['nsubj_he', 'aux_is', 'rcmodI_book', 'punct_-', 'dobj_story']
Contexts in vocabulary for target holding are: ['nsubj_he', 'aux_is', 'rcmodI_book', 'punct_-', 'dobj_story']
Top most similar embeddings: holding 0.02519	narrating 0.02006	co-authoring 0.01947	co-editing 0.01905	romancing 0.01862	peddling 0.01862	clutching 0.01855	retells 0.01853	recounting 0.01841	co-producing 0.01839

Generated lemmatized results
***************
GENERATED	hold.v 1390 ::: narrate;romance;peddle;clutch;retell;recount;writting;concoct;base;tell

Filtered results
***************
RANKED	hold.v 1390	clutch 0.01855	grip 0.01791	carry 0.01709	host 0.01672	put 0.01659	keep 0.01627	grasp 0.01594	take 0.01551	own 0.01527	stand 0.01521	call 0.01487	organise 0.01487	occupy 0.01477	believe 0.01467	support 0.01461	clasp 0.01442	conduct 0.01440	possess 0.01437	lift 0.01417	have 0.01404	place 0.01380	store 0.01331	handle 0.01329	maintain 0.01328	retain 0.01328	convene 0.01294	cache 0.01283	contain 0.01221	adhere 0.01170	position 0.01153

Test context:
***************
informal.a	1391	21	to facilitate that involvement , the university will maintain appropriate processes within which students can communicate their views by formal and __informal__ means , and can , directly or through their representatives , actively contribute to decisions affecting the university community .
Contexts for target informal are: ['conjI_formal']
Contexts in vocabulary for target informal are: ['conjI_formal']
Top most similar embeddings: informal 0.57839	formal 0.47560	semi-formal 0.46607	non-formal 0.43984	non-adversarial 0.40536	casual 0.40524	unstructured 0.40275	collegial 0.40090	non-institutional 0.39384	non-hierarchical 0.38998

Generated lemmatized results
***************
GENERATED	informal.a 1391 ::: formal;casual;unstructured;collegial;intimate;unstuffy;participative;relaxed;unsystematic;inquisitorial

Filtered results
***************
RANKED	informal.a 1391	casual 0.40524	relaxed 0.37933	unofficial 0.36804	spontaneous 0.36239	imprecise 0.34713	easygoing 0.34189	friendly 0.33304	untrained 0.30987	ordinary 0.28749	everyday 0.28219	approximate 0.27915

Test context:
***************
informal.a	1392	9	this is one of the most important areas of __informal__ employment and can take place in home-based , micro-enterprise-based or in factory-based locations .
Contexts for target informal are: ['amodI_employment']
Contexts in vocabulary for target informal are: ['amodI_employment']
Top most similar embeddings: informal 0.51751	formal 0.43024	casual 0.39727	semi-formal 0.39485	non-formal 0.39144	non-farm 0.38848	gainful 0.38652	non-institutional 0.38333	family-based 0.38232	low-status 0.38229

Generated lemmatized results
***************
GENERATED	informal.a 1392 ::: formal;casual;gainful;unsubsidised;consortial;casualised;remunerative;timeous;collegial;unadvertised

Filtered results
***************
RANKED	informal.a 1392	casual 0.39727	unofficial 0.35796	spontaneous 0.33721	friendly 0.32712	relaxed 0.32692	easygoing 0.31035	imprecise 0.30904	ordinary 0.30569	untrained 0.29912	approximate 0.29295	everyday 0.27834

Test context:
***************
informal.a	1393	7	there are also quite a number of __informal__ barriers .
Contexts for target informal are: ['amodI_barriers']
Contexts in vocabulary for target informal are: ['amodI_barriers']
Top most similar embeddings: informal 0.49353	formal 0.41734	non-tariff 0.39107	semi-formal 0.38910	school-related 0.38346	age-based 0.38220	non-formal 0.38183	nonfinancial 0.38171	clearly-defined 0.37623	agro-ecological 0.37531

Generated lemmatized results
***************
GENERATED	informal.a 1393 ::: formal;nonfinancial;interpretational;associational;attitudinal;taphonomic;collegial;steric;intimidatory;traditional

Filtered results
***************
RANKED	informal.a 1393	unofficial 0.34833	casual 0.34453	spontaneous 0.31904	relaxed 0.31786	imprecise 0.31235	friendly 0.30736	easygoing 0.30277	ordinary 0.29831	untrained 0.28831	everyday 0.28605	approximate 0.27981

Test context:
***************
informal.a	1394	11	for instance , copls generally provide interface specifications ( formal or __informal__ ) for classes by running a tool such as javadoc or eiffel 's ' short ' over the class definition , meaning that the poor person writing a class has to write to 4 different ' audiences ' at once : the compiler , people writing code that uses the class , people writing derived classes and people maintaining the class itself .
Contexts for target informal are: ['conjI_formal']
Contexts in vocabulary for target informal are: ['conjI_formal']
Top most similar embeddings: informal 0.57839	formal 0.47560	semi-formal 0.46607	non-formal 0.43984	non-adversarial 0.40536	casual 0.40524	unstructured 0.40275	collegial 0.40090	non-institutional 0.39384	non-hierarchical 0.38998

Generated lemmatized results
***************
GENERATED	informal.a 1394 ::: formal;casual;unstructured;collegial;intimate;unstuffy;participative;relaxed;unsystematic;inquisitorial

Filtered results
***************
RANKED	informal.a 1394	casual 0.40524	relaxed 0.37933	unofficial 0.36804	spontaneous 0.36239	imprecise 0.34713	easygoing 0.34189	friendly 0.33304	untrained 0.30987	ordinary 0.28749	everyday 0.28219	approximate 0.27915

Test context:
***************
informal.a	1395	3	institutions can be __informal__ or formal .
Contexts for target informal are: ['nsubj_institutions', 'aux_can', 'cop_be', 'rootI_*root*', 'cc_or', 'conj_formal', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target informal are: ['nsubj_institutions', 'aux_can', 'cop_be', 'rootI_*root*', 'cc_or', 'conj_formal', 'punct_.']
Top most similar embeddings: informal 0.00619	formalised 0.00542	unstructured 0.00534	inquisitorial 0.00513	self-selected 0.00510	formalized 0.00509	proscriptive 0.00507	decentralized 0.00496	haphazard 0.00492	regimented 0.00483

Generated lemmatized results
***************
GENERATED	informal.a 1395 ::: formalised;unstructured;inquisitorial;formalized;proscriptive;decentralized;haphazard;regimented;modularised;infrequent

Filtered results
***************
RANKED	informal.a 1395	imprecise 0.00464	casual 0.00445	spontaneous 0.00414	relaxed 0.00412	friendly 0.00369	approximate 0.00354	untrained 0.00318	easygoing 0.00298	unofficial 0.00289	ordinary 0.00235	everyday 0.00195

Test context:
***************
informal.a	1396	4	things continued on an __informal__ , personal basis , by phone , i [ remained ] close friends with two of them , but izzat al gazawi died last year .
Contexts for target informal are: ['amodI_basis']
Contexts in vocabulary for target informal are: ['amodI_basis']
Top most similar embeddings: informal 0.52996	project-by-project 0.44252	as-needed 0.43164	formal 0.42801	off-the-record 0.42075	non-adversarial 0.40888	first-come-first-served 0.40821	semi-formal 0.40626	site-by-site 0.40390	1-to-1 0.40384

Generated lemmatized results
***************
GENERATED	informal.a 1396 ::: formal;consortial;casual;phatic;concessional;plurilateral;intersectoral;trilateral;semiannual;collegial

Filtered results
***************
RANKED	informal.a 1396	casual 0.38369	unofficial 0.36341	spontaneous 0.34984	relaxed 0.33439	easygoing 0.32713	friendly 0.32404	imprecise 0.32135	approximate 0.30688	everyday 0.29979	untrained 0.29567	ordinary 0.29563

Test context:
***************
informal.a	1397	17	schoolyard habitats - national wildlife federation - offers an array of resources and programs for formal and __informal__ k-12 educators in a traditional classroom situation , nature center or other youth service facility .
Contexts for target informal are: ['conjI_formal']
Contexts in vocabulary for target informal are: ['conjI_formal']
Top most similar embeddings: informal 0.57839	formal 0.47560	semi-formal 0.46607	non-formal 0.43984	non-adversarial 0.40536	casual 0.40524	unstructured 0.40275	collegial 0.40090	non-institutional 0.39384	non-hierarchical 0.38998

Generated lemmatized results
***************
GENERATED	informal.a 1397 ::: formal;casual;unstructured;collegial;intimate;unstuffy;participative;relaxed;unsystematic;inquisitorial

Filtered results
***************
RANKED	informal.a 1397	casual 0.40524	relaxed 0.37933	unofficial 0.36804	spontaneous 0.36239	imprecise 0.34713	easygoing 0.34189	friendly 0.33304	untrained 0.30987	ordinary 0.28749	everyday 0.28219	approximate 0.27915

Test context:
***************
informal.a	1398	26	since kt is the established symbol for the kilotonne , kn is the best choice as a symbol for the knot. knot [ 2 ] an __informal__ unit of distance equal to the nautical mile .
Contexts for target informal are: ['amodI_unit']
Contexts in vocabulary for target informal are: ['amodI_unit']
Top most similar embeddings: informal 0.48301	consultant-led 0.41061	midwifery-led 0.40338	formal 0.40043	semi-formal 0.39926	newly-developed 0.39611	faculty-based 0.39169	midwife-led 0.39117	non-formal 0.39090	family-based 0.38846

Generated lemmatized results
***************
GENERATED	informal.a 1398 ::: formal;neurocognitive;clausal;intensive;siphonic;tional;neurovascular;trilateral;multiprofessional;workbased

Filtered results
***************
RANKED	informal.a 1398	casual 0.34979	unofficial 0.34743	friendly 0.33146	easygoing 0.32350	spontaneous 0.32335	relaxed 0.31581	imprecise 0.31352	ordinary 0.31101	approximate 0.29804	untrained 0.29283	everyday 0.27503

Test context:
***************
informal.a	1399	5	jeffs and smith suggest that __informal__ educators are ' guided...by their understanding of what makes for the good ; of what makes for human well being ' ( 1990 : 1 7-1 8 ) .
Contexts for target informal are: ['amodI_educators']
Contexts in vocabulary for target informal are: ['amodI_educators']
Top most similar embeddings: informal 0.52803	formal 0.42635	non-formal 0.41179	semi-formal 0.39541	early-years 0.39433	play-based 0.38904	postsecondary 0.38854	technology-enhanced 0.38277	second-language 0.37803	university-level 0.37688

Generated lemmatized results
***************
GENERATED	informal.a 1399 ::: formal;postsecondary;multiprofessional;collegial;experiential;workbased;participative;unaccredited;diaconal;rogerian

Filtered results
***************
RANKED	informal.a 1399	casual 0.35144	unofficial 0.34032	spontaneous 0.32464	relaxed 0.32359	untrained 0.31503	friendly 0.31456	easygoing 0.31042	ordinary 0.30199	imprecise 0.30082	everyday 0.27933	approximate 0.25393

Test context:
***************
informal.a	1400	6	key findings are available in the __informal__ education archives : ; full report : ' institute of public policy research 2003 reprinted here with the kind permission of the institute of public policy research first placed in the archives : december 2003
Contexts for target informal are: ['amodI_education']
Contexts in vocabulary for target informal are: ['amodI_education']
Top most similar embeddings: informal 0.53229	formal 0.44469	non-formal 0.43628	postsecondary 0.42813	consciousness-based 0.42642	peer-led 0.42474	post-secondary 0.42162	outcomes-based 0.42029	non-advanced 0.41237	play-based 0.40976

Generated lemmatized results
***************
GENERATED	informal.a 1400 ::: formal;postsecondary;multiprofessional;workbased;collegial;transcultural;inclusionary;optometric;experiential;unaccredited

Filtered results
***************
RANKED	informal.a 1400	unofficial 0.34416	casual 0.32777	spontaneous 0.32671	relaxed 0.32418	imprecise 0.32205	friendly 0.30477	easygoing 0.30322	ordinary 0.30168	untrained 0.28804	everyday 0.27816	approximate 0.27251

Test context:
***************
inner.a	1401	45	she does this first of all through the sacrament of penance and reconciliation : bringing the grace of divine mercy and of forgiveness , she arrives at the very roots of human suffering , she heals consciences wounded by sin so that the person experiences __inner__ comfort and becomes a peacemaker .
Contexts for target inner are: ['amodI_comfort']
Contexts in vocabulary for target inner are: ['amodI_comfort']
Top most similar embeddings: inner 0.51743	outer 0.43890	zen-like 0.37958	preternatural 0.37100	unwonted 0.37078	fathomless 0.36626	light-filled 0.36605	wordly 0.36570	full-body 0.36470	shock-absorbing 0.36410

Generated lemmatized results
***************
GENERATED	inner.a 1401 ::: out;preternatural;unwonted;fathomless;wordly;innermost;inmost;sisterly;wonted;clitoral

Filtered results
***************
RANKED	inner.a 1401	inmost 0.36215	spiritual 0.35160	inward 0.34982	internal 0.33960	interior 0.33936	mental 0.31824	inside 0.30496	private 0.28914	central 0.27966	focal 0.27806	original 0.27678	enclosed 0.27401	close 0.26952	clique 0.25671	under 0.25022

Test context:
***************
inner.a	1402	14	" mrs. crayford looked round her , and noticed a second door at the __inner__ end of the boat-house .
Contexts for target inner are: ['amodI_end']
Contexts in vocabulary for target inner are: ['amodI_end']
Top most similar embeddings: inner 0.51313	outer 0.45740	shoreward 0.37632	innermost 0.37573	southern-most 0.37045	apsidal 0.37033	ventral 0.36926	outermost 0.36900	proximal 0.36866	inmost 0.36778

Generated lemmatized results
***************
GENERATED	inner.a 1402 ::: out;shoreward;innermost;apsidal;ventral;outermost;proximal;inmost;rearmost;upper

Filtered results
***************
RANKED	inner.a 1402	inmost 0.36778	internal 0.33255	spiritual 0.32901	inward 0.32869	interior 0.31732	mental 0.30850	original 0.29596	inside 0.29577	central 0.29350	private 0.29231	focal 0.28582	enclosed 0.28499	close 0.27654	clique 0.25551	under 0.24783

Test context:
***************
inner.a	1403	23	possible career paths : counselor , salesperson , politician , business person intrapersonal intelligence ability to self-reflect and be aware of one 's __inner__ state of being .
Contexts for target inner are: ['amodI_state']
Contexts in vocabulary for target inner are: ['amodI_state']
Top most similar embeddings: inner 0.51149	outer 0.42141	egoic 0.41039	inmost 0.39453	innermost 0.39085	liquid-like 0.38895	trance-like 0.38833	mid-western 0.38804	oligomeric 0.38744	after-death 0.38739

Generated lemmatized results
***************
GENERATED	inner.a 1403 ::: out;egoic;inmost;innermost;oligomeric;confederal;nonequilibrium;westphalian;libidinal;primordial

Filtered results
***************
RANKED	inner.a 1403	inmost 0.39453	internal 0.36062	spiritual 0.35529	mental 0.34400	inward 0.33859	interior 0.32562	original 0.31397	central 0.30961	private 0.29891	focal 0.28714	enclosed 0.28306	inside 0.27692	close 0.27152	clique 0.26847	under 0.25473

Test context:
***************
inner.a	1404	20	she continues by reasoning that " an element of propaganda , of sales and marketing , always intervened between the __inner__ and the outer person " ( 7 ) .
Contexts for target inner are: ['det_the', 'prep:betweenI_intervened', 'cc_and', 'conj_7']
Contexts in vocabulary for target inner are: ['det_the', 'cc_and', 'conj_7']
Top most similar embeddings: inner 0.10232	trigrams 0.08761	jejunum 0.08739	outer 0.08622	do-minimum 0.08573	cprs 0.08571	easting 0.08511	sacrum 0.08428	premolars 0.08418	groins 0.08409

Generated lemmatized results
***************
GENERATED	inner.a 1404 ::: trigrams;jejunum;out;cprs;easting;sacrum;premolars;groins;axilla;moabites

Filtered results
***************
RANKED	inner.a 1404	inside 0.07471	interior 0.07358	inward 0.07193	spiritual 0.07172	inmost 0.06397	internal 0.06353	original 0.06297	close 0.06128	mental 0.06007	central 0.05811	private 0.05783	clique 0.05455	enclosed 0.05446	under 0.05021	focal 0.04738

Test context:
***************
inner.a	1405	15	we are guided by ideals , the examples of others , a delicate sense of __inner__ vision .
Contexts for target inner are: ['amodI_vision']
Contexts in vocabulary for target inner are: ['amodI_vision']
Top most similar embeddings: inner 0.52013	outer 0.43612	egoic 0.40055	beatific 0.38674	preternatural 0.37642	innermost 0.37621	psycho-spiritual 0.37415	neo-platonic 0.37283	foveal 0.37164	wholistic 0.36987

Generated lemmatized results
***************
GENERATED	inner.a 1405 ::: out;egoic;beatific;preternatural;innermost;foveal;wholistic;libidinal;panoptic;imaginal

Filtered results
***************
RANKED	inner.a 1405	inmost 0.36806	inward 0.36187	spiritual 0.35579	internal 0.33992	mental 0.32095	interior 0.31634	central 0.31481	original 0.31394	focal 0.30149	private 0.29339	inside 0.28600	enclosed 0.26918	close 0.26678	clique 0.24758	under 0.24555

Test context:
***************
inner.a	1406	50	147 as vinzant notes , it may indeed be more than coincidence that gainesville , florida , was home not only to crossroads , but also to another 1970s discipling movement , maranatha ministries , but the details of such connections will not be known until one of the " __inner__ circle of founders " wants to tell it .
Contexts for target inner are: ['amodI_circle']
Contexts in vocabulary for target inner are: ['amodI_circle']
Top most similar embeddings: inner 0.54928	outer 0.47316	innermost 0.40352	ever-widening 0.38799	outermost 0.38564	ten-foot 0.38080	zodiacal 0.38057	cyclopean 0.37542	three-sided 0.37344	diamond-shaped 0.37013

Generated lemmatized results
***************
GENERATED	inner.a 1406 ::: out;innermost;outermost;zodiacal;cyclopean;saturnian;inmost;fathomless;hermeneutical;jeweled

Filtered results
***************
RANKED	inner.a 1406	inmost 0.36725	inward 0.34253	spiritual 0.34141	internal 0.33439	interior 0.32395	central 0.31160	inside 0.30542	original 0.29754	private 0.29698	focal 0.29666	mental 0.29541	enclosed 0.29039	close 0.28070	clique 0.26605	under 0.24101

Test context:
***************
inner.a	1407	15	quite by accident , will discovered that the outer suit would sometimes slide over the __inner__ suit , and the feeling was pleasing beyond belief .
Contexts for target inner are: ['amodI_suit']
Contexts in vocabulary for target inner are: ['amodI_suit']
Top most similar embeddings: inner 0.46599	outer 0.42882	full-body 0.38590	double-breasted 0.38471	sequined 0.37754	long-sleeved 0.37435	skin-tight 0.37272	zip-up 0.37230	four-card 0.37137	close-fitting 0.36993

Generated lemmatized results
***************
GENERATED	inner.a 1407 ::: out;sequined;sequinned;rubberized;silken;tasselled;pinstriped;footless;strappy;backless

Filtered results
***************
RANKED	inner.a 1407	inmost 0.33162	internal 0.32896	interior 0.31711	spiritual 0.31431	inward 0.30847	mental 0.29709	original 0.29289	private 0.29222	inside 0.28627	focal 0.28601	central 0.27846	enclosed 0.27026	close 0.26651	clique 0.26201	under 0.24735

Test context:
***************
inner.a	1408	23	one can proclaim the metaphysical oneness of the universe and the intrinsic divinity of man , but it is hard todeny man 's __inner__ alienation his condemnation of himself.the best we can do is to try to explain it away as socialconditioning .
Contexts for target inner are: ['amodI_alienation']
Contexts in vocabulary for target inner are: ['amodI_alienation']
Top most similar embeddings: inner 0.51212	outer 0.41664	sociopolitical 0.37320	post-imperial 0.37229	egoic 0.37026	libidinal 0.36689	inner-city 0.36404	zen-like 0.36254	psycho-spiritual 0.36197	inter-ethnic 0.36190

Generated lemmatized results
***************
GENERATED	inner.a 1408 ::: out;sociopolitical;egoic;libidinal;profound;interethnic;filial;unwonted;procreative;intercommunal

Filtered results
***************
RANKED	inner.a 1408	spiritual 0.34806	inmost 0.34458	inward 0.33341	internal 0.33278	mental 0.33032	interior 0.30137	central 0.28973	private 0.28923	focal 0.28115	original 0.27188	inside 0.26838	enclosed 0.25941	clique 0.24619	close 0.24431	under 0.23329

Test context:
***************
inner.a	1409	23	thus , the language in saalbach 's plays functions as a transparent medium : we see right through the words and into the __inner__ core of the social situation from which they spring .
Contexts for target inner are: ['amodI_core']
Contexts in vocabulary for target inner are: ['amodI_core']
Top most similar embeddings: inner 0.54164	outer 0.46356	innermost 0.40265	inmost 0.39424	egoic 0.38744	ideational 0.36913	shock-absorbing 0.36843	hyphal 0.36806	imaginal 0.36731	two-layer 0.36492

Generated lemmatized results
***************
GENERATED	inner.a 1409 ::: out;innermost;inmost;egoic;ideational;hyphal;imaginal;primordial;outermost;saturnian

Filtered results
***************
RANKED	inner.a 1409	inmost 0.39424	spiritual 0.34924	internal 0.34549	inward 0.33371	interior 0.32829	central 0.32671	mental 0.30751	original 0.30700	focal 0.29291	inside 0.29072	enclosed 0.28482	private 0.27645	close 0.26672	clique 0.26628	under 0.25895

Test context:
***************
inner.a	1410	19	khandropa is the inner male quality of spaciousness which arises and manifests externally when a male practitioner realises his __inner__ khandro .
Contexts for target inner are: ['amodI_khandro']
Contexts in vocabulary for target inner are: []
Top most similar embeddings: inner 1.00000	outer 0.87075	innermost 0.75144	inmost 0.73676	egoic 0.73379	intercostal 0.70988	labial 0.70521	2-berth 0.70329	cyclopean 0.70198	supernal 0.69915

Generated lemmatized results
***************
GENERATED	inner.a 1410 ::: out;innermost;inmost;egoic;intercostal;labial;cyclopean;supernal;cricoid;orbitofrontal

Filtered results
***************
RANKED	inner.a 1410	inmost 0.73676	internal 0.68821	inward 0.68654	spiritual 0.67881	interior 0.67031	mental 0.64328	inside 0.61700	central 0.61366	private 0.61091	focal 0.60798	enclosed 0.60028	original 0.60027	clique 0.56716	close 0.55981	under 0.55188

Test context:
***************
investigator.n	1411	1	the __investigators__ , all part of a team known as the antithrombotic trialists ' collaboration ( atc ) , looked at whether the antiplatelets cut patients ' risk of heart attack , stroke and death from a cardiovascular cause .
Contexts for target investigators are: ['det_the', 'nsubjI_looked', 'punct_,', 'appos_part', 'punct_,']
Contexts in vocabulary for target investigators are: ['det_the', 'nsubjI_looked', 'punct_,', 'appos_part', 'punct_,']
Top most similar embeddings: investigators 0.02633	qdr 0.02509	bretons 0.02377	impaler 0.02366	khawarij 0.02351	epidemiologists 0.02335	yadin 0.02330	samnites 0.02329	rockefellers 0.02322	rosicrucians 0.02309

Generated lemmatized results
***************
GENERATED	investigator.n 1411 ::: qdr;breton;impaler;khawarij;epidemiologist;yadin;samnite;rockefeller;rosicrucian;ntsb

Filtered results
***************
RANKED	investigator.n 1411	detective 0.02254	researcher 0.02233	inquirer 0.01908	experimenter 0.01882	inspector 0.01833	officer 0.01690	official 0.01683	examiner 0.01526

Test context:
***************
investigator.n	1412	33	reilly says he lost interest in the phone tap after finding in the wastebasket a piece of carbon paper with the impression of 15 questions which otepka had allegedly typed out for senate __investigators__ to ask reilly .
Contexts for target investigators are: ['nn_senate', 'nsubjI_ask']
Contexts in vocabulary for target investigators are: ['nn_senate', 'nsubjI_ask']
Top most similar embeddings: investigators 0.24753	investigator 0.18745	researchers 0.18714	assessors 0.18211	negotiators 0.18119	interviewers 0.17720	prosecutors 0.17701	lawmakers 0.17628	evaluators 0.17619	observers 0.17436

Generated lemmatized results
***************
GENERATED	investigator.n 1412 ::: researcher;assessor;negotiator;interviewer;prosecutor;lawmaker;evaluator;observer;detective;gvos

Filtered results
***************
RANKED	investigator.n 1412	researcher 0.18714	detective 0.17359	examiner 0.17268	official 0.16764	inspector 0.16254	experimenter 0.16089	officer 0.15691	inquirer 0.15598

Test context:
***************
investigator.n	1413	14	" [ new york times , 9/11/02 ] oct 5 , 2002 : congressional __investigators__ say the fbi 's efforts to block their inquiry makes them skeptical of fbi assertions .
Contexts for target investigators are: ['amod_congressional', 'nsubjI_say']
Contexts in vocabulary for target investigators are: ['amod_congressional', 'nsubjI_say']
Top most similar embeddings: investigators 0.26829	researchers 0.20502	officials 0.19836	analysts 0.19820	prosecutors 0.19448	scientists 0.19246	insiders 0.19234	vivisectionists 0.19106	observers 0.19067	pollsters 0.18953

Generated lemmatized results
***************
GENERATED	investigator.n 1413 ::: researcher;official;analyst;prosecutor;scientist;insider;vivisectionist;observer;pollster;lawmaker

Filtered results
***************
RANKED	investigator.n 1413	researcher 0.20502	official 0.19836	experimenter 0.17710	detective 0.17485	inspector 0.16934	examiner 0.16295	inquirer 0.16135	officer 0.16013

Test context:
***************
investigator.n	1414	20	the key to good science in this field is always to keep the experiment totally under the control of the __investigators__ and to use blind and double-blind testing procedures wherever possible .
Contexts for target investigators are: ['det_the', 'prep:ofI_control']
Contexts in vocabulary for target investigators are: ['det_the', 'prep:ofI_control']
Top most similar embeddings: investigators 0.23569	investigator 0.19089	distrainor 0.18999	infracos 0.18898	cmcu 0.18795	aidb 0.18755	hussites 0.18645	cheka 0.18643	provos 0.18602	rockefellers 0.18485

Generated lemmatized results
***************
GENERATED	investigator.n 1414 ::: distrainor;infracos;cmcu;aidb;hussite;cheka;provo;rockefeller;tremere;neum

Filtered results
***************
RANKED	investigator.n 1414	researcher 0.18228	experimenter 0.17459	detective 0.17097	inspector 0.17035	official 0.16974	examiner 0.16946	officer 0.16749	inquirer 0.15546

Test context:
***************
investigator.n	1415	22	leading international private detective and private investigator firm for all private investigations , we stand ready with any private detective or private __investigator__ matter .
Contexts for target investigator are: ['nnI_matter']
Contexts in vocabulary for target investigator are: ['nnI_matter']
Top most similar embeddings: investigator 0.43521	investigators 0.34460	detective 0.34128	researcher 0.33686	scientist 0.33601	circumstellar 0.32807	observer 0.32517	grosser 0.32347	climatologist 0.32342	professor 0.32102

Generated lemmatized results
***************
GENERATED	investigator.n 1415 ::: detective;researcher;scientist;circumstellar;observer;grosser;climatologist;professor;ufologist;informer

Filtered results
***************
RANKED	investigator.n 1415	detective 0.34128	researcher 0.33686	inspector 0.31416	examiner 0.31305	inquirer 0.30598	officer 0.29605	experimenter 0.29182	official 0.27692

Test context:
***************
investigator.n	1416	9	in addition , it is important for clinicians and __investigators__ to account for any herbs or natural products being taken by their patients or research subjects that might interact with traditional treatments .
Contexts for target investigators are: ['conjI_clinicians']
Contexts in vocabulary for target investigators are: ['conjI_clinicians']
Top most similar embeddings: investigators 0.51395	researchers 0.44942	scientists 0.41655	clinicians 0.41236	pharmacologists 0.40902	geneticists 0.40272	virologists 0.40258	epidemiologists 0.40108	toxicologists 0.40106	immunologists 0.40073

Generated lemmatized results
***************
GENERATED	investigator.n 1416 ::: researcher;scientist;clinician;pharmacologist;geneticist;virologist;epidemiologist;toxicologist;immunologist;metallurgist

Filtered results
***************
RANKED	investigator.n 1416	researcher 0.44942	experimenter 0.36795	official 0.35464	inquirer 0.34848	officer 0.33996	detective 0.33771	examiner 0.33290	inspector 0.33016

Test context:
***************
investigator.n	1417	1	american __investigators__ had to be sent anywhere but holland .
Contexts for target investigators are: ['amod_american', 'nsubjI_had']
Contexts in vocabulary for target investigators are: ['amod_american', 'nsubjI_had']
Top most similar embeddings: investigators 0.24813	researchers 0.19648	interrogators 0.19538	cryptographers 0.19366	organ-builders 0.19256	scientists 0.18698	oilmen 0.18678	soliders 0.18673	lexicographers 0.18591	folklorists 0.18410

Generated lemmatized results
***************
GENERATED	investigator.n 1417 ::: researcher;interrogator;cryptographer;scientist;oilman;soliders;lexicographer;folklorists;colonist;archeologist

Filtered results
***************
RANKED	investigator.n 1417	researcher 0.19648	experimenter 0.18315	official 0.17993	detective 0.17064	officer 0.16405	inspector 0.16224	inquirer 0.15888	examiner 0.15192

Test context:
***************
investigator.n	1418	3	they suggest that __investigators__ of new religious movements should look into adaptation in host communities as well as nrms , and that they pay special attention to the role of the mass media in this two-way process of adaptation .
Contexts for target investigators are: ['nsubjI_look', 'prep:of_movements']
Contexts in vocabulary for target investigators are: ['nsubjI_look', 'prep:of_movements']
Top most similar embeddings: investigators 0.23024	researchers 0.17220	observers 0.16946	astrophysicists 0.16914	paleontologists 0.16786	analysts 0.16776	leaders 0.16775	evaluators 0.16762	theoreticians 0.16558	ethnographers 0.16506

Generated lemmatized results
***************
GENERATED	investigator.n 1418 ::: researcher;observer;astrophysicist;paleontologist;analyst;leader;evaluator;theoretician;ethnographer;negotiator

Filtered results
***************
RANKED	investigator.n 1418	researcher 0.17220	detective 0.16140	official 0.15798	inspector 0.15740	experimenter 0.15688	officer 0.14976	examiner 0.14800	inquirer 0.14752

Test context:
***************
investigator.n	1419	6	the present , rejecting attitude restricts __investigators__ to using simple tools , which are incapable of answering the questions skeptics demand be answered .
Contexts for target investigators are: ['dobjI_restricts']
Contexts in vocabulary for target investigators are: ['dobjI_restricts']
Top most similar embeddings: investigators 0.45892	researchers 0.36768	investigator 0.35304	surgeons 0.34072	scientists 0.33599	scholars 0.33563	experimenters 0.33546	detectives 0.33415	astronomers 0.33405	investigation 0.33394

Generated lemmatized results
***************
GENERATED	investigator.n 1419 ::: researcher;surgeon;scientist;scholar;experimenter;detective;astronomer;investigation;prosecutor;deductibility

Filtered results
***************
RANKED	investigator.n 1419	researcher 0.36768	experimenter 0.33546	detective 0.33415	inspector 0.32362	inquirer 0.32220	officer 0.31793	examiner 0.30511	official 0.30168

Test context:
***************
investigator.n	1420	11	there he was a section leader for inorganic chemistry and principal __investigator__ on several research projects dealing with actinide coordination and organometallic chemistry , organometallic chemical vapor deposition , and technetium-99 chemistry .
Contexts for target investigator are: ['amod_principal', 'conjI_chemistry']
Contexts in vocabulary for target investigator are: ['amod_principal', 'conjI_chemistry']
Top most similar embeddings: investigator 0.26412	investigators 0.20350	researcher 0.19070	scientist 0.18661	co-investigators 0.18004	collaborator 0.17908	toxicologist 0.17601	co-applicant 0.17494	co-investigator 0.17322	photochemistry 0.17057

Generated lemmatized results
***************
GENERATED	investigator.n 1420 ::: researcher;scientist;collaborator;toxicologist;photochemistry;geophysicist;geologist;examiner;climatologist;epidemiologist

Filtered results
***************
RANKED	investigator.n 1420	researcher 0.19070	examiner 0.16931	officer 0.16008	inspector 0.15098	experimenter 0.14479	detective 0.14338	official 0.13066	inquirer 0.12863

Test context:
***************
letter.n	1421	19	on september 30th of last year rep. john conyers , ranking member of the house judiciary committee sent a __letter__ to the cia requesting a description of what contacts the agency had had with justice about the plame matter prior to the commencement of the investigation .
Contexts for target letter are: ['det_a', 'dobjI_sent']
Contexts in vocabulary for target letter are: ['det_a', 'dobjI_sent']
Top most similar embeddings: letter 0.28717	telegram 0.22964	missive 0.21304	memo 0.21266	phone-call 0.21101	phonecall 0.20226	sighup 0.20161	postcard 0.20156	mailshot 0.20049	e-postcard 0.19601

Generated lemmatized results
***************
GENERATED	letter.n 1421 ::: telegram;missive;memo;phonecall;sighup;postcard;mailshot;deputation;mesage;handbill

Filtered results
***************
RANKED	letter.n 1421	missive 0.21304	memo 0.21266	message 0.18387	correspondence 0.17476	epistle 0.17131	document 0.17002	note 0.15762	mail 0.15634	alphabet 0.14454	glyph 0.14409	character 0.13846	dispatch 0.13582	communication 0.13555

Test context:
***************
letter.n	1422	2	although her __letters__ were far colder than martha 's , she wrote us in october 1991 : " we are bad .
Contexts for target letters are: ['poss_her', 'nsubjI_colder']
Contexts in vocabulary for target letters are: ['poss_her', 'nsubjI_colder']
Top most similar embeddings: letters 0.21520	letter 0.17207	underclothes 0.16716	labia 0.16573	eares 0.16230	feete 0.16095	eardrums 0.15935	snow-shoes 0.15925	armpits 0.15810	shirtsleeves 0.15806

Generated lemmatized results
***************
GENERATED	letter.n 1422 ::: underclothes;labium;eares;feete;eardrum;armpit;shirtsleeve;initial;ankle;vitals

Filtered results
***************
RANKED	letter.n 1422	correspondence 0.14888	missive 0.14389	epistle 0.14153	memo 0.13744	character 0.13563	glyph 0.13243	mail 0.13187	alphabet 0.13043	dispatch 0.12827	message 0.12452	communication 0.11702	note 0.11665	document 0.10994

Test context:
***************
letter.n	1423	30	nethack is a computer roleplaying game where creatures are represented by letters. a d= a dragon , a v= a vampire , etc. for about three days afterward i saw __letters__ as monsters .
Contexts for target letters are: ['dobjI_saw']
Contexts in vocabulary for target letters are: ['dobjI_saw']
Top most similar embeddings: letters 0.46481	letter 0.39481	cahonies 0.34350	correspondence 0.34081	mugshot 0.34029	initials 0.33903	swastikas 0.33501	telegrams 0.33443	handprints 0.33421	forktail 0.33390

Generated lemmatized results
***************
GENERATED	letter.n 1423 ::: cahonies;correspondence;mugshot;initial;swastika;telegram;handprints;forktail;halo;grackle

Filtered results
***************
RANKED	letter.n 1423	correspondence 0.34081	epistle 0.32390	missive 0.32309	memo 0.32255	mail 0.30581	message 0.30535	alphabet 0.30292	glyph 0.30194	character 0.29913	document 0.29429	dispatch 0.29184	note 0.26953	communication 0.26507

Test context:
***************
letter.n	1424	3	i read your __letter__ d. at first i looked at it and saw your concern and it 's a legitimate concern .
Contexts for target letter are: ['poss_your', 'dobjI_read', 'appos_d.']
Contexts in vocabulary for target letter are: ['poss_your', 'dobjI_read', 'appos_d.']
Top most similar embeddings: letter 0.11963	letters 0.09598	telegram 0.08652	c.v. 0.08388	vitae 0.08224	cv 0.08158	lre 0.08080	artical 0.08054	note-book 0.08024	postcard 0.08010

Generated lemmatized results
***************
GENERATED	letter.n 1424 ::: telegram;vitae;cv;lre;artical;postcard;kfi;copie;epistle;missive

Filtered results
***************
RANKED	letter.n 1424	epistle 0.07924	missive 0.07894	memo 0.07856	correspondence 0.07757	mail 0.07513	message 0.07391	document 0.06958	note 0.06756	alphabet 0.06638	dispatch 0.06576	character 0.06203	communication 0.06201	glyph 0.06052

Test context:
***************
letter.n	1425	14	" ( were any of you spoken to by your father quietly in capital __letters__ ?
Contexts for target letters are: ['nn_capital', 'prep:inI_spoken']
Contexts in vocabulary for target letters are: ['nn_capital', 'prep:inI_spoken']
Top most similar embeddings: letters 0.25767	letter 0.20109	capitals 0.17264	freetown 0.17157	port-au-prince 0.17137	accra 0.16825	manama 0.16823	tashkent 0.16761	nouakchott 0.16718	correspondence 0.16713

Generated lemmatized results
***************
GENERATED	letter.n 1425 ::: capital;freetown;accra;manama;tashkent;nouakchott;correspondence;bishkek;sanaa;tegucigalpa

Filtered results
***************
RANKED	letter.n 1425	correspondence 0.16713	epistle 0.16444	memo 0.15544	alphabet 0.15129	missive 0.14687	character 0.13633	dispatch 0.13624	mail 0.13253	glyph 0.12781	document 0.12685	note 0.12634	message 0.12037	communication 0.11856

Test context:
***************
letter.n	1426	37	but we have to learn to make that choice for ourselves.the only thing i did not like about the book was an annoying tendency to put every first letter of each word in a meditation in capital __letters__ .
Contexts for target letters are: ['nn_capital', 'prep:inI_meditation']
Contexts in vocabulary for target letters are: ['nn_capital', 'prep:inI_meditation']
Top most similar embeddings: letters 0.23925	letter 0.18925	tashkent 0.16284	capitals 0.15731	correspondence 0.15638	islamabad 0.15637	port-au-prince 0.15631	tehran 0.15612	cantos 0.15436	epigrams 0.15431

Generated lemmatized results
***************
GENERATED	letter.n 1426 ::: tashkent;capital;correspondence;islamabad;tehran;canto;epigram;accra;kigali;numeral

Filtered results
***************
RANKED	letter.n 1426	correspondence 0.15638	epistle 0.15191	memo 0.14095	missive 0.13902	alphabet 0.13833	note 0.12686	character 0.12429	dispatch 0.12317	glyph 0.12293	document 0.12269	message 0.11963	mail 0.11725	communication 0.11467

Test context:
***************
letter.n	1427	23	click here for the address by general sir michael walker and here for that by miss helen tridgell click here for extracts from __letters__ written to and b&c extracts referring to major-general sir david thorne kbe cvo below : chapel memorial to sir david thorne did you know 5573508 es collins ?
Contexts for target letters are: ['prep:fromI_extracts', 'partmod_written']
Contexts in vocabulary for target letters are: ['prep:fromI_extracts', 'partmod_written']
Top most similar embeddings: letters 0.28568	letter 0.22546	libretti 0.22006	epigrams 0.20951	memoires 0.20813	epistles 0.20214	eclogues 0.20099	autobiographies 0.20063	memos 0.19978	encyclicals 0.19937

Generated lemmatized results
***************
GENERATED	letter.n 1427 ::: libretto;epigram;memoires;epistle;eclogue;autobiography;memo;encyclical;sonnet;oration

Filtered results
***************
RANKED	letter.n 1427	epistle 0.20214	memo 0.19978	correspondence 0.18944	missive 0.18008	document 0.16957	alphabet 0.16235	message 0.16116	mail 0.16045	dispatch 0.15921	note 0.15859	glyph 0.14845	character 0.14578	communication 0.12793

Test context:
***************
letter.n	1428	5	so keep those cards and __letters__ coming , but in doing so think about how they could be most helpful to the rule-making process and to us .
Contexts for target letters are: ['conjI_cards']
Contexts in vocabulary for target letters are: ['conjI_cards']
Top most similar embeddings: letters 0.52362	chequebooks 0.41659	postcards 0.39740	telegrams 0.39245	post-its 0.38587	letter 0.38259	e-mails 0.38050	notelets 0.38036	memos 0.37759	mousemats 0.37437

Generated lemmatized results
***************
GENERATED	letter.n 1428 ::: chequebook;postcard;telegram;notelets;memo;mousemats;notecards;handbill;voicemail;phonecards

Filtered results
***************
RANKED	letter.n 1428	memo 0.37759	correspondence 0.35361	epistle 0.34613	alphabet 0.34481	message 0.33894	missive 0.33841	glyph 0.32268	document 0.32199	mail 0.31999	character 0.31136	note 0.30427	dispatch 0.29343	communication 0.28242

Test context:
***************
letter.n	1429	32	he returned to the 105th ohio for the drive on atlanta ( two letters , june to july , 1864 ) and for subsequent operations in georgia and the carolinas ( six __letters__ , october 1864 to april 1865 ) .
Contexts for target letters are: ['punct_-lrb-', 'num_six', 'depI_carolinas', 'punct_,', 'appos_october', 'punct_.']
Contexts in vocabulary for target letters are: ['num_six', 'punct_,', 'appos_october', 'punct_.']
Top most similar embeddings: letters 0.05649	wed. 0.04456	neuropsychologia 0.04381	neuroimage 0.04376	econometrica 0.04363	bifolios 0.04359	gazeta 0.04353	mon. 0.04337	geoforum 0.04316	xlviii 0.04309

Generated lemmatized results
***************
GENERATED	letter.n 1429 ::: neuropsychologia;neuroimage;econometrica;bifolios;gazeta;geoforum;xlviii;josemi;xxxvi;oikos

Filtered results
***************
RANKED	letter.n 1429	epistle 0.03653	memo 0.03592	missive 0.03419	dispatch 0.03375	correspondence 0.03320	note 0.03299	alphabet 0.03260	mail 0.03197	character 0.02943	glyph 0.02899	document 0.02828	message 0.02827	communication 0.02559

Test context:
***************
letter.n	1430	5	i did wait for his __letter__ , but it did not come , and the next day i got a telegraphic dispatch from governor johnson , who , at sacramento , had heard of general wool 's ' back-down, ' asking me to meet him again at benicia that night .
Contexts for target letter are: ['poss_his', 'prep:forI_wait']
Contexts in vocabulary for target letter are: ['poss_his', 'prep:forI_wait']
Top most similar embeddings: letter 0.24866	telegram 0.20152	missive 0.19906	letters 0.19692	come-uppance 0.19381	comeuppance 0.18672	recantation 0.18550	peroration 0.18268	phonecall 0.18096	admonishment 0.17992

Generated lemmatized results
***************
GENERATED	letter.n 1430 ::: telegram;missive;comeuppance;recantation;peroration;phonecall;admonishment;exoneration;affidavit;admonition

Filtered results
***************
RANKED	letter.n 1430	missive 0.19906	epistle 0.17729	memo 0.17153	correspondence 0.16979	message 0.16118	mail 0.15306	dispatch 0.14933	character 0.14352	alphabet 0.14168	glyph 0.13711	note 0.13518	document 0.13325	communication 0.12930

Test context:
***************
loud.a	1431	71	but now there is a court of appeal in the state of supreme news judgment , and everyone knows the initial verdict can be reversed ... " more ... maybe media bias has become a dumb debate : " this here is a post for practically everyone in the game of seizing on media bias and denouncing it , which is part of our popular culture , and of course a __loud__ part of our politics .
Contexts for target loud are: ['amodI_part']
Contexts in vocabulary for target loud are: ['amodI_part']
Top most similar embeddings: loud 0.47953	loudest 0.38040	louder 0.37871	high-pitched 0.37262	noisy 0.37096	long-neglected 0.36907	bassy 0.36748	ear-splitting 0.36224	well-played 0.35785	biggish 0.35717

Generated lemmatized results
***************
GENERATED	loud.a 1431 ::: noisy;bassy;biggish;twiddly;echoey;sonorous;posh;dissonant;large;strident

Filtered results
***************
RANKED	loud.a 1431	noisy 0.37096	strident 0.35145	raucous 0.35137	shrill 0.34902	big 0.34506	deafening 0.34491	vociferous 0.34193	obtrusive 0.33017	rowdy 0.32375	forceful 0.32324	strong 0.31792	thundering 0.31789	heavy 0.31521	disturbing 0.31478	powerful 0.31344	booming 0.31111	resonant 0.30911	blaring 0.30816	conspicuous 0.30645	amplified 0.29369	clear 0.28350	imposing 0.27246

Test context:
***************
loud.a	1432	39	this indicated to him a means of solving the problem , and he did not delay , but in his joy leapt out of the tub and , rushing naked towards his home , he cried out with a __loud__ voice that he had found what he sought .
Contexts for target loud are: ['amodI_voice']
Contexts in vocabulary for target loud are: ['amodI_voice']
Top most similar embeddings: loud 0.54515	raspy 0.43688	high-pitched 0.43551	shrill 0.42771	loudest 0.41928	stentorian 0.41751	bassy 0.41539	ear-splitting 0.41397	throaty 0.41377	breathy 0.41362

Generated lemmatized results
***************
GENERATED	loud.a 1432 ::: raspy;shrill;stentorian;bassy;throaty;breathy;hoarse;crackly;plaintive;whiney

Filtered results
***************
RANKED	loud.a 1432	shrill 0.42771	strident 0.40058	raucous 0.39473	deafening 0.38762	noisy 0.37886	vociferous 0.35816	blaring 0.35512	forceful 0.35512	booming 0.35067	strong 0.34579	powerful 0.34442	rowdy 0.33972	thundering 0.33933	resonant 0.33751	big 0.33264	obtrusive 0.33031	amplified 0.32147	heavy 0.32052	disturbing 0.31161	clear 0.30938	conspicuous 0.29235	imposing 0.26811

Test context:
***************
loud.a	1433	34	every so often i look up from the book and see a roomful of people waiting for me to make a decision about whether the music is too soft or the thunder is too __loud__ , and i ca n't believe they do n't understand that what i 'm doing is much more important ' i 'm reading the most wonderful book .
Contexts for target loud are: ['nsubj_thunder', 'cop_is', 'advmod_too', 'conjI_soft']
Contexts in vocabulary for target loud are: ['nsubj_thunder', 'cop_is', 'advmod_too', 'conjI_soft']
Top most similar embeddings: loud 0.07217	high-pitched 0.05307	bassy 0.05131	crackly 0.05125	deafening 0.05094	noisy 0.05011	brassy 0.04962	hoarse 0.04957	raspy 0.04933	crumbly 0.04925

Generated lemmatized results
***************
GENERATED	loud.a 1433 ::: bassy;crackly;deafening;noisy;brassy;hoarse;raspy;crumbly;whiney;tinny

Filtered results
***************
RANKED	loud.a 1433	deafening 0.05094	noisy 0.05011	raucous 0.04796	shrill 0.04763	strident 0.04460	obtrusive 0.04394	heavy 0.04218	rowdy 0.04081	strong 0.04074	powerful 0.03905	forceful 0.03902	big 0.03782	booming 0.03770	disturbing 0.03688	vociferous 0.03669	resonant 0.03510	thundering 0.03330	clear 0.03260	blaring 0.03220	conspicuous 0.03160	amplified 0.02680	imposing 0.02522

Test context:
***************
loud.a	1434	10	the conductor uses a small fob transmitter to trigger a __loud__ siren alerting the engineer to stop the train .
Contexts for target loud are: ['amodI_siren']
Contexts in vocabulary for target loud are: ['amodI_siren']
Top most similar embeddings: loud 0.55729	ear-splitting 0.42412	high-pitched 0.42182	crackly 0.41380	shrill 0.41209	loudest 0.40381	brassy 0.40146	guttural 0.40139	thunderous 0.39982	tuneless 0.39959

Generated lemmatized results
***************
GENERATED	loud.a 1434 ::: crackly;shrill;brassy;guttural;thunderous;tuneless;raucous;deafening;noisy;cacophonous

Filtered results
***************
RANKED	loud.a 1434	shrill 0.41209	raucous 0.39745	deafening 0.39709	noisy 0.39568	blaring 0.37420	strident 0.36620	thundering 0.35299	vociferous 0.34519	forceful 0.33554	rowdy 0.33492	resonant 0.33224	booming 0.33130	obtrusive 0.31891	big 0.31760	powerful 0.31598	heavy 0.31448	amplified 0.31027	clear 0.30601	disturbing 0.30327	strong 0.30010	conspicuous 0.27258	imposing 0.26528

Test context:
***************
loud.a	1435	2	after a __loud__ set of cracks , the thetan was overwhelmed by darkness ( atack , 1990 : 32 ) .
Contexts for target loud are: ['amodI_set']
Contexts in vocabulary for target loud are: ['amodI_set']
Top most similar embeddings: loud 0.49671	singsational 0.39129	raucous 0.38440	2-cd 0.38201	ear-splitting 0.38052	now-familiar 0.37741	cacophonous 0.37574	double-disc 0.37541	old-skool 0.37303	tuneless 0.37295

Generated lemmatized results
***************
GENERATED	loud.a 1435 ::: singsational;raucous;cacophonous;tuneless;thunderous;crackly;noisy;splashy;jangly;godawful

Filtered results
***************
RANKED	loud.a 1435	raucous 0.38440	noisy 0.36902	shrill 0.36061	strident 0.35305	deafening 0.35244	rowdy 0.33963	vociferous 0.33316	powerful 0.33049	forceful 0.32982	strong 0.32773	thundering 0.32518	heavy 0.32496	big 0.32316	blaring 0.32192	resonant 0.31020	obtrusive 0.30790	booming 0.30562	clear 0.30475	amplified 0.30441	disturbing 0.30127	imposing 0.28090	conspicuous 0.26837

Test context:
***************
loud.a	1436	15	clocking in at a grand total of 17:05 , f.y.p. packs in eight tracks of __loud__ , fast , and bratty punk rock .
Contexts for target loud are: ['prep:ofI_tracks', 'punct_,', 'conj_fast', 'punct_,', 'cc_and', 'conj_rock']
Contexts in vocabulary for target loud are: ['prep:ofI_tracks', 'punct_,', 'conj_fast', 'punct_,', 'cc_and', 'conj_rock']
Top most similar embeddings: loud 0.01502	jazzanova 0.01367	zepplin 0.01360	be-bop 0.01359	sparklehorse 0.01353	grooverider 0.01342	royksopp 0.01340	2-tone 0.01327	rootsy 0.01303	mandolins 0.01296

Generated lemmatized results
***************
GENERATED	loud.a 1436 ::: jazzanova;zepplin;sparklehorse;grooverider;royksopp;rootsy;mandolins;fugazi;autechre;coheed

Filtered results
***************
RANKED	loud.a 1436	raucous 0.01102	noisy 0.01082	shrill 0.01008	rowdy 0.00906	strident 0.00897	blaring 0.00882	forceful 0.00877	thundering 0.00869	deafening 0.00848	heavy 0.00836	vociferous 0.00756	powerful 0.00755	booming 0.00755	strong 0.00725	obtrusive 0.00706	resonant 0.00676	clear 0.00653	amplified 0.00648	big 0.00637	disturbing 0.00622	conspicuous 0.00621	imposing 0.00515

Test context:
***************
loud.a	1437	6	she interrupts his sleep with her __loud__ noises , ruins his breakfast , and loses his magnifying glass .
Contexts for target loud are: ['amodI_noises']
Contexts in vocabulary for target loud are: ['amodI_noises']
Top most similar embeddings: loud 0.55311	ear-splitting 0.43459	high-pitched 0.42697	louder 0.42017	tinny 0.41505	noisy 0.41398	loudest 0.41269	shrill 0.41096	guttural 0.41007	tuneless 0.40830

Generated lemmatized results
***************
GENERATED	loud.a 1437 ::: tinny;noisy;shrill;guttural;tuneless;audible;thunderous;crackly;deafening;squelchy

Filtered results
***************
RANKED	loud.a 1437	noisy 0.41398	shrill 0.41096	deafening 0.40273	raucous 0.39911	strident 0.37888	vociferous 0.36724	blaring 0.35112	obtrusive 0.34492	thundering 0.34151	booming 0.34072	rowdy 0.34003	resonant 0.33342	disturbing 0.33266	heavy 0.33029	big 0.33015	forceful 0.32909	amplified 0.32079	powerful 0.31287	strong 0.31250	conspicuous 0.28495	clear 0.28100	imposing 0.26994

Test context:
***************
loud.a	1438	4	he said in a __loud__ voice , ' fear god and give him glory , for his time has come to sit in judgment .
Contexts for target loud are: ['amodI_voice']
Contexts in vocabulary for target loud are: ['amodI_voice']
Top most similar embeddings: loud 0.54515	raspy 0.43688	high-pitched 0.43551	shrill 0.42771	loudest 0.41928	stentorian 0.41751	bassy 0.41539	ear-splitting 0.41397	throaty 0.41377	breathy 0.41362

Generated lemmatized results
***************
GENERATED	loud.a 1438 ::: raspy;shrill;stentorian;bassy;throaty;breathy;hoarse;crackly;plaintive;whiney

Filtered results
***************
RANKED	loud.a 1438	shrill 0.42771	strident 0.40058	raucous 0.39473	deafening 0.38762	noisy 0.37886	vociferous 0.35816	blaring 0.35512	forceful 0.35512	booming 0.35067	strong 0.34579	powerful 0.34442	rowdy 0.33972	thundering 0.33933	resonant 0.33751	big 0.33264	obtrusive 0.33031	amplified 0.32147	heavy 0.32052	disturbing 0.31161	clear 0.30938	conspicuous 0.29235	imposing 0.26811

Test context:
***************
loud.a	1439	17	when we 're stressed our ears become more susceptible , noises don 't have to be as __loud__ to affect hearing. " can loud rock music cause deafness ?
Contexts for target loud are: ['aux_to', 'cop_be', 'advmod_as', 'xcompI_have', 'xcomp_affect']
Contexts in vocabulary for target loud are: ['aux_to', 'cop_be', 'advmod_as', 'xcompI_have', 'xcomp_affect']
Top most similar embeddings: loud 0.02741	careful 0.02012	thick-skinned 0.02000	vigilant 0.01968	carefull 0.01956	precise 0.01897	obtrusive 0.01895	super-fit 0.01880	honest 0.01874	tactful 0.01852

Generated lemmatized results
***************
GENERATED	loud.a 1439 ::: careful;vigilant;carefull;precise;obtrusive;honest;tactful;strong;indelicate;pedantic

Filtered results
***************
RANKED	loud.a 1439	obtrusive 0.01895	strong 0.01826	forceful 0.01775	noisy 0.01766	deafening 0.01601	raucous 0.01580	big 0.01557	clear 0.01554	vociferous 0.01533	powerful 0.01515	heavy 0.01487	rowdy 0.01472	strident 0.01466	disturbing 0.01451	booming 0.01405	amplified 0.01380	conspicuous 0.01350	resonant 0.01348	shrill 0.01342	blaring 0.01137	thundering 0.01111	imposing 0.01075

Test context:
***************
loud.a	1440	11	valera denounced the quality of traditional karate refereeing and made a __loud__ , controversial exit from traditional karate at the 3 rd wuko world championships in 1975 at long beach , calif. when valera took up full-contact karate , many younger karatemen showed interest .
Contexts for target loud are: ['amodI_exit']
Contexts in vocabulary for target loud are: ['amodI_exit']
Top most similar embeddings: loud 0.46204	noisy 0.38187	abrupt 0.36190	raucous 0.36031	tinny 0.35845	thunderous 0.35641	deafening 0.35247	shrill 0.35247	loudest 0.35124	ear-splitting 0.34999

Generated lemmatized results
***************
GENERATED	loud.a 1440 ::: noisy;abrupt;raucous;tinny;thunderous;deafening;shrill;crackly;splashy;slowish

Filtered results
***************
RANKED	loud.a 1440	noisy 0.38187	raucous 0.36031	deafening 0.35247	shrill 0.35247	strident 0.33733	forceful 0.33025	thundering 0.32275	vociferous 0.32016	big 0.31887	rowdy 0.31871	obtrusive 0.31807	blaring 0.31509	disturbing 0.30746	strong 0.30496	resonant 0.30445	heavy 0.30179	powerful 0.29997	conspicuous 0.29811	booming 0.29488	clear 0.28301	imposing 0.26305	amplified 0.25896

Test context:
***************
mad.a	1441	17	connecticut at last we arrived at penn station , grabbed our carry-on bags , and made a __mad__ dash for the exit .
Contexts for target mad are: ['amodI_dash']
Contexts in vocabulary for target mad are: ['amodI_dash']
Top most similar embeddings: mad 0.55609	crazy 0.43709	insane 0.41208	frantic 0.38180	barmy 0.38093	bonkers 0.37356	nutty 0.37187	full-throttle 0.36627	dotty 0.36356	teary 0.36201

Generated lemmatized results
***************
GENERATED	mad.a 1441 ::: crazy;insane;frantic;barmy;bonkers;nutty;dotty;teary;madcap;dizzy

Filtered results
***************
RANKED	mad.a 1441	crazy 0.43709	insane 0.41208	frantic 0.38180	frenzied 0.35413	angry 0.35045	wild 0.34398	furious 0.33535	rabid 0.33229	frenetic 0.32704	fast 0.30599	annoyed 0.29491	hurried 0.28782	rapid 0.28734	uncontrolled 0.28549	pn 0.24823

Test context:
***************
mad.a	1442	3	she was not __mad__ before she was prescribed complete rest , but rather the complete rest which caused her madness .
Contexts for target mad are: ['nsubj_she', 'cop_was', 'neg_not', 'rootI_*root*', 'advcl_prescribed', 'punct_,', 'cc_but', 'conj_rest', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target mad are: ['nsubj_she', 'cop_was', 'neg_not', 'rootI_*root*', 'advcl_prescribed', 'punct_,', 'cc_but', 'conj_rest', 'punct_.']
Top most similar embeddings: mad 0.00145	knowen 0.00125	surprized 0.00123	heart-broken 0.00123	displeased 0.00123	amerced 0.00123	inconsolable 0.00122	indeede 0.00120	mortified 0.00119	grieved 0.00118

Generated lemmatized results
***************
GENERATED	mad.a 1442 ::: knowen;surprized;displeased;amerced;inconsolable;indeede;mortified;grieved;elated;heartbroken

Filtered results
***************
RANKED	mad.a 1442	insane 0.00114	crazy 0.00112	angry 0.00109	furious 0.00103	annoyed 0.00102	hurried 0.00087	frantic 0.00085	frenetic 0.00070	fast 0.00066	wild 0.00065	rabid 0.00062	uncontrolled 0.00056	frenzied 0.00052	rapid 0.00044	pn 0.00044

Test context:
***************
mad.a	1443	3	i was so __mad__ , i jumped up and whirled around .
Contexts for target mad are: ['nsubj_i', 'cop_was', 'advmod_so', 'rootI_*root*', 'punct_,', 'conj_jumped', 'cc_and', 'conj_whirled', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target mad are: ['nsubj_i', 'cop_was', 'advmod_so', 'rootI_*root*', 'punct_,', 'conj_jumped', 'cc_and', 'punct_.']
Top most similar embeddings: hillarious 0.00473	heart-broken 0.00467	dumbstruck 0.00465	short-tempered 0.00457	tutted 0.00457	crestfallen 0.00455	yelped 0.00452	inconsolable 0.00449	ornery 0.00444	hereupon 0.00434

Generated lemmatized results
***************
GENERATED	mad.a 1443 ::: hillarious;dumbstruck;tutted;crestfallen;yelped;inconsolable;ornery;hereupon;dumbfounded;scandalized

Filtered results
***************
RANKED	mad.a 1443	angry 0.00398	furious 0.00385	crazy 0.00364	annoyed 0.00362	frantic 0.00341	insane 0.00340	frenetic 0.00316	hurried 0.00307	fast 0.00279	rabid 0.00255	frenzied 0.00246	wild 0.00233	rapid 0.00207	uncontrolled 0.00200	pn 0.00163

Test context:
***************
mad.a	1444	4	if you want a __mad__ night out , find out when the party nights are on , they are the ones not to miss .
Contexts for target mad are: ['amodI_night']
Contexts in vocabulary for target mad are: ['amodI_night']
Top most similar embeddings: mad 0.49740	crazy 0.42822	barmy 0.40023	insane 0.38213	moonless 0.37855	maddest 0.37508	boozy 0.37415	drug-fuelled 0.37355	frantic 0.36525	god-awful 0.36255

Generated lemmatized results
***************
GENERATED	mad.a 1444 ::: crazy;barmy;insane;moonless;boozy;frantic;dreadful;wintery;godawful;fantasic

Filtered results
***************
RANKED	mad.a 1444	crazy 0.42822	insane 0.38213	frantic 0.36525	wild 0.34709	angry 0.33474	frenzied 0.33225	frenetic 0.32605	furious 0.32252	rabid 0.31563	fast 0.28526	uncontrolled 0.28486	annoyed 0.28385	hurried 0.27737	rapid 0.26434	pn 0.24738

Test context:
***************
mad.a	1445	34	the process of rendering animal waste into animal feed has been a massive and ongoing experiment in the creation of new tses , one of which emerged in britain in the mid 1980s as __mad__ cow disease , has clearly spread into humans claiming over fifty so far , and in my guess will in the years ahead be founded to have infected hundreds of thousands of britons .
Contexts for target mad are: ['amodI_disease']
Contexts in vocabulary for target mad are: ['amodI_disease']
Top most similar embeddings: mad 0.52749	crazy 0.39940	diverticular 0.39771	decompensated 0.37990	insane 0.37955	neuronopathic 0.37790	hemorrhagic 0.37519	intercurrent 0.37181	granulomatous 0.37095	obesity-related 0.37054

Generated lemmatized results
***************
GENERATED	mad.a 1445 ::: crazy;diverticular;decompensated;insane;neuronopathic;hemorrhagic;intercurrent;granulomatous;senile;tuberculous

Filtered results
***************
RANKED	mad.a 1445	crazy 0.39940	insane 0.37955	frantic 0.33907	rabid 0.33715	wild 0.31658	uncontrolled 0.31435	angry 0.30811	furious 0.29971	frenzied 0.29859	frenetic 0.29155	fast 0.29103	rapid 0.28128	annoyed 0.27836	hurried 0.27283	pn 0.25023

Test context:
***************
mad.a	1446	17	ibm 's once-disparaged mainframes are now mighty web servers for fortune 500 companies , and selling like __mad__ .
Contexts for target mad are: ['prep:likeI_selling']
Contexts in vocabulary for target mad are: ['prep:likeI_selling']
Top most similar embeddings: mad 0.51459	crazy 0.44085	hotcakes 0.39845	insane 0.37840	barmy 0.36528	bonkers 0.35221	dizzy 0.34406	dotty 0.34023	nutty 0.33831	cakes 0.33675

Generated lemmatized results
***************
GENERATED	mad.a 1446 ::: crazy;hotcakes;insane;barmy;bonkers;dizzy;dotty;nutty;cakes;nuts

Filtered results
***************
RANKED	mad.a 1446	crazy 0.44085	insane 0.37840	frantic 0.30988	frenzied 0.30541	furious 0.30162	angry 0.29934	wild 0.29487	rabid 0.29406	frenetic 0.26979	annoyed 0.25765	uncontrolled 0.24777	fast 0.24651	pn 0.23817	hurried 0.23129	rapid 0.22013

Test context:
***************
mad.a	1447	12	thomas son of thomas smith , in compton , bit by a __mad__ dog- " one wonders whether this might have been a case of rabies .
Contexts for target mad are: ['amodI_dog']
Contexts in vocabulary for target mad are: ['amodI_dog']
Top most similar embeddings: mad 0.53361	crazy 0.43704	three-headed 0.40496	scaredy 0.39356	crotchety 0.39145	one-legged 0.39138	insane 0.38825	long-haired 0.38762	short-haired 0.38680	hot-blooded 0.38643

Generated lemmatized results
***************
GENERATED	mad.a 1447 ::: crazy;scaredy;crotchety;insane;flatulent;moustachioed;longhaired;rascally;scrawny;podgy

Filtered results
***************
RANKED	mad.a 1447	crazy 0.43704	insane 0.38825	rabid 0.36964	angry 0.35327	frantic 0.35298	wild 0.34844	frenzied 0.34107	furious 0.33207	frenetic 0.31161	uncontrolled 0.30434	annoyed 0.30207	fast 0.30124	rapid 0.27544	hurried 0.27318	pn 0.23511

Test context:
***************
mad.a	1448	4	i first began investigating __mad__ cow type diseases in the early 1990s when i was working in wisconsin organizing farmers and consumers opposed to monsanto 's genetically engineered bovine growth hormone , the cattle equivalent of human growth hormone which when injected into cattle forced them to produce more milk .
Contexts for target mad are: ['amodI_diseases']
Contexts in vocabulary for target mad are: ['amodI_diseases']
Top most similar embeddings: mad 0.48042	non-communicable 0.37506	obesity-related 0.37447	crazy 0.37408	diverticular 0.37249	intercurrent 0.36993	diet-related 0.36894	smoking-related 0.36723	sexually-transmitted 0.36592	soil-borne 0.36565

Generated lemmatized results
***************
GENERATED	mad.a 1448 ::: crazy;diverticular;intercurrent;hemorrhagic;protozoal;pestilential;neuronopathic;insane;tuberculous;diarrhoeal

Filtered results
***************
RANKED	mad.a 1448	crazy 0.37408	insane 0.35834	frantic 0.32893	wild 0.32259	rabid 0.31935	angry 0.30938	uncontrolled 0.30204	furious 0.29080	frenzied 0.28982	frenetic 0.28801	fast 0.27818	annoyed 0.27284	rapid 0.27250	hurried 0.26876	pn 0.25067

Test context:
***************
mad.a	1449	19	if they want to come along to one of our shows and shake their heads and run around like __mad__ pigs , they can .
Contexts for target mad are: ['amodI_pigs']
Contexts in vocabulary for target mad are: ['amodI_pigs']
Top most similar embeddings: mad 0.48799	crazy 0.41196	insane 0.38819	pure-bred 0.38601	factory-farmed 0.37866	four-footed 0.37413	scaredy 0.37227	man-eating 0.37107	purebred 0.37075	hand-reared 0.37048

Generated lemmatized results
***************
GENERATED	mad.a 1449 ::: crazy;insane;scaredy;purebred;longhaired;flatulent;demented;scrawny;headless;frisky

Filtered results
***************
RANKED	mad.a 1449	crazy 0.41196	insane 0.38819	wild 0.35901	rabid 0.34453	angry 0.34443	frantic 0.33221	frenzied 0.32559	furious 0.31708	frenetic 0.30223	uncontrolled 0.30205	annoyed 0.29380	fast 0.27625	hurried 0.26638	rapid 0.24379	pn 0.24303

Test context:
***************
mad.a	1450	34	jennifer kelly or amy leska , ems 202/463-6670 washington , d.c. public health advocates are demanding that the food and drug administration close loopholes in animal feed regulations to prevent the spread of u.s. __mad__ cow-type diseases now at epidemic levels in western deer and elk that might infect people who eat meat .
Contexts for target mad are: ['amodI_diseases']
Contexts in vocabulary for target mad are: ['amodI_diseases']
Top most similar embeddings: mad 0.48042	non-communicable 0.37506	obesity-related 0.37447	crazy 0.37408	diverticular 0.37249	intercurrent 0.36993	diet-related 0.36894	smoking-related 0.36723	sexually-transmitted 0.36592	soil-borne 0.36565

Generated lemmatized results
***************
GENERATED	mad.a 1450 ::: crazy;diverticular;intercurrent;hemorrhagic;protozoal;pestilential;neuronopathic;insane;tuberculous;diarrhoeal

Filtered results
***************
RANKED	mad.a 1450	crazy 0.37408	insane 0.35834	frantic 0.32893	wild 0.32259	rabid 0.31935	angry 0.30938	uncontrolled 0.30204	furious 0.29080	frenzied 0.28982	frenetic 0.28801	fast 0.27818	annoyed 0.27284	rapid 0.27250	hurried 0.26876	pn 0.25067

Test context:
***************
make.v	1451	17	no one can bear to think that , less than an hour later , the person who __made__ it is dead .
Contexts for target made are: ['nsubj_who', 'rcmodI_person', 'xcomp_dead']
Contexts in vocabulary for target made are: ['nsubj_who', 'rcmodI_person', 'xcomp_dead']
Top most similar embeddings: made 0.11111	professes 0.09809	wants 0.09794	covets 0.09522	harasses 0.09466	wished 0.09384	feareth 0.09330	detests 0.09300	disobeys 0.09238	procures 0.09089

Generated lemmatized results
***************
GENERATED	make.v 1451 ::: profess;want;covet;harass;wish;feareth;detest;disobey;procure;detain

Filtered results
***************
RANKED	make.v 1451	commit 0.08722	have 0.08292	turn 0.08139	help 0.08076	write 0.07923	cause 0.07885	complete 0.07848	take 0.07748	succeed 0.07746	initiate 0.07587	create 0.07398	perform 0.07331	do 0.07238	produce 0.07200	reach 0.07143	compel 0.06948	change 0.06780	form 0.06675	affect 0.06574	construct 0.06403	generate 0.06095

Test context:
***************
make.v	1452	5	here are some tips to __make__ yours stand out : catch the editor 's attention with your first sentence .
Contexts for target make are: ['aux_to', 'infmodI_tips', 'ccomp_stand']
Contexts in vocabulary for target make are: ['aux_to', 'infmodI_tips', 'ccomp_stand']
Top most similar embeddings: make 0.14396	ensure 0.10038	help 0.09530	relearn 0.09372	keep 0.09045	consider 0.09039	civilize 0.09018	wheedle 0.08981	reassure 0.08977	create 0.08967

Generated lemmatized results
***************
GENERATED	make.v 1452 ::: ensure;help;relearn;keep;consider;civilize;wheedle;reassure;create;fatten

Filtered results
***************
RANKED	make.v 1452	help 0.09530	create 0.08967	generate 0.08115	take 0.08095	do 0.08088	write 0.08041	succeed 0.08032	perform 0.07780	initiate 0.07768	produce 0.07727	compel 0.07271	turn 0.07134	commit 0.07090	construct 0.07033	reach 0.06998	complete 0.06901	have 0.06698	affect 0.06496	change 0.06277	cause 0.05980	form 0.05577

Test context:
***************
make.v	1453	23	" lavish use of water in the arid west extends from california through oregon and into washington , and hogan believes gardeners should __make__ clear decisions about how much water they need to use in their gardens and plants .
Contexts for target make are: ['nsubj_gardeners', 'aux_should', 'ccompI_believes', 'dobj_decisions']
Contexts in vocabulary for target make are: ['nsubj_gardeners', 'aux_should', 'ccompI_believes', 'dobj_decisions']
Top most similar embeddings: make 0.06171	adopt 0.04445	pre-judge 0.04393	over-rule 0.04326	discourage 0.04206	take 0.04192	reconsider 0.04181	re-consider 0.04142	second-guess 0.04094	misconstrue 0.04076

Generated lemmatized results
***************
GENERATED	make.v 1453 ::: adopt;discourage;take;reconsider;misconstrue;underpin;consider;encourage;forgo;regulate

Filtered results
***************
RANKED	make.v 1453	take 0.04192	have 0.03723	create 0.03715	reach 0.03659	help 0.03584	initiate 0.03569	produce 0.03564	generate 0.03541	compel 0.03538	affect 0.03459	perform 0.03406	succeed 0.03384	commit 0.03377	do 0.03219	write 0.03168	turn 0.03064	complete 0.02964	change 0.02963	construct 0.02933	cause 0.02878	form 0.02835

Test context:
***************
make.v	1454	8	he willingly signed the checks when the eagles __made__ a super bowl-or-bust push last offseason with a pair of uncharacteristically high-profile acquisitions : wide receiver terrell owens and defensive end jevon kearse .
Contexts for target made are: ['advmod_when', 'nsubj_eagles', 'advclI_signed', 'dobj_push']
Contexts in vocabulary for target made are: ['advmod_when', 'nsubj_eagles', 'advclI_signed', 'dobj_push']
Top most similar embeddings: made 0.04999	re-signed 0.04309	gatecrashed 0.04253	began 0.04175	resumed 0.04137	scored 0.04132	stalled 0.04100	netted 0.04099	launched 0.04095	fluffed 0.04086

Generated lemmatized results
***************
GENERATED	make.v 1454 ::: gatecrashed;begin;resume;score;stall;net;launch;fluff;miscued;give

Filtered results
***************
RANKED	make.v 1454	complete 0.03915	take 0.03890	turn 0.03669	reach 0.03668	form 0.03540	create 0.03514	have 0.03451	do 0.03434	perform 0.03403	initiate 0.03400	succeed 0.03285	help 0.03200	produce 0.03192	write 0.03176	cause 0.03088	construct 0.03060	change 0.03026	commit 0.03013	compel 0.02900	generate 0.02878	affect 0.02851

Test context:
***************
make.v	1455	22	this reflective work should constitute your meditation work in the future ; it will condition your interior development and will also inevitably __make__ your outer work more dynamic .
Contexts for target make are: ['aux_will', 'advmod_also', 'advmod_inevitably', 'conjI_condition', 'xcomp_dynamic']
Contexts in vocabulary for target make are: ['aux_will', 'advmod_also', 'advmod_inevitably', 'conjI_condition', 'xcomp_dynamic']
Top most similar embeddings: make 0.02397	complicate 0.02008	affect 0.01970	necessitate 0.01944	require 0.01937	predispose 0.01937	constrain 0.01921	worsen 0.01896	involve 0.01887	endanger 0.01882

Generated lemmatized results
***************
GENERATED	make.v 1455 ::: complicate;affect;necessitate;require;predispose;constrain;worsen;involve;endanger;tend

Filtered results
***************
RANKED	make.v 1455	affect 0.01970	cause 0.01708	generate 0.01597	create 0.01567	produce 0.01556	compel 0.01551	have 0.01503	perform 0.01467	help 0.01429	change 0.01414	succeed 0.01414	initiate 0.01368	reach 0.01356	take 0.01334	commit 0.01296	turn 0.01293	complete 0.01249	construct 0.01210	write 0.01195	form 0.01169	do 0.01054

Test context:
***************
make.v	1456	14	there are a number of errors that experienced inform coders are less likely to __make__ , such as " you have so far scored 0 out of a possible 0 , in 36 turns " in response to score .
Contexts for target make are: ['aux_to', 'xcompI_likely', 'punct_,', 'advcl_have']
Contexts in vocabulary for target make are: ['aux_to', 'xcompI_likely', 'punct_,', 'advcl_have']
Top most similar embeddings: make 0.06031	miscarry 0.04917	overeat 0.04902	prevaricate 0.04874	abscond 0.04872	overreact 0.04872	undersell 0.04856	reoffend 0.04845	vacillate 0.04838	under-perform 0.04828

Generated lemmatized results
***************
GENERATED	make.v 1456 ::: miscarry;overeat;prevaricate;abscond;overreact;undersell;reoffend;vacillate;understate;misbehave

Filtered results
***************
RANKED	make.v 1456	succeed 0.04654	take 0.04533	generate 0.04434	create 0.04355	have 0.04275	commit 0.04250	initiate 0.04234	produce 0.04204	write 0.04088	perform 0.04021	compel 0.04009	do 0.03979	affect 0.03953	cause 0.03734	reach 0.03711	turn 0.03687	help 0.03687	change 0.03544	construct 0.03491	complete 0.03488	form 0.02891

Test context:
***************
make.v	1457	35	) , james meister , rc , isabelle , dave - all of you have made truly excellent posts , but lately i find myself quickly reaching aldous ' rather acerbic viewpoint - i 'll __make__ a couple of impassioned posts based on solid facts , but then it 'll suddenly sink in with a sickening thud that we are in fact often hitting a solid brick wall of denial - with absolutely no chance of breaking through .
Contexts for target make are: ['dep_acerbic', 'dep_viewpoint', 'punct_-', 'nsubj_i', "aux_'ll", 'dobjI_reaching', 'dobj_couple']
Contexts in vocabulary for target make are: ['dep_viewpoint', 'punct_-', 'nsubj_i', "aux_'ll", 'dobjI_reaching', 'dobj_couple']
Top most similar embeddings: shush 0.01154	re-shoot 0.01120	freeze-frame 0.01111	nab 0.01095	gether 0.01086	pootle 0.01043	make 0.01036	grab 0.01028	rememeber 0.01023	kep 0.01020

Generated lemmatized results
***************
GENERATED	make.v 1457 ::: shush;nab;gether;pootle;grab;rememeber;kep;divvy;bung;smoko

Filtered results
***************
RANKED	make.v 1457	turn 0.00912	have 0.00864	change 0.00854	write 0.00850	take 0.00849	reach 0.00799	construct 0.00778	complete 0.00763	create 0.00759	commit 0.00753	help 0.00747	perform 0.00740	succeed 0.00737	form 0.00732	do 0.00726	affect 0.00724	produce 0.00718	generate 0.00702	initiate 0.00685	compel 0.00669	cause 0.00649

Test context:
***************
make.v	1458	16	i have wished since that i had said more , said something that could perhaps have __made__ a great burden a little easier for that brave and tortured soul .
Contexts for target made are: ['nsubjpass_that', 'aux_could', 'advmod_perhaps', 'aux_have', 'rcmodI_something', 'dobj_burden']
Contexts in vocabulary for target made are: ['nsubjpass_that', 'aux_could', 'advmod_perhaps', 'aux_have', 'rcmodI_something', 'dobj_burden']
Top most similar embeddings: forseen 0.01302	avoided 0.01225	foreseen 0.01224	shirked 0.01166	made 0.01163	obviated 0.01145	imagined 0.01124	done 0.01092	overlooked 0.01088	attributed 0.01076

Generated lemmatized results
***************
GENERATED	make.v 1458 ::: forseen;avoid;foresee;shirk;obviate;imagine;do;overlook;attribute;spar

Filtered results
***************
RANKED	make.v 1458	do 0.01092	cause 0.01030	take 0.00970	create 0.00954	change 0.00942	affect 0.00879	help 0.00874	reach 0.00861	generate 0.00837	initiate 0.00829	turn 0.00820	construct 0.00818	produce 0.00814	compel 0.00811	write 0.00797	perform 0.00769	form 0.00760	succeed 0.00755	complete 0.00718	commit 0.00716	have 0.00688

Test context:
***************
make.v	1459	2	these errors __made__ me wonder which other facts you had presented with a sensationalistic skew , or skipped completely .
Contexts for target made are: ['nsubj_errors', 'rootI_*root*', 'xcomp_wonder']
Contexts in vocabulary for target made are: ['nsubj_errors', 'rootI_*root*', 'xcomp_wonder']
Top most similar embeddings: made 0.11832	makes 0.09558	occurred 0.09489	caused 0.09189	began 0.09162	crept 0.09104	make 0.09063	occur 0.09045	prompted 0.08908	occured 0.08907

Generated lemmatized results
***************
GENERATED	make.v 1459 ::: occur;cause;begin;creep;prompt;lead;start;tend;stop;arise

Filtered results
***************
RANKED	make.v 1459	cause 0.09189	have 0.08062	turn 0.07917	take 0.07690	help 0.07622	initiate 0.07574	produce 0.07385	reach 0.07350	write 0.07339	generate 0.07298	change 0.07257	compel 0.07178	affect 0.07153	create 0.07148	form 0.07104	succeed 0.06903	complete 0.06756	do 0.06678	commit 0.06553	construct 0.06529	perform 0.06433

Test context:
***************
make.v	1460	30	the trip over was quite easy , i had a tail wind the whole way and the thermals were all strong and easy to find , this is where i __made__ my first major mistake !
Contexts for target made are: ['advmod_where', 'nsubj_i', 'ccompI_is', 'dobj_mistake']
Contexts in vocabulary for target made are: ['advmod_where', 'nsubj_i', 'ccompI_is', 'dobj_mistake']
Top most similar embeddings: made 0.09324	make 0.06805	makes 0.06795	misinterprets 0.06030	see/hear 0.05847	crystallizes 0.05838	preempted 0.05818	find 0.05808	disallows 0.05799	found 0.05794

Generated lemmatized results
***************
GENERATED	make.v 1460 ::: misinterpret;crystallize;preempt;find;disallow;prevent;contemplate;countermand;transgress;discover

Filtered results
***************
RANKED	make.v 1460	commit 0.05518	do 0.05394	cause 0.05375	take 0.05319	create 0.05239	have 0.05230	turn 0.05172	produce 0.05081	compel 0.05064	reach 0.05054	construct 0.04997	change 0.04986	initiate 0.04908	form 0.04858	succeed 0.04841	perform 0.04812	generate 0.04761	write 0.04753	help 0.04702	affect 0.04546	complete 0.04335

Test context:
***************
mission.n	1461	14	" something will hopefully be done " , to ensure that even if the __mission__ were to close tomorrow , fm103 " continues in some form or sort , to consolidate the peace process .
Contexts for target mission are: ['det_the', 'nsubjI_were']
Contexts in vocabulary for target mission are: ['det_the', 'nsubjI_were']
Top most similar embeddings: mission 0.22377	missions 0.20844	augustinians 0.18998	argives 0.18268	lacedaemonians 0.18250	rockefellers 0.18248	salesians 0.18190	maroons 0.18105	apaches 0.18076	moravians 0.18053

Generated lemmatized results
***************
GENERATED	mission.n 1461 ::: augustinian;argive;lacedaemonians;rockefeller;salesians;maroon;apache;moravians;summiteers;seasiders

Filtered results
***************
RANKED	mission.n 1461	objective 0.17673	aim 0.16349	purpose 0.16251	quest 0.16121	task 0.15965	duty 0.15893	calling 0.15829	church 0.15744	delegation 0.15572	arrival 0.15404	operation 0.15355	vocation 0.15338	negotiation 0.15269	legation 0.15088	office 0.14401	assignment 0.14222	project 0.14087	preaching 0.13963	oratory 0.13855	charity 0.13239	outreach 0.13156	work 0.12405	evangelical 0.12006	ministering 0.11336

Test context:
***************
mission.n	1462	11	" what we 're seeing over time is the equivalent of __mission__ creep : cases that would not be terrorism cases before sept. 11 are swept onto the terrorism docket , " said juliette kayyem , a former clinton administration justice official who heads the national security program at harvard university 's john f. kennedy school of government .
Contexts for target mission are: ['nnI_creep']
Contexts in vocabulary for target mission are: ['nnI_creep']
Top most similar embeddings: mission 0.54510	missions 0.41570	spacecraft 0.34565	remit 0.33711	crusade 0.33636	sortie 0.33597	envisat 0.33174	sfor 0.33026	exomars 0.32928	ecumenism 0.32814

Generated lemmatized results
***************
GENERATED	mission.n 1462 ::: spacecraft;remit;crusade;sortie;envisat;sfor;exomars;ecumenism;purpose;mothership

Filtered results
***************
RANKED	mission.n 1462	purpose 0.32729	task 0.32434	objective 0.32061	quest 0.31840	vocation 0.31037	duty 0.31027	project 0.30791	aim 0.30512	church 0.30236	preaching 0.30056	operation 0.29454	outreach 0.29290	assignment 0.28394	evangelical 0.28016	negotiation 0.27409	delegation 0.27018	legation 0.26335	oratory 0.26306	arrival 0.26248	charity 0.25820	calling 0.25550	office 0.25540	ministering 0.25264	work 0.23967

Test context:
***************
mission.n	1463	24	and are we doing it in a way that keeps us competitive economically? " his question defined his passion , my stewardship and the __mission__ of the environmental protection agency .
Contexts for target mission are: ['det_the', 'conjI_passion', 'prep:of_agency']
Contexts in vocabulary for target mission are: ['det_the', 'conjI_passion', 'prep:of_agency']
Top most similar embeddings: mission 0.11871	purpose 0.08939	missions 0.08932	charism 0.08811	ethos 0.08531	creativeness 0.08425	ministry 0.08354	ardor 0.08259	ambition 0.08252	remit 0.08241

Generated lemmatized results
***************
GENERATED	mission.n 1463 ::: purpose;charism;ethos;creativeness;ministry;ardor;ambition;remit;vision;professionalism

Filtered results
***************
RANKED	mission.n 1463	purpose 0.08939	vocation 0.08037	task 0.07693	objective 0.07685	quest 0.07628	aim 0.07591	duty 0.07453	operation 0.07262	delegation 0.06925	arrival 0.06911	oratory 0.06792	office 0.06780	preaching 0.06690	project 0.06663	calling 0.06412	work 0.06315	church 0.06283	outreach 0.06244	assignment 0.06225	legation 0.06096	charity 0.05990	negotiation 0.05847	evangelical 0.05242	ministering 0.05107

Test context:
***************
mission.n	1464	10	local churches reproduce themselves in their neighborhood and on the __mission__ field .
Contexts for target mission are: ['nnI_field']
Contexts in vocabulary for target mission are: ['nnI_field']
Top most similar embeddings: mission 0.51874	missions 0.40599	mangala 0.36855	horseley 0.35192	apostolate 0.34796	flodden 0.34769	shobnall 0.34375	apton 0.34213	oiwfs 0.34207	iar 0.34071

Generated lemmatized results
***************
GENERATED	mission.n 1464 ::: mangala;horseley;apostolate;flodden;shobnall;apton;oiwfs;iar;xlfd;spacecraft

Filtered results
***************
RANKED	mission.n 1464	quest 0.32718	purpose 0.32118	task 0.32005	vocation 0.31424	operation 0.31236	objective 0.31053	outreach 0.30600	church 0.30285	assignment 0.30042	duty 0.29949	project 0.29767	legation 0.29655	preaching 0.29422	aim 0.28729	delegation 0.28531	charity 0.27953	office 0.27446	arrival 0.27394	oratory 0.27231	evangelical 0.26871	calling 0.26819	ministering 0.26645	negotiation 0.25661	work 0.25442

Test context:
***************
mission.n	1465	31	" 52 the method of al imam al shafi'i in his book , al risalah al imam al shafi'i began his book by describing the state of mankind just before the __mission__ of the prophet .
Contexts for target mission are: ['det_the', 'prep:beforeI_describing', 'prep:of_prophet']
Contexts in vocabulary for target mission are: ['det_the', 'prep:of_prophet']
Top most similar embeddings: mission 0.25607	missions 0.19783	apostolate 0.19433	charism 0.19088	kerygma 0.18738	sunnah 0.18727	gospell 0.18331	parousia 0.18254	sunna 0.18229	imamate 0.18213

Generated lemmatized results
***************
GENERATED	mission.n 1465 ::: apostolate;charism;kerygma;sunnah;gospell;parousia;sunna;imamate;charisms;shahadah

Filtered results
***************
RANKED	mission.n 1465	task 0.17537	quest 0.17311	purpose 0.17279	vocation 0.17247	legation 0.16777	aim 0.16019	objective 0.15928	preaching 0.15900	office 0.15844	church 0.15813	calling 0.15648	duty 0.15323	operation 0.15167	arrival 0.15031	assignment 0.14924	project 0.14788	delegation 0.14664	oratory 0.14569	outreach 0.13432	charity 0.13231	work 0.13061	ministering 0.12988	negotiation 0.12563	evangelical 0.12273

Test context:
***************
mission.n	1466	15	there are many important and urgent responsibilities to attract the missionary 's attention on the __mission__ field , e.g. adult literacy. social and developmental projects , educational and medical work .
Contexts for target mission are: ['nnI_field']
Contexts in vocabulary for target mission are: ['nnI_field']
Top most similar embeddings: mission 0.51874	missions 0.40599	mangala 0.36855	horseley 0.35192	apostolate 0.34796	flodden 0.34769	shobnall 0.34375	apton 0.34213	oiwfs 0.34207	iar 0.34071

Generated lemmatized results
***************
GENERATED	mission.n 1466 ::: mangala;horseley;apostolate;flodden;shobnall;apton;oiwfs;iar;xlfd;spacecraft

Filtered results
***************
RANKED	mission.n 1466	quest 0.32718	purpose 0.32118	task 0.32005	vocation 0.31424	operation 0.31236	objective 0.31053	outreach 0.30600	church 0.30285	assignment 0.30042	duty 0.29949	project 0.29767	legation 0.29655	preaching 0.29422	aim 0.28729	delegation 0.28531	charity 0.27953	office 0.27446	arrival 0.27394	oratory 0.27231	evangelical 0.26871	calling 0.26819	ministering 0.26645	negotiation 0.25661	work 0.25442

Test context:
***************
mission.n	1467	19	e-mail to : methodius baptist union of great britain - archive of mission-related dissertations with a focus on baptist __mission__ in the uk e-mail to : darrell jackson , mission adviser bethany christian services ( bcs ) - bcs is a non-profit organization with a mission to protect and enhance the lives of children and individuals through professional social services like int. and dom. adoption , counseling ( pregnancy+family ) foster care and a 1-800-bethany hotline .
Contexts for target mission are: ['amod_baptist', 'prep:onI_focus', 'prep:in_e-mail']
Contexts in vocabulary for target mission are: ['amod_baptist', 'prep:onI_focus', 'prep:in_e-mail']
Top most similar embeddings: mission 0.10729	missions 0.09005	ecumenism 0.07704	evangelism 0.07431	ecclesiology 0.07385	distinctives 0.07206	discipleship 0.07174	spirituality 0.07091	missiology 0.06967	self-understanding 0.06879

Generated lemmatized results
***************
GENERATED	mission.n 1467 ::: ecumenism;evangelism;ecclesiology;distinctives;discipleship;spirituality;missiology;identity;christology;origin

Filtered results
***************
RANKED	mission.n 1467	vocation 0.06761	church 0.06579	task 0.06253	outreach 0.06239	calling 0.06154	quest 0.06105	preaching 0.06094	objective 0.06056	operation 0.06002	duty 0.05920	purpose 0.05900	delegation 0.05636	evangelical 0.05554	oratory 0.05518	charity 0.05485	arrival 0.05477	aim 0.05462	assignment 0.05317	office 0.05295	ministering 0.05285	project 0.05243	legation 0.05241	negotiation 0.05116	work 0.04300

Test context:
***************
mission.n	1468	17	nk : we are the children of the hippie generation and girl has been imbued with this __mission__ from her mother from a very young age .
Contexts for target mission are: ['det_this', 'prep:withI_imbued', 'prep:from_mother']
Contexts in vocabulary for target mission are: ['det_this', 'prep:withI_imbued', 'prep:from_mother']
Top most similar embeddings: mission 0.09631	charism 0.08610	aloofness 0.07999	detachment 0.07952	aspiration 0.07763	separateness 0.07715	life-force 0.07702	message 0.07619	filiation 0.07559	instinct 0.07536

Generated lemmatized results
***************
GENERATED	mission.n 1468 ::: charism;aloofness;detachment;aspiration;separateness;message;filiation;instinct;unction;exclusiveness

Filtered results
***************
RANKED	mission.n 1468	purpose 0.07411	vocation 0.07068	quest 0.06615	objective 0.06476	preaching 0.06458	duty 0.06411	assignment 0.06259	delegation 0.06227	task 0.06219	aim 0.06091	oratory 0.05796	operation 0.05777	project 0.05678	arrival 0.05483	outreach 0.05474	charity 0.05435	church 0.05269	evangelical 0.05253	legation 0.05158	calling 0.05154	office 0.05022	negotiation 0.04960	ministering 0.04919	work 0.04873

Test context:
***************
mission.n	1469	17	c. operational role of weu weu 's operational role will be strengthened by examining and defining appropriate __missions__ , structures and means , covering in particular : weu planning cell ; closer military cooperation complementary to the alliance in particular in the fields of logistics , transport , training and strategic surveillance ; meetings of weu chiefs of defence staff ; military units answerable to weu .
Contexts for target missions are: ['amod_appropriate', 'dobjI_examining', 'punct_,', 'conj_structures', 'cc_and', 'conj_means']
Contexts in vocabulary for target missions are: ['amod_appropriate', 'dobjI_examining', 'punct_,', 'conj_structures', 'cc_and', 'conj_means']
Top most similar embeddings: missions 0.01023	alphabets 0.00983	fluorophores 0.00975	methodologies 0.00972	pedagogies 0.00958	guardrails 0.00956	remits 0.00950	letterforms 0.00949	timelines 0.00947	structures 0.00947

Generated lemmatized results
***************
GENERATED	mission.n 1469 ::: alphabet;fluorophores;methodology;pedagogy;guardrail;remit;letterforms;timeline;structure;stance

Filtered results
***************
RANKED	mission.n 1469	assignment 0.00799	quest 0.00799	vocation 0.00761	objective 0.00729	negotiation 0.00715	church 0.00702	task 0.00699	calling 0.00691	operation 0.00674	duty 0.00659	delegation 0.00647	project 0.00634	outreach 0.00631	preaching 0.00622	aim 0.00620	charity 0.00619	oratory 0.00612	office 0.00605	work 0.00604	purpose 0.00592	evangelical 0.00481	ministering 0.00478	arrival 0.00472	legation 0.00384

Test context:
***************
mission.n	1470	11	that said , the best foundations are focused on accomplishing programmatic __missions__ .
Contexts for target missions are: ['nn_accomplishing', 'amod_programmatic', 'prep:onI_focused']
Contexts in vocabulary for target missions are: ['amod_programmatic', 'prep:onI_focused']
Top most similar embeddings: missions 0.24263	mission 0.20481	tasks 0.17712	quests 0.17028	goals 0.16883	experimentations 0.16859	inculturation 0.16783	objectives 0.16624	verifiability 0.16598	activities 0.16557

Generated lemmatized results
***************
GENERATED	mission.n 1470 ::: task;quest;goal;experimentation;inculturation;objective;verifiability;activity;intervention;distinctives

Filtered results
***************
RANKED	mission.n 1470	task 0.17712	quest 0.17028	objective 0.16624	assignment 0.16110	project 0.15869	operation 0.15722	vocation 0.15286	negotiation 0.15112	outreach 0.14929	calling 0.14316	duty 0.14121	purpose 0.14007	delegation 0.13329	aim 0.13321	work 0.13106	church 0.13073	preaching 0.13069	oratory 0.12522	office 0.12306	charity 0.12041	arrival 0.11422	evangelical 0.11238	legation 0.10221	ministering 0.10001

Test context:
***************
near.r	1471	20	therefore , while significant dry and wet periods will persist , it is felt that overall , rainfall will average __near__ normal to above .
Contexts for target near are: []
Contexts in vocabulary for target near are: []
Top most similar embeddings: near 1.00000	not-too-distant 0.71075	nearer 0.69398	nearest 0.67912	close 0.67480	beside 0.67106	nigh 0.67018	on 0.66630	adjacent 0.66613	neare 0.66512

Generated lemmatized results
***************
GENERATED	near.r 1471 ::: nearer;nearest;close;beside;nigh;on;adjacent;neare;across;geosynchronous

Filtered results
***************
RANKED	near.r 1471	close 0.67480	approaching 0.62907	about 0.62084	alongside 0.61803	nearly 0.60615	adjoining 0.60380	neighbouring 0.59896	approximately 0.59613	closely 0.58781	virtually 0.58038	almost 0.57923	practically 0.57142

Test context:
***************
near.r	1472	3	they may fly __near__ and wonder what ever possessed you to buy one , but do n't take that for rent sign down just yet because they wo n't move in .
Contexts for target near are: ['advmodI_fly']
Contexts in vocabulary for target near are: ['advmodI_fly']
Top most similar embeddings: near 0.48386	temptingly 0.34990	proably 0.34841	nearer 0.34623	around 0.34424	sedately 0.33843	prosperously 0.33648	noiselessly 0.33640	close 0.33541	across 0.33516

Generated lemmatized results
***************
GENERATED	near.r 1472 ::: temptingly;proably;nearer;around;sedately;prosperously;noiselessly;close;across;glacially

Filtered results
***************
RANKED	near.r 1472	close 0.33541	about 0.30366	alongside 0.30001	nearly 0.29395	virtually 0.29255	practically 0.29064	almost 0.28047	approximately 0.27948	closely 0.27305	adjoining 0.26325	approaching 0.25942	neighbouring 0.24885

Test context:
***************
near.r	1473	13	temperatures were below normal the first half of june , but warmed to __near__ normal in the second half .
Contexts for target near are: ['pcompI_to']
Contexts in vocabulary for target near are: ['pcompI_to']
Top most similar embeddings: near 0.52489	within 0.35776	in 0.34833	beside 0.34539	nearer 0.34451	glenridding 0.34446	around 0.34248	amid 0.34198	austin.gardening 0.33841	ionizing 0.33786

Generated lemmatized results
***************
GENERATED	near.r 1473 ::: within;in;beside;nearer;glenridding;around;amid;ionizing;among;on

Filtered results
***************
RANKED	near.r 1473	approaching 0.32142	about 0.31417	close 0.30606	alongside 0.30344	neighbouring 0.30210	adjoining 0.27841	nearly 0.27498	approximately 0.26255	practically 0.25916	virtually 0.25633	closely 0.25528	almost 0.24795

Test context:
***************
near.r	1474	5	fortunately , the tire is __near__ cut proof with a 4ply , 370tpi casing , and i never once had a flat tire in 1500 miles despite riding through glass , sand , and scoria rock on and off paved roads .
Contexts for target near are: []
Contexts in vocabulary for target near are: []
Top most similar embeddings: near 1.00000	not-too-distant 0.71075	nearer 0.69398	nearest 0.67912	close 0.67480	beside 0.67106	nigh 0.67018	on 0.66630	adjacent 0.66613	neare 0.66512

Generated lemmatized results
***************
GENERATED	near.r 1474 ::: nearer;nearest;close;beside;nigh;on;adjacent;neare;across;geosynchronous

Filtered results
***************
RANKED	near.r 1474	close 0.67480	approaching 0.62907	about 0.62084	alongside 0.61803	nearly 0.60615	adjoining 0.60380	neighbouring 0.59896	approximately 0.59613	closely 0.58781	virtually 0.58038	almost 0.57923	practically 0.57142

Test context:
***************
near.r	1475	15	once within , the noise made by the shod hooves of the great horses was __near__ deafening .
Contexts for target near are: []
Contexts in vocabulary for target near are: []
Top most similar embeddings: near 1.00000	not-too-distant 0.71075	nearer 0.69398	nearest 0.67912	close 0.67480	beside 0.67106	nigh 0.67018	on 0.66630	adjacent 0.66613	neare 0.66512

Generated lemmatized results
***************
GENERATED	near.r 1475 ::: nearer;nearest;close;beside;nigh;on;adjacent;neare;across;geosynchronous

Filtered results
***************
RANKED	near.r 1475	close 0.67480	approaching 0.62907	about 0.62084	alongside 0.61803	nearly 0.60615	adjoining 0.60380	neighbouring 0.59896	approximately 0.59613	closely 0.58781	virtually 0.58038	almost 0.57923	practically 0.57142

Test context:
***************
near.r	1476	30	examples given in this paper assume the bad eye is totally blind and that the good eye has a normal visual field and acuity that is correctible to normal or __near__ normal .
Contexts for target near are: ['conjI_normal']
Contexts in vocabulary for target near are: ['conjI_normal']
Top most similar embeddings: near 0.50116	leukaemic 0.34575	neoplastic 0.33839	hyperplastic 0.33506	premalignant 0.33265	underactive 0.33188	abnormal 0.33150	normal 0.32998	dysplastic 0.32957	axillary 0.32849

Generated lemmatized results
***************
GENERATED	near.r 1476 ::: leukaemic;neoplastic;hyperplastic;premalignant;underactive;abnormal;normal;dysplastic;axillary;leukemic

Filtered results
***************
RANKED	near.r 1476	close 0.31208	approaching 0.28155	alongside 0.27779	neighbouring 0.27128	about 0.26791	adjoining 0.26715	practically 0.25979	nearly 0.25971	virtually 0.25039	closely 0.24859	approximately 0.24153	almost 0.23801

Test context:
***************
near.r	1477	24	having helped convert most of the warsaw pact into well-functioning democracies , the eu has the capacity repeat its success in its new " __near__ abroad " .
Contexts for target near are: ['amod_new', "punct_''", "punct_''"]
Contexts in vocabulary for target near are: ['amod_new']
Top most similar embeddings: near 0.41784	dancehouse 0.32817	square-foot 0.32546	scanias 0.32458	a120 0.32436	almera 0.32413	york-based 0.32246	princesshay 0.32084	5-series 0.31996	frenchgate 0.31994

Generated lemmatized results
***************
GENERATED	near.r 1477 ::: dancehouse;scanias;almera;princesshay;frenchgate;twikicontributor;minisatellite;axim;zeland;brenna

Filtered results
***************
RANKED	near.r 1477	close 0.27940	adjoining 0.27891	approaching 0.25827	alongside 0.25501	nearly 0.25243	about 0.25107	virtually 0.25068	neighbouring 0.25054	practically 0.24778	closely 0.24274	almost 0.24108	approximately 0.23223

Test context:
***************
near.r	1478	5	as that ship was drawing __near__ , the stern of no. 34 rose suddenly , and she sank .
Contexts for target near are: ['advmodI_drawing']
Contexts in vocabulary for target near are: ['advmodI_drawing']
Top most similar embeddings: near 0.52921	nearer 0.35974	temptingly 0.34256	close 0.34027	nigh 0.33976	promiscuously 0.33774	deviously 0.33741	dexterously 0.33686	shallowly 0.33600	proably 0.33431

Generated lemmatized results
***************
GENERATED	near.r 1478 ::: nearer;temptingly;close;nigh;promiscuously;deviously;dexterously;shallowly;proably;closer

Filtered results
***************
RANKED	near.r 1478	close 0.34027	alongside 0.30099	closely 0.29637	nearly 0.29226	about 0.28764	almost 0.28325	practically 0.28182	virtually 0.27719	approximately 0.27203	adjoining 0.25264	approaching 0.25090	neighbouring 0.23751

Test context:
***************
near.r	1479	20	it is still voice-centric at a time when data usage is gaining fast , a conversion that 3g can nowhere __near__ fully accommodate .
Contexts for target near are: ['advmodI_accommodate']
Contexts in vocabulary for target near are: ['advmodI_accommodate']
Top most similar embeddings: near 0.47026	feasibly 0.34152	proably 0.32664	easilly 0.32519	dexterously 0.32430	stably 0.32426	apprently 0.32425	frugally 0.32404	legislatively 0.32361	nearer 0.32344

Generated lemmatized results
***************
GENERATED	near.r 1479 ::: feasibly;proably;easilly;dexterously;stably;apprently;frugally;legislatively;nearer;inconspicuously

Filtered results
***************
RANKED	near.r 1479	close 0.30449	practically 0.28700	approximately 0.28400	closely 0.28344	about 0.28132	alongside 0.27992	nearly 0.27601	virtually 0.27347	almost 0.26830	adjoining 0.25869	neighbouring 0.24359	approaching 0.23987

Test context:
***************
near.r	1480	4	you know i damn __near__ puke every time i look at her .
Contexts for target near are: []
Contexts in vocabulary for target near are: []
Top most similar embeddings: near 1.00000	not-too-distant 0.71075	nearer 0.69398	nearest 0.67912	close 0.67480	beside 0.67106	nigh 0.67018	on 0.66630	adjacent 0.66613	neare 0.66512

Generated lemmatized results
***************
GENERATED	near.r 1480 ::: nearer;nearest;close;beside;nigh;on;adjacent;neare;across;geosynchronous

Filtered results
***************
RANKED	near.r 1480	close 0.67480	approaching 0.62907	about 0.62084	alongside 0.61803	nearly 0.60615	adjoining 0.60380	neighbouring 0.59896	approximately 0.59613	closely 0.58781	virtually 0.58038	almost 0.57923	practically 0.57142

Test context:
***************
open.a	1481	4	a coffee/snack cart is __open__ in the allied health centre on monday through friday from 9:00 a.m. to 1:00 p.m .
Contexts for target open are: ['nsubj_cart', 'cop_is', 'rootI_*root*', 'prep:in_centre', 'prep:through_friday', 'prep:from_a.m.', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target open are: ['nsubj_cart', 'cop_is', 'rootI_*root*', 'prep:in_centre', 'prep:through_friday', 'prep:from_a.m.', 'punct_.']
Top most similar embeddings: open 0.00804	available 0.00541	availiable 0.00535	avaialable 0.00525	unstaffed 0.00521	avaliable 0.00515	availible 0.00515	avilable 0.00514	bookable 0.00509	avialable 0.00509

Generated lemmatized results
***************
GENERATED	open.a 1481 ::: available;availiable;avaialable;unstaffed;avaliable;availible;avilable;bookable;avialable;avalable

Filtered results
***************
RANKED	open.a 1481	available 0.00541	unlocked 0.00435	accessible 0.00420	empty 0.00365	ajar 0.00353	unrestricted 0.00330	free 0.00318	unfastened 0.00318	unobstructed 0.00303	clear 0.00291	alert 0.00286	working 0.00267	susceptible 0.00252	green 0.00252	approachable 0.00243	exposed 0.00237	peep 0.00236	peeled 0.00225	receptive 0.00224	gaping 0.00216	aware 0.00213	unclosed 0.00202	wide 0.00201	sandal 0.00192

Test context:
***************
open.a	1482	14	this drew a few stares as i walked around downtown san jose with an __open__ notebook computer .
Contexts for target open are: ['amodI_computer']
Contexts in vocabulary for target open are: ['amodI_computer']
Top most similar embeddings: open 0.46804	internet-connected 0.39867	pc-compatible 0.38977	diskless 0.38001	unpatched 0.37816	internet-linked 0.37730	wireless-enabled 0.37606	ibm-compatible 0.37510	freely-available 0.37396	full-function 0.37295

Generated lemmatized results
***************
GENERATED	open.a 1482 ::: diskless;unpatched;unsecure;ruggedised;loanable;networkable;electonic;networked;evolvable;passworded

Filtered results
***************
RANKED	open.a 1482	unlocked 0.32308	accessible 0.32131	empty 0.31726	free 0.31705	unclosed 0.31639	available 0.30983	unrestricted 0.30198	unobstructed 0.30172	gaping 0.29904	ajar 0.29626	unfastened 0.28908	green 0.28907	clear 0.28738	receptive 0.28570	susceptible 0.28552	working 0.28176	wide 0.28154	alert 0.27612	exposed 0.27557	approachable 0.27036	peeled 0.26488	aware 0.26255	sandal 0.25221	peep 0.24747

Test context:
***************
open.a	1483	29	poverty in clare 's life is the servant to this end , that is , ' poverty ' is the creation of a space in which we can be __open__ to the needs of our fellow human beings and to be there for god .
Contexts for target open are: ['prep:in_which', 'nsubj_we', 'aux_can', 'cop_be', 'rcmodI_space', 'prep:to_needs', 'cc_and', 'conj_be']
Contexts in vocabulary for target open are: ['prep:in_which', 'nsubj_we', 'aux_can', 'cop_be', 'rcmodI_space', 'prep:to_needs', 'cc_and', 'conj_be']
Top most similar embeddings: open 0.00261	re-configured 0.00238	attune 0.00228	reconfigured 0.00227	attuned 0.00221	responsive 0.00219	adaptable 0.00217	re-sized 0.00216	maximised 0.00214	fine-tuned 0.00213

Generated lemmatized results
***************
GENERATED	open.a 1483 ::: attune;reconfigured;attuned;responsive;adaptable;maximised;regionalised;flexible;navigated;mapped

Filtered results
***************
RANKED	open.a 1483	receptive 0.00203	unlocked 0.00177	accessible 0.00173	empty 0.00171	susceptible 0.00170	approachable 0.00164	alert 0.00159	free 0.00153	aware 0.00150	clear 0.00150	unrestricted 0.00144	exposed 0.00142	unobstructed 0.00137	unfastened 0.00134	peeled 0.00133	available 0.00132	ajar 0.00129	green 0.00126	wide 0.00105	peep 0.00102	working 0.00100	unclosed 0.00100	gaping 0.00093	sandal 0.00060

Test context:
***************
open.a	1484	17	unidentified man #4: ' sure , we can try. ' but this is a free country , __open__ borders , lots of little roads , miles of open coastline .
Contexts for target open are: ['amodI_borders']
Contexts in vocabulary for target open are: ['amodI_borders']
Top most similar embeddings: open 0.51103	wide-open 0.39037	semi-open 0.38718	half-open 0.36917	horseshoe-shaped 0.36504	close-set 0.36453	unshaded 0.36184	ever-shifting 0.35793	two-tiered 0.35618	sunlit 0.35603

Generated lemmatized results
***************
GENERATED	open.a 1484 ::: unshaded;sunlit;quadrangular;latticed;arcaded;crenellated;unfenced;corniced;ungrazed;openable

Filtered results
***************
RANKED	open.a 1484	unclosed 0.32928	gaping 0.32843	unobstructed 0.32750	ajar 0.32393	empty 0.31909	free 0.31281	clear 0.30880	unrestricted 0.30845	accessible 0.30529	unlocked 0.30409	unfastened 0.30345	wide 0.30322	receptive 0.29594	exposed 0.29131	green 0.28797	susceptible 0.28680	alert 0.28410	available 0.28123	peeled 0.27367	approachable 0.25876	working 0.25774	aware 0.25343	sandal 0.25243	peep 0.24042

Test context:
***************
open.a	1485	6	you have trouble keeping your eyes __open__ and focused , especially at stop lights .
Contexts for target open are: ['depI_keeping', 'cc_and', 'conj_focused']
Contexts in vocabulary for target open are: ['depI_keeping', 'cc_and', 'conj_focused']
Top most similar embeddings: open 0.11032	re-energised 0.08922	moisturised 0.08910	self-disciplined 0.08909	focussed 0.08799	relaxed 0.08772	well-organized 0.08636	energised 0.08633	wide-open 0.08605	unfocussed 0.08585

Generated lemmatized results
***************
GENERATED	open.a 1485 ::: moisturised;focussed;relaxed;energised;unfocussed;refreshed;unfocused;focused;businesslike;orientated

Filtered results
***************
RANKED	open.a 1485	unobstructed 0.08065	clear 0.07770	ajar 0.07713	unlocked 0.07581	approachable 0.07518	accessible 0.07352	unfastened 0.07281	peeled 0.07258	receptive 0.07253	green 0.07061	unrestricted 0.07001	free 0.06875	alert 0.06682	unclosed 0.06587	wide 0.06573	empty 0.06385	exposed 0.06373	aware 0.06126	gaping 0.05895	working 0.05832	susceptible 0.05828	available 0.05363	peep 0.05063	sandal 0.04252

Test context:
***************
open.a	1486	0	__open__ toed shoes with " scuffed " nails are especially bad news .
Contexts for target open are: ['amodI_shoes']
Contexts in vocabulary for target open are: ['amodI_shoes']
Top most similar embeddings: open 0.47784	well-fitting 0.39331	high-heeled 0.38760	tight-fitting 0.38250	wide-open 0.37705	low-cut 0.37287	sealable 0.37108	ill-fitting 0.37105	strappy 0.36856	slip-on 0.36835

Generated lemmatized results
***************
GENERATED	open.a 1486 ::: sealable;strappy;dressy;rimless;soled;backless;unshaded;jeweled;childproof;louvered

Filtered results
***************
RANKED	open.a 1486	unclosed 0.33389	empty 0.32830	unfastened 0.32357	ajar 0.31793	gaping 0.31647	available 0.30606	free 0.30560	wide 0.30367	clear 0.30124	unobstructed 0.30026	unlocked 0.29963	accessible 0.29659	unrestricted 0.29268	receptive 0.29250	susceptible 0.29030	green 0.29018	sandal 0.28763	exposed 0.28619	peeled 0.27379	approachable 0.27070	peep 0.26948	working 0.26662	alert 0.25969	aware 0.25858

Test context:
***************
open.a	1487	24	c. access and use effective and stable contractual arrangements for the supply , distribution and transportation of natural gas , including adherence to the __open__ access principle as well as management of the pipelines in accordance with such internationally accepted standards in the oil and gas industry .
Contexts for target open are: ['amodI_principle']
Contexts in vocabulary for target open are: ['amodI_principle']
Top most similar embeddings: open 0.45935	semi-open 0.36337	wide-open 0.36113	ecclesiological 0.35838	decades-old 0.35683	lockean 0.35473	inter-denominational 0.35460	universalistic 0.35368	superordinate 0.35273	meritocratic 0.35158

Generated lemmatized results
***************
GENERATED	open.a 1487 ::: ecclesiological;lockean;universalistic;superordinate;meritocratic;fundemental;regulative;undamped;bicameral;dialogical

Filtered results
***************
RANKED	open.a 1487	free 0.32085	clear 0.31558	unclosed 0.31485	unrestricted 0.31445	ajar 0.31177	empty 0.31128	accessible 0.30988	receptive 0.30965	wide 0.30684	unobstructed 0.30348	gaping 0.29719	available 0.29545	green 0.28715	working 0.28289	unlocked 0.28230	susceptible 0.27746	unfastened 0.27487	approachable 0.27425	exposed 0.26937	alert 0.26226	aware 0.25999	peeled 0.25619	sandal 0.24383	peep 0.23469

Test context:
***************
open.a	1488	13	unfortunately thought , both the gothic church and the castle itself were not __open__ because monday was their closed day .
Contexts for target open are: ['nsubj_church', 'cop_were', 'neg_not', 'ccompI_thought', 'advcl_day']
Contexts in vocabulary for target open are: ['nsubj_church', 'cop_were', 'neg_not', 'ccompI_thought', 'advcl_day']
Top most similar embeddings: open 0.02443	untypical 0.01987	polytheistic 0.01967	half-full 0.01950	ready 0.01943	invulnerable 0.01933	unwelcoming 0.01927	quorate 0.01925	cliquey 0.01920	re-opened 0.01920

Generated lemmatized results
***************
GENERATED	open.a 1488 ::: untypical;polytheistic;ready;invulnerable;unwelcoming;quorate;cliquey;propitious;drivable;unusual

Filtered results
***************
RANKED	open.a 1488	empty 0.01832	ajar 0.01735	receptive 0.01730	clear 0.01598	unlocked 0.01577	accessible 0.01553	susceptible 0.01524	aware 0.01496	approachable 0.01485	green 0.01404	unfastened 0.01361	available 0.01325	free 0.01318	unobstructed 0.01293	wide 0.01256	gaping 0.01255	alert 0.01226	unrestricted 0.01211	exposed 0.01203	unclosed 0.01180	peeled 0.01123	peep 0.01101	working 0.01039	sandal 0.00889

Test context:
***************
open.a	1489	34	the correspondent reports that the committee is evaluating five aspects of the area 's landscape : its scenic roads ; wildlife and outdoor recreation ; water resources ; forestland ; and farmland and other __open__ spaces .
Contexts for target open are: ['amodI_spaces']
Contexts in vocabulary for target open are: ['amodI_spaces']
Top most similar embeddings: open 0.54078	wide-open 0.43382	non-breaking 0.41813	semi-open 0.39890	artist-run 0.39771	double-height 0.39078	finite-dimensional 0.39015	women-only 0.38931	high-dimensional 0.38320	light-filled 0.38194

Generated lemmatized results
***************
GENERATED	open.a 1489 ::: rentable;normed;undesignated;unventilated;unbuilt;unroofed;unconsecrated;unenclosed;sealable;lettable

Filtered results
***************
RANKED	open.a 1489	empty 0.35195	unclosed 0.34253	unobstructed 0.34170	ajar 0.33570	accessible 0.33502	available 0.33461	gaping 0.32495	unrestricted 0.32436	free 0.32370	green 0.31874	wide 0.31644	unlocked 0.31437	receptive 0.30801	clear 0.30466	unfastened 0.29173	susceptible 0.29159	exposed 0.28448	working 0.28254	approachable 0.26786	peeled 0.26627	alert 0.25448	sandal 0.25377	peep 0.24973	aware 0.24762

Test context:
***************
open.a	1490	0	__open__ members of the isfp are listed on the isfp open members page .
Contexts for target open are: ['amodI_members']
Contexts in vocabulary for target open are: ['amodI_members']
Top most similar embeddings: open 0.44931	card-carrying 0.37760	regionally-based 0.37701	semi-open 0.36789	200-plus 0.36742	non-elite 0.36632	non-council 0.36471	non-regular 0.36247	pro-hunt 0.36202	non-playing 0.36139

Generated lemmatized results
***************
GENERATED	open.a 1490 ::: undesignated;unaffiliated;parlimentary;undermentioned;likeminded;unestablished;enthusiatic;diaconal;juried;certian

Filtered results
***************
RANKED	open.a 1490	unclosed 0.31442	free 0.31296	receptive 0.30781	gaping 0.30465	unrestricted 0.30330	empty 0.30177	accessible 0.29865	susceptible 0.29853	wide 0.29738	available 0.29729	unobstructed 0.29397	clear 0.29237	alert 0.29224	ajar 0.29027	approachable 0.29019	green 0.28474	working 0.28443	exposed 0.28229	unlocked 0.27882	aware 0.27295	unfastened 0.26982	peeled 0.25346	peep 0.24657	sandal 0.24199

Test context:
***************
pot.n	1491	40	confronted with a chilling account of a kid turning in his own father to the police , kiro , king 5 , komo , q13 , and both daily papers stuck to the drug war script : people who use __pot__ , very bad ; people who grow pot , even worse .
Contexts for target pot are: ['dobjI_use']
Contexts in vocabulary for target pot are: ['dobjI_use']
Top most similar embeddings: pot 0.48183	pots 0.40094	dibber 0.38187	inhalator 0.36925	bedpan 0.36813	c-word 0.36536	keepnet 0.36286	strainer 0.36204	footbath 0.36135	burette 0.36091

Generated lemmatized results
***************
GENERATED	pot.n 1491 ::: dibber;inhalator;bedpan;keepnet;strainer;footbath;burette;pipette;ccdsetup;cashcard

Filtered results
***************
RANKED	pot.n 1491	bowl 0.34563	tub 0.34069	saucepan 0.33913	canister 0.33780	tray 0.33438	teapot 0.33437	container 0.33338	pan 0.33299	pourer 0.32535	marijuana 0.32238	casserole 0.31850	winning 0.30730	cannabis 0.30274	stake 0.30229	vessel 0.29596	dope 0.29096	ceramic 0.27836	weed 0.27026	prize 0.26348

Test context:
***************
pot.n	1492	22	how did felt manage , while he 's running the bureau 's day-to-day operations , to keep an eye on the flower __pot__ on woodward 's balcony to see if the red flag was out ?
Contexts for target pot are: ['det_the', 'nn_flower', 'prep:onI_eye']
Contexts in vocabulary for target pot are: ['det_the', 'nn_flower', 'prep:onI_eye']
Top most similar embeddings: pot 0.13106	pots 0.09679	vase 0.08884	jug 0.08831	seedpod 0.08785	bowl 0.08695	teacups 0.08603	mug 0.08537	rootball 0.08484	seedheads 0.08454

Generated lemmatized results
***************
GENERATED	pot.n 1492 ::: vase;jug;seedpod;bowl;teacup;mug;rootball;seedheads;jar;saucer

Filtered results
***************
RANKED	pot.n 1492	bowl 0.08695	teapot 0.08290	tub 0.08283	container 0.08162	canister 0.08114	tray 0.07766	pan 0.07585	casserole 0.07449	saucepan 0.07364	pourer 0.07354	stake 0.07211	vessel 0.07151	weed 0.07106	prize 0.07075	marijuana 0.06203	winning 0.06023	ceramic 0.05952	dope 0.05824	cannabis 0.05495

Test context:
***************
pot.n	1493	45	the way the day was organised as regards to bars and food was breakfast from ' i do n't know what ' o'clock ( as i only made it twice ) til 10.00 then the pool bars would open which also had 3 silver hot __pots__ filled with food , one was meat ( chicken , beef , or kebab ) the next was chips and the third was usually some form of eggplant .
Contexts for target pots are: ['num_3', 'nn_silver', 'amod_hot', 'dobjI_had', 'partmod_filled']
Contexts in vocabulary for target pots are: ['num_3', 'nn_silver', 'amod_hot', 'dobjI_had', 'partmod_filled']
Top most similar embeddings: pots 0.03067	tubs 0.02664	goblets 0.02572	canisters 0.02548	cups 0.02545	pot 0.02542	buckets 0.02535	teacups 0.02524	bottles 0.02503	trays 0.02481

Generated lemmatized results
***************
GENERATED	pot.n 1493 ::: tub;goblet;canister;cup;bucket;teacup;bottle;tray;ramekin;flagon

Filtered results
***************
RANKED	pot.n 1493	tub 0.02664	canister 0.02548	tray 0.02481	saucepan 0.02419	teapot 0.02345	pan 0.02267	container 0.02203	bowl 0.02141	casserole 0.01930	pourer 0.01896	vessel 0.01762	stake 0.01643	ceramic 0.01450	prize 0.01402	weed 0.01337	dope 0.01259	winning 0.01168	marijuana 0.01132	cannabis 0.01033

Test context:
***************
pot.n	1494	8	jim and louise anderson have been importing these __pots__ for years , and all their pots are lead-free , making them suitable to use for any type of tea .
Contexts for target pots are: ['det_these', 'dobjI_importing']
Contexts in vocabulary for target pots are: ['det_these', 'dobjI_importing']
Top most similar embeddings: pots 0.23728	jugs 0.19482	urns 0.19113	briquettes 0.18874	holdalls 0.18702	vases 0.18663	teapots 0.18591	containers 0.18589	kalashnikovs 0.18556	tubs 0.18550

Generated lemmatized results
***************
GENERATED	pot.n 1494 ::: jug;urn;briquette;holdall;vas;teapot;container;kalashnikov;tub;matrix

Filtered results
***************
RANKED	pot.n 1494	teapot 0.18591	container 0.18589	tub 0.18550	saucepan 0.17823	tray 0.17736	canister 0.17704	vessel 0.17116	pan 0.16532	bowl 0.16128	casserole 0.16045	ceramic 0.16004	weed 0.15129	stake 0.13617	prize 0.13489	winning 0.13260	marijuana 0.13195	cannabis 0.12438	dope 0.12436	pourer 0.12277

Test context:
***************
pot.n	1495	8	it is also custom to hold the long-spouted __pot__ high above the glass as he pours .
Contexts for target pot are: ['det_the', 'amod_long-spouted', 'dobjI_hold', 'amod_high']
Contexts in vocabulary for target pot are: ['det_the', 'dobjI_hold', 'amod_high']
Top most similar embeddings: pot 0.11592	stakes 0.09201	pots 0.09152	jug 0.09149	work-piece 0.09141	handstick 0.08842	circlip 0.08833	chockstone 0.08827	halberd 0.08781	caisson 0.08768

Generated lemmatized results
***************
GENERATED	pot.n 1495 ::: stake;jug;handstick;circlip;chockstone;halberd;caisson;rootball;kopje;gunwale

Filtered results
***************
RANKED	pot.n 1495	stake 0.09201	bowl 0.08389	teapot 0.08180	canister 0.08141	pan 0.07988	saucepan 0.07979	tray 0.07786	tub 0.07656	container 0.07649	pourer 0.07278	casserole 0.07259	winning 0.07244	vessel 0.07103	prize 0.06875	dope 0.06588	weed 0.06457	ceramic 0.06337	marijuana 0.06236	cannabis 0.05897

Test context:
***************
pot.n	1496	7	loose games with poor players and larger __pots__ are easier to beat in the first place , plus the charges are proportionately lower .
Contexts for target pots are: ['amod_larger', 'conjI_players']
Contexts in vocabulary for target pots are: ['amod_larger', 'conjI_players']
Top most similar embeddings: pots 0.23798	kettles 0.18621	saucepans 0.18488	pot 0.18309	holdalls 0.18028	troughs 0.17975	tankards 0.17943	jugs 0.17928	mixers 0.17925	evaporators 0.17922

Generated lemmatized results
***************
GENERATED	pot.n 1496 ::: kettle;saucepan;holdall;trough;tankard;jug;mixer;evaporators;jar;tub

Filtered results
***************
RANKED	pot.n 1496	saucepan 0.18488	tub 0.17875	tray 0.17766	bowl 0.17679	pan 0.17482	teapot 0.17095	canister 0.16933	container 0.16904	vessel 0.15884	casserole 0.15185	stake 0.14839	prize 0.14571	ceramic 0.13798	winning 0.13705	pourer 0.13367	weed 0.12523	dope 0.10800	marijuana 0.10304	cannabis 0.09873

Test context:
***************
pot.n	1497	24	we found some tattered clothes , a torn leather knapsack , a small case of 8 mm cartridges , a canvas shelter , cooking __pots__ and other gear .
Contexts for target pots are: ['nn_cooking', 'apposI_cartridges', 'cc_and', 'conj_gear']
Contexts in vocabulary for target pots are: ['nn_cooking', 'apposI_cartridges', 'cc_and', 'conj_gear']
Top most similar embeddings: pots 0.06824	saucepans 0.05050	sterilisers 0.04979	utensils 0.04904	ladles 0.04829	trowels 0.04826	holdalls 0.04760	ashtrays 0.04731	flasks 0.04728	pails 0.04722

Generated lemmatized results
***************
GENERATED	pot.n 1497 ::: saucepan;steriliser;utensil;ladle;trowel;holdall;ashtray;flask;pail;tub

Filtered results
***************
RANKED	pot.n 1497	saucepan 0.05050	tub 0.04721	tray 0.04604	canister 0.04556	teapot 0.04456	pan 0.04381	bowl 0.04350	container 0.04210	casserole 0.03974	vessel 0.03637	pourer 0.03631	ceramic 0.03549	dope 0.03222	prize 0.02972	marijuana 0.02941	stake 0.02928	weed 0.02724	cannabis 0.02476	winning 0.02409

Test context:
***************
pot.n	1498	9	" she had grown strawberries before , but in __pots__ , when she was single and in college and did n't have much room .
Contexts for target pots are: ['conj:inI_grown']
Contexts in vocabulary for target pots are: ['conj:inI_grown']
Top most similar embeddings: pots 0.51887	tubs 0.39115	pot 0.38787	trays 0.37126	polytunnels 0.36869	vases 0.36863	jugs 0.36634	cauldrons 0.35803	fermenters 0.35795	troughs 0.35697

Generated lemmatized results
***************
GENERATED	pot.n 1498 ::: tub;tray;polytunnels;vas;jug;cauldron;fermenters;trough;container;jar

Filtered results
***************
RANKED	pot.n 1498	tub 0.39115	tray 0.37126	container 0.35649	saucepan 0.35027	teapot 0.33795	bowl 0.33407	pan 0.32963	casserole 0.32398	canister 0.32121	ceramic 0.31243	vessel 0.30501	stake 0.30034	pourer 0.28358	weed 0.27772	winning 0.25508	prize 0.25131	marijuana 0.24763	dope 0.24243	cannabis 0.23554

Test context:
***************
pot.n	1499	9	visualising an old chicken carcass boiling in a big __pot__ of water .
Contexts for target pot are: ['det_a', 'amod_big', 'prep:inI_boiling', 'prep:of_water']
Contexts in vocabulary for target pot are: ['det_a', 'amod_big', 'prep:inI_boiling', 'prep:of_water']
Top most similar embeddings: pot 0.07443	jug 0.05873	bucket 0.05537	bowl 0.05515	cupful 0.05501	saucepan 0.05454	jar 0.05347	skillet 0.05263	cauldron 0.05214	pots 0.05186

Generated lemmatized results
***************
GENERATED	pot.n 1499 ::: jug;bucket;bowl;cupful;saucepan;jar;skillet;cauldron;pail;tureen

Filtered results
***************
RANKED	pot.n 1499	bowl 0.05515	saucepan 0.05454	tub 0.05108	pan 0.04912	canister 0.04695	teapot 0.04589	container 0.04528	tray 0.04266	casserole 0.03978	pourer 0.03922	vessel 0.03686	stake 0.03110	dope 0.02740	prize 0.02733	weed 0.02721	winning 0.02692	ceramic 0.02446	marijuana 0.02410	cannabis 0.02086

Test context:
***************
pot.n	1500	22	there 's only a couple of cringe-inducing moments ( like when the singer goes " i learned a lot / from smoking __pot__ / but i do n't remember / what i forgot " , but all in all this is a record that will have your hips moving wildly independent from the rest of yer body , like byram 's butt is doing right now ... go byram go !
Contexts for target pot are: ['nn_smoking', 'prep:fromI_learned']
Contexts in vocabulary for target pot are: ['nn_smoking', 'prep:fromI_learned']
Top most similar embeddings: pot 0.23473	pots 0.16897	mug 0.16254	spliffs 0.15813	teapot 0.15767	marijuana 0.15602	jar 0.15402	spliff 0.15326	epidemic 0.15252	fags 0.15106

Generated lemmatized results
***************
GENERATED	pot.n 1500 ::: mug;spliff;teapot;marijuana;jar;epidemic;fag;creamer;wok;cauldron

Filtered results
***************
RANKED	pot.n 1500	teapot 0.15767	marijuana 0.15602	dope 0.14995	bowl 0.14950	pan 0.14946	saucepan 0.14285	cannabis 0.14254	canister 0.13974	tub 0.13953	casserole 0.13526	stake 0.13192	container 0.13174	vessel 0.12971	tray 0.12958	weed 0.12637	pourer 0.12500	winning 0.12252	ceramic 0.12098	prize 0.11611

Test context:
***************
profound.a	1501	5	there is something just so __profound__ about that .
Contexts for target profound are: ['advmod_just', 'advmod_so', 'amodI_something', 'prep:about_that']
Contexts in vocabulary for target profound are: ['advmod_just', 'advmod_so', 'amodI_something', 'prep:about_that']
Top most similar embeddings: profound 0.05837	goddamned 0.04886	obtuse 0.04769	off-the-wall 0.04736	contraversial 0.04702	matter-of-fact 0.04650	indelicate 0.04645	tarty 0.04643	icky 0.04636	immodest 0.04600

Generated lemmatized results
***************
GENERATED	profound.a 1501 ::: goddamned;obtuse;contraversial;indelicate;tarty;icky;immodest;shocking;bizzare;unchristian

Filtered results
***************
RANKED	profound.a 1501	serious 0.04437	insightful 0.04151	thoughtful 0.04120	intense 0.04068	deep 0.03981	important 0.03826	great 0.03697	significant 0.03637	sagacious 0.03477	thorough 0.03396	penetrating 0.03332	acute 0.03260	wise 0.03239	pronounced 0.03211	huge 0.03204	complex 0.03178	keen 0.02906	intellectual 0.02903	extensive 0.02882

Test context:
***************
profound.a	1502	4	segall and timiras discovered __profound__ changes in neurotransmitter levels in the brains of their experimental animals , but were unable to explore the implications of these changes with regard to aging because their funding ran out .
Contexts for target profound are: ['amodI_changes']
Contexts in vocabulary for target profound are: ['amodI_changes']
Top most similar embeddings: profound 0.54550	far-reaching 0.43656	climate-related 0.42057	post-depositional 0.42057	profoundest 0.41904	life-altering 0.41317	epochal 0.41171	wide-reaching 0.40955	stress-induced 0.40951	far-ranging 0.40807

Generated lemmatized results
***************
GENERATED	profound.a 1502 ::: epochal;subtle;fundamental;significant;signficant;drastic;mutational;fundemental;conjunctural;precancerous

Filtered results
***************
RANKED	profound.a 1502	significant 0.40365	deep 0.36349	huge 0.35084	serious 0.35037	intense 0.34982	thoughtful 0.34362	acute 0.34148	great 0.33968	insightful 0.33886	extensive 0.33771	important 0.33569	thorough 0.33347	complex 0.32955	intellectual 0.31833	pronounced 0.31626	sagacious 0.31468	wise 0.30448	penetrating 0.30447	keen 0.30080

Test context:
***************
profound.a	1503	9	the human genome project is going to be of __profound__ significance for the pharmaceuticals and healthcare sectors , offering real hope in the treatment of conditions such as cystic fibrosis and cancer .
Contexts for target profound are: ['amodI_significance']
Contexts in vocabulary for target profound are: ['amodI_significance']
Top most similar embeddings: profound 0.54022	profoundest 0.43024	far-reaching 0.41461	ineradicable 0.41228	historiographic 0.40861	soteriological 0.40441	epochal 0.40363	sociopolitical 0.40261	universalistic 0.39972	ineluctable 0.39814

Generated lemmatized results
***************
GENERATED	profound.a 1503 ::: ineradicable;historiographic;soteriological;epochal;sociopolitical;universalistic;ineluctable;procreative;originary;numerological

Filtered results
***************
RANKED	profound.a 1503	deep 0.38541	significant 0.36366	great 0.35278	intense 0.34977	huge 0.34892	serious 0.34180	acute 0.33481	intellectual 0.32702	insightful 0.31961	important 0.31720	thoughtful 0.31598	complex 0.31346	thorough 0.31043	penetrating 0.30820	pronounced 0.30356	extensive 0.30331	keen 0.29959	sagacious 0.29464	wise 0.28497

Test context:
***************
profound.a	1504	18	25 association , of course , does not establish causality ' but it raises the possibility that the __profound__ and apparently deepening pessimism about personal circumstances widely reflected in an array of opinion polls and surveys is among the determinants underlying russia 's fearsome levels of cardiovascular death .
Contexts for target profound are: ['det_the', 'nsubjI_is', 'cc_and', 'conj_deepening']
Contexts in vocabulary for target profound are: ['det_the', 'nsubjI_is', 'cc_and', 'conj_deepening']
Top most similar embeddings: profound 0.05179	deepening 0.04800	interrelatedness 0.04459	brokenness 0.04395	impermanence 0.04267	inwardness 0.04243	cross-fertilization 0.04242	secularisation 0.04242	concreteness 0.04216	sattva 0.04170

Generated lemmatized results
***************
GENERATED	profound.a 1504 ::: deepening;interrelatedness;brokenness;impermanence;inwardness;secularisation;concreteness;sattva;quickening;expansiveness

Filtered results
***************
RANKED	profound.a 1504	deep 0.03996	penetrating 0.03567	complex 0.03429	insightful 0.03231	wise 0.03191	thoughtful 0.03151	great 0.03117	serious 0.03112	acute 0.03033	keen 0.02925	thorough 0.02905	intense 0.02894	intellectual 0.02873	significant 0.02803	sagacious 0.02769	huge 0.02720	extensive 0.02587	pronounced 0.02538	important 0.02252

Test context:
***************
profound.a	1505	20	if you hesitate , therefore , a moment , or if , after reflection , you produce any intricate or __profound__ argument , you , in a manner , give up the question , and confess that it is not reasoning which engages us to suppose the past resembling the future , and to expect similar effects from causes which are , to appearance , similar .
Contexts for target profound are: ['conjI_intricate']
Contexts in vocabulary for target profound are: ['conjI_intricate']
Top most similar embeddings: profound 0.51119	intricate 0.42055	heart-wrenching 0.41901	many-sided 0.41238	far-ranging 0.40541	subtle 0.40524	recondite 0.40173	far-reaching 0.40158	heart-rending 0.40066	epigrammatic 0.39777

Generated lemmatized results
***************
GENERATED	profound.a 1505 ::: intricate;subtle;recondite;epigrammatic;contrapuntal;poignant;allusive;heartfelt;expressionistic;heartrending

Filtered results
***************
RANKED	profound.a 1505	insightful 0.38244	thoughtful 0.38171	intense 0.36589	complex 0.35982	deep 0.34981	significant 0.34414	penetrating 0.34325	thorough 0.34195	sagacious 0.33312	serious 0.33265	huge 0.32748	extensive 0.32491	intellectual 0.31356	great 0.30559	important 0.30487	acute 0.30258	wise 0.28868	pronounced 0.28793	keen 0.27864

Test context:
***************
profound.a	1506	7	a fresh miracle , one with a __profound__ political dimension and such spectacular possibilities was just what they had to be looking for. [ 8 ] lourdes ' mother superior is depicted as a jealous , resentful and ambitious woman who viewed the newly arrived order as a threat - a competitor for donations and novices .
Contexts for target profound are: ['amodI_dimension']
Contexts in vocabulary for target profound are: ['amodI_dimension']
Top most similar embeddings: profound 0.50554	profoundest 0.40968	communicational 0.40372	sociopolitical 0.40243	historiographic 0.39871	universalistic 0.39571	ineluctable 0.39539	originary 0.39465	psycho-spiritual 0.39360	life-altering 0.39347

Generated lemmatized results
***************
GENERATED	profound.a 1506 ::: communicational;sociopolitical;historiographic;universalistic;ineluctable;originary;soteriological;ineradicable;connotative;fundemental

Filtered results
***************
RANKED	profound.a 1506	deep 0.37203	significant 0.36879	intense 0.33990	insightful 0.33922	serious 0.33798	thoughtful 0.33600	intellectual 0.33342	important 0.33150	huge 0.33087	great 0.33073	penetrating 0.32105	thorough 0.31796	complex 0.31675	acute 0.31642	pronounced 0.30871	extensive 0.30780	sagacious 0.30046	keen 0.28935	wise 0.28922

Test context:
***************
profound.a	1507	10	you have surely given an exceptional argument which raises many __profound__ questions concerning the foundations of artificial intelligence .
Contexts for target profound are: ['amodI_questions']
Contexts in vocabulary for target profound are: ['amodI_questions']
Top most similar embeddings: profound 0.52866	profoundest 0.43153	researchable 0.42837	far-ranging 0.41520	fundamental 0.40669	source-based 0.40637	much-discussed 0.40057	far-reaching 0.40053	career-related 0.39747	life-altering 0.39712

Generated lemmatized results
***************
GENERATED	profound.a 1507 ::: researchable;fundamental;historiographic;interpretational;geniune;missiological;unresolvable;definitional;fundemental;universalistic

Filtered results
***************
RANKED	profound.a 1507	insightful 0.38085	deep 0.37994	serious 0.37372	thoughtful 0.36600	significant 0.36596	penetrating 0.35012	important 0.34254	intense 0.34002	complex 0.33962	huge 0.33340	acute 0.32915	thorough 0.32877	great 0.32862	intellectual 0.32605	sagacious 0.32211	extensive 0.31532	wise 0.30994	keen 0.30825	pronounced 0.28536

Test context:
***************
profound.a	1508	20	return to contents natural selection and other mechanisms - such as chromosomal changes , symbiosis and hybridization - can drive __profound__ changes in populations over time .
Contexts for target profound are: ['amodI_changes']
Contexts in vocabulary for target profound are: ['amodI_changes']
Top most similar embeddings: profound 0.54550	far-reaching 0.43656	climate-related 0.42057	post-depositional 0.42057	profoundest 0.41904	life-altering 0.41317	epochal 0.41171	wide-reaching 0.40955	stress-induced 0.40951	far-ranging 0.40807

Generated lemmatized results
***************
GENERATED	profound.a 1508 ::: epochal;subtle;fundamental;significant;signficant;drastic;mutational;fundemental;conjunctural;precancerous

Filtered results
***************
RANKED	profound.a 1508	significant 0.40365	deep 0.36349	huge 0.35084	serious 0.35037	intense 0.34982	thoughtful 0.34362	acute 0.34148	great 0.33968	insightful 0.33886	extensive 0.33771	important 0.33569	thorough 0.33347	complex 0.32955	intellectual 0.31833	pronounced 0.31626	sagacious 0.31468	wise 0.30448	penetrating 0.30447	keen 0.30080

Test context:
***************
profound.a	1509	24	gaining the confidence of local residents , for example , so that they will allow the students to enter and test their homes requires __profound__ cultural understanding .
Contexts for target profound are: ['amodI_understanding']
Contexts in vocabulary for target profound are: ['amodI_understanding']
Top most similar embeddings: profound 0.53250	profoundest 0.43228	universalistic 0.40832	thorough-going 0.40750	thoroughgoing 0.40254	deeper 0.40120	metalinguistic 0.40072	clear-sighted 0.39634	fundamental 0.39610	commonly-held 0.39594

Generated lemmatized results
***************
GENERATED	profound.a 1509 ::: universalistic;thoroughgoing;deep;metalinguistic;fundamental;historiographic;vedantic;christocentric;lockean;nuanced

Filtered results
***************
RANKED	profound.a 1509	deep 0.40120	thorough 0.38544	insightful 0.37271	thoughtful 0.35727	great 0.35558	intense 0.35134	significant 0.34946	acute 0.34337	intellectual 0.34059	penetrating 0.33542	serious 0.33271	extensive 0.33033	sagacious 0.32543	complex 0.32412	huge 0.31942	keen 0.31887	wise 0.31132	important 0.30472	pronounced 0.29249

Test context:
***************
profound.a	1510	25	but even willy 's conception of the past is not as idyllic as it seems on the surface , as his split consciousness , the __profound__ rift in his psyche , shows through .
Contexts for target profound are: ['amodI_rift']
Contexts in vocabulary for target profound are: ['amodI_rift']
Top most similar embeddings: profound 0.50024	ever-widening 0.39565	fathomless 0.39456	deep-seated 0.39016	unbridgeable 0.38890	profoundest 0.38884	life-altering 0.38473	centuries-long 0.38316	deep 0.38183	far-reaching 0.38021

Generated lemmatized results
***************
GENERATED	profound.a 1510 ::: fathomless;unbridgeable;deep;irresolvable;vertiginous;epochal;ineluctable;unwonted;ineradicable;impalpable

Filtered results
***************
RANKED	profound.a 1510	deep 0.38183	serious 0.35636	huge 0.35101	significant 0.34862	intense 0.33669	great 0.33160	insightful 0.32976	acute 0.32488	penetrating 0.32295	thorough 0.32012	thoughtful 0.31283	extensive 0.31043	intellectual 0.31018	pronounced 0.30953	complex 0.30424	keen 0.30270	sagacious 0.30067	important 0.29922	wise 0.28625

Test context:
***************
prominent.a	1511	29	" what meeks did not mention is that guea bought the building from her church , victory apostolic faith church in chicago , where she and her father are __prominent__ members , according to cook county property records and the church 's web site .
Contexts for target prominent are: ['amodI_members']
Contexts in vocabulary for target prominent are: ['amodI_members']
Top most similar embeddings: prominent 0.53484	prominant 0.42400	card-carrying 0.41949	longest-standing 0.41381	highest-ranking 0.40886	influential 0.40355	200-plus 0.39819	longest-serving 0.39749	highest-paid 0.39336	much-respected 0.39225

Generated lemmatized results
***************
GENERATED	prominent.a 1511 ::: prominant;influential;undermentioned;influencial;staunch;hawkish;eminent;dominant;notable;likeminded

Filtered results
***************
RANKED	prominent.a 1511	eminent 0.37594	notable 0.37350	conspicuous 0.36707	foremost 0.35527	visible 0.35278	leading 0.35193	famous 0.33992	significant 0.33851	important 0.33088	prevalent 0.32727	noticeable 0.32159	obvious 0.31229	renowned 0.30484	salient 0.30426	major 0.29994	pronounced 0.27916

Test context:
***************
prominent.a	1512	4	among the recipients were __prominent__ journalists and producers , scions of the alternative press , and a smattering of current and former intelligence analysts who often serve as sources in news analyses and articles .
Contexts for target prominent are: ['amodI_journalists']
Contexts in vocabulary for target prominent are: ['amodI_journalists']
Top most similar embeddings: prominent 0.52215	prominant 0.41742	highest-ranking 0.41270	internationally-known 0.40859	wellknown 0.40455	highest-paid 0.40397	much-respected 0.40266	influential 0.40048	independent-minded 0.39788	longest-serving 0.39535

Generated lemmatized results
***************
GENERATED	prominent.a 1512 ::: prominant;wellknown;influential;influencial;foremost;able;monied;cretinous;staunch;likeminded

Filtered results
***************
RANKED	prominent.a 1512	foremost 0.37831	conspicuous 0.36769	notable 0.36632	eminent 0.36458	leading 0.35647	famous 0.34521	prevalent 0.32937	noticeable 0.32927	visible 0.32593	obvious 0.32183	renowned 0.32167	significant 0.32020	important 0.31778	major 0.30911	salient 0.30499	pronounced 0.30114

Test context:
***************
prominent.a	1513	32	update posted at 10:00 am ' permalink back in this post , i reported that the tropicana hotel in las vegas had stopped accepting reservations for after april 15 and that a __prominent__ demolition company had told a reporter that it was studying how to blow up the place .
Contexts for target prominent are: ['amodI_company']
Contexts in vocabulary for target prominent are: ['amodI_company']
Top most similar embeddings: prominent 0.50744	toronto-based 0.42250	kent-based 0.41230	old-established 0.41209	privately-held 0.40952	coventry-based 0.40929	boston-based 0.40892	atlanta-based 0.40793	employee-owned 0.40790	longest-established 0.40685

Generated lemmatized results
***************
GENERATED	prominent.a 1513 ::: prestigeous;wellknown;prominant;influential;usthe;prestigous;foremost;preeminent;influencial;conspicuous

Filtered results
***************
RANKED	prominent.a 1513	foremost 0.38081	conspicuous 0.37585	leading 0.36727	eminent 0.36670	notable 0.35641	famous 0.35177	significant 0.33726	renowned 0.33686	major 0.33133	visible 0.32606	important 0.32020	prevalent 0.32013	noticeable 0.31584	obvious 0.30949	salient 0.29416	pronounced 0.28780

Test context:
***************
prominent.a	1514	10	" evidence is easily found of multipolarity and china 's __prominent__ role in promoting it .
Contexts for target prominent are: ['amodI_role']
Contexts in vocabulary for target prominent are: ['amodI_role']
Top most similar embeddings: prominent 0.53961	prominant 0.44047	influential 0.40498	dominant 0.39873	pivotal 0.39350	conspicuous 0.39322	preponderant 0.39292	influencial 0.39092	pre-eminent 0.38983	much-valued 0.38739

Generated lemmatized results
***************
GENERATED	prominent.a 1514 ::: prominant;influential;dominant;pivotal;conspicuous;preponderant;influencial;predominant;significant;important

Filtered results
***************
RANKED	prominent.a 1514	conspicuous 0.39322	significant 0.38555	important 0.37736	notable 0.37077	leading 0.36611	foremost 0.36291	eminent 0.35917	visible 0.35651	noticeable 0.35168	famous 0.34694	obvious 0.33998	major 0.33631	prevalent 0.33347	salient 0.32728	renowned 0.31208	pronounced 0.30946

Test context:
***************
prominent.a	1515	9	reeling from the effects of world war ii , __prominent__ local businessmen led by the visionary archie jewell , purchased the building in 1943 and renovated it to become " the international house " , a newly-created non-profit trade association dedicated to world peace , trade and understanding .
Contexts for target prominent are: ['amodI_businessmen']
Contexts in vocabulary for target prominent are: ['amodI_businessmen']
Top most similar embeddings: prominent 0.53426	prominant 0.40944	independent-minded 0.40254	influential 0.39856	highest-ranking 0.39071	wellknown 0.39004	influencial 0.38979	dyed-in-the-wool 0.38948	old-established 0.38726	well-know 0.38652

Generated lemmatized results
***************
GENERATED	prominent.a 1515 ::: prominant;influential;wellknown;influencial;monied;corpulent;wealthy;beleagured;besuited;youngish

Filtered results
***************
RANKED	prominent.a 1515	eminent 0.37153	foremost 0.36417	conspicuous 0.36139	notable 0.35976	leading 0.35804	famous 0.34305	visible 0.32683	significant 0.32281	important 0.32250	renowned 0.31860	noticeable 0.31566	prevalent 0.31301	obvious 0.31164	salient 0.29886	major 0.29857	pronounced 0.29641

Test context:
***************
prominent.a	1516	38	there were five references to crawford : three dealing with his present claims that he lied on behalf of the tobacco companies , one dealing with a property dispute , and another , which identified him as a __prominent__ criminal lawyer , who had been involved in 33 capital cases .
Contexts for target prominent are: ['amodI_lawyer']
Contexts in vocabulary for target prominent are: ['amodI_lawyer']
Top most similar embeddings: prominent 0.53977	much-respected 0.41344	highest-ranking 0.41130	court-appointed 0.41024	prominant 0.40799	internationally-known 0.40760	well-know 0.39964	highest-paid 0.39956	wellknown 0.39935	well-known 0.39538

Generated lemmatized results
***************
GENERATED	prominent.a 1516 ::: prominant;wellknown;eminent;influential;hawkish;influencial;foremost;archetypical;notable;moustachioed

Filtered results
***************
RANKED	prominent.a 1516	eminent 0.38419	foremost 0.37111	notable 0.36966	conspicuous 0.36489	leading 0.35548	famous 0.35430	renowned 0.33753	visible 0.33371	obvious 0.32890	important 0.32263	noticeable 0.31730	significant 0.31649	prevalent 0.30856	pronounced 0.30463	major 0.29174	salient 0.28263

Test context:
***************
prominent.a	1517	21	expansion of markets , improvement of profit potential , and reduction of cost factors join the enhancement of competitive position as __prominent__ forces moving organizations toward globalization .
Contexts for target prominent are: ['amodI_forces']
Contexts in vocabulary for target prominent are: ['amodI_forces']
Top most similar embeddings: prominent 0.48121	pro-russian 0.41732	anti-occupation 0.40956	prominant 0.40483	non-conservative 0.39453	anti-agreement 0.39262	influential 0.39039	dominant 0.38999	anti-castro 0.38882	non-scottish 0.38158

Generated lemmatized results
***************
GENERATED	prominent.a 1517 ::: prominant;influential;dominant;centripetal;compressional;preponderant;predominant;oligarchic;mutinous;powerful

Filtered results
***************
RANKED	prominent.a 1517	foremost 0.36083	conspicuous 0.35739	visible 0.35431	significant 0.35221	prevalent 0.34093	notable 0.33991	eminent 0.33705	famous 0.33483	leading 0.33449	noticeable 0.32633	important 0.32614	salient 0.32605	obvious 0.32325	major 0.31839	pronounced 0.30220	renowned 0.30211

Test context:
***************
prominent.a	1518	33	i have argued in my previous article for pdf that ' [f]or armstrong williams-like bloggers actually paid by campaigns or other political committees to promote or attack a candidate for federal office , __prominent__ and on-the-spot disclosure should be mandated. ' a disclosure on a campaign 's website in a quarterly report after the election deprives voters of valuable information about the possible motivations for an analysis or commentary appearing on a website .
Contexts for target prominent are: ['amodI_disclosure', 'cc_and', 'conj_on-the-spot']
Contexts in vocabulary for target prominent are: ['amodI_disclosure', 'cc_and']
Top most similar embeddings: prominent 0.23689	timeous 0.18122	conspicuous 0.17989	wide-spread 0.17878	forceful 0.17597	expeditious 0.17508	pervasive 0.17311	well-considered 0.17280	broad-ranging 0.17272	eloquent 0.17176

Generated lemmatized results
***************
GENERATED	prominent.a 1518 ::: timeous;conspicuous;forceful;expeditious;pervasive;eloquent;credible;uncorroborated;unwarrantable;voluble

Filtered results
***************
RANKED	prominent.a 1518	conspicuous 0.17989	visible 0.16407	eminent 0.16107	notable 0.15811	significant 0.15607	noticeable 0.15557	prevalent 0.15078	obvious 0.14829	foremost 0.14732	leading 0.14716	important 0.14622	famous 0.14533	salient 0.14064	pronounced 0.13883	renowned 0.13474	major 0.13456

Test context:
***************
prominent.a	1519	7	this pattern of bad journalism is a __prominent__ feature of every pro-hoax text and video .
Contexts for target prominent are: ['amodI_feature']
Contexts in vocabulary for target prominent are: ['amodI_feature']
Top most similar embeddings: prominent 0.54817	prominant 0.45244	conspicuous 0.40902	notable 0.40628	dominant 0.40299	noteable 0.39972	predominant 0.39732	long-neglected 0.39644	noticeable 0.39289	distinctive 0.38983

Generated lemmatized results
***************
GENERATED	prominent.a 1519 ::: prominant;conspicuous;notable;dominant;noteable;predominant;noticeable;distinctive;wellknown;influential

Filtered results
***************
RANKED	prominent.a 1519	conspicuous 0.40902	notable 0.40628	noticeable 0.39289	visible 0.37366	significant 0.37053	important 0.36832	foremost 0.35961	salient 0.35793	obvious 0.35414	prevalent 0.35238	famous 0.35105	eminent 0.34303	leading 0.33371	pronounced 0.33282	major 0.33257	renowned 0.31166

Test context:
***************
prominent.a	1520	15	apple vs. microsoft my altavista survey results revealed that " gates hate " is more __prominent__ among mac fans than with other groups -- providing a rationale for starting with apple in our examination of the various conflicts listed above .
Contexts for target prominent are: ['csubj_hate', 'cop_is', 'advmod_more', 'ccompI_revealed', 'prep:among_fans', 'punct_--', 'dep_providing']
Contexts in vocabulary for target prominent are: ['csubj_hate', 'cop_is', 'advmod_more', 'ccompI_revealed', 'prep:among_fans', 'punct_--', 'dep_providing']
Top most similar embeddings: prominent 0.00497	prevalent 0.00442	rife 0.00421	notorious 0.00413	widespread 0.00400	rampant 0.00386	pronounced 0.00385	pervasive 0.00384	conspicuous 0.00380	omnipresent 0.00377

Generated lemmatized results
***************
GENERATED	prominent.a 1520 ::: prevalent;rife;notorious;widespread;rampant;pronounced;pervasive;conspicuous;omnipresent;promiscuous

Filtered results
***************
RANKED	prominent.a 1520	prevalent 0.00442	pronounced 0.00385	conspicuous 0.00380	famous 0.00371	notable 0.00358	noticeable 0.00341	important 0.00324	visible 0.00318	renowned 0.00299	obvious 0.00297	eminent 0.00290	salient 0.00288	significant 0.00276	foremost 0.00274	leading 0.00227	major 0.00142

Test context:
***************
pull.v	1521	11	trichotillomania is an obsessive compulsive disorder which compels a person to __pull__ out either their hair , their eyelashes or their eyebrows .
Contexts for target pull are: ['aux_to', 'infmodI_person', 'prt_out', 'dobj_hair']
Contexts in vocabulary for target pull are: ['aux_to', 'infmodI_person', 'prt_out', 'dobj_hair']
Top most similar embeddings: pull 0.07058	manhandle 0.05429	wheedle 0.05152	straighten 0.05101	pry 0.04926	tease 0.04898	prise 0.04873	push 0.04740	pluck 0.04703	pulled 0.04699

Generated lemmatized results
***************
GENERATED	pull.v 1521 ::: manhandle;wheedle;straighten;pry;tease;prise;push;pluck;amputate;fondle

Filtered results
***************
RANKED	pull.v 1521	push 0.04740	pluck 0.04703	squeeze 0.04306	rip 0.04246	remove 0.04208	heave 0.04079	yank 0.04041	drag 0.03978	draw 0.03977	tug 0.03848	move 0.03801	stretch 0.03725	haul 0.03697	tow 0.03679	lure 0.03553	withdraw 0.03552	manipulate 0.03544	stop 0.03504	read 0.03469	wrench 0.03423	attract 0.03231	shift 0.03125	extract 0.03027	park 0.02803	request 0.02734

Test context:
***************
pull.v	1522	5	each portion was rolled and __pulled__ into a boule shape and i discovered that the dough was n't too hard to work with .
Contexts for target pulled are: ['conjI_rolled', 'prep:into_shape']
Contexts in vocabulary for target pulled are: ['conjI_rolled', 'prep:into_shape']
Top most similar embeddings: pulled 0.26228	tugged 0.21773	slid 0.21001	yanked 0.20775	knocked 0.20587	sagged 0.20355	pulling 0.20325	squeezed 0.20258	twirled 0.20250	twitched 0.20207

Generated lemmatized results
***************
GENERATED	pull.v 1522 ::: tug;slide;yank;knock;sag;squeeze;twirl;twitch;knead;unfasten

Filtered results
***************
RANKED	pull.v 1522	tug 0.21773	yank 0.20775	squeeze 0.20258	wrench 0.20028	heave 0.19965	push 0.19931	rip 0.19026	drag 0.18959	stretch 0.18590	pluck 0.18094	haul 0.17567	tow 0.15880	withdraw 0.15830	draw 0.15726	stop 0.15470	shift 0.15189	move 0.15156	manipulate 0.15134	remove 0.14907	extract 0.14340	lure 0.14289	park 0.13796	attract 0.12850	request 0.12107	read 0.11177

Test context:
***************
pull.v	1523	1	i __pulled__ over and made a u turn while chris got out , ran over and took a picture .
Contexts for target pulled are: ['nsubj_i', 'rootI_*root*', 'prt_over', 'cc_and', 'conj_made', 'advcl_got', 'punct_,', 'conj_ran', 'cc_and', 'conj_took', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target pulled are: ['nsubj_i', 'rootI_*root*', 'prt_over', 'cc_and', 'conj_made', 'advcl_got', 'punct_,', 'conj_ran', 'cc_and', 'conj_took', 'punct_.']
Top most similar embeddings: tutted 0.00096	pulled 0.00080	huffed 0.00080	yelped 0.00080	sulked 0.00078	wheezed 0.00077	clanged 0.00076	wiggled 0.00075	bided 0.00075	fidgeted 0.00075

Generated lemmatized results
***************
GENERATED	pull.v 1523 ::: tutted;huff;yelp;sulk;wheeze;clang;wiggle;bid;fidget;unbolt

Filtered results
***************
RANKED	pull.v 1523	heave 0.00073	tug 0.00065	yank 0.00061	stop 0.00057	push 0.00052	drag 0.00052	wrench 0.00051	withdraw 0.00047	move 0.00047	rip 0.00046	squeeze 0.00046	draw 0.00045	haul 0.00044	pluck 0.00044	stretch 0.00043	tow 0.00040	park 0.00039	shift 0.00039	lure 0.00038	attract 0.00036	remove 0.00033	extract 0.00027	read 0.00027	manipulate 0.00026	request 0.00022

Test context:
***************
pull.v	1524	3	you have to __pull__ instead... pull targeted visitors into your site , presell them... then , and only then , sell .
Contexts for target pull are: ['aux_to', 'xcompI_have', 'advmod_instead']
Contexts in vocabulary for target pull are: ['aux_to', 'xcompI_have', 'advmod_instead']
Top most similar embeddings: pull 0.12397	manhandle 0.09801	unhook 0.09750	amputate 0.09608	traipse 0.09553	re-shoot 0.09542	twiddle 0.09538	wheedle 0.09522	re-adjust 0.09516	re-tune 0.09510

Generated lemmatized results
***************
GENERATED	pull.v 1524 ::: manhandle;unhook;amputate;traipse;twiddle;wheedle;wrestle;retune;prussik;jiggle

Filtered results
***************
RANKED	pull.v 1524	push 0.08884	squeeze 0.08526	pluck 0.08461	drag 0.08240	withdraw 0.08223	move 0.08047	draw 0.08038	manipulate 0.08027	yank 0.07987	heave 0.07909	remove 0.07813	lure 0.07549	rip 0.07516	stop 0.07482	haul 0.07288	read 0.07242	tow 0.07170	attract 0.07073	shift 0.07010	stretch 0.06840	wrench 0.06770	tug 0.06768	extract 0.06531	park 0.06236	request 0.06118

Test context:
***************
pull.v	1525	14	" but i would 've been more than happy to go up there and __pull__ the lever both times .
Contexts for target pull are: ['conjI_go', 'dobj_lever', 'tmod_times']
Contexts in vocabulary for target pull are: ['conjI_go', 'dobj_lever', 'tmod_times']
Top most similar embeddings: pull 0.13264	pulled 0.09989	pulling 0.09712	jiggle 0.09499	push 0.09407	twiddle 0.09406	pulls 0.09331	waggle 0.09223	re-attach 0.09185	reattach 0.09127

Generated lemmatized results
***************
GENERATED	pull.v 1525 ::: jiggle;push;twiddle;waggle;reattach;unclip;unhook;straighten;decelerate;depress

Filtered results
***************
RANKED	pull.v 1525	push 0.09407	drag 0.08529	yank 0.08402	squeeze 0.08128	move 0.07876	tug 0.07806	heave 0.07758	pluck 0.07597	wrench 0.07549	remove 0.07491	stretch 0.07159	shift 0.07147	draw 0.07141	haul 0.07066	withdraw 0.07037	manipulate 0.06918	rip 0.06811	tow 0.06802	stop 0.06581	read 0.06545	lure 0.06509	park 0.05829	attract 0.05741	extract 0.05625	request 0.05551

Test context:
***************
pull.v	1526	11	during the dcc test , the two rs-3 's would n't __pull__ the sum of their individual loads by several cars .
Contexts for target pull are: ['prep:during_test', 'punct_,', 'nsubj_rs-3', 'aux_would', "neg_n't", 'rootI_*root*', 'dobj_sum', 'prep:by_cars', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target pull are: ['prep:during_test', 'punct_,', 'aux_would', "neg_n't", 'rootI_*root*', 'dobj_sum', 'prep:by_cars', 'punct_.']
Top most similar embeddings: pull 0.00258	pulled 0.00256	depress 0.00231	balked 0.00230	budged 0.00229	begrudge 0.00228	baulked 0.00228	deplete 0.00222	coughed 0.00221	plowed 0.00218

Generated lemmatized results
***************
GENERATED	pull.v 1526 ::: depress;balk;budge;begrudge;baulk;deplete;cough;plow;clock;sniff

Filtered results
***************
RANKED	pull.v 1526	push 0.00213	stop 0.00204	drag 0.00199	lure 0.00193	yank 0.00190	tug 0.00190	squeeze 0.00188	tow 0.00188	attract 0.00187	rip 0.00187	haul 0.00185	stretch 0.00184	wrench 0.00184	pluck 0.00174	heave 0.00173	park 0.00173	extract 0.00171	remove 0.00171	withdraw 0.00170	shift 0.00167	draw 0.00166	request 0.00164	move 0.00164	manipulate 0.00152	read 0.00138

Test context:
***************
pull.v	1527	3	instead , he __pulls__ over and watches his brother 's " taillights disappear, " thinking of " how nothin ' feels better than blood on blood. " " he can 't arrest his brother, " james said , and quoted the song : " a man turns his back on family , well , he just ain 't no good. " " i think that 's how it is, " james continued. " that 's how i feel about dobson , or haggard .
Contexts for target pulls are: ['advmod_instead', 'punct_,', 'nsubj_he', 'depI_disappear', 'prt_over', 'cc_and', 'conj_watches', 'dobj_brother', "punct_''"]
Contexts in vocabulary for target pulls are: ['advmod_instead', 'punct_,', 'nsubj_he', 'depI_disappear', 'prt_over', 'cc_and', 'conj_watches', 'dobj_brother']
Top most similar embeddings: pulls 0.00329	plucks 0.00292	watches 0.00287	shoves 0.00272	kidnaps 0.00265	skims 0.00260	fumbles 0.00256	kneels 0.00253	scolds 0.00253	topples 0.00253

Generated lemmatized results
***************
GENERATED	pull.v 1527 ::: pluck;watch;shove;kidnap;skim;fumble;kneel;scold;topple;knock

Filtered results
***************
RANKED	pull.v 1527	pluck 0.00292	drag 0.00246	rip 0.00228	squeeze 0.00225	yank 0.00224	push 0.00223	heave 0.00221	haul 0.00197	wrench 0.00197	tug 0.00190	stop 0.00182	manipulate 0.00180	lure 0.00180	withdraw 0.00179	draw 0.00177	move 0.00171	remove 0.00169	read 0.00169	shift 0.00154	stretch 0.00153	attract 0.00148	park 0.00144	tow 0.00133	extract 0.00116	request 0.00106

Test context:
***************
pull.v	1528	7	however , it appears they intend to __pull__ out all stops to get what they want .
Contexts for target pull are: ['aux_to', 'xcompI_intend', 'prt_out', 'dobj_stops', 'xcomp_get']
Contexts in vocabulary for target pull are: ['aux_to', 'xcompI_intend', 'prt_out', 'dobj_stops', 'xcomp_get']
Top most similar embeddings: pull 0.03752	pulling 0.02531	manhandle 0.02473	wheedle 0.02296	push 0.02272	traipse 0.02258	knock 0.02250	pulled 0.02222	bulldoze 0.02221	squeeze 0.02150

Generated lemmatized results
***************
GENERATED	pull.v 1528 ::: manhandle;wheedle;push;traipse;knock;bulldoze;squeeze;wriggle;flatten;carry

Filtered results
***************
RANKED	pull.v 1528	push 0.02272	squeeze 0.02150	drag 0.02046	pluck 0.01990	draw 0.01971	heave 0.01953	haul 0.01890	remove 0.01849	move 0.01841	yank 0.01823	lure 0.01816	rip 0.01749	manipulate 0.01691	stretch 0.01682	withdraw 0.01667	tow 0.01659	stop 0.01603	attract 0.01575	tug 0.01541	read 0.01509	wrench 0.01454	shift 0.01407	park 0.01351	extract 0.01321	request 0.01231

Test context:
***************
pull.v	1529	24	i managed to take all seven of the birds , but one of those wascally wabbits bounced high into the air just as i __pulled__ the trigger , and i missed by a country mile .
Contexts for target pulled are: ['advmod_just', 'mark_as', 'nsubj_i', 'advclI_bounced', 'dobj_trigger']
Contexts in vocabulary for target pulled are: ['advmod_just', 'mark_as', 'nsubj_i', 'advclI_bounced', 'dobj_trigger']
Top most similar embeddings: pulled 0.04861	slid 0.03648	yanked 0.03512	pulls 0.03469	pull 0.03467	ricocheted 0.03451	tugged 0.03451	chugged 0.03416	pinged 0.03385	bobbled 0.03359

Generated lemmatized results
***************
GENERATED	pull.v 1529 ::: slide;yank;ricochet;tug;chug;ping;bobble;clang;grab;wallop

Filtered results
***************
RANKED	pull.v 1529	yank 0.03512	tug 0.03451	heave 0.03199	push 0.03165	wrench 0.02925	squeeze 0.02914	drag 0.02895	pluck 0.02722	stop 0.02654	haul 0.02650	rip 0.02648	draw 0.02554	move 0.02483	withdraw 0.02472	stretch 0.02396	shift 0.02328	tow 0.02268	park 0.02208	lure 0.02172	remove 0.02154	manipulate 0.02075	attract 0.02021	request 0.01984	extract 0.01973	read 0.01865

Test context:
***************
pull.v	1530	2	you should __pull__ your credit report at least once every two years to check for errors .
Contexts for target pull are: ['nsubj_you', 'aux_should', 'rootI_*root*', 'dobj_report', 'prep:at_least', 'prep:at_years', 'xcomp_check', 'punct_.', 'dobj_<eol>']
Contexts in vocabulary for target pull are: ['nsubj_you', 'aux_should', 'rootI_*root*', 'dobj_report', 'prep:at_least', 'prep:at_years', 'xcomp_check', 'punct_.']
Top most similar embeddings: pull 0.00262	re-checked 0.00250	check 0.00246	recheck 0.00239	re-read 0.00235	re-visit 0.00235	remember 0.00232	revisit 0.00232	proofread 0.00231	inspect 0.00228

Generated lemmatized results
***************
GENERATED	pull.v 1530 ::: check;recheck;remember;revisit;proofread;inspect;read;rechecked;review;begin

Filtered results
***************
RANKED	pull.v 1530	read 0.00228	stop 0.00193	remove 0.00179	withdraw 0.00177	draw 0.00176	yank 0.00176	request 0.00171	drag 0.00168	tug 0.00163	push 0.00163	heave 0.00162	pluck 0.00161	tow 0.00159	haul 0.00159	squeeze 0.00156	rip 0.00154	move 0.00152	park 0.00150	lure 0.00150	extract 0.00146	shift 0.00144	wrench 0.00138	stretch 0.00138	attract 0.00138	manipulate 0.00136

Test context:
***************
range.n	1531	2	a full __range__ of hp care pack hardware and software services are available including : installation and start up education courses extended onsite hardware coverage hours from next business day to 24 hours a day , 7 days a week with options including 4-hour response or 6-hour call to repair comprehensive range of software technical support for microsoft and linux-based it solutions helping to deliver high level of application availability .
Contexts for target range are: ['det_a', 'amod_full', 'nsubjI_available', 'prep:of_hardware']
Contexts in vocabulary for target range are: ['det_a', 'amod_full', 'nsubjI_available', 'prep:of_hardware']
Top most similar embeddings: range 0.07532	varity 0.05566	variety 0.05230	panoply 0.05077	selction 0.05053	wide-range 0.04908	backfile 0.04828	assortment 0.04784	selection 0.04764	spectrum 0.04704

Generated lemmatized results
***************
GENERATED	range.n 1531 ::: varity;variety;panoply;selction;backfile;assortment;selection;spectrum;gamut;boatload

Filtered results
***************
RANKED	range.n 1531	variety 0.05230	assortment 0.04784	selection 0.04764	array 0.04564	breadth 0.04252	collection 0.03942	choice 0.03735	series 0.03634	coverage 0.03611	span 0.03447	scope 0.03350	extent 0.03287	distance 0.03218	area 0.03052	limit 0.02935	gallery 0.02921	spread 0.02758	access 0.02728	roaming 0.02629	run 0.02270

Test context:
***************
range.n	1532	4	the guy down the __range__ gave his son something smaller than he had been shooting ( i did n't ever go look at it ) and his kid responded , " i do n't want to shoot those girly bullets .
Contexts for target range are: ['det_the', 'prep:downI_guy']
Contexts in vocabulary for target range are: ['det_the']
Top most similar embeddings: range 0.49880	minerva-press 0.38881	ranges 0.38767	t-series 0.38747	gamut 0.38527	variety 0.38437	d666 0.38355	adenda 0.37863	age-range 0.37851	fridayfax 0.37820

Generated lemmatized results
***************
GENERATED	range.n 1532 ::: gamut;variety;adenda;fridayfax;nomber;snazzmattazz;otherhand;sfvs;spectrum;panoply

Filtered results
***************
RANKED	range.n 1532	variety 0.38437	breadth 0.36821	array 0.36120	assortment 0.35103	selection 0.34233	area 0.33812	series 0.33771	scope 0.33474	collection 0.32807	span 0.32682	extent 0.31882	gallery 0.31524	limit 0.31021	coverage 0.30936	distance 0.30858	choice 0.30837	spread 0.30194	run 0.26891	access 0.26207	roaming 0.25311

Test context:
***************
range.n	1533	28	both mod 0 and mod 1 guns have the capability to fire the new high explosive extended range ammunition developed by ro defence , which extends the surface __range__ to 27km .
Contexts for target range are: ['det_the', 'nn_surface', 'dobjI_extends']
Contexts in vocabulary for target range are: ['det_the', 'nn_surface', 'dobjI_extends']
Top most similar embeddings: range 0.11387	passband 0.09042	gamut 0.09031	field-of-view 0.08969	spectrum 0.08886	clubface 0.08829	ranges 0.08792	isotherm 0.08772	parameterisations 0.08718	parametrization 0.08709

Generated lemmatized results
***************
GENERATED	range.n 1533 ::: passband;gamut;spectrum;clubface;isotherm;parameterisations;parametrization;linewidth;array;toolset

Filtered results
***************
RANKED	range.n 1533	array 0.08663	breadth 0.08600	area 0.08295	scope 0.08103	span 0.07930	coverage 0.07814	distance 0.07746	variety 0.07604	selection 0.07590	assortment 0.07447	collection 0.07412	extent 0.07120	limit 0.07089	gallery 0.06926	spread 0.06899	series 0.06806	choice 0.06656	access 0.06088	run 0.05423	roaming 0.05392

Test context:
***************
range.n	1534	14	in high school , students can prepare for these careers by taking a broad __range__ of courses that include english writing and comprehension , foreign languages , and basic computer proficiency .
Contexts for target range are: ['det_a', 'amod_broad', 'dobjI_taking', 'prep:of_courses']
Contexts in vocabulary for target range are: ['det_a', 'amod_broad', 'dobjI_taking', 'prep:of_courses']
Top most similar embeddings: range 0.07272	variety 0.05553	wide-range 0.05427	varity 0.05152	spectrum 0.04756	selction 0.04688	cross-section 0.04668	portfolio 0.04654	age-range 0.04580	swathe 0.04568

Generated lemmatized results
***************
GENERATED	range.n 1534 ::: variety;varity;spectrum;selction;portfolio;swathe;selection;array;assortment;gamut

Filtered results
***************
RANKED	range.n 1534	variety 0.05553	selection 0.04465	array 0.04454	assortment 0.04430	breadth 0.04338	series 0.03819	choice 0.03715	span 0.03687	scope 0.03573	collection 0.03454	coverage 0.03352	distance 0.03322	extent 0.03160	area 0.03082	spread 0.03023	limit 0.02711	gallery 0.02619	run 0.02269	access 0.02269	roaming 0.02205

Test context:
***************
range.n	1535	8	also not implemented in pgmeter are a wide __range__ of features supported by iometer , including , a graphical configuration user interface , the ability to create , modify and save configuration files , and a fully graphical display of results .
Contexts for target range are: ['det_a', 'amod_wide', 'nsubjpassI_implemented', 'prep:of_features']
Contexts in vocabulary for target range are: ['det_a', 'amod_wide', 'nsubjpassI_implemented', 'prep:of_features']
Top most similar embeddings: range 0.07241	variety 0.05851	wide-range 0.05577	varity 0.05108	array 0.05008	assortment 0.04969	plethora 0.04724	selection 0.04716	selction 0.04703	gamut 0.04664

Generated lemmatized results
***************
GENERATED	range.n 1535 ::: variety;varity;array;assortment;plethora;selection;selction;gamut;swathe;raft

Filtered results
***************
RANKED	range.n 1535	variety 0.05851	array 0.05008	assortment 0.04969	selection 0.04716	breadth 0.04180	span 0.03743	choice 0.03688	series 0.03667	collection 0.03563	scope 0.03525	coverage 0.03247	extent 0.03095	spread 0.02933	area 0.02914	distance 0.02881	limit 0.02860	gallery 0.02640	roaming 0.02482	access 0.02327	run 0.02126

Test context:
***************
range.n	1536	13	she had two small dogs that peed on everything , and had free __range__ of the office and clients ' portfolios .
Contexts for target range are: ['amod_free', 'dobjI_had', 'prep:of_office']
Contexts in vocabulary for target range are: ['amod_free', 'dobjI_had', 'prep:of_office']
Top most similar embeddings: range 0.10483	varity 0.08189	selction 0.08109	assortment 0.08057	ranges 0.07882	variety 0.07873	seisin 0.07764	checkup 0.07764	wide-range 0.07744	clear-out 0.07729

Generated lemmatized results
***************
GENERATED	range.n 1536 ::: varity;selction;assortment;variety;seisin;checkup;privelege;backlist;choice;plateful

Filtered results
***************
RANKED	range.n 1536	assortment 0.08057	variety 0.07873	choice 0.07627	selection 0.07413	array 0.07030	coverage 0.07015	breadth 0.06969	span 0.06964	scope 0.06910	collection 0.06846	series 0.06801	distance 0.06645	access 0.06614	limit 0.06271	extent 0.06246	area 0.06162	gallery 0.06027	spread 0.05920	roaming 0.05899	run 0.05829

Test context:
***************
range.n	1537	5	first , choose a date __range__ for your search .
Contexts for target range are: ['det_a', 'nn_date', 'dobjI_choose', 'prep:for_search']
Contexts in vocabulary for target range are: ['det_a', 'nn_date', 'dobjI_choose', 'prep:for_search']
Top most similar embeddings: range 0.06150	variety 0.04239	wordlist 0.04095	submenu 0.04045	selection 0.04023	ranges 0.04023	subkey 0.04003	radiobutton 0.03995	check-box 0.03985	sub-topic 0.03982

Generated lemmatized results
***************
GENERATED	range.n 1537 ::: variety;wordlist;submenu;selection;subkey;radiobutton;datatype;contextobject;selction;pallette

Filtered results
***************
RANKED	range.n 1537	variety 0.04239	selection 0.04023	array 0.03847	assortment 0.03796	limit 0.03396	span 0.03338	distance 0.03335	choice 0.03320	scope 0.03303	collection 0.03264	series 0.03243	area 0.03213	breadth 0.03185	coverage 0.03046	extent 0.03032	gallery 0.02652	spread 0.02579	roaming 0.02352	access 0.02288	run 0.02183

Test context:
***************
range.n	1538	40	a variety of outdoor and environmental groups hammered out an agreement in july with the air force , which has used the fragile canyonlands-home to elk , deer , and bighorn sheep , and beloved by river rafters-as a bombing __range__ .
Contexts for target range are: ['det_a', 'nn_bombing', 'depI_rafters-as']
Contexts in vocabulary for target range are: ['det_a', 'nn_bombing']
Top most similar embeddings: range 0.26970	variety 0.19876	wide-range 0.19361	varity 0.18053	roomful 0.17735	cross-section 0.17655	counter-offensive 0.17620	assortment 0.17453	multitude 0.17371	array 0.17276

Generated lemmatized results
***************
GENERATED	range.n 1538 ::: variety;varity;roomful;assortment;multitude;array;plethora;swathe;repetoire;throughball

Filtered results
***************
RANKED	range.n 1538	variety 0.19876	assortment 0.17453	array 0.17276	selection 0.16847	series 0.16269	span 0.15932	breadth 0.15575	area 0.14800	collection 0.14666	distance 0.14298	coverage 0.14234	scope 0.14196	limit 0.14195	run 0.13997	gallery 0.13704	extent 0.13592	choice 0.13559	spread 0.13380	roaming 0.11164	access 0.10734

Test context:
***************
range.n	1539	15	" the forum on children and violence is a membership organisation bringing together a wide __range__ of people committed to the goal of creating a nonviolent society .
Contexts for target range are: ['det_a', 'amod_wide', 'dobjI_bringing', 'prep:of_people']
Contexts in vocabulary for target range are: ['det_a', 'amod_wide', 'dobjI_bringing', 'prep:of_people']
Top most similar embeddings: range 0.07632	variety 0.05995	wide-range 0.05758	cross-section 0.05394	roomful 0.05341	selction 0.05160	varity 0.05143	assortment 0.05141	swathe 0.04970	boatload 0.04939

Generated lemmatized results
***************
GENERATED	range.n 1539 ::: variety;roomful;selction;varity;assortment;swathe;boatload;busload;multitude;gamut

Filtered results
***************
RANKED	range.n 1539	variety 0.05995	assortment 0.05141	array 0.04703	selection 0.04643	breadth 0.04419	span 0.03740	collection 0.03707	choice 0.03615	coverage 0.03432	series 0.03347	scope 0.03325	distance 0.03132	spread 0.03123	extent 0.03117	area 0.03036	limit 0.02855	gallery 0.02788	roaming 0.02453	access 0.02369	run 0.02067

Test context:
***************
range.n	1540	20	tidbits was a way for this rarefied group of people to get the information they needed on a very narrow __range__ of topics .
Contexts for target range are: ['det_a', 'amod_narrow', 'prep:onI_needed', 'prep:of_topics']
Contexts in vocabulary for target range are: ['det_a', 'amod_narrow', 'prep:onI_needed', 'prep:of_topics']
Top most similar embeddings: range 0.06771	variety 0.05150	wide-range 0.04977	spectrum 0.04407	gamut 0.04384	swath 0.04246	varity 0.04232	selection 0.04218	swathe 0.04205	sub-set 0.04205

Generated lemmatized results
***************
GENERATED	range.n 1540 ::: variety;spectrum;gamut;swath;varity;selection;swathe;array;raft;selction

Filtered results
***************
RANKED	range.n 1540	variety 0.05150	selection 0.04218	array 0.04200	breadth 0.04047	assortment 0.04045	span 0.03656	scope 0.03638	choice 0.03529	series 0.03505	collection 0.03329	extent 0.03201	spread 0.03089	area 0.03016	limit 0.02969	coverage 0.02960	distance 0.02845	gallery 0.02668	access 0.02266	run 0.02238	roaming 0.02148

Test context:
***************
rather.r	1541	8	4. technology is a tool ' a means __rather__ than an end .
Contexts for target rather are: ['advmodI_than']
Contexts in vocabulary for target rather are: ['advmodI_than']
Top most similar embeddings: rather 0.57315	aggressively 0.36686	even 0.36579	otherwise 0.36568	perhaps 0.36063	demographically 0.35974	tenaciously 0.35868	more 0.35403	tiresomely 0.35297	modestly 0.35132

Generated lemmatized results
***************
GENERATED	rather.r 1541 ::: aggressively;even;otherwise;perhaps;demographically;tenaciously;more;tiresomely;modestly;somewhat

Filtered results
***************
RANKED	rather.r 1541	more 0.35403	somewhat 0.35113	instead 0.34666	fairly 0.34222	slightly 0.33527	significantly 0.32450	quite 0.31939	sooner 0.30888	very 0.30616	moderately 0.29783	preferably 0.26376

Test context:
***************
rather.r	1542	11	doane argues that the female spectator is consumed by the image __rather__ than consuming it .
Contexts for target rather are: ['advmodI_than']
Contexts in vocabulary for target rather are: ['advmodI_than']
Top most similar embeddings: rather 0.57315	aggressively 0.36686	even 0.36579	otherwise 0.36568	perhaps 0.36063	demographically 0.35974	tenaciously 0.35868	more 0.35403	tiresomely 0.35297	modestly 0.35132

Generated lemmatized results
***************
GENERATED	rather.r 1542 ::: aggressively;even;otherwise;perhaps;demographically;tenaciously;more;tiresomely;modestly;somewhat

Filtered results
***************
RANKED	rather.r 1542	more 0.35403	somewhat 0.35113	instead 0.34666	fairly 0.34222	slightly 0.33527	significantly 0.32450	quite 0.31939	sooner 0.30888	very 0.30616	moderately 0.29783	preferably 0.26376

Test context:
***************
rather.r	1543	10	it is characteristic of those who take power by conquest __rather__ than honest means , to seek first to contain and control their opposition .
Contexts for target rather are: ['ccI_conquest', 'mwe_than']
Contexts in vocabulary for target rather are: ['ccI_conquest', 'mwe_than']
Top most similar embeddings: rather 0.26591	well 0.15854	or 0.15079	and 0.14528	instead 0.14440	vs. 0.14239	nor 0.13791	but 0.13336	and/or 0.12921	somewhat 0.12760

Generated lemmatized results
***************
GENERATED	rather.r 1543 ::: well;or;and;instead;nor;but;somewhat;plus;versus;either

Filtered results
***************
RANKED	rather.r 1543	instead 0.14440	somewhat 0.12760	slightly 0.12148	fairly 0.11660	moderately 0.10724	quite 0.10674	very 0.10299	significantly 0.10276	sooner 0.10212	preferably 0.10018	more 0.09136

Test context:
***************
rather.r	1544	40	it is therefore becoming increasingly important when using this term , particularly in an environment of users with a variety of computing backgrounds and experience , to be precise and refer to a particular type of computer and computing environment __rather__ than assume that everyone means the same thing by the term " workstation .
Contexts for target rather are: ['ccI_type', 'mwe_than']
Contexts in vocabulary for target rather are: ['ccI_type', 'mwe_than']
Top most similar embeddings: rather 0.29004	well 0.16164	or 0.15963	instead 0.15727	vs. 0.15075	and 0.14846	but 0.14257	either 0.13937	nor 0.13771	and/or 0.13707

Generated lemmatized results
***************
GENERATED	rather.r 1544 ::: well;or;instead;and;but;either;nor;versus;plus;somewhat

Filtered results
***************
RANKED	rather.r 1544	instead 0.15727	somewhat 0.13459	slightly 0.12381	fairly 0.12163	quite 0.11127	moderately 0.10902	very 0.10668	sooner 0.10572	significantly 0.10543	preferably 0.10224	more 0.09145

Test context:
***************
rather.r	1545	28	his finger on the pulse of the american people is more of what he can get away with and have them still support him ; a political calculation __rather__ than either an ideological or philosophical calculation .
Contexts for target rather are: ['advmodI_than']
Contexts in vocabulary for target rather are: ['advmodI_than']
Top most similar embeddings: rather 0.57315	aggressively 0.36686	even 0.36579	otherwise 0.36568	perhaps 0.36063	demographically 0.35974	tenaciously 0.35868	more 0.35403	tiresomely 0.35297	modestly 0.35132

Generated lemmatized results
***************
GENERATED	rather.r 1545 ::: aggressively;even;otherwise;perhaps;demographically;tenaciously;more;tiresomely;modestly;somewhat

Filtered results
***************
RANKED	rather.r 1545	more 0.35403	somewhat 0.35113	instead 0.34666	fairly 0.34222	slightly 0.33527	significantly 0.32450	quite 0.31939	sooner 0.30888	very 0.30616	moderately 0.29783	preferably 0.26376

Test context:
***************
rather.r	1546	10	please do n't be intimidated by the good dancers but __rather__ be inspired !
Contexts for target rather are: ['advmodI_inspired']
Contexts in vocabulary for target rather are: ['advmodI_inspired']
Top most similar embeddings: rather 0.48729	ineffably 0.40537	tiresomely 0.39968	beguilingly 0.39801	fearsomely 0.39665	pleasently 0.39555	crushingly 0.39396	heartbreakingly 0.39391	apprently 0.39352	contrastingly 0.39123

Generated lemmatized results
***************
GENERATED	rather.r 1546 ::: ineffably;tiresomely;beguilingly;fearsomely;pleasently;crushingly;heartbreakingly;apprently;contrastingly;viscerally

Filtered results
***************
RANKED	rather.r 1546	somewhat 0.37192	instead 0.36998	very 0.35547	quite 0.35331	slightly 0.33879	fairly 0.33855	more 0.32373	significantly 0.31577	moderately 0.31542	preferably 0.30665	sooner 0.30429

Test context:
***************
rather.r	1547	13	but if the party identification distribution is fairly stable and tends to change __rather__ slowly , why would polls suddenly be turning up unrealistically high numbers of republican identifiers ?
Contexts for target rather are: ['advmodI_slowly']
Contexts in vocabulary for target rather are: ['advmodI_slowly']
Top most similar embeddings: rather 0.52395	crushingly 0.39011	extemely 0.38781	ineffably 0.38751	fearsomely 0.38473	very 0.38406	comparitively 0.38383	decidely 0.38351	indescribably 0.38338	tiresomely 0.38273

Generated lemmatized results
***************
GENERATED	rather.r 1547 ::: crushingly;extemely;ineffably;fearsomely;very;comparitively;decidely;indescribably;tiresomely;too

Filtered results
***************
RANKED	rather.r 1547	very 0.38406	somewhat 0.37919	quite 0.36788	fairly 0.36565	more 0.35038	slightly 0.34840	instead 0.34605	moderately 0.31783	sooner 0.31493	significantly 0.30453	preferably 0.29543

Test context:
***************
rather.r	1548	19	this is in line with the aims of water pollution control , which is designed to produce healthy lakes __rather__ than maximizing fish yields. pdf ( 197 kb ) energy saving energy - and protecting the climate in the late 1980s , the debate on energy policy was still dominated by the issue of nuclear power .
Contexts for target rather are: ['ccI_lakes', 'mwe_than']
Contexts in vocabulary for target rather are: ['ccI_lakes', 'mwe_than']
Top most similar embeddings: rather 0.24892	well 0.16073	or 0.14780	and 0.14710	vs. 0.14052	instead 0.13843	& 0.13576	plus 0.13506	somewhat 0.13053	nor 0.12929

Generated lemmatized results
***************
GENERATED	rather.r 1548 ::: well;or;and;instead;plus;somewhat;nor;but;versus;minus

Filtered results
***************
RANKED	rather.r 1548	instead 0.13843	somewhat 0.13053	slightly 0.11964	fairly 0.11566	moderately 0.10880	quite 0.10813	very 0.10730	significantly 0.10205	sooner 0.10066	preferably 0.09935	more 0.09241

Test context:
***************
rather.r	1549	12	and , as a purely semantic matter , i always find it __rather__ ironic that the label " god-given " is attached to " rights " by mere mortal men and women .
Contexts for target rather are: ['advmodI_ironic']
Contexts in vocabulary for target rather are: ['advmodI_ironic']
Top most similar embeddings: rather 0.53466	tiresomely 0.41354	ineffably 0.41108	comically 0.40786	heartbreakingly 0.40350	bitingly 0.40264	maddeningly 0.40119	somewhat 0.40007	perhaps 0.39993	indescribably 0.39879

Generated lemmatized results
***************
GENERATED	rather.r 1549 ::: tiresomely;ineffably;comically;heartbreakingly;bitingly;maddeningly;somewhat;perhaps;indescribably;pleasently

Filtered results
***************
RANKED	rather.r 1549	somewhat 0.40007	quite 0.37013	slightly 0.36623	instead 0.35968	very 0.35579	fairly 0.34720	moderately 0.32640	more 0.32365	significantly 0.31140	sooner 0.28859	preferably 0.28737

Test context:
***************
rather.r	1550	28	in response to criticism , changes were made at the end of 2002 to the implementation of the pact , notably to focus more on cyclically adjusted , __rather__ than current budget deficits .
Contexts for target rather are: ['advmodI_than']
Contexts in vocabulary for target rather are: ['advmodI_than']
Top most similar embeddings: rather 0.57315	aggressively 0.36686	even 0.36579	otherwise 0.36568	perhaps 0.36063	demographically 0.35974	tenaciously 0.35868	more 0.35403	tiresomely 0.35297	modestly 0.35132

Generated lemmatized results
***************
GENERATED	rather.r 1550 ::: aggressively;even;otherwise;perhaps;demographically;tenaciously;more;tiresomely;modestly;somewhat

Filtered results
***************
RANKED	rather.r 1550	more 0.35403	somewhat 0.35113	instead 0.34666	fairly 0.34222	slightly 0.33527	significantly 0.32450	quite 0.31939	sooner 0.30888	very 0.30616	moderately 0.29783	preferably 0.26376

Test context:
***************
render.v	1551	6	in short , he may be __rendered__ insane upon every subject which is not founded on , and which does not remain in never-varying consistency with , the facts that surround mankind .
Contexts for target rendered are: ['prep:in_short', 'punct_,', 'nsubjpass_he', 'aux_may', 'auxpass_be', 'rootI_*root*', 'dobj_insane', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target rendered are: ['prep:in_short', 'punct_,', 'nsubjpass_he', 'aux_may', 'auxpass_be', 'rootI_*root*', 'dobj_insane', 'punct_.']
Top most similar embeddings: rendered 0.00352	judged 0.00272	driven 0.00260	regarded 0.00254	deemed 0.00249	transformed 0.00244	considered 0.00243	characterized 0.00241	proved 0.00240	declared 0.00239

Generated lemmatized results
***************
GENERATED	render.v 1551 ::: judge;drive;regard;deem;transform;consider;characterize;prove;declare;preclude

Filtered results
***************
RANKED	render.v 1551	portray 0.00221	convert 0.00213	represent 0.00209	make 0.00203	create 0.00196	show 0.00190	deliver 0.00190	give 0.00186	bestow 0.00183	provide 0.00180	encode 0.00177	display 0.00174	use 0.00174	leave 0.00166	submit 0.00161

Test context:
***************
render.v	1552	10	a shared interest in prosperity has not been enough to __render__ benign alienage and the political erasures of borders .
Contexts for target render are: ['aux_to', 'xcompI_enough', 'dobj_alienage']
Contexts in vocabulary for target render are: ['aux_to', 'xcompI_enough']
Top most similar embeddings: render 0.27352	unnerve 0.20338	propitiate 0.20141	supress 0.19684	legitimize 0.19602	gainsay 0.19558	proove 0.19523	satiate 0.19400	expiate 0.19376	overawe 0.19332

Generated lemmatized results
***************
GENERATED	render.v 1552 ::: unnerve;propitiate;supress;legitimize;gainsay;proove;satiate;expiate;overawe;dehumanise

Filtered results
***************
RANKED	render.v 1552	make 0.19113	give 0.17863	create 0.17502	bestow 0.17366	portray 0.17296	provide 0.16585	encode 0.16464	deliver 0.16338	convert 0.16092	represent 0.15411	leave 0.15159	show 0.14992	display 0.14835	submit 0.14391	use 0.14374

Test context:
***************
render.v	1553	17	it is , therefore , without any substance to urge that the services under the scheme are __rendered__ free of charge and , therefore , the scheme is not a " service " under the act .
Contexts for target rendered are: ['mark_that', 'nsubjpass_services', 'auxpass_are', 'ccompI_urge', 'dep_free']
Contexts in vocabulary for target rendered are: ['mark_that', 'nsubjpass_services', 'auxpass_are', 'ccompI_urge', 'dep_free']
Top most similar embeddings: rendered 0.03088	provided 0.02256	delivered 0.02144	warranted 0.02053	deemed 0.02027	given 0.02023	accorded 0.02014	offered 0.01996	mainstreamed 0.01994	judged 0.01989

Generated lemmatized results
***************
GENERATED	render.v 1553 ::: provide;deliver;warrant;deem;give;accord;offer;mainstreamed;judge;afford

Filtered results
***************
RANKED	render.v 1553	provide 0.02256	deliver 0.02144	give 0.02023	represent 0.01731	make 0.01715	display 0.01651	use 0.01607	bestow 0.01598	create 0.01575	encode 0.01567	portray 0.01562	convert 0.01490	show 0.01472	submit 0.01453	leave 0.01369

Test context:
***************
render.v	1554	19	posted by : robrob at june 23 , 2005 02:04 am where will the greed of corporations intent on __rendering__ skilled american workers obsolete end ?
Contexts for target rendering are: ['pcompI_on', 'dobj_end']
Contexts in vocabulary for target rendering are: ['pcompI_on', 'dobj_end']
Top most similar embeddings: rendering 0.23484	demarcating 0.18087	sandwiching 0.18048	snuffing 0.17873	re-instating 0.17797	sealing 0.17701	punctuating 0.17650	charring 0.17641	parsing 0.17639	upsizing 0.17554

Generated lemmatized results
***************
GENERATED	render.v 1554 ::: demarcate;sandwich;snuff;seal;punctuate;char;parse;upsizing;scupper;spice

Filtered results
***************
RANKED	render.v 1554	make 0.17348	leave 0.16538	use 0.16244	create 0.16047	convert 0.15865	show 0.15718	provide 0.15609	encode 0.15436	deliver 0.15362	portray 0.15362	give 0.15258	represent 0.15101	display 0.15005	bestow 0.14905	submit 0.14806

Test context:
***************
render.v	1555	37	in general , the speech stylesheet will not attempt to specify the mapping between visual layout tags and speech properties , instead leaving it to specific browser implementations and user-specific stylesheets to decide how such tags are __rendered__ .
Contexts for target rendered are: ['advmod_how', 'nsubjpass_tags', 'auxpass_are', 'ccompI_decide']
Contexts in vocabulary for target rendered are: ['advmod_how', 'nsubjpass_tags', 'auxpass_are', 'ccompI_decide']
Top most similar embeddings: rendered 0.05670	handled 0.04505	interpreted 0.04303	implemented 0.04294	repurposed 0.04197	displayed 0.04183	concatenated 0.04149	serialized 0.04129	applied 0.04110	processed 0.04088

Generated lemmatized results
***************
GENERATED	render.v 1555 ::: handle;interpret;implement;repurposed;display;concatenate;serialize;apply;process;parse

Filtered results
***************
RANKED	render.v 1555	display 0.04183	encode 0.04051	use 0.04033	represent 0.03934	deliver 0.03873	portray 0.03759	create 0.03602	convert 0.03535	provide 0.03481	make 0.03475	give 0.03329	show 0.03191	bestow 0.03178	leave 0.02943	submit 0.02850

Test context:
***************
render.v	1556	19	you produce the content , and my browser decides -- along with some input from me -- how to __render__ the content .
Contexts for target render are: ['advmod_how', 'aux_to', 'ccompI_decides', 'dobj_content']
Contexts in vocabulary for target render are: ['advmod_how', 'aux_to', 'ccompI_decides', 'dobj_content']
Top most similar embeddings: render 0.05866	monetise 0.04806	sanitise 0.04513	actualise 0.04511	serialize 0.04510	predetermine 0.04475	re-produce 0.04464	re-present 0.04378	scrutinise 0.04373	translate 0.04371

Generated lemmatized results
***************
GENERATED	render.v 1556 ::: monetise;sanitise;actualise;serialize;predetermine;scrutinise;translate;classify;interpret;delimit

Filtered results
***************
RANKED	render.v 1556	encode 0.04221	create 0.04184	deliver 0.04153	make 0.04001	portray 0.03885	convert 0.03744	represent 0.03624	submit 0.03616	display 0.03591	give 0.03558	provide 0.03535	use 0.03496	bestow 0.03272	leave 0.03232	show 0.02906

Test context:
***************
render.v	1557	18	in particular , provision of an alternative route for cyclists should never be regarded as an excuse for __rendering__ the original road or junction unsuitable for cyclists .
Contexts for target rendering are: ['pcompI_for', 'dobj_road']
Contexts in vocabulary for target rendering are: ['pcompI_for', 'dobj_road']
Top most similar embeddings: rendering 0.24636	re-instating 0.19132	beautifying 0.18908	blocking 0.18747	demarcating 0.18136	livening 0.18110	inclosing 0.18043	abbreviating 0.18025	nuking 0.17930	re-painting 0.17924

Generated lemmatized results
***************
GENERATED	render.v 1557 ::: beautify;block;demarcate;liven;inclose;abbreviate;nuke;derail;name;blanket

Filtered results
***************
RANKED	render.v 1557	make 0.17385	convert 0.17320	leave 0.17050	create 0.16590	use 0.16302	show 0.16038	provide 0.15721	encode 0.15527	portray 0.15525	display 0.15472	deliver 0.15256	represent 0.15203	bestow 0.14983	submit 0.14982	give 0.14920

Test context:
***************
render.v	1558	37	although technological advancements make it possible to ship products from one side of the world to the other within a few days , abuse of a good-quality food before , during or after transportation and storage may __render__ it spoiled or unsafe by the time it reaches the consumer .
Contexts for target render are: ['nsubj_it', 'dep_possible', 'punct_,', 'nsubj_abuse', 'aux_may', 'xcompI_make', 'ccomp_spoiled']
Contexts in vocabulary for target render are: ['nsubj_it', 'dep_possible', 'punct_,', 'nsubj_abuse', 'aux_may', 'xcompI_make', 'ccomp_spoiled']
Top most similar embeddings: render 0.00631	transpire 0.00454	inevitable 0.00441	excusable 0.00435	invalidate 0.00432	understandable 0.00425	inconceivable 0.00422	disturb 0.00420	offend 0.00420	connote 0.00419

Generated lemmatized results
***************
GENERATED	render.v 1558 ::: transpire;inevitable;excusable;invalidate;understandable;inconceivable;disturb;offend;connote;arguable

Filtered results
***************
RANKED	render.v 1558	bestow 0.00328	portray 0.00317	create 0.00309	make 0.00305	represent 0.00286	encode 0.00285	leave 0.00283	convert 0.00275	give 0.00262	deliver 0.00261	display 0.00259	provide 0.00254	show 0.00253	submit 0.00251	use 0.00214

Test context:
***************
render.v	1559	2	" this __renders__ necessary a brief review of the position occupied by the administration on this important and vital question .
Contexts for target renders are: ["punct_''", 'nsubj_this', 'rootI_*root*', 'amod_necessary', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target renders are: ['nsubj_this', 'rootI_*root*', 'amod_necessary', 'punct_.']
Top most similar embeddings: renders 0.06073	means 0.04936	substantiates 0.04862	obviates 0.04818	necessitates 0.04781	ensures 0.04755	underlines 0.04686	reinforces 0.04676	complicates 0.04625	implies 0.04618

Generated lemmatized results
***************
GENERATED	render.v 1559 ::: mean;substantiate;obviate;necessitate;ensure;underline;reinforce;complicate;imply;corroborate

Filtered results
***************
RANKED	render.v 1559	create 0.04344	make 0.04235	give 0.03884	encode 0.03863	use 0.03805	show 0.03793	represent 0.03691	convert 0.03678	leave 0.03671	bestow 0.03644	provide 0.03610	deliver 0.03599	portray 0.03570	display 0.03499	submit 0.03444

Test context:
***************
render.v	1560	29	schon ( 1983,1987 ) has noted that " practice is characterized by indeterminacy , and what distinguishes the excellent practitioner from the merely adequate one is the ability to __render__ indeterminate situations determinate .
Contexts for target render are: ['aux_to', 'infmodI_ability', 'ccomp_determinate']
Contexts in vocabulary for target render are: ['aux_to', 'infmodI_ability']
Top most similar embeddings: render 0.26646	notate 0.20137	objectify 0.19919	actualise 0.19880	supress 0.19686	mass-produce 0.19659	actualize 0.19642	reprogramme 0.19531	dehumanise 0.19519	re-activate 0.19467

Generated lemmatized results
***************
GENERATED	render.v 1560 ::: notate;objectify;actualise;supress;actualize;reprogramme;dehumanise;externalise;reorient;irradiate

Filtered results
***************
RANKED	render.v 1560	make 0.18606	create 0.18595	deliver 0.18074	encode 0.17842	portray 0.17831	provide 0.17341	convert 0.16934	give 0.16881	bestow 0.16690	represent 0.16032	display 0.15834	use 0.15649	submit 0.15032	show 0.14564	leave 0.14458

Test context:
***************
rhythm.n	1561	28	intermediate level - musicians who can play in the usual keys of the instrument , have knowledge of where to find the notes , a fair idea of __rhythm__ , and can follow at a reasonable pace .
Contexts for target rhythm are: ['prep:ofI_idea']
Contexts in vocabulary for target rhythm are: ['prep:ofI_idea']
Top most similar embeddings: rhythm 0.48540	rythm 0.40450	rhythms 0.38704	scansion 0.37929	rythmn 0.37497	interiority 0.37058	tempo 0.36838	self-reflexivity 0.36776	raga 0.36581	serialism 0.36575

Generated lemmatized results
***************
GENERATED	rhythm.n 1561 ::: rythm;scansion;rythmn;interiority;tempo;raga;serialism;aliveness;drumbeat;synchronicity

Filtered results
***************
RANKED	rhythm.n 1561	tempo 0.36838	harmony 0.36005	cadence 0.34702	pattern 0.32936	pulse 0.31156	beat 0.30538	cycle 0.30019	clock 0.28383	form 0.27096

Test context:
***************
rhythm.n	1562	11	research has shown that with consistent active lifestyle , your circadian __rhythm__ can change to improve the quality of sleep you can get .
Contexts for target rhythm are: ['poss_your', 'amod_circadian', 'nsubjI_change']
Contexts in vocabulary for target rhythm are: ['poss_your', 'amod_circadian', 'nsubjI_change']
Top most similar embeddings: rhythm 0.12619	rhythms 0.10785	rythm 0.09585	brainwaves 0.08858	biorhythms 0.08787	tempo 0.08715	patterns 0.08689	moods 0.08470	pattern 0.08241	patters 0.08181

Generated lemmatized results
***************
GENERATED	rhythm.n 1562 ::: rythm;brainwave;biorhythms;tempo;pattern;mood;patter;timing;clock;heartbeat

Filtered results
***************
RANKED	rhythm.n 1562	tempo 0.08715	pattern 0.08689	clock 0.08092	pulse 0.07823	cadence 0.07823	cycle 0.07406	beat 0.06971	harmony 0.06872	form 0.05380

Test context:
***************
rhythm.n	1563	19	( back to top ) why it is used adenosine is used to restore a normal heart rate and __rhythm__ when you are having an episode of supraventricular tachycardia .
Contexts for target rhythm are: ['conjI_restore', 'rcmod_having']
Contexts in vocabulary for target rhythm are: ['conjI_restore', 'rcmod_having']
Top most similar embeddings: rhythm 0.18944	rythm 0.15250	rhythms 0.15191	harmony 0.15133	composure 0.14668	palpitations 0.14588	groove 0.14544	riff 0.14535	mood 0.14525	moods 0.14459

Generated lemmatized results
***************
GENERATED	rhythm.n 1563 ::: rythm;harmony;composure;palpitation;groove;riff;mood;heartache;oversteer;bassline

Filtered results
***************
RANKED	rhythm.n 1563	harmony 0.15133	tempo 0.14240	cadence 0.14063	pattern 0.13469	pulse 0.13278	beat 0.13142	cycle 0.12685	clock 0.11497	form 0.11096

Test context:
***************
rhythm.n	1564	13	' using print shop i printed the names of various animals with a __rhythm__ that matched the number of syllables in its name .
Contexts for target rhythm are: ['det_a', 'prep:withI_animals', 'rcmod_matched']
Contexts in vocabulary for target rhythm are: ['det_a', 'prep:withI_animals', 'rcmod_matched']
Top most similar embeddings: rhythm 0.11824	bassline 0.09072	rythm 0.08872	pattern 0.08857	muscularity 0.08841	vibrato 0.08785	riff 0.08700	sonority 0.08565	rhythms 0.08515	groove 0.08509

Generated lemmatized results
***************
GENERATED	rhythm.n 1564 ::: bassline;rythm;pattern;muscularity;vibrato;riff;sonority;groove;backbeat;melody

Filtered results
***************
RANKED	rhythm.n 1564	pattern 0.08857	cadence 0.08339	tempo 0.08046	harmony 0.07375	pulse 0.07272	beat 0.06937	cycle 0.06713	clock 0.06476	form 0.06107

Test context:
***************
rhythm.n	1565	9	negative mental and emotional processes electrically scramble the natural __rhythms__ of the heart , creating jerky rhythms as well as incoherent patterns in the heart 's electrical frequency domain .
Contexts for target rhythms are: ['det_the', 'amod_natural', 'dobjI_scramble', 'prep:of_heart']
Contexts in vocabulary for target rhythms are: ['det_the', 'amod_natural', 'dobjI_scramble', 'prep:of_heart']
Top most similar embeddings: rhythms 0.06412	rhythm 0.05343	cadences 0.04764	drumbeats 0.04614	pulsations 0.04508	impulses 0.04410	lineaments 0.04393	promptings 0.04377	chords 0.04366	blueness 0.04348

Generated lemmatized results
***************
GENERATED	rhythm.n 1565 ::: cadence;drumbeat;pulsation;impulse;lineament;prompting;chord;blueness;exhalation;instinct

Filtered results
***************
RANKED	rhythm.n 1565	cadence 0.04764	harmony 0.04224	beat 0.03803	pattern 0.03802	pulse 0.03749	tempo 0.03715	cycle 0.03563	clock 0.03434	form 0.02964

Test context:
***************
rhythm.n	1566	8	sometimes , with the dancing , and the __rhythm__ , the walls of the house would bow in an out like an early disney cartoon .
Contexts for target rhythm are: ['punct_,', 'cc_and', 'det_the', 'parataxisI_bow', 'punct_,']
Contexts in vocabulary for target rhythm are: ['punct_,', 'cc_and', 'det_the', 'punct_,']
Top most similar embeddings: quadrilles 0.06341	rhythm 0.06222	cornetts 0.06160	erhu 0.06018	fifes 0.05943	shawms 0.05927	sattva 0.05821	spleenwort 0.05784	montagues 0.05773	groundhogs 0.05768

Generated lemmatized results
***************
GENERATED	rhythm.n 1566 ::: quadrille;cornetts;erhu;fife;shawm;sattva;spleenwort;montagues;groundhog;oysterband

Filtered results
***************
RANKED	rhythm.n 1566	tempo 0.04870	cadence 0.04685	harmony 0.04537	beat 0.04276	clock 0.04072	pulse 0.04000	pattern 0.03722	cycle 0.03517	form 0.03164

Test context:
***************
rhythm.n	1567	7	when you introduce the values of a __rhythm__ or when you modify them by double-clicking on the element , the score view always uses a 4/4 measure by default .
Contexts for target rhythm are: ['det_a', 'prep:ofI_values', 'cc_or', 'conj_modify']
Contexts in vocabulary for target rhythm are: ['det_a', 'prep:ofI_values', 'cc_or', 'conj_modify']
Top most similar embeddings: rhythm 0.04982	hyperbola 0.04087	vibrato 0.04015	timbre 0.04013	sinusoid 0.03883	polyline 0.03873	tempo 0.03864	hotkey 0.03843	luminance 0.03842	diphthong 0.03841

Generated lemmatized results
***************
GENERATED	rhythm.n 1567 ::: hyperbola;vibrato;timbre;sinusoid;polyline;tempo;hotkey;luminance;diphthong;lexeme

Filtered results
***************
RANKED	rhythm.n 1567	tempo 0.03864	cadence 0.03700	pattern 0.03415	pulse 0.03407	harmony 0.03301	cycle 0.03253	clock 0.03128	beat 0.02905	form 0.02817

Test context:
***************
rhythm.n	1568	10	possible complications include wound and chest infections and abnormal heart __rhythms__ .
Contexts for target rhythms are: ['amod_abnormal', 'nn_heart', 'conjI_infections']
Contexts in vocabulary for target rhythms are: ['amod_abnormal', 'nn_heart', 'conjI_infections']
Top most similar embeddings: rhythms 0.12923	rhythm 0.10520	inflammations 0.10162	palpitation 0.09844	haemodynamics 0.09739	emboli 0.09691	dysregulation 0.09681	contractility 0.09508	arteriosclerosis 0.09502	pericarditis 0.09494

Generated lemmatized results
***************
GENERATED	rhythm.n 1568 ::: inflammation;palpitation;haemodynamics;embolus;dysregulation;contractility;arteriosclerosis;pericarditis;arrhythmia;paraesthesia

Filtered results
***************
RANKED	rhythm.n 1568	beat 0.08708	pattern 0.08638	pulse 0.07941	cycle 0.07332	cadence 0.07065	harmony 0.06713	tempo 0.06549	form 0.06293	clock 0.06251

Test context:
***************
rhythm.n	1569	31	the ideas we unfold in reading images apply only to the spatial aspects of film ( e.g. the composition of shots ) and not to the temporal aspects of film ( __rhythm__ , editing and so on ) , and , secondly , because of the added time dimension , in film the systems of visual communication we have described become dynamic .
Contexts for target rhythm are: ['punct_-lrb-', 'depI_film', 'punct_,', 'conj_editing', 'cc_and', 'conj_on', 'punct_,', 'cc_and', 'punct_,', 'conj_secondly', 'punct_,', 'prep:of_time', 'punct_,', 'prep:in_film', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target rhythm are: ['depI_film', 'punct_,', 'conj_editing', 'cc_and', 'conj_on', 'punct_,', 'cc_and', 'punct_,', 'conj_secondly', 'punct_,', 'prep:of_time', 'punct_,', 'prep:in_film', 'punct_.']
Top most similar embeddings: gerunds 0.00005	quadrilles 0.00005	storyboarding 0.00004	festen 0.00004	shawms 0.00004	minix 0.00004	bioenergetics 0.00004	sixthly 0.00004	actualities 0.00004	hiragana 0.00004

Generated lemmatized results
***************
GENERATED	rhythm.n 1569 ::: gerund;quadrille;storyboarding;festen;shawm;minix;bioenergetics;sixthly;actuality;hiragana

Filtered results
***************
RANKED	rhythm.n 1569	tempo 0.00003	cadence 0.00002	beat 0.00002	clock 0.00002	harmony 0.00002	pulse 0.00002	cycle 0.00002	pattern 0.00001	form 0.00001

Test context:
***************
rhythm.n	1570	24	" according to burns 's telling , jazz history screeched to a halt in 1968 , when davis went electric , abandoned traditional jazz __rhythms__ , and , a few years later , hired jarrett .
Contexts for target rhythms are: ['amod_abandoned', 'amod_traditional', 'nn_jazz', 'dobjI_screeched', 'punct_,', 'cc_and', 'punct_,', 'advmod_later', 'punct_,', 'partmod_hired']
Contexts in vocabulary for target rhythms are: ['amod_abandoned', 'amod_traditional', 'nn_jazz', 'punct_,', 'cc_and', 'punct_,', 'advmod_later', 'punct_,', 'partmod_hired']
Top most similar embeddings: quadrilles 0.00160	mandolins 0.00156	fifes 0.00155	shawms 0.00151	erhu 0.00148	lutes 0.00147	cornetts 0.00146	polkas 0.00145	gramophones 0.00142	rhythms 0.00141

Generated lemmatized results
***************
GENERATED	rhythm.n 1570 ::: quadrille;mandolin;fife;shawm;erhu;lute;cornetts;polka;gramophone;tablas

Filtered results
***************
RANKED	rhythm.n 1570	cadence 0.00107	harmony 0.00103	tempo 0.00103	beat 0.00101	clock 0.00096	cycle 0.00082	pulse 0.00073	form 0.00071	pattern 0.00068

Test context:
***************
scene.n	1571	23	( missing last minute)(gsn/wo/c/a+/133 ) biography bob barker ( a+ ) mark goodson ( a+ ) deal a very interesting and intimate behind-the __scenes__ look at " let 's make a deal " , one of the most popular game shows of all time .
Contexts for target scenes are: ['det_a', 'amod_interesting', 'amod_behind-the', 'nsubjI_look']
Contexts in vocabulary for target scenes are: ['det_a', 'amod_interesting', 'nsubjI_look']
Top most similar embeddings: scenes 0.11408	scene 0.09628	featurette 0.09041	subplot 0.08644	denouement 0.08594	storyline 0.08567	cutscenes 0.08563	featurettes 0.08557	back-story 0.08540	cutscene 0.08457

Generated lemmatized results
***************
GENERATED	scene.n 1571 ::: featurette;subplot;denouement;storyline;cutscenes;featurettes;cutscene;tableau;moment;backstory

Filtered results
***************
RANKED	scene.n 1571	picture 0.07859	sequence 0.07494	sight 0.07380	landscape 0.07174	segment 0.07045	site 0.06922	image 0.06920	event 0.06817	incident 0.06725	place 0.06555	location 0.06372	part 0.06184	environment 0.06126	area 0.06125	programme 0.06073	arena 0.06068	stage 0.06038	setting 0.05844	scale 0.05795	field 0.05703	sphere 0.05697	backstage 0.05687	level 0.05601	business 0.05506	community 0.05493	act 0.05203

Test context:
***************
scene.n	1572	3	hence becoming the __scene__ of more than one major battle between the olde enemy england .
Contexts for target scene are: ['det_the', 'xcompI_becoming', 'prep:of_battle']
Contexts in vocabulary for target scene are: ['det_the', 'xcompI_becoming', 'prep:of_battle']
Top most similar embeddings: scene 0.12469	epicenter 0.09526	scenes 0.09486	epicentre 0.09290	high-point 0.08619	battlegrounds 0.08570	victim 0.08535	burial-place 0.08528	instigator 0.08488	maelstrom 0.08443

Generated lemmatized results
***************
GENERATED	scene.n 1572 ::: epicenter;epicentre;battleground;victim;instigator;maelstrom;battlefield;megalopolis;ringleader;spectacle

Filtered results
***************
RANKED	scene.n 1572	landscape 0.08090	arena 0.07809	site 0.07780	field 0.07723	event 0.07433	sight 0.07376	part 0.07365	area 0.07129	stage 0.07108	incident 0.07108	sphere 0.07046	segment 0.06951	picture 0.06900	location 0.06867	sequence 0.06865	community 0.06801	scale 0.06773	image 0.06679	environment 0.06327	act 0.06200	place 0.06162	setting 0.06084	level 0.06064	business 0.05873	backstage 0.05444	programme 0.05256

Test context:
***************
scene.n	1573	46	framed by the remains of a smoking , burning doorway and silhouetted against the light , ethan squats and surveys the butchered dead , and his head drops as he imagines the torture that three family members suffered , including martha 's rape. [ a similar __scene__ of luke skywalker 's discovery of his aunt and uncle 's burning home after their murder by imperial stormtroopers is found in george lucas ' star wars ( 1977 ) .
Contexts for target scene are: ['amod_framed', 'punct_.', 'punct_-lsb-', 'det_a', 'amod_similar', 'nsubjpassI_found', 'prep:of_discovery', 'prep:after_murder']
Contexts in vocabulary for target scene are: ['amod_framed', 'punct_.', 'det_a', 'amod_similar', 'nsubjpassI_found', 'prep:of_discovery', 'prep:after_murder']
Top most similar embeddings: scene 0.00530	scenes 0.00408	story 0.00394	photograph 0.00389	picture 0.00389	tombstone 0.00389	portrait 0.00385	tale 0.00380	screenshot 0.00379	description 0.00378

Generated lemmatized results
***************
GENERATED	scene.n 1573 ::: story;photograph;picture;tombstone;portrait;tale;screenshot;description;motif;photo

Filtered results
***************
RANKED	scene.n 1573	picture 0.00389	sequence 0.00349	incident 0.00342	image 0.00310	scale 0.00290	location 0.00289	event 0.00284	landscape 0.00278	sphere 0.00276	field 0.00268	sight 0.00263	site 0.00262	act 0.00258	setting 0.00252	place 0.00252	arena 0.00249	stage 0.00238	segment 0.00236	level 0.00236	area 0.00226	environment 0.00222	programme 0.00218	part 0.00206	business 0.00173	community 0.00173	backstage 0.00169

Test context:
***************
scene.n	1574	13	' it does n't come into play unless you 're actually at a __scene__ or taking action photographs , but digital cameras do not have a shutter speed fast enough to photograph action, ' says pasqualone .
Contexts for target scene are: ['det_a', "prep:atI_'re"]
Contexts in vocabulary for target scene are: ['det_a', "prep:atI_'re"]
Top most similar embeddings: scene 0.24560	bullfight 0.18611	blogmeet 0.18337	dinner-party 0.18142	stratlan 0.17799	dinner-table 0.17779	photo-shoot 0.17678	boarding-house 0.17600	moment 0.17477	landing-place 0.17410

Generated lemmatized results
***************
GENERATED	scene.n 1574 ::: bullfight;blogmeet;stratlan;moment;stakeout;gunfight;seance;waterhole;pawnshop;kopje

Filtered results
***************
RANKED	scene.n 1574	stage 0.16331	level 0.15622	event 0.15299	site 0.15190	incident 0.15131	arena 0.15128	sequence 0.14938	landscape 0.14823	picture 0.14699	sight 0.14688	scale 0.14604	location 0.14482	place 0.14399	segment 0.14248	community 0.13677	sphere 0.13671	image 0.13650	environment 0.13428	area 0.13405	field 0.13403	part 0.13256	setting 0.13188	business 0.12940	backstage 0.12331	programme 0.12247	act 0.11857

Test context:
***************
scene.n	1575	1	every __scene__ seems totally natural like it could have really happened , and yet the movie is not a dull slice-of-life diorama either .
Contexts for target scene are: ['det_every', 'nsubjI_natural']
Contexts in vocabulary for target scene are: ['det_every', 'nsubjI_natural']
Top most similar embeddings: scene 0.23257	scenes 0.17317	gradation 0.16351	tableau 0.16322	gesture 0.15554	emotion 0.15513	episode 0.15488	sentiment 0.15462	nuance 0.15362	skit 0.15328

Generated lemmatized results
***************
GENERATED	scene.n 1575 ::: gradation;tableau;gesture;emotion;episode;sentiment;nuance;skit;exhalation;caesura

Filtered results
***************
RANKED	scene.n 1575	landscape 0.14808	incident 0.14615	stage 0.14179	sequence 0.13999	sphere 0.13735	image 0.13459	level 0.13381	event 0.13346	sight 0.13172	arena 0.13034	field 0.12979	area 0.12963	environment 0.12931	location 0.12837	segment 0.12704	picture 0.12574	part 0.12548	community 0.12418	setting 0.12393	site 0.12196	place 0.12182	scale 0.12180	act 0.12039	business 0.11587	backstage 0.11358	programme 0.09749

Test context:
***************
scene.n	1576	7	undoubtedly a mainstay of the texas music __scene__ , one of lloyd 's best known credits is his daughter , natalie maines , the lead singer for the grammy award winning dixie chicks .
Contexts for target scene are: ['det_the', 'nn_texas', 'nn_music', 'prep:ofI_mainstay']
Contexts in vocabulary for target scene are: ['det_the', 'nn_texas', 'nn_music', 'prep:ofI_mainstay']
Top most similar embeddings: scene 0.07115	scenes 0.04451	industry 0.04406	theater 0.04261	glitterati 0.04226	circuit 0.04218	fraternity 0.04202	subculture 0.04180	fests 0.04121	lineup 0.04120

Generated lemmatized results
***************
GENERATED	scene.n 1576 ::: industry;theater;glitterati;circuit;fraternity;subculture;fests;lineup;revival;weekly

Filtered results
***************
RANKED	scene.n 1576	community 0.03800	arena 0.03781	landscape 0.03739	event 0.03509	site 0.03483	business 0.03467	field 0.03432	stage 0.03340	segment 0.03328	sequence 0.03293	area 0.03197	picture 0.03145	sight 0.03112	scale 0.03068	environment 0.02982	sphere 0.02965	act 0.02951	setting 0.02930	programme 0.02925	level 0.02907	location 0.02897	incident 0.02838	image 0.02740	backstage 0.02710	part 0.02578	place 0.02481

Test context:
***************
scene.n	1577	14	on the plus side , the immediate mode offers the possibility of exploring dynamic __scenes__ .
Contexts for target scenes are: ['amod_dynamic', 'dobjI_exploring']
Contexts in vocabulary for target scenes are: ['amod_dynamic', 'dobjI_exploring']
Top most similar embeddings: scenes 0.23026	landscapes 0.19041	scene 0.19022	inter-relations 0.18608	cityscapes 0.18457	enviroments 0.18271	visualizations 0.18239	juxtapositions 0.18230	soundscapes 0.18083	scenarios 0.18077

Generated lemmatized results
***************
GENERATED	scene.n 1577 ::: landscape;cityscape;enviroments;visualization;juxtaposition;soundscapes;scenario;environment;interrelation;interplay

Filtered results
***************
RANKED	scene.n 1577	landscape 0.19041	environment 0.17974	image 0.16725	sequence 0.16694	sight 0.16475	area 0.15559	arena 0.15485	site 0.15338	location 0.15252	field 0.15111	setting 0.14676	event 0.14486	picture 0.14464	segment 0.14397	part 0.14345	place 0.13969	incident 0.13874	stage 0.13760	sphere 0.13699	level 0.13614	community 0.13239	programme 0.12699	scale 0.12504	business 0.12389	act 0.12362	backstage 0.11670

Test context:
***************
scene.n	1578	50	both times we have a cajus who goes out to walk ; both times a carriage full of people , who both times sing and shout ; both times cajus meets with the carnage ; both times a family is mentioned ; both times an aged woman figures in the __scene__ ; both times the hand is kissed .
Contexts for target scene are: ['det_the', 'prep:inI_figures']
Contexts in vocabulary for target scene are: ['det_the', 'prep:inI_figures']
Top most similar embeddings: scene 0.26949	scenes 0.21034	pericope 0.18509	landscape 0.18484	martyrology 0.18148	half-light 0.18122	silmarillion 0.18003	muqam 0.17967	heavenlies 0.17964	subculture 0.17914

Generated lemmatized results
***************
GENERATED	scene.n 1578 ::: pericope;landscape;martyrology;silmarillion;muqam;heavenlies;subculture;blogosphere;gathas;megalopolis

Filtered results
***************
RANKED	scene.n 1578	landscape 0.18484	arena 0.17263	field 0.17050	community 0.16814	sphere 0.16241	sequence 0.16073	area 0.15876	stage 0.15459	incident 0.15431	environment 0.15429	segment 0.15314	picture 0.15163	image 0.15103	event 0.14843	sight 0.14604	setting 0.14253	scale 0.14094	location 0.13925	site 0.13688	part 0.13445	place 0.13282	business 0.13231	act 0.13164	programme 0.13158	level 0.12983	backstage 0.11209

Test context:
***************
scene.n	1579	4	" reverse : whaling __scene__ with two boats , one being stove by a whale ; ship in background , labeled " 18 jan 1851 / the accident off new zealand .
Contexts for target scene are: ['amod_whaling', 'depI_reverse', 'prep:with_boats', 'punct_,', 'rcmod_stove', 'punct_;', 'conj_ship']
Contexts in vocabulary for target scene are: ['amod_whaling', 'depI_reverse', 'prep:with_boats', 'punct_,', 'punct_;', 'conj_ship']
Top most similar embeddings: scene 0.00987	schooners 0.00895	sloops 0.00891	brig 0.00866	ketch 0.00850	frigates 0.00842	sloop 0.00840	shipbuilders 0.00834	barque 0.00824	brigs 0.00823

Generated lemmatized results
***************
GENERATED	scene.n 1579 ::: schooner;sloop;brig;ketch;frigate;shipbuilder;barque;lugger;seaport;trawler

Filtered results
***************
RANKED	scene.n 1579	sight 0.00633	arena 0.00630	landscape 0.00602	incident 0.00573	sequence 0.00557	act 0.00536	backstage 0.00515	segment 0.00490	picture 0.00485	event 0.00484	stage 0.00462	setting 0.00457	sphere 0.00454	field 0.00451	place 0.00443	scale 0.00438	environment 0.00438	location 0.00437	image 0.00436	community 0.00422	site 0.00418	part 0.00401	programme 0.00384	area 0.00366	business 0.00364	level 0.00356

Test context:
***************
scene.n	1580	10	if we do not take a lead on the national __scene__ , our fate will be in the hands of others ' others who are not likely to share our mission or concerns .
Contexts for target scene are: ['det_the', 'amod_national', 'prep:onI_take']
Contexts in vocabulary for target scene are: ['det_the', 'amod_national', 'prep:onI_take']
Top most similar embeddings: scene 0.12819	otherhand 0.09746	backburner 0.09163	frontlines 0.08909	winline 0.08892	scenes 0.08800	circuit 0.08730	undercard 0.08688	backbenches 0.08582	off-chance 0.08507

Generated lemmatized results
***************
GENERATED	scene.n 1580 ::: otherhand;backburner;frontlines;winline;circuit;undercard;backbench;copperbelt;warpath;chessboard

Filtered results
***************
RANKED	scene.n 1580	landscape 0.08227	arena 0.08109	level 0.07855	scale 0.07839	stage 0.07781	event 0.07560	incident 0.07330	site 0.07312	picture 0.07273	sphere 0.07244	environment 0.07030	field 0.06877	sight 0.06866	programme 0.06852	community 0.06762	image 0.06753	sequence 0.06716	setting 0.06559	area 0.06532	segment 0.06432	location 0.06365	business 0.05977	act 0.05965	part 0.05608	backstage 0.05571	place 0.05442

Test context:
***************
serious.a	1581	7	so that 's going to take some __serious__ cash .
Contexts for target serious are: ['amodI_cash']
Contexts in vocabulary for target serious are: ['amodI_cash']
Top most similar embeddings: serious 0.50620	serous 0.36767	commission-free 0.36705	non-discretionary 0.36635	trumped-up 0.36634	near-fatal 0.36529	non-recurrent 0.36395	geniune 0.36271	pretax 0.36001	uncompensated 0.35995

Generated lemmatized results
***************
GENERATED	serious.a 1581 ::: serous;geniune;pretax;uncompensated;significant;uncleared;substantial;addtional;unspent;genuine

Filtered results
***************
RANKED	serious.a 1581	significant 0.35783	substantial 0.35241	real 0.34835	grave 0.33884	severe 0.33586	urgent 0.33490	considerable 0.33091	major 0.32356	sincere 0.31432	heavy 0.31146	acute 0.31115	businesslike 0.30267	important 0.29886	proper 0.29669	critical 0.29537	resolute 0.29344	impressive 0.29338	concerned 0.27938

Test context:
***************
serious.a	1582	7	it 's long past time to get __serious__ about that one .
Contexts for target serious are: ['aux_to', 'dep_get', 'infmodI_time', 'prep:about_one']
Contexts in vocabulary for target serious are: ['aux_to', 'dep_get', 'infmodI_time', 'prep:about_one']
Top most similar embeddings: serious 0.04755	blase 0.04330	mope 0.04270	fantasise 0.04261	rid 0.04203	choosy 0.04198	fantasize 0.04180	overexcited 0.04124	complacent 0.04111	ruminate 0.04096

Generated lemmatized results
***************
GENERATED	serious.a 1582 ::: blase;mope;fantasise;rid;choosy;fantasize;overexcited;complacent;ruminate;gloat

Filtered results
***************
RANKED	serious.a 1582	businesslike 0.03155	sincere 0.02994	severe 0.02957	concerned 0.02888	resolute 0.02864	heavy 0.02852	urgent 0.02716	critical 0.02702	real 0.02685	grave 0.02581	acute 0.02450	significant 0.02433	important 0.02221	proper 0.02146	substantial 0.02130	impressive 0.02120	considerable 0.02006	major 0.01778

Test context:
***************
serious.a	1583	35	a necessary voice i am truly bewildered by the logic of those who assert that augmentative communications devices are somehow less " necessary " to an als patient ( or any other person with a __serious__ speech impairment ) than a cane , wheelchair , or any other piece of durable medical equipment .
Contexts for target serious are: ['amodI_speech']
Contexts in vocabulary for target serious are: ['amodI_speech']
Top most similar embeddings: serious 0.48577	non-serious 0.39728	vituperative 0.38919	well-publicized 0.38603	extemporaneous 0.38312	grandiloquent 0.38255	much-discussed 0.37893	high-flown 0.37841	severe 0.37794	intemperate 0.37676

Generated lemmatized results
***************
GENERATED	serious.a 1583 ::: vituperative;extemporaneous;grandiloquent;severe;intemperate;valedictory;serous;satiric;perspicacious;cretinous

Filtered results
***************
RANKED	serious.a 1583	severe 0.37794	grave 0.36466	sincere 0.35816	significant 0.35427	major 0.34530	real 0.33899	substantial 0.33481	urgent 0.32988	important 0.31991	considerable 0.31349	resolute 0.31217	acute 0.31202	impressive 0.31101	businesslike 0.30747	critical 0.30698	heavy 0.30660	proper 0.30043	concerned 0.29435

Test context:
***************
serious.a	1584	4	they face a more __serious__ problem in that the bottom of the market is beginning to bundle these sorts of features and rightly so .
Contexts for target serious are: ['advmod_more', 'amodI_problem']
Contexts in vocabulary for target serious are: ['advmod_more', 'amodI_problem']
Top most similar embeddings: serious 0.29458	severe 0.21248	persistant 0.20902	non-serious 0.20880	thorough-going 0.20851	ticklish 0.19996	intractable 0.19988	serous 0.19917	vexing 0.19901	insidious 0.19878

Generated lemmatized results
***************
GENERATED	serious.a 1584 ::: severe;persistant;ticklish;intractable;serous;vexing;insidious;significant;irremediable;thoroughgoing

Filtered results
***************
RANKED	serious.a 1584	severe 0.21248	significant 0.19805	grave 0.19281	substantial 0.18793	urgent 0.18536	real 0.18306	acute 0.17982	important 0.17312	major 0.16911	critical 0.16804	considerable 0.16007	businesslike 0.15977	sincere 0.15956	resolute 0.15215	impressive 0.14842	heavy 0.14816	concerned 0.14471	proper 0.14203

Test context:
***************
serious.a	1585	25	while increasing the number of h-1b visas is important , " we ca n't be so naive to believe that there is not a very __serious__ border-security problem that we need to deal with , " said california republican rep. david dreier ( news , bio , voting record ) , who heads the house rules committee .
Contexts for target serious are: ['advmod_very', 'amodI_problem']
Contexts in vocabulary for target serious are: ['advmod_very', 'amodI_problem']
Top most similar embeddings: serious 0.28563	severe 0.20794	ticklish 0.20332	persistant 0.20331	contraversial 0.20100	gravest 0.19963	geniune 0.19875	niggly 0.19863	significant 0.19797	vexing 0.19792

Generated lemmatized results
***************
GENERATED	serious.a 1585 ::: severe;ticklish;persistant;contraversial;grave;geniune;niggly;significant;vexing;slight

Filtered results
***************
RANKED	serious.a 1585	severe 0.20794	grave 0.19963	significant 0.19797	real 0.19230	substantial 0.18473	urgent 0.17722	considerable 0.17584	major 0.17341	important 0.17266	acute 0.16951	sincere 0.16488	heavy 0.16401	critical 0.16393	businesslike 0.15475	impressive 0.15047	proper 0.14739	resolute 0.14477	concerned 0.14228

Test context:
***************
serious.a	1586	4	this was a very __serious__ criminal act , but , as i point out , to them , every day over 30,000 children die of poverty related diseases which are preventable and could be eradicated .
Contexts for target serious are: ['advmod_very', 'amodI_act']
Contexts in vocabulary for target serious are: ['advmod_very', 'amodI_act']
Top most similar embeddings: serious 0.26197	serious-minded 0.20537	contraversial 0.20211	ungentlemanly 0.19973	heinous 0.19818	masturbatory 0.19631	media-friendly 0.19521	self-regarding 0.19507	venial 0.19486	vituperative 0.19437

Generated lemmatized results
***************
GENERATED	serious.a 1586 ::: contraversial;ungentlemanly;heinous;masturbatory;venial;vituperative;vigourous;unmeaning;ceremonious;geniune

Filtered results
***************
RANKED	serious.a 1586	grave 0.18732	severe 0.18644	significant 0.18266	sincere 0.17803	substantial 0.17728	real 0.17544	businesslike 0.16748	important 0.16597	impressive 0.16575	considerable 0.16526	urgent 0.16243	heavy 0.15986	major 0.15821	resolute 0.15605	critical 0.15464	acute 0.15222	proper 0.14979	concerned 0.14332

Test context:
***************
serious.a	1587	10	there are shadowed circles under her eyes , indicating a __serious__ lack of sleep which was her initial complaint when she phoned for the appointment .
Contexts for target serious are: ['amodI_lack']
Contexts in vocabulary for target serious are: ['amodI_lack']
Top most similar embeddings: serious 0.52394	near-fatal 0.40971	severe 0.40270	irremediable 0.40059	gravest 0.39071	serous 0.38916	non-serious 0.38830	near-total 0.38382	flagrant 0.38184	baneful 0.38176

Generated lemmatized results
***************
GENERATED	serious.a 1587 ::: severe;irremediable;grave;serous;flagrant;baneful;pardonable;profound;deplorable;gross

Filtered results
***************
RANKED	serious.a 1587	severe 0.40270	grave 0.39071	significant 0.36940	substantial 0.35381	real 0.34970	considerable 0.34152	acute 0.33657	major 0.33164	sincere 0.32787	urgent 0.32659	critical 0.31846	resolute 0.31802	impressive 0.30838	heavy 0.30671	important 0.30428	proper 0.29947	businesslike 0.29877	concerned 0.29015

Test context:
***************
serious.a	1588	23	we will know that the right wing and capitalism bias is being broken through , in my view , and the system under __serious__ threat , only when we see large numbers of folks in serious motion , challenging ruling class and their apologists ' presumptions , take on economics and poltics .
Contexts for target serious are: ['amodI_threat']
Contexts in vocabulary for target serious are: ['amodI_threat']
Top most similar embeddings: serious 0.54321	gravest 0.42807	near-fatal 0.40837	terrorist-related 0.39661	life-or-death 0.39337	severe 0.39228	irremediable 0.38830	decades-old 0.38763	racially-motivated 0.38667	centuries-long 0.38588

Generated lemmatized results
***************
GENERATED	serious.a 1588 ::: grave;severe;irremediable;unpredicted;baneful;serous;significant;bioterrorist;intercommunal;insidious

Filtered results
***************
RANKED	serious.a 1588	grave 0.42807	severe 0.39228	significant 0.38054	real 0.36509	major 0.35630	substantial 0.34995	urgent 0.34332	considerable 0.34221	acute 0.32866	sincere 0.32712	important 0.31586	heavy 0.31377	critical 0.31320	resolute 0.31017	businesslike 0.29436	proper 0.29327	impressive 0.28951	concerned 0.27714

Test context:
***************
serious.a	1589	29	in most cases , if you can just restrain the tongue from moving for few a seconds during treatment , you may have a good chance to see some __serious__ healing .
Contexts for target serious are: ['amodI_healing']
Contexts in vocabulary for target serious are: ['amodI_healing']
Top most similar embeddings: serious 0.46183	stress-induced 0.37814	post-surgical 0.37804	profound 0.37310	near-fatal 0.37277	thorough-going 0.37211	life-altering 0.36914	psycho-spiritual 0.36904	drug-induced 0.36827	centuries-long 0.36498

Generated lemmatized results
***************
GENERATED	serious.a 1589 ::: profound;incisional;serous;severe;meditational;spiritual;irremediable;fibrotic;psychologic;genuine

Filtered results
***************
RANKED	serious.a 1589	severe 0.36282	sincere 0.34513	real 0.34295	significant 0.34032	substantial 0.33791	grave 0.32795	acute 0.32480	urgent 0.31630	considerable 0.31626	proper 0.31623	major 0.31109	critical 0.29874	businesslike 0.29714	heavy 0.29497	important 0.29393	impressive 0.29363	resolute 0.28703	concerned 0.26862

Test context:
***************
serious.a	1590	18	although the picture presented by the data just cited--and those contained in several other surveys--is itself cause for __serious__ concern , the situation is obviously not a static one , nor is there by any means unanimity of opinion concerning a number of the most important points at issue ( including the definition of literacy itself ) .
Contexts for target serious are: ['amodI_concern']
Contexts in vocabulary for target serious are: ['amodI_concern']
Top most similar embeddings: serious 0.53567	gravest 0.41637	near-universal 0.38611	well-publicized 0.38384	life-or-death 0.38303	near-fatal 0.38174	geniune 0.38143	genuine 0.38113	thorough-going 0.38094	profoundest 0.38076

Generated lemmatized results
***************
GENERATED	serious.a 1590 ::: grave;geniune;genuine;profound;serous;irremediable;significant;universalistic;ostensible;researchable

Filtered results
***************
RANKED	serious.a 1590	grave 0.41637	significant 0.37271	sincere 0.36339	severe 0.36190	major 0.35993	real 0.35902	considerable 0.35411	urgent 0.35321	substantial 0.34546	acute 0.33117	important 0.32599	critical 0.32123	proper 0.31525	resolute 0.30933	businesslike 0.30931	heavy 0.30445	concerned 0.29051	impressive 0.27460

Test context:
***************
shade.n	1591	27	a nice park , with direct gate access to entry to katherine hot springs access path ( about 200 metres walk to pool ) , plenty of __shade__ for all sites .
Contexts for target shade are: ['prep:ofI_plenty']
Contexts in vocabulary for target shade are: ['prep:ofI_plenty']
Top most similar embeddings: shade 0.50935	greenery 0.36577	handholds 0.36473	fruitiness 0.36352	shades 0.36279	sunshine 0.36091	smokiness 0.35438	shading 0.35270	spiciness 0.35235	seedheads 0.35177

Generated lemmatized results
***************
GENERATED	shade.n 1591 ::: greenery;handhold;fruitiness;sunshine;smokiness;shading;spiciness;seedheads;sunlight;pizzazz

Filtered results
***************
RANKED	shade.n 1591	colour 0.34789	shelter 0.33935	shadow 0.33048	tint 0.32809	tinge 0.32662	hue 0.32559	gradation 0.31111	tone 0.30898	canopy 0.30885	depth 0.30821	nuance 0.30677	cover 0.30661	hint 0.29745	sunglasses 0.29549	echo 0.28856	suggestion 0.28082	trace 0.26915	screen 0.26500	degree 0.25843

Test context:
***************
shade.n	1592	15	i am more inclined to see the world and the regimes in it in varying __shades__ of grey .
Contexts for target shades are: ['dobjI_varying', 'prep:of_grey']
Contexts in vocabulary for target shades are: ['dobjI_varying', 'prep:of_grey']
Top most similar embeddings: shades 0.31609	hues 0.22032	tints 0.21565	shade 0.20911	colours 0.20856	tones 0.20140	tint 0.19910	gradations 0.19906	hue 0.19723	shadings 0.19346

Generated lemmatized results
***************
GENERATED	shade.n 1592 ::: hue;tint;colour;tone;gradation;shading;tinge;color;palette;texture

Filtered results
***************
RANKED	shade.n 1592	hue 0.22032	tint 0.21565	colour 0.20856	tone 0.20140	gradation 0.19906	tinge 0.19206	depth 0.17612	shadow 0.16785	nuance 0.16683	degree 0.15391	canopy 0.14765	echo 0.14482	trace 0.14152	sunglasses 0.13632	hint 0.13503	cover 0.12194	screen 0.12030	shelter 0.11976	suggestion 0.11703

Test context:
***************
shade.n	1593	19	coffee and the environment until the 1970s , farmers mostly used sustainable agricultural techniques to grow coffee in the __shade__ of native forests and other cash crops , without extensive use of chemicals and fertilizers .
Contexts for target shade are: ['det_the', 'prep:inI_grow', 'prep:of_forests']
Contexts in vocabulary for target shade are: ['det_the', 'prep:inI_grow', 'prep:of_forests']
Top most similar embeddings: shade 0.13566	understory 0.10505	luxuriance 0.09878	underbrush 0.09743	lushness 0.09696	greenness 0.09486	semi-darkness 0.09417	verdure 0.09403	undergrowth 0.09254	understorey 0.09231

Generated lemmatized results
***************
GENERATED	shade.n 1593 ::: understory;luxuriance;underbrush;lushness;greenness;verdure;undergrowth;understorey;shadow;blueness

Filtered results
***************
RANKED	shade.n 1593	shadow 0.09200	depth 0.08575	canopy 0.08445	shelter 0.08382	tint 0.08092	hue 0.07978	colour 0.07763	gradation 0.07309	tone 0.07191	nuance 0.06915	tinge 0.06620	echo 0.06144	trace 0.06131	cover 0.06104	screen 0.05951	degree 0.05730	hint 0.05668	sunglasses 0.05533	suggestion 0.05445

Test context:
***************
shade.n	1594	9	super polished dream pop like a swirling carousel in __shades__ of bacharach and morricone .
Contexts for target shades are: ['prep:inI_carousel', 'prep:of_bacharach']
Contexts in vocabulary for target shades are: []
Top most similar embeddings: shades 1.00000	colours 0.77995	hues 0.77788	tints 0.75945	shade 0.75093	colors 0.74402	shadings 0.73721	tinges 0.73708	colourways 0.73224	darks 0.72702

Generated lemmatized results
***************
GENERATED	shade.n 1594 ::: colour;hue;tint;color;shading;tinge;colourways;dark;brocade;palest

Filtered results
***************
RANKED	shade.n 1594	colour 0.77995	hue 0.77788	tint 0.75945	tinge 0.73708	tone 0.71828	gradation 0.71760	shadow 0.68742	nuance 0.66552	depth 0.66189	sunglasses 0.65909	echo 0.64653	canopy 0.63653	degree 0.61226	screen 0.61205	trace 0.60699	hint 0.60553	cover 0.60118	shelter 0.59778	suggestion 0.57053

Test context:
***************
shade.n	1595	4	diseases of forest and __shade__ trees of the united states .
Contexts for target shade are: ['conjI_forest']
Contexts in vocabulary for target shade are: ['conjI_forest']
Top most similar embeddings: shade 0.50028	understory 0.37872	scrubland 0.37160	semi-desert 0.36456	thicket 0.36166	mallee 0.36063	shrubberies 0.35963	clearings 0.35931	verdure 0.35926	glades 0.35895

Generated lemmatized results
***************
GENERATED	shade.n 1595 ::: understory;scrubland;thicket;mallee;shrubbery;clearing;verdure;glade;tussock;sagebrush

Filtered results
***************
RANKED	shade.n 1595	shadow 0.33055	shelter 0.33047	canopy 0.32823	hue 0.31706	tint 0.31554	tinge 0.30924	colour 0.30888	depth 0.30084	tone 0.29645	gradation 0.28736	cover 0.27983	nuance 0.27704	echo 0.27361	sunglasses 0.27262	hint 0.26583	trace 0.26168	degree 0.24640	screen 0.24638	suggestion 0.24210

Test context:
***************
shade.n	1596	13	the trail is now mostly in the open with a few evergreens providing __shade__ , a welcome relief on a hot day .
Contexts for target shade are: ['dobjI_providing', 'punct_,', 'appos_relief']
Contexts in vocabulary for target shade are: ['dobjI_providing', 'punct_,', 'appos_relief']
Top most similar embeddings: shade 0.11262	shelter 0.08840	succour 0.08320	shading 0.08044	roughage 0.08041	relief 0.08041	respite 0.08015	anh 0.08000	windbreaks 0.07993	solace 0.07987

Generated lemmatized results
***************
GENERATED	shade.n 1596 ::: shelter;succour;shading;roughage;relief;respite;anh;windbreak;solace;sustenance

Filtered results
***************
RANKED	shade.n 1596	shelter 0.08840	tint 0.07580	hue 0.07535	colour 0.07287	tone 0.07230	gradation 0.06691	shadow 0.06662	cover 0.06571	nuance 0.06560	canopy 0.06525	sunglasses 0.06517	depth 0.06376	hint 0.06151	echo 0.06091	tinge 0.05977	trace 0.05931	screen 0.05577	suggestion 0.05566	degree 0.05508

Test context:
***************
shade.n	1597	13	it 'd also be nice if paragraph breaks were n't formed by ; __shades__ of netscape 4. tonight i help my mother set up her dsl in seattle , and all of us will have broadband connections at home ' much better for ichat av .
Contexts for target shades are: ['depI_nice', 'prep:of_netscape']
Contexts in vocabulary for target shades are: ['depI_nice', 'prep:of_netscape']
Top most similar embeddings: shades 0.20536	colours 0.16512	colors 0.16085	flavours 0.16027	flavors 0.15536	piccy 0.15474	patches 0.15468	tones 0.15391	hues 0.15306	tints 0.15278

Generated lemmatized results
***************
GENERATED	shade.n 1597 ::: colour;color;flavour;flavor;piccy;patch;tone;hue;tint;ontop

Filtered results
***************
RANKED	shade.n 1597	colour 0.16512	tone 0.15391	hue 0.15306	tint 0.15278	tinge 0.15035	depth 0.14820	shadow 0.14463	echo 0.13753	gradation 0.13404	hint 0.13100	nuance 0.12887	sunglasses 0.12776	trace 0.11996	screen 0.11728	canopy 0.11529	suggestion 0.10793	degree 0.10603	cover 0.10330	shelter 0.10316

Test context:
***************
shade.n	1598	14	the color may shift from top to bottom in delicate progressions or around the __shade__ as flowers are different from season to season .
Contexts for target shade are: ['det_the', 'conj:aroundI_progressions']
Contexts in vocabulary for target shade are: ['det_the']
Top most similar embeddings: shade 0.51586	semi-darkness 0.38763	half-light 0.38472	understory 0.38319	firelight 0.37596	tree-tops 0.37509	minerva-press 0.37431	d666 0.37360	side-netting 0.37267	lamplight 0.37124

Generated lemmatized results
***************
GENERATED	shade.n 1598 ::: understory;firelight;lamplight;erlle;coldframe;heavenlies;treeline;gloaming;shadow;underbrush

Filtered results
***************
RANKED	shade.n 1598	shadow 0.36754	colour 0.35227	shelter 0.35182	tint 0.34933	canopy 0.34909	hue 0.34591	tone 0.33179	nuance 0.33078	depth 0.32997	gradation 0.32341	tinge 0.32053	screen 0.30721	cover 0.30624	echo 0.30070	sunglasses 0.29853	suggestion 0.29738	hint 0.29552	degree 0.28296	trace 0.28185

Test context:
***************
shade.n	1599	12	kate hudson sheds her sunny screen persona for something a couple of __shades__ darker in this haunted house horror , set in america 's deep south .
Contexts for target shades are: ['prep:ofI_couple', 'amod_darker']
Contexts in vocabulary for target shades are: ['prep:ofI_couple', 'amod_darker']
Top most similar embeddings: shades 0.27271	tints 0.19739	shadings 0.19668	hues 0.19593	darks 0.19377	colours 0.19336	stripes 0.18976	tones 0.18797	colors 0.18755	tinges 0.18723

Generated lemmatized results
***************
GENERATED	shade.n 1599 ::: tint;shading;hue;dark;colour;stripe;tone;color;tinge;speckle

Filtered results
***************
RANKED	shade.n 1599	tint 0.19739	hue 0.19593	colour 0.19336	tone 0.18797	tinge 0.18723	gradation 0.17637	shadow 0.16740	nuance 0.16368	sunglasses 0.15625	depth 0.15572	canopy 0.14575	echo 0.14567	screen 0.14093	degree 0.13968	hint 0.13814	shelter 0.13453	suggestion 0.13255	trace 0.13180	cover 0.12540

Test context:
***************
shade.n	1600	26	mistake #5 when susan tries on a hat while the couple are shopping in the island town , you can see the cameraman in her mirrored __shades__ .
Contexts for target shades are: ['poss_her', 'amod_mirrored', 'prep:inI_see']
Contexts in vocabulary for target shades are: ['poss_her', 'amod_mirrored', 'prep:inI_see']
Top most similar embeddings: shades 0.12371	dressing-gown 0.09373	nightgown 0.09244	tutus 0.09214	shirtsleeves 0.09131	underclothes 0.09078	ringlets 0.09044	hues 0.09026	lampshade 0.08983	speedos 0.08931

Generated lemmatized results
***************
GENERATED	shade.n 1600 ::: nightgown;tutu;shirtsleeve;underclothes;ringlet;hue;lampshade;speedos;pajama;hotpants

Filtered results
***************
RANKED	shade.n 1600	hue 0.09026	tint 0.08659	colour 0.08639	shadow 0.08206	tone 0.08022	sunglasses 0.07798	depth 0.07442	canopy 0.07353	gradation 0.07032	screen 0.06835	tinge 0.06813	echo 0.06386	nuance 0.06136	shelter 0.06073	trace 0.05785	degree 0.05702	suggestion 0.05579	hint 0.05345	cover 0.05333

Test context:
***************
so.r	1601	17	chapter 17 - not all comparisons are equal chapter objective : tell how and why lisp has __so__ many different comparison functions .
Contexts for target so are: ['advmodI_many']
Contexts in vocabulary for target so are: ['advmodI_many']
Top most similar embeddings: so 0.55911	too 0.40006	how 0.38648	proably 0.38434	however 0.37713	because 0.37207	defintely 0.36992	indeed 0.36963	contrastingly 0.36647	though 0.36510

Generated lemmatized results
***************
GENERATED	so.r 1601 ::: too;how;proably;however;because;defintely;indeed;contrastingly;though;even

Filtered results
***************
RANKED	so.r 1601	as 0.35580	very 0.35319	thus 0.35265	therefore 0.33125	consequently 0.32187	likewise 0.32045	hence 0.30280	approximately 0.30249	thereabouts 0.29395	that 0.26779	this 0.22881

Test context:
***************
so.r	1602	39	the homestay family can help the student by giving practical information about melbourne and the local area , shopping , transport , entertainment , sporting facilities etc. the student should be treated as one of the family and not __so__ much as a guest .
Contexts for target so are: ['advmodI_much']
Contexts in vocabulary for target so are: ['advmodI_much']
Top most similar embeddings: so 0.55125	proably 0.40613	too 0.39640	how 0.38305	defintely 0.38263	as 0.38125	sooooo 0.38055	however 0.37801	very 0.37435	usally 0.37302

Generated lemmatized results
***************
GENERATED	so.r 1602 ::: proably;too;how;defintely;as;sooooo;however;very;usally;probaly

Filtered results
***************
RANKED	so.r 1602	as 0.38125	very 0.37435	thus 0.35901	therefore 0.33693	consequently 0.31600	likewise 0.31183	hence 0.30426	approximately 0.29925	thereabouts 0.29907	that 0.29543	this 0.23765

Test context:
***************
so.r	1603	16	rs : it 's an agenda that requires an appropriate autodidacticism , in the spirit , __so__ to speak , of a historicosocial stylistic .
Contexts for target so are: ['advmodI_speak']
Contexts in vocabulary for target so are: ['advmodI_speak']
Top most similar embeddings: so 0.53612	presumptuously 0.42284	proably 0.41843	defintely 0.40605	bascially 0.40016	usally 0.39975	insultingly 0.39803	flippantly 0.39794	futhermore 0.39723	facetiously 0.39341

Generated lemmatized results
***************
GENERATED	so.r 1603 ::: presumptuously;proably;defintely;bascially;usally;insultingly;flippantly;futhermore;facetiously;virtuously

Filtered results
***************
RANKED	so.r 1603	thus 0.38040	therefore 0.36296	likewise 0.33349	consequently 0.32929	hence 0.32415	as 0.31967	very 0.30900	thereabouts 0.29358	approximately 0.29288	that 0.25726	this 0.23078

Test context:
***************
so.r	1604	34	the tea usually arrives well stewed and is poured into the smallest of cups ever devised so you invariably need another one , by which time it has been stood in the pot for __so__ long that its like poison .
Contexts for target so are: ['advmodI_long']
Contexts in vocabulary for target so are: ['advmodI_long']
Top most similar embeddings: so 0.54133	proably 0.39616	extemely 0.39540	comparitively 0.39268	freakishly 0.39071	as 0.38835	numbingly 0.38734	inconceivably 0.38726	too 0.38666	fearsomely 0.38464

Generated lemmatized results
***************
GENERATED	so.r 1604 ::: proably;extemely;comparitively;freakishly;as;numbingly;inconceivably;too;fearsomely;extrememly

Filtered results
***************
RANKED	so.r 1604	as 0.38835	very 0.36416	thus 0.34724	therefore 0.33155	consequently 0.31311	hence 0.30995	likewise 0.30920	approximately 0.30847	thereabouts 0.29541	that 0.26912	this 0.22024

Test context:
***************
so.r	1605	10	it 's about an hour 's worth of time , __so__ it 's not for the faint hearted !
Contexts for target so are: ["markI_'s"]
Contexts in vocabulary for target so are: ["markI_'s"]
Top most similar embeddings: so 0.52090	because 0.42262	though 0.40145	although 0.39753	if 0.39438	since 0.36856	as 0.36681	until 0.36250	unless 0.36130	once 0.35387

Generated lemmatized results
***************
GENERATED	so.r 1605 ::: because;though;although;if;since;as;until;unless;once;before

Filtered results
***************
RANKED	so.r 1605	as 0.36681	that 0.34707	thereabouts 0.29316	thus 0.28845	very 0.27508	therefore 0.27055	hence 0.26994	likewise 0.26133	consequently 0.25924	approximately 0.25038	this 0.22875

Test context:
***************
so.r	1606	31	generally , if the sky is covered in thin cirrus or smoke , one 's chances are somewhat reduced and one can only expect to see the really bright satellites , __so__ ideally one needs a dark sky away from city lights and pollution and little or no moonlight .
Contexts for target so are: ['advmodI_ideally']
Contexts in vocabulary for target so are: ['advmodI_ideally']
Top most similar embeddings: so 0.53344	proably 0.37416	perhaps 0.37229	defintely 0.37194	then 0.37173	everlastingly 0.37140	however 0.36646	though 0.36456	contrastingly 0.36442	thus 0.36362

Generated lemmatized results
***************
GENERATED	so.r 1606 ::: proably;perhaps;defintely;then;everlastingly;however;though;contrastingly;thus;apprently

Filtered results
***************
RANKED	so.r 1606	thus 0.36362	therefore 0.35535	very 0.31709	thereabouts 0.31120	consequently 0.30891	hence 0.30822	as 0.30718	likewise 0.30714	approximately 0.29146	that 0.24256	this 0.21779

Test context:
***************
so.r	1607	0	__so__ adopting a more positive stance and exercising mind over matter could keep you from becoming a statistic .
Contexts for target so are: ['advmodI_adopting']
Contexts in vocabulary for target so are: ['advmodI_adopting']
Top most similar embeddings: so 0.49112	proably 0.39034	thus 0.38106	however 0.37893	presumptuously 0.37836	spuriously 0.37551	affectively 0.37382	futhermore 0.37368	defintely 0.37325	everlastingly 0.37322

Generated lemmatized results
***************
GENERATED	so.r 1607 ::: proably;thus;however;presumptuously;spuriously;affectively;futhermore;defintely;everlastingly;duely

Filtered results
***************
RANKED	so.r 1607	thus 0.38106	therefore 0.34633	hence 0.33157	consequently 0.32711	likewise 0.32401	very 0.31219	as 0.30362	approximately 0.27724	thereabouts 0.27549	that 0.24183	this 0.22149

Test context:
***************
so.r	1608	25	it was n't necessary to have a movie star , it was my decision to go with the actors that i was comfortable with and __so__ it 's my fault .
Contexts for target so are: ['conjI_with']
Contexts in vocabulary for target so are: ['conjI_with']
Top most similar embeddings: so 0.45963	without 0.37290	with 0.36932	then 0.36480	amid 0.36120	perhaps 0.35932	indeed 0.35928	8776 0.35308	beside 0.35039	consequentially 0.35010

Generated lemmatized results
***************
GENERATED	so.r 1608 ::: without;with;then;amid;perhaps;indeed;beside;consequentially;for;alack

Filtered results
***************
RANKED	so.r 1608	thus 0.34410	therefore 0.33752	thereabouts 0.33175	as 0.32652	consequently 0.32375	hence 0.32191	likewise 0.32036	that 0.25967	very 0.25489	approximately 0.25478	this 0.22979

Test context:
***************
so.r	1609	18	( ++p)-&gt;x increments p before getting x *p-&gt;y++ uses y as a pointer , then increments it *(p-&gt;y)++ __so__ does this *(p++)-&gt;y uses y as a pointer , then increments p the way to remember these is that -&gt; , .
Contexts for target so are: ['advmodI_does']
Contexts in vocabulary for target so are: ['advmodI_does']
Top most similar embeddings: so 0.53780	proably 0.42289	defintely 0.40985	usally 0.40358	futhermore 0.39868	bascially 0.39460	however 0.39216	acutally 0.38869	apprently 0.38653	alledgedly 0.38544

Generated lemmatized results
***************
GENERATED	so.r 1609 ::: proably;defintely;usally;futhermore;bascially;however;acutally;apprently;alledgedly;unfortuantely

Filtered results
***************
RANKED	so.r 1609	thus 0.36526	therefore 0.34182	likewise 0.34035	as 0.32862	consequently 0.31606	very 0.31466	hence 0.30756	approximately 0.28817	thereabouts 0.28468	that 0.25630	this 0.23565

Test context:
***************
so.r	1610	37	you 'd like to tie the hair at the base of your neck , but much of it is n't long enough for that yet ; you probably have to start by tying it an inch or __so__ above the hairline .
Contexts for target so are: ['advmodI_above']
Contexts in vocabulary for target so are: ['advmodI_above']
Top most similar embeddings: so 0.48387	proably 0.40341	defintely 0.38753	imediately 0.38682	just 0.38657	precipitously 0.38255	usally 0.38125	probally 0.38114	jauntily 0.38019	regally 0.37959

Generated lemmatized results
***************
GENERATED	so.r 1610 ::: proably;defintely;imediately;just;precipitously;usally;probally;jauntily;regally;icily

Filtered results
***************
RANKED	so.r 1610	as 0.36780	thus 0.35330	therefore 0.33567	likewise 0.31689	hence 0.31621	consequently 0.31306	very 0.31231	thereabouts 0.31217	approximately 0.30238	that 0.29800	this 0.23541

Test context:
***************
soft.a	1611	42	the court 's rejection of the floor statements of certain senators because they are " frankly partisan " and " cannot plausibly be read as reflecting any general agreement " ante , at 17 , reads like any other exercise in the __soft__ science of legislative historicizing , 1 undisciplined by any distinctive " clear statement " requirement .
Contexts for target soft are: ['amodI_science']
Contexts in vocabulary for target soft are: ['amodI_science']
Top most similar embeddings: soft 0.49346	goethean 0.38751	softer 0.38213	bio-medical 0.36537	vetinary 0.36138	gaian 0.36108	college-level 0.36042	cardiological 0.35802	mesoscopic 0.35798	namby-pamby 0.35614

Generated lemmatized results
***************
GENERATED	soft.a 1611 ::: goethean;vetinary;gaian;cardiological;mesoscopic;inexact;parapsychological;oncological;positivistic;pulpy

Filtered results
***************
RANKED	soft.a 1611	spongy 0.34416	imprecise 0.33223	squashy 0.33200	weak 0.32049	gentle 0.31451	malleable 0.31272	comfy 0.31033	tender 0.30648	faint 0.29999	cushioned 0.29857	compassionate 0.29797	undemanding 0.29703	feeble 0.29632	smooth 0.29310	easy 0.29124	quiet 0.28791	lenient 0.28772	restful 0.28726	flexible 0.27695	yielding 0.27137	comfortable 0.27046

Test context:
***************
soft.a	1612	13	yet hearing the beeping of a heart monitor somewhere nearby , and the __soft__ , but tinny tones of an intercom told me that was where i was .
Contexts for target soft are: ['amodI_tones', 'punct_,', 'cc_but', 'conj_tinny']
Contexts in vocabulary for target soft are: ['amodI_tones', 'punct_,', 'cc_but']
Top most similar embeddings: soft 0.12293	low-pitched 0.10826	softer 0.10689	doughy 0.10101	unctuous 0.09939	raspy 0.09936	sweetish 0.09816	breathy 0.09784	ornery 0.09781	malty 0.09723

Generated lemmatized results
***************
GENERATED	soft.a 1612 ::: doughy;unctuous;raspy;sweetish;breathy;ornery;malty;syrupy;plasticky;tremulous

Filtered results
***************
RANKED	soft.a 1612	gentle 0.09054	smooth 0.08616	spongy 0.08530	squashy 0.08132	faint 0.08120	weak 0.08066	restful 0.08021	feeble 0.07965	comfy 0.07953	quiet 0.07950	undemanding 0.07840	imprecise 0.07771	malleable 0.07739	cushioned 0.07574	compassionate 0.07396	lenient 0.07347	easy 0.07124	comfortable 0.07122	tender 0.06635	flexible 0.06504	yielding 0.06302

Test context:
***************
soft.a	1613	7	only the truly strong can be " __soft__ and yielding " , for their strength comes from emptiness .
Contexts for target soft are: ['nsubj_strong', 'aux_can', 'cop_be', "punct_''", 'rootI_*root*', 'cc_and', 'conj_yielding', "punct_''", 'punct_,', 'prep:for_strength', 'dep_comes', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target soft are: ['nsubj_strong', 'aux_can', 'cop_be', 'rootI_*root*', 'cc_and', 'conj_yielding', 'punct_,', 'prep:for_strength', 'dep_comes', 'punct_.']
Top most similar embeddings: soft 0.00066	softer 0.00056	hypo-allergenic 0.00056	resistant 0.00054	resilient 0.00053	tough 0.00053	unscrewed 0.00053	brittle 0.00053	rubbery 0.00053	steadfast 0.00053

Generated lemmatized results
***************
GENERATED	soft.a 1613 ::: resistant;resilient;tough;unscrewed;brittle;rubbery;steadfast;pliable;hypoallergenic;soothed

Filtered results
***************
RANKED	soft.a 1613	weak 0.00052	malleable 0.00048	cushioned 0.00047	gentle 0.00044	smooth 0.00043	spongy 0.00040	lenient 0.00040	quiet 0.00040	flexible 0.00039	imprecise 0.00039	faint 0.00038	compassionate 0.00037	feeble 0.00037	easy 0.00037	comfy 0.00035	comfortable 0.00035	restful 0.00035	yielding 0.00035	undemanding 0.00035	tender 0.00034	squashy 0.00024

Test context:
***************
soft.a	1614	4	they are n't very __soft__ and if you ( or someone blowing for you ) gets at them with their teeth , they scar easily and the scars are very rough on the lips .
Contexts for target soft are: ['nsubj_they', 'cop_are', "neg_n't", 'advmod_very', 'rootI_*root*', 'cc_and', 'conj_gets', 'punct_,', 'conj_scar', 'cc_and', 'conj_rough', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target soft are: ['nsubj_they', 'cop_are', "neg_n't", 'advmod_very', 'rootI_*root*', 'cc_and', 'conj_gets', 'punct_,', 'conj_scar', 'cc_and', 'conj_rough', 'punct_.']
Top most similar embeddings: soft 0.00018	brittle 0.00017	clingy 0.00017	grippy 0.00017	dull 0.00016	slimey 0.00016	flighty 0.00016	blocky 0.00016	stretchy 0.00016	absorbant 0.00016

Generated lemmatized results
***************
GENERATED	soft.a 1614 ::: brittle;clingy;grippy;dull;slimey;flighty;blocky;stretchy;absorbant;doughy

Filtered results
***************
RANKED	soft.a 1614	smooth 0.00015	spongy 0.00014	weak 0.00013	faint 0.00012	gentle 0.00012	comfy 0.00011	undemanding 0.00011	malleable 0.00011	easy 0.00011	lenient 0.00011	quiet 0.00010	restful 0.00010	cushioned 0.00010	comfortable 0.00010	feeble 0.00010	imprecise 0.00010	flexible 0.00009	tender 0.00009	compassionate 0.00008	squashy 0.00008	yielding 0.00006

Test context:
***************
soft.a	1615	30	read the full review product rating : shaft flex : soft , forgiving and long -- very long by herculaneum , jul 29 ' 04 pros : good distance , __soft__ feel , very forgiving , stable at impact cons : it takes time to adjust to added distance , pay attention to alignment. they 're straight !
Contexts for target soft are: ['amodI_feel']
Contexts in vocabulary for target soft are: ['amodI_feel']
Top most similar embeddings: soft 0.53457	softer 0.42844	velvety 0.41490	super-soft 0.41136	springy 0.41050	squelchy 0.40518	old-skool 0.40456	silky 0.40112	syrupy 0.39838	down-home 0.39661

Generated lemmatized results
***************
GENERATED	soft.a 1615 ::: velvety;springy;squelchy;silky;syrupy;squashy;gloopy;echoey;plasticky;squishy

Filtered results
***************
RANKED	soft.a 1615	squashy 0.39629	spongy 0.38988	comfy 0.35466	smooth 0.35083	restful 0.35009	gentle 0.34607	cushioned 0.33512	comfortable 0.32959	weak 0.32414	malleable 0.32331	faint 0.32145	undemanding 0.31780	imprecise 0.31729	easy 0.31226	tender 0.31119	quiet 0.31072	compassionate 0.30686	feeble 0.30046	lenient 0.29922	flexible 0.29822	yielding 0.26939

Test context:
***************
soft.a	1616	14	for example , you could light the room with candles or put on some __soft__ , romantic music .
Contexts for target soft are: ['amodI_music']
Contexts in vocabulary for target soft are: ['amodI_music']
Top most similar embeddings: soft 0.51263	guitar-based 0.41543	easy-listening 0.41003	old-skool 0.40377	new-wave 0.40346	guitar-driven 0.40328	softer 0.39705	foot-tapping 0.39684	unamplified 0.39621	down-home 0.39565

Generated lemmatized results
***************
GENERATED	soft.a 1616 ::: unamplified;gloopy;acousmatic;squelchy;diegetic;atonal;twangy;tuneless;brassy;dubby

Filtered results
***************
RANKED	soft.a 1616	gentle 0.35329	squashy 0.35290	spongy 0.33179	smooth 0.33049	restful 0.32385	undemanding 0.32173	comfy 0.32060	quiet 0.31756	malleable 0.31740	faint 0.31700	tender 0.31637	weak 0.30847	easy 0.30777	compassionate 0.30221	cushioned 0.30175	imprecise 0.29265	comfortable 0.29065	feeble 0.28838	lenient 0.28669	flexible 0.28637	yielding 0.26911

Test context:
***************
soft.a	1617	25	these items are accepted with little difficulty and include photographic equipment , automobiles , computers , pharmaceutical products , wine and distilled spirits , and __soft__ drinks .
Contexts for target soft are: ['amodI_drinks']
Contexts in vocabulary for target soft are: ['amodI_drinks']
Top most similar embeddings: soft 0.55395	milk-based 0.40565	caffeinated 0.40486	pre-lunch 0.40449	hot/cold 0.40037	softer 0.39328	high-calorie 0.39160	alcohol-based 0.39052	flavorful 0.39036	frothy 0.38925

Generated lemmatized results
***************
GENERATED	soft.a 1617 ::: caffeinated;flavorful;frothy;carbonated;microwaveable;syrupy;zesty;soupy;sugary;hypotonic

Filtered results
***************
RANKED	soft.a 1617	squashy 0.36649	spongy 0.34179	weak 0.32609	gentle 0.32190	comfy 0.32074	smooth 0.31899	cushioned 0.31314	malleable 0.30941	quiet 0.30338	restful 0.30288	tender 0.30030	undemanding 0.29792	comfortable 0.29758	feeble 0.29581	flexible 0.29101	easy 0.28673	lenient 0.28672	compassionate 0.28225	imprecise 0.28160	yielding 0.27950	faint 0.27707

Test context:
***************
soft.a	1618	36	" i am worried that the question of how to do the trials , and whether they can be done fairly and ethically , will overshadow the science itself , " he said , in a __soft__ british accent .
Contexts for target soft are: ['amodI_accent']
Contexts in vocabulary for target soft are: ['amodI_accent']
Top most similar embeddings: soft 0.51656	cut-glass 0.41001	plummy 0.39901	softer 0.39870	soupy 0.38723	guttural 0.38255	down-home 0.38202	squelchy 0.38148	unctuous 0.38051	velvety 0.37999

Generated lemmatized results
***************
GENERATED	soft.a 1618 ::: plummy;soupy;guttural;squelchy;unctuous;velvety;silky;rubbery;syrupy;glutinous

Filtered results
***************
RANKED	soft.a 1618	squashy 0.36208	spongy 0.34621	gentle 0.33936	smooth 0.32994	weak 0.32877	faint 0.32438	malleable 0.32322	tender 0.31242	imprecise 0.31094	undemanding 0.31083	comfy 0.31060	feeble 0.30267	quiet 0.30254	lenient 0.30220	comfortable 0.29294	restful 0.29251	easy 0.28996	cushioned 0.28663	yielding 0.27752	compassionate 0.27502	flexible 0.27052

Test context:
***************
soft.a	1619	24	realizing the high rate of unemployment of the young graduates , the punjab government has introduced the scheme of awarding small-scale business loans on __soft__ terms for self-employment of these young people .
Contexts for target soft are: ['amodI_terms']
Contexts in vocabulary for target soft are: ['amodI_terms']
Top most similar embeddings: soft 0.47407	hello@walkermorris.co.uk 0.38556	softer 0.38403	non-preferred 0.38177	first-name 0.36874	then-current 0.36773	service-specific 0.36567	euphemistic 0.36510	short/long 0.36419	shock-absorbing 0.36254

Generated lemmatized results
***************
GENERATED	soft.a 1619 ::: euphemistic;monadic;jamesian;diffusive;addtional;tenseless;concessional;coarse;faddish;connotative

Filtered results
***************
RANKED	soft.a 1619	imprecise 0.33890	squashy 0.33790	spongy 0.32887	gentle 0.32638	malleable 0.32580	lenient 0.32477	weak 0.32371	flexible 0.31651	undemanding 0.31583	easy 0.31347	tender 0.31078	smooth 0.30935	compassionate 0.30178	faint 0.30055	restful 0.29992	comfortable 0.29632	comfy 0.29390	feeble 0.29359	cushioned 0.28869	quiet 0.28760	yielding 0.27128

Test context:
***************
soft.a	1620	21	putting a baby into a double , queen , or king-sized bed , 2-3 feet off the floor , with a __soft__ mattress , mattress pads , thick covers , blankets , pillows , comforters , etc... may be quite different from co-sleeping as practiced in asian countries for example .
Contexts for target soft are: ['amodI_mattress']
Contexts in vocabulary for target soft are: ['amodI_mattress']
Top most similar embeddings: soft 0.53149	super-soft 0.41785	squashy 0.40886	self-inflating 0.40810	shock-absorbing 0.40675	well-fitting 0.40497	springy 0.40372	rubberized 0.40359	soft-touch 0.40273	rock-hard 0.40210

Generated lemmatized results
***************
GENERATED	soft.a 1620 ::: squashy;springy;rubberized;rubberised;supersoft;undyed;squishy;plasticised;quilted;absorbant

Filtered results
***************
RANKED	soft.a 1620	squashy 0.40886	spongy 0.38332	comfy 0.37547	cushioned 0.35902	gentle 0.33559	comfortable 0.33193	smooth 0.32285	weak 0.31811	malleable 0.30968	restful 0.29677	undemanding 0.29225	tender 0.29118	imprecise 0.29001	easy 0.28928	flexible 0.28729	lenient 0.28480	faint 0.28415	compassionate 0.28335	quiet 0.28176	feeble 0.27516	yielding 0.27006

Test context:
***************
soil.n	1621	13	however , if you start your own seedlings in a sterile or artificial __soil__ , inoculating them may help them survive transplanting and increase their resistance against soil-borne disease .
Contexts for target soil are: ['det_a', 'amod_sterile', 'prep:inI_start']
Contexts in vocabulary for target soil are: ['det_a', 'amod_sterile', 'prep:inI_start']
Top most similar embeddings: soil 0.11720	rootzone 0.09331	coldframe 0.09024	footbath 0.08927	terrarium 0.08795	clime 0.08749	seedbed 0.08700	loam 0.08684	bioreactor 0.08673	flowerbed 0.08609

Generated lemmatized results
***************
GENERATED	soil.n 1621 ::: rootzone;coldframe;footbath;terrarium;clime;seedbed;loam;bioreactor;flowerbed;waterbath

Filtered results
***************
RANKED	soil.n 1621	compost 0.08424	layer 0.07307	terrain 0.07196	ground 0.07131	earth 0.07019	land 0.06963	stain 0.06621	dirt 0.06397	geological 0.05191	pn 0.04955	tarnish 0.04855

Test context:
***************
soil.n	1622	0	__soil__ scientists use very broad definitions to describe soil organic matter components ; " fulvic acids " and " humic acids " are terms lumping complex families of organic compounds together on the basis of how they can be most easily extracted from soil .
Contexts for target soil are: ['nnI_scientists']
Contexts in vocabulary for target soil are: ['nnI_scientists']
Top most similar embeddings: soil 0.52366	soils 0.42713	turfgrass 0.36953	dryland 0.36830	rhizosphere 0.36396	rootzone 0.36301	earth 0.36245	topsoil 0.36145	checkbiotech.org 0.36005	biowaste 0.35916

Generated lemmatized results
***************
GENERATED	soil.n 1622 ::: turfgrass;dryland;rhizosphere;rootzone;earth;topsoil;biowaste;permafrost;vegetation;rangeland

Filtered results
***************
RANKED	soil.n 1622	earth 0.36245	compost 0.33727	geological 0.32083	dirt 0.31549	terrain 0.31354	ground 0.30725	land 0.30578	layer 0.28309	stain 0.27394	tarnish 0.26707	pn 0.24943

Test context:
***************
soil.n	1623	32	composting most of these waste streams would reduce the amount of municipal solid waste ( msw ) requiring disposal by almost one fourth , while at the same time provide a nutrient-rich __soil__ amendment .
Contexts for target soil are: ['nnI_amendment']
Contexts in vocabulary for target soil are: ['nnI_amendment']
Top most similar embeddings: soil 0.50635	soils 0.41314	rootzone 0.38064	topsoil 0.37544	loam 0.36140	sediment 0.35012	silt 0.34945	groundwater 0.34748	testate 0.34610	rainwater 0.34574

Generated lemmatized results
***************
GENERATED	soil.n 1623 ::: rootzone;topsoil;loam;sediment;silt;groundwater;testate;rainwater;subsoil;biowaste

Filtered results
***************
RANKED	soil.n 1623	compost 0.34196	earth 0.32292	land 0.31815	terrain 0.30765	geological 0.30505	ground 0.30163	dirt 0.29705	stain 0.28811	pn 0.26910	tarnish 0.26742	layer 0.26514

Test context:
***************
soil.n	1624	11	usually it is recommended not to put plants in moss into __soil__ without removing the moss , but i wanted to see what would happen if i kept the top of the moss above the soil , so that air could keept the moss roots nice and airy .
Contexts for target soil are: ['prep:intoI_put']
Contexts in vocabulary for target soil are: ['prep:intoI_put']
Top most similar embeddings: soil 0.50605	soils 0.38617	rootzone 0.37483	coldframe 0.37164	compost 0.37149	topsoil 0.36649	mothballs 0.36533	tilth 0.36245	loam 0.35971	vermiculite 0.35840

Generated lemmatized results
***************
GENERATED	soil.n 1624 ::: rootzone;coldframe;compost;topsoil;mothball;tilth;loam;vermiculite;subsoil;burette

Filtered results
***************
RANKED	soil.n 1624	compost 0.37149	earth 0.33253	ground 0.32524	terrain 0.30996	land 0.30738	dirt 0.30639	layer 0.29466	stain 0.27243	geological 0.26006	tarnish 0.24367	pn 0.24143

Test context:
***************
soil.n	1625	4	' where the mineral __soil__ is coarse and well-drained , the soil also has high infiltration capacity .
Contexts for target soil are: ['det_the', 'nn_mineral', 'nsubjI_coarse']
Contexts in vocabulary for target soil are: ['det_the', 'nn_mineral', 'nsubjI_coarse']
Top most similar embeddings: soil 0.13194	soils 0.11053	topsoil 0.10705	subsoil 0.10507	sub-soil 0.10300	substrata 0.09964	rootzone 0.09911	herbage 0.09619	brickearth 0.09522	ploughsoil 0.09519

Generated lemmatized results
***************
GENERATED	soil.n 1625 ::: topsoil;subsoil;substrata;rootzone;herbage;brickearth;ploughsoil;silt;substrate;clay

Filtered results
***************
RANKED	soil.n 1625	compost 0.08376	layer 0.08126	dirt 0.08085	earth 0.07699	ground 0.07632	terrain 0.07520	stain 0.07462	land 0.07058	geological 0.05949	tarnish 0.05537	pn 0.04952

Test context:
***************
soil.n	1626	9	used for dust control , erosion control , and __soil__ stabilization on unpaved roads , building pads , parking lots , fields , and other off-road motor vehicle parks , the product has a molecular structure that allows bonding and cohesion with small soil particles , resulting in a strong surface sealant .
Contexts for target soil are: ['nnI_stabilization']
Contexts in vocabulary for target soil are: ['nnI_stabilization']
Top most similar embeddings: soil 0.53237	soils 0.41884	topsoil 0.40990	rootzone 0.39644	hillslope 0.39441	snowpack 0.38138	sediment 0.38100	subsoil 0.37982	permafrost 0.36887	laterite 0.36877

Generated lemmatized results
***************
GENERATED	soil.n 1626 ::: topsoil;rootzone;hillslope;snowpack;sediment;subsoil;permafrost;laterite;shoreface;nanoparticle

Filtered results
***************
RANKED	soil.n 1626	compost 0.34110	terrain 0.32863	earth 0.32238	layer 0.31865	ground 0.31174	land 0.30360	geological 0.30357	dirt 0.30325	stain 0.28368	tarnish 0.25385	pn 0.24390

Test context:
***************
soil.n	1627	15	clear the ground of large weeds first with a hoe and rake and avoid stony __soil__ .
Contexts for target soil are: ['det_a', 'nn_hoe', 'amod_stony', 'prep:withI_ground']
Contexts in vocabulary for target soil are: ['det_a', 'nn_hoe', 'amod_stony', 'prep:withI_ground']
Top most similar embeddings: soil 0.05682	loam 0.04748	subsoil 0.04718	sward 0.04688	topsoil 0.04576	slope 0.04516	sub-soil 0.04466	scree 0.04240	sand 0.04219	gravel 0.04207

Generated lemmatized results
***************
GENERATED	soil.n 1627 ::: loam;subsoil;sward;topsoil;slope;scree;sand;gravel;greensward;silt

Filtered results
***************
RANKED	soil.n 1627	compost 0.03968	ground 0.03932	terrain 0.03879	layer 0.03471	dirt 0.03430	land 0.03370	earth 0.03127	stain 0.02838	geological 0.02197	tarnish 0.02108	pn 0.02105

Test context:
***************
soil.n	1628	38	glassware that has not been pre-soaked or that is very heavily soiled should be completely immersed in warm ( 50-60 ' c. ) haemo-sol solution for ten minutes or longer , depending on the amount and kind of __soil__ present .
Contexts for target soil are: ['prep:ofI_amount', 'amod_present']
Contexts in vocabulary for target soil are: ['prep:ofI_amount', 'amod_present']
Top most similar embeddings: soil 0.22764	topsoil 0.19689	silt 0.19080	cropland 0.18581	sediment 0.18514	soils 0.18393	humus 0.17981	moisture 0.17893	biowaste 0.17766	volatiles 0.17762

Generated lemmatized results
***************
GENERATED	soil.n 1628 ::: topsoil;silt;cropland;sediment;humus;moisture;biowaste;volatile;vegetation;loam

Filtered results
***************
RANKED	soil.n 1628	compost 0.17238	dirt 0.15941	land 0.15290	ground 0.15049	terrain 0.15045	earth 0.14824	stain 0.14131	geological 0.13011	layer 0.13000	tarnish 0.12397	pn 0.11744

Test context:
***************
soil.n	1629	18	information from a supplementary study show that lower application rates ( 0.3 pounds per acre ) have faster __soil__ degradation rates .
Contexts for target soil are: ['nnI_rates']
Contexts in vocabulary for target soil are: ['nnI_rates']
Top most similar embeddings: soil 0.48390	sediment 0.37616	bedload 0.37563	office@rcpbml.org.uk 0.37487	soils 0.37104	reconviction 0.36750	rootzone 0.36604	topsoil 0.36464	refi 0.36407	sedimentation 0.36349

Generated lemmatized results
***************
GENERATED	soil.n 1629 ::: sediment;bedload;reconviction;rootzone;topsoil;refi;sedimentation;lgd;subsoil;fertiliser

Filtered results
***************
RANKED	soil.n 1629	compost 0.34522	terrain 0.31354	dirt 0.30651	ground 0.30409	geological 0.29959	earth 0.29865	land 0.29797	layer 0.28935	stain 0.27030	pn 0.26420	tarnish 0.25041

Test context:
***************
soil.n	1630	1	modern __soil__ surveys include permeability data for the mapped soils at varying depths .
Contexts for target soil are: ['nnI_surveys']
Contexts in vocabulary for target soil are: ['nnI_surveys']
Top most similar embeddings: soil 0.51454	soils 0.40380	topsoil 0.39807	macrophyte 0.39551	nilt 0.38675	shbdep 0.38357	sediment 0.38084	microgravity 0.38083	vegetation 0.37631	ice-core 0.37141

Generated lemmatized results
***************
GENERATED	soil.n 1630 ::: topsoil;macrophyte;nilt;shbdep;sediment;microgravity;vegetation;rootzone;peatland;loam

Filtered results
***************
RANKED	soil.n 1630	geological 0.34632	compost 0.34381	earth 0.34082	ground 0.33204	land 0.32930	terrain 0.31428	dirt 0.30586	layer 0.27305	stain 0.26177	pn 0.25920	tarnish 0.22727

Test context:
***************
steady.a	1631	7	with rain periods forecast , and a __steady__ downpour over most of the morning , a wash-out was definitely on the cards , but aside from a few sprinkles , the gods smiled and the moisture stayed in the clouds .
Contexts for target steady are: ['amodI_downpour']
Contexts in vocabulary for target steady are: ['amodI_downpour']
Top most similar embeddings: steady 0.53618	relentless 0.39695	remorseless 0.38109	unremitting 0.38016	constant 0.37948	unrelenting 0.37843	ceaseless 0.37614	unseasonal 0.37520	unceasing 0.37486	steadier 0.37444

Generated lemmatized results
***************
GENERATED	steady.a 1631 ::: relentless;remorseless;unremitting;constant;unrelenting;ceaseless;unseasonal;unceasing;continual;fitful

Filtered results
***************
RANKED	steady.a 1631	unremitting 0.38016	constant 0.37948	continuous 0.34961	solid 0.34309	unvarying 0.34201	gradual 0.33818	persistent 0.33088	regular 0.32780	stable 0.32525	unbroken 0.32366	unwavering 0.31891	uninterrupted 0.30108	unchanging 0.29543	firm 0.29240	sure 0.28010	fixed 0.27585

Test context:
***************
steady.a	1632	26	draw on a large piece of paper ( 2 to 3 times the final size ) to make it easier - you wo n't need a __steady__ hand.after you settle on the content and general layout , *then* do some research and figure out how to make the final document .
Contexts for target steady are: ['amodI_hand.after']
Contexts in vocabulary for target steady are: []
Top most similar embeddings: steady 1.00000	steadier 0.75164	constant 0.71428	slowish 0.71291	lowish 0.70769	stable 0.70676	bouyant 0.70430	metronomic 0.70365	relentless 0.70354	slow 0.70267

Generated lemmatized results
***************
GENERATED	steady.a 1632 ::: constant;slowish;lowish;stable;bouyant;metronomic;relentless;slow;remorseless;decelerating

Filtered results
***************
RANKED	steady.a 1632	constant 0.71428	stable 0.70676	unvarying 0.69389	solid 0.68317	gradual 0.67913	unremitting 0.67794	unwavering 0.66836	continuous 0.66195	firm 0.65781	regular 0.65491	unbroken 0.64507	unchanging 0.63795	persistent 0.63794	sure 0.62850	uninterrupted 0.61755	fixed 0.61438

Test context:
***************
steady.a	1633	18	after losing 23 % of its jobs between 1998 and 1999 , employment in this industry remained fairly __steady__ for two years .
Contexts for target steady are: ['punct_,', 'nsubj_employment', 'cop_remained', 'advmod_fairly', 'rootI_*root*', 'prep:for_years', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target steady are: ['punct_,', 'nsubj_employment', 'cop_remained', 'advmod_fairly', 'rootI_*root*', 'prep:for_years', 'punct_.']
Top most similar embeddings: steady 0.00765	unchanged 0.00635	buoyant 0.00608	stable 0.00588	stagnated 0.00577	symptom-free 0.00576	stagnant 0.00574	tight-lipped 0.00566	untroubled 0.00552	unstudied 0.00548

Generated lemmatized results
***************
GENERATED	steady.a 1633 ::: unchanged;buoyant;stable;stagnated;stagnant;untroubled;unstudied;uneventful;unaltered;unproblematic

Filtered results
***************
RANKED	steady.a 1633	stable 0.00588	constant 0.00530	unbroken 0.00424	unchanging 0.00417	continuous 0.00387	uninterrupted 0.00385	unwavering 0.00382	solid 0.00374	fixed 0.00373	unremitting 0.00367	firm 0.00363	unvarying 0.00345	gradual 0.00343	persistent 0.00338	sure 0.00304	regular 0.00272

Test context:
***************
steady.a	1634	15	to steer the argument around the shoals and snags took a sharp eye and a __steady__ hand .
Contexts for target steady are: ['amodI_hand']
Contexts in vocabulary for target steady are: ['amodI_hand']
Top most similar embeddings: steady 0.52686	steadying 0.39304	steadier 0.39040	three-card 0.37227	five-card 0.37011	sinewy 0.36901	non-dominant 0.36830	palsied 0.36324	unsteady 0.36174	gloved 0.35926

Generated lemmatized results
***************
GENERATED	steady.a 1634 ::: steadying;sinewy;palsied;unsteady;gloved;upraised;cadaverous;brawny;lowish;cupped

Filtered results
***************
RANKED	steady.a 1634	stable 0.34629	constant 0.34324	unwavering 0.33659	solid 0.33487	unremitting 0.33084	unvarying 0.32837	firm 0.32520	sure 0.31918	regular 0.31774	gradual 0.31202	persistent 0.30936	unchanging 0.30721	unbroken 0.30657	continuous 0.30430	uninterrupted 0.29419	fixed 0.28767

Test context:
***************
steady.a	1635	0	__steady__ 20-30mph nw wind throughout the afternoon hunt .
Contexts for target steady are: ['amodI_wind']
Contexts in vocabulary for target steady are: ['amodI_wind']
Top most similar embeddings: steady 0.52472	e'ly 0.40867	steadier 0.40170	gale-force 0.40078	south-easterly 0.39480	n'ly 0.39357	geostrophic 0.39273	northeasterly 0.38811	s'ly 0.38645	southwesterly 0.38641

Generated lemmatized results
***************
GENERATED	steady.a 1635 ::: geostrophic;northeasterly;southwesterly;northwesterly;relentless;lowish;brisk;cyclonic;unceasing;remorseless

Filtered results
***************
RANKED	steady.a 1635	constant 0.36556	unremitting 0.35447	unvarying 0.35069	stable 0.34732	solid 0.33612	persistent 0.32962	continuous 0.32957	unwavering 0.31994	gradual 0.31894	firm 0.31880	sure 0.31651	unbroken 0.31266	regular 0.31094	unchanging 0.30871	uninterrupted 0.29533	fixed 0.28385

Test context:
***************
steady.a	1636	4	also unchanged is the __steady__ stream of reports of mysterious civilian killings like ishak 's .
Contexts for target steady are: ['amodI_stream']
Contexts in vocabulary for target steady are: ['amodI_stream']
Top most similar embeddings: steady 0.55382	fast-flowing 0.39746	never-failing 0.39445	steadier 0.39241	constant 0.38660	lowish 0.37927	wind-driven 0.37795	continual 0.37744	ceaseless 0.37435	limpid 0.37270

Generated lemmatized results
***************
GENERATED	steady.a 1636 ::: constant;lowish;continual;ceaseless;limpid;continous;relentless;unvarying;sluggish;slowish

Filtered results
***************
RANKED	steady.a 1636	constant 0.38660	unvarying 0.36993	continuous 0.36169	stable 0.35358	unremitting 0.35219	unbroken 0.34837	solid 0.34768	unwavering 0.33777	persistent 0.33729	regular 0.33710	gradual 0.33451	unchanging 0.32730	uninterrupted 0.31837	firm 0.31554	sure 0.31545	fixed 0.29784

Test context:
***************
steady.a	1637	28	we have lost a huge amount of our manufacturing capacity , and those products we still make do not compete well on the world market , despite the __steady__ devaluation of the dollar .
Contexts for target steady are: ['amodI_devaluation']
Contexts in vocabulary for target steady are: ['amodI_devaluation']
Top most similar embeddings: steady 0.52507	house-price 0.37564	across-the-board 0.37561	steadier 0.37213	remorseless 0.37110	decade-long 0.36832	constant 0.36780	gradual 0.36570	economy-wide 0.36351	relentless 0.36156

Generated lemmatized results
***************
GENERATED	steady.a 1637 ::: remorseless;constant;gradual;relentless;inexorable;continual;surreptitious;unremitting;widescale;rapid

Filtered results
***************
RANKED	steady.a 1637	constant 0.36780	gradual 0.36570	unremitting 0.35292	stable 0.34006	unvarying 0.33197	continuous 0.32625	persistent 0.32546	solid 0.31279	regular 0.31096	unwavering 0.30730	firm 0.29754	uninterrupted 0.29736	unbroken 0.29141	fixed 0.28512	sure 0.28295	unchanging 0.27965

Test context:
***************
steady.a	1638	18	nor did it represent the thousands of ways in which a now affluent teachers college was forwarding the __steady__ overhaul of american education .
Contexts for target steady are: ['amodI_overhaul']
Contexts in vocabulary for target steady are: ['amodI_overhaul']
Top most similar embeddings: steady 0.48153	long-overdue 0.38566	decade-long 0.36033	much-heralded 0.35585	relentless 0.35584	long-expected 0.34803	unceasing 0.34801	long-promised 0.34795	widescale 0.34793	steadier 0.34697

Generated lemmatized results
***************
GENERATED	steady.a 1638 ::: relentless;unceasing;widescale;constant;unremitting;thoroughgoing;thorough;remorseless;continous;continual

Filtered results
***************
RANKED	steady.a 1638	constant 0.34646	unremitting 0.34472	gradual 0.33190	solid 0.33071	stable 0.32634	continuous 0.31967	regular 0.31865	unvarying 0.30979	unbroken 0.30504	persistent 0.30271	unwavering 0.30235	uninterrupted 0.29847	firm 0.29496	unchanging 0.28405	sure 0.27772	fixed 0.27403

Test context:
***************
steady.a	1639	10	rather , she reports , most romance readers consume a __steady__ diet of quality literature , supplemented with their guilty pleasure of choice .
Contexts for target steady are: ['amodI_diet']
Contexts in vocabulary for target steady are: ['amodI_diet']
Top most similar embeddings: steady 0.52166	high-carbohydrate 0.40200	low-salt 0.39019	low-gi 0.37677	high-calorie 0.37654	ketogenic 0.37547	pre-exercise 0.37441	low-carbohydrate 0.37217	meat-based 0.37170	steadier 0.37069

Generated lemmatized results
***************
GENERATED	steady.a 1639 ::: ketogenic;abstemious;constant;healthful;relentless;healthy;lowish;unvarying;postprandial;equable

Filtered results
***************
RANKED	steady.a 1639	constant 0.36108	unvarying 0.35307	stable 0.34896	unremitting 0.34823	solid 0.34302	regular 0.33662	gradual 0.32957	continuous 0.32403	firm 0.32195	unwavering 0.31378	unchanging 0.31255	uninterrupted 0.31002	persistent 0.30872	unbroken 0.30774	sure 0.29980	fixed 0.29383

Test context:
***************
steady.a	1640	30	however , two opposing trends were revealed : during the first part of the study ( november 1993 ' june 1995 ) , the population increased in a slow but __steady__ fashion ; after june 1995 , it decreased very slightly up to the month of november 1997 .
Contexts for target steady are: ['conjI_slow']
Contexts in vocabulary for target steady are: ['conjI_slow']
Top most similar embeddings: steady 0.56699	slow 0.41888	steadier 0.39557	erratic 0.38895	sluggish 0.38715	slowish 0.38466	well-controlled 0.37937	inexorable 0.37903	decelerating 0.37777	unsteady 0.37625

Generated lemmatized results
***************
GENERATED	steady.a 1640 ::: slow;erratic;sluggish;slowish;inexorable;decelerating;unsteady;gradual;relentless;fitful

Filtered results
***************
RANKED	steady.a 1640	gradual 0.37506	unremitting 0.36647	unvarying 0.35716	constant 0.34618	stable 0.34058	continuous 0.33733	persistent 0.33044	solid 0.32877	unwavering 0.32869	regular 0.32264	unchanging 0.31205	unbroken 0.30970	sure 0.30579	uninterrupted 0.30321	firm 0.30229	fixed 0.28245

Test context:
***************
stiff.a	1641	19	even though it may be able to pump a normal amount of blood out of the ventricles , the __stiff__ heart does not allow as much blood to enter its chambers from the veins .
Contexts for target stiff are: ['amodI_heart']
Contexts in vocabulary for target stiff are: ['amodI_heart']
Top most similar embeddings: stiff 0.49525	achy 0.38548	saggy 0.38107	pulpy 0.38034	heavy 0.37844	scrawny 0.37729	cadaverous 0.37671	clammy 0.37550	flabby 0.37517	prehensile 0.37425

Generated lemmatized results
***************
GENERATED	stiff.a 1641 ::: achy;saggy;pulpy;heavy;scrawny;cadaverous;clammy;flabby;prehensile;brawny

Filtered results
***************
RANKED	stiff.a 1641	heavy 0.37844	unyielding 0.36724	aching 0.36691	unbending 0.35829	rigid 0.35738	strong 0.35289	stern 0.35289	sore 0.34789	tough 0.34102	severe 0.34040	firm 0.33150	rheumatic 0.32810	painful 0.32625	inflexible 0.32494	harsh 0.32488	good 0.31991	intense 0.31901	hard 0.31322	solid 0.30927	powerful 0.30667	frozen 0.30337	inelastic 0.30286	unnatural 0.29833	formal 0.29399	constrained 0.25468

Test context:
***************
stiff.a	1642	9	the classic symptom of a shaft that is too __stiff__ is a low fade .
Contexts for target stiff are: ['nsubj_that', 'cop_is', 'advmod_too', 'nsubjI_fade']
Contexts in vocabulary for target stiff are: ['nsubj_that', 'cop_is', 'advmod_too', 'nsubjI_fade']
Top most similar embeddings: stiff 0.05699	bothersome 0.04475	icky 0.04254	slushy 0.04251	scarey 0.04210	babyish 0.04200	painfull 0.04177	rubbery 0.04130	weak 0.04110	sappy 0.04089

Generated lemmatized results
***************
GENERATED	stiff.a 1642 ::: bothersome;icky;slushy;scarey;babyish;painfull;rubbery;weak;sappy;sore

Filtered results
***************
RANKED	stiff.a 1642	sore 0.04086	harsh 0.04069	heavy 0.04014	tough 0.03908	painful 0.03890	rigid 0.03828	strong 0.03785	intense 0.03603	hard 0.03575	inflexible 0.03555	unnatural 0.03515	powerful 0.03419	severe 0.03364	unyielding 0.03328	unbending 0.03320	solid 0.03237	aching 0.03209	good 0.03158	inelastic 0.03050	firm 0.03031	stern 0.02996	formal 0.02684	frozen 0.02549	constrained 0.02158	rheumatic 0.02019

Test context:
***************
stiff.a	1643	1	one __stiff__ punch would do it .
Contexts for target stiff are: ['amodI_punch']
Contexts in vocabulary for target stiff are: ['amodI_punch']
Top most similar embeddings: stiff 0.49308	well-aimed 0.39871	stiffest 0.38819	stiffer 0.38321	rock-hard 0.37993	three-cornered 0.37838	hefty 0.37812	squelchy 0.37420	super-charged 0.37381	brawny 0.37240

Generated lemmatized results
***************
GENERATED	stiff.a 1643 ::: hefty;squelchy;brawny;heavy;sinewy;tingly;adamantine;prehensile;syrupy;rubbery

Filtered results
***************
RANKED	stiff.a 1643	heavy 0.37140	rigid 0.36242	severe 0.35804	strong 0.35461	unyielding 0.34798	stern 0.34746	tough 0.34474	unbending 0.34097	powerful 0.33802	firm 0.33765	aching 0.33408	painful 0.33027	solid 0.32814	intense 0.32017	sore 0.31726	harsh 0.31688	hard 0.31510	good 0.31169	inflexible 0.30564	rheumatic 0.30534	formal 0.28764	inelastic 0.28708	unnatural 0.28587	frozen 0.27823	constrained 0.25057

Test context:
***************
stiff.a	1644	19	the employer must also be a " substitute state " in times of increasing globalisation , the commission faces __stiff__ competition from other international businesses and organisations for the best people on the world job market .
Contexts for target stiff are: ['amodI_competition']
Contexts in vocabulary for target stiff are: ['amodI_competition']
Top most similar embeddings: stiff 0.54951	stiffer 0.39904	stiffest 0.39787	6-a-side 0.38779	intraspecific 0.38115	inter-college 0.37639	fierce 0.37518	non-price 0.37508	tough 0.37289	vigorous 0.37183

Generated lemmatized results
***************
GENERATED	stiff.a 1644 ::: intraspecific;fierce;tough;vigorous;strong;cutthroat;heavy;interspecific;brisk;severe

Filtered results
***************
RANKED	stiff.a 1644	tough 0.37289	strong 0.36965	heavy 0.35849	severe 0.35489	intense 0.35280	rigid 0.34997	stern 0.34984	unyielding 0.33941	harsh 0.32870	unbending 0.31992	firm 0.31736	painful 0.31250	sore 0.30994	inflexible 0.30819	rheumatic 0.30642	powerful 0.30623	hard 0.30502	inelastic 0.30473	good 0.30436	formal 0.30366	aching 0.30088	unnatural 0.29754	solid 0.29680	frozen 0.28106	constrained 0.26252

Test context:
***************
stiff.a	1645	39	charles umbenhauer , abate of pennsylvania racing champion stopped by stiff neck former world champion racecar driver michael schumacher had to abandon testing of ferrari 's new formula one car recently in fiorano , italy , because of a __stiff__ neck after just four laps .
Contexts for target stiff are: ['amodI_neck']
Contexts in vocabulary for target stiff are: ['amodI_neck']
Top most similar embeddings: stiff 0.55139	prehensile 0.41592	scraggy 0.40407	saggy 0.39847	stiffer 0.39781	achy 0.39475	well-shaped 0.39249	rigid 0.39204	scrawny 0.39191	sinewy 0.38781

Generated lemmatized results
***************
GENERATED	stiff.a 1645 ::: prehensile;scraggy;saggy;achy;rigid;scrawny;sinewy;crinkled;ingrown;squashy

Filtered results
***************
RANKED	stiff.a 1645	rigid 0.39204	aching 0.36451	sore 0.35950	heavy 0.35773	firm 0.35281	strong 0.35030	unyielding 0.34869	unbending 0.34865	painful 0.34478	severe 0.34081	rheumatic 0.33651	tough 0.33422	inflexible 0.32584	stern 0.32094	solid 0.31507	inelastic 0.31354	powerful 0.31227	hard 0.31058	intense 0.30993	harsh 0.30978	good 0.30111	unnatural 0.28897	frozen 0.28677	formal 0.27275	constrained 0.26556

Test context:
***************
stiff.a	1646	6	" he told me he was __stiff__ , he said go to jamal ( crawford ) , " brown said yesterday after the knicks ' optional practice in greenburgh .
Contexts for target stiff are: ['nsubj_he', 'cop_was', 'depI_told']
Contexts in vocabulary for target stiff are: ['nsubj_he', 'cop_was', 'depI_told']
Top most similar embeddings: stiff 0.11563	tender-hearted 0.10038	demon-possessed 0.09961	remorseful 0.09847	bed-ridden 0.09655	goner 0.09551	heart-broken 0.09517	livid 0.09369	peevish 0.09361	concussed 0.09267

Generated lemmatized results
***************
GENERATED	stiff.a 1646 ::: remorseful;goner;livid;peevish;concussed;uncommunicative;obstinate;dumbstruck;inconsolable;crotchety

Filtered results
***************
RANKED	stiff.a 1646	tough 0.08355	sore 0.08117	unbending 0.07895	heavy 0.07724	strong 0.07713	harsh 0.07500	unyielding 0.07387	rigid 0.07224	firm 0.07114	inflexible 0.06971	painful 0.06921	good 0.06907	stern 0.06762	severe 0.06751	hard 0.06750	solid 0.06738	aching 0.06735	intense 0.06690	unnatural 0.06560	powerful 0.06372	inelastic 0.06168	frozen 0.06017	formal 0.05136	rheumatic 0.04776	constrained 0.04466

Test context:
***************
stiff.a	1647	15	" in 1968 when originally commissioned to do a cigarstore indian , he rejected the __stiff__ image of the adorned and phony native and carved " blue nose , " replica of a delaware indian .
Contexts for target stiff are: ['amodI_image']
Contexts in vocabulary for target stiff are: ['amodI_image']
Top most similar embeddings: stiff 0.48358	contrasty 0.38760	squeaky-clean 0.38364	well-shaped 0.37592	flicker-free 0.37444	s-shaped 0.37336	fan-shaped 0.37322	vaporous 0.37317	swirly 0.37225	ultra-clear 0.37200

Generated lemmatized results
***************
GENERATED	stiff.a 1647 ::: contrasty;vaporous;swirly;pixelated;clumpy;blotchy;fusty;darkish;yellowy;waxen

Filtered results
***************
RANKED	stiff.a 1647	rigid 0.36299	strong 0.35886	unyielding 0.34626	heavy 0.34219	tough 0.34212	firm 0.33751	stern 0.33113	severe 0.32396	intense 0.32347	powerful 0.32266	harsh 0.31856	inflexible 0.31785	unbending 0.31755	aching 0.31447	painful 0.31438	solid 0.31131	good 0.31061	sore 0.30596	hard 0.30362	frozen 0.30207	unnatural 0.29834	formal 0.29761	inelastic 0.29754	rheumatic 0.28992	constrained 0.26299

Test context:
***************
stiff.a	1648	0	__stiffer__ penalties for virus writers--no matter how tempting they seem right now--are not the answer .
Contexts for target stiffer are: ['amodI_penalties']
Contexts in vocabulary for target stiffer are: ['amodI_penalties']
Top most similar embeddings: stiffer 0.54434	tougher 0.42248	heavier 0.41298	stiff 0.41044	severer 0.40817	harsher 0.39983	stronger 0.39287	lighter 0.38659	costlier 0.38408	stiffest 0.38353

Generated lemmatized results
***************
GENERATED	stiff.a 1648 ::: tough;heavy;severe;harsh;strong;light;costly;strict;fierce;sturdy

Filtered results
***************
RANKED	stiff.a 1648	tough 0.42248	heavy 0.41298	severe 0.40817	harsh 0.39983	strong 0.39287	rigid 0.36209	firm 0.36154	stern 0.34565	painful 0.34562	hard 0.33939	inflexible 0.33938	unyielding 0.32958	unbending 0.32509	intense 0.31550	inelastic 0.30881	powerful 0.30605	sore 0.30589	good 0.30452	unnatural 0.30402	aching 0.29590	formal 0.29560	rheumatic 0.28493	solid 0.28170	constrained 0.27073	frozen 0.26481

Test context:
***************
stiff.a	1649	7	it 's aluminium frame delivers a a __stiff__ and responsive ride which gives it the feel of a performance rather than a recreational folder .
Contexts for target stiff are: ['amodI_ride', 'cc_and', 'conj_responsive']
Contexts in vocabulary for target stiff are: ['amodI_ride', 'cc_and', 'conj_responsive']
Top most similar embeddings: stiff 0.13178	stiffer 0.10201	pliant 0.09927	rigid 0.09915	taut 0.09896	springy 0.09810	supple 0.09756	smooth 0.09614	sure-footed 0.09580	smoother 0.09538

Generated lemmatized results
***************
GENERATED	stiff.a 1649 ::: pliant;rigid;taut;springy;supple;smooth;responsive;robust;nimble;manoeuvrable

Filtered results
***************
RANKED	stiff.a 1649	rigid 0.09915	firm 0.08885	strong 0.08653	inflexible 0.08623	tough 0.08460	heavy 0.08442	intense 0.08126	solid 0.07880	powerful 0.07878	unbending 0.07825	unyielding 0.07687	harsh 0.07618	painful 0.07538	stern 0.07524	severe 0.07512	aching 0.07440	formal 0.07266	sore 0.07238	inelastic 0.06947	good 0.06871	hard 0.06837	unnatural 0.06485	rheumatic 0.06417	frozen 0.06139	constrained 0.05657

Test context:
***************
stiff.a	1650	6	at this stage there is fairly __stiff__ pressure to go the commercial way .
Contexts for target stiff are: ['advmod_fairly', 'amodI_pressure']
Contexts in vocabulary for target stiff are: ['advmod_fairly', 'amodI_pressure']
Top most similar embeddings: stiff 0.26208	heavy 0.19642	vigourous 0.19052	hefty 0.18952	rigid 0.18812	equable 0.18631	strong 0.18583	unyielding 0.18574	sharp-edged 0.18508	imperturbable 0.18272

Generated lemmatized results
***************
GENERATED	stiff.a 1650 ::: heavy;vigourous;hefty;rigid;equable;strong;unyielding;imperturbable;lowish;intense

Filtered results
***************
RANKED	stiff.a 1650	heavy 0.19642	rigid 0.18812	strong 0.18583	unyielding 0.18574	intense 0.18124	severe 0.17920	sore 0.17418	unbending 0.17020	tough 0.17000	harsh 0.16776	inflexible 0.16684	painful 0.16562	inelastic 0.16452	firm 0.15918	solid 0.15872	aching 0.15719	good 0.15378	unnatural 0.15223	powerful 0.15204	hard 0.14909	formal 0.14861	stern 0.14787	rheumatic 0.14156	frozen 0.12195	constrained 0.12110

Test context:
***************
strange.a	1651	3	one of these __strange__ prophets is idris .
Contexts for target strange are: ['amodI_prophets']
Contexts in vocabulary for target strange are: ['amodI_prophets']
Top most similar embeddings: strange 0.46578	odd 0.38502	weird 0.38225	monkish 0.38086	eighth-century 0.37809	un-christian 0.37149	damnable 0.37145	millenarian 0.36997	orphic 0.36982	long-dead 0.36895

Generated lemmatized results
***************
GENERATED	strange.a 1651 ::: odd;weird;monkish;damnable;millenarian;orphic;unlettered;extraordinary;abrahamic;bizarre

Filtered results
***************
RANKED	strange.a 1651	odd 0.38502	weird 0.38225	bizarre 0.36783	peculiar 0.34336	unusual 0.34197	surprising 0.33743	different 0.33649	unexpected 0.32865	alien 0.32235	unfamiliar 0.31775	foreign 0.31081	unknown 0.30812	unlikely 0.30464	abnormal 0.28410

Test context:
***************
strange.a	1652	27	these were an enormous head start in the often dislocating experience of moving one 's home and coming to live in a new country with its often __strange__ and unfamiliar culture .
Contexts for target strange are: ['advmod_often', 'amodI_its', 'cc_and', 'conj_culture']
Contexts in vocabulary for target strange are: ['advmod_often', 'amodI_its', 'cc_and', 'conj_culture']
Top most similar embeddings: strange 0.04905	bizarre 0.04783	faddish 0.04670	recondite 0.04427	weird 0.04391	anti-intellectual 0.04331	uncouth 0.04284	bewildering 0.04192	atonal 0.04191	capricious 0.04180

Generated lemmatized results
***************
GENERATED	strange.a 1652 ::: bizarre;faddish;recondite;weird;uncouth;bewildering;atonal;capricious;narcissistic;grotesque

Filtered results
***************
RANKED	strange.a 1652	bizarre 0.04783	weird 0.04391	peculiar 0.03789	unusual 0.03709	surprising 0.03540	unexpected 0.03533	odd 0.03508	unfamiliar 0.03438	alien 0.03379	abnormal 0.03374	foreign 0.03076	different 0.03020	unknown 0.02854	unlikely 0.02639

Test context:
***************
strange.a	1653	9	indeed , " ... the commission has noted the __strange__ manner in which section 827 is worded ; the drafting of this particular section has been the source of conflicting decisions by our courts .
Contexts for target strange are: ['amodI_manner']
Contexts in vocabulary for target strange are: ['amodI_manner']
Top most similar embeddings: strange 0.51135	bizarre 0.42560	weird 0.41168	untraditional 0.40836	odd 0.40776	unsual 0.40588	freakish 0.40532	peculiar 0.40460	kafkaesque 0.40421	rough-and-ready 0.40314

Generated lemmatized results
***************
GENERATED	strange.a 1653 ::: bizarre;weird;untraditional;odd;unsual;freakish;peculiar;kafkaesque;decorous;uncomplimentary

Filtered results
***************
RANKED	strange.a 1653	bizarre 0.42560	weird 0.41168	odd 0.40776	peculiar 0.40460	unusual 0.38985	surprising 0.36603	unexpected 0.35622	different 0.34854	abnormal 0.33808	unfamiliar 0.33758	alien 0.33659	unlikely 0.31533	unknown 0.30597	foreign 0.30002

Test context:
***************
strange.a	1654	14	" i was thinking of ' what happens sometimes when women get themselves in __strange__ positions in the eyes of the world from no fault of their own .
Contexts for target strange are: ['amodI_positions']
Contexts in vocabulary for target strange are: ['amodI_positions']
Top most similar embeddings: strange 0.49381	odd 0.42051	bizarre 0.41208	weird 0.41175	persecutory 0.39427	unusual 0.38597	freakish 0.38149	certian 0.38143	now-familiar 0.37613	unsual 0.37514

Generated lemmatized results
***************
GENERATED	strange.a 1654 ::: odd;bizarre;weird;persecutory;unusual;freakish;certian;unsual;peculiar;paradoxical

Filtered results
***************
RANKED	strange.a 1654	odd 0.42051	bizarre 0.41208	weird 0.41175	unusual 0.38597	peculiar 0.37488	different 0.36219	unexpected 0.35380	surprising 0.35044	unfamiliar 0.34454	abnormal 0.33224	alien 0.33131	foreign 0.32354	unlikely 0.30870	unknown 0.30149

Test context:
***************
strange.a	1655	8	" i feel as if , in some __strange__ way , i could be you , as for your feelings during your diagnosis and treatment , " wrote salvador martinez of san francisco , who had testicular cancer .
Contexts for target strange are: ['amodI_way']
Contexts in vocabulary for target strange are: ['amodI_way']
Top most similar embeddings: strange 0.52190	weird 0.44337	bizarre 0.43569	odd 0.42337	bizzare 0.41788	wierd 0.40586	untraditional 0.40504	rough-and-ready 0.40501	peculiar 0.40035	mysterious 0.39764

Generated lemmatized results
***************
GENERATED	strange.a 1655 ::: weird;bizarre;odd;bizzare;wierd;untraditional;peculiar;mysterious;unusual;kitschy

Filtered results
***************
RANKED	strange.a 1655	weird 0.44337	bizarre 0.43569	odd 0.42337	peculiar 0.40035	unusual 0.39550	surprising 0.36820	different 0.36096	unexpected 0.36001	unfamiliar 0.34115	alien 0.33125	abnormal 0.32838	unknown 0.30976	unlikely 0.30968	foreign 0.30545

Test context:
***************
strange.a	1656	6	or is it because of that __strange__ smell of kerosene that seems so mysterious to a five-year-old ?
Contexts for target strange are: ['amodI_smell']
Contexts in vocabulary for target strange are: ['amodI_smell']
Top most similar embeddings: strange 0.54637	weird 0.44749	odd 0.43781	horrible 0.42278	bizarre 0.42181	peculiar 0.41583	wierd 0.40845	pestilential 0.40827	spooky 0.40348	ghastly 0.40291

Generated lemmatized results
***************
GENERATED	strange.a 1656 ::: weird;odd;horrible;bizarre;peculiar;wierd;pestilential;spooky;ghastly;freakish

Filtered results
***************
RANKED	strange.a 1656	weird 0.44749	odd 0.43781	bizarre 0.42181	peculiar 0.41583	unusual 0.39124	unfamiliar 0.35625	surprising 0.35198	unexpected 0.34832	alien 0.34124	different 0.33567	abnormal 0.32786	unlikely 0.30229	foreign 0.30112	unknown 0.30092

Test context:
***************
strange.a	1657	21	the odd thing , of course , is that all the way back since christmas we have enjoyed ( yeah , __strange__ word ) supernaturally warm temperatures this winter .
Contexts for target strange are: ['amodI_word']
Contexts in vocabulary for target strange are: ['amodI_word']
Top most similar embeddings: strange 0.51412	odd 0.43768	weird 0.43386	bizarre 0.41906	unmeaning 0.40589	four-letter 0.40534	polysyllabic 0.40041	uncomplimentary 0.39840	onomatopoeic 0.39833	euphemistic 0.39778

Generated lemmatized results
***************
GENERATED	strange.a 1657 ::: odd;weird;bizarre;unmeaning;polysyllabic;uncomplimentary;onomatopoeic;euphemistic;wierd;horrible

Filtered results
***************
RANKED	strange.a 1657	odd 0.43768	weird 0.43386	bizarre 0.41906	unusual 0.38581	peculiar 0.37802	unfamiliar 0.35490	unexpected 0.35295	surprising 0.35134	alien 0.34612	different 0.33628	foreign 0.32813	unknown 0.32645	unlikely 0.31811	abnormal 0.31707

Test context:
***************
strange.a	1658	17	but cockatiels , by far , are the most common perpetrators when it comes to performing this __strange__ head-shaking behavior .
Contexts for target strange are: ['amodI_behavior']
Contexts in vocabulary for target strange are: ['amodI_behavior']
Top most similar embeddings: strange 0.53205	bizarre 0.44590	weird 0.43968	odd 0.43052	freakish 0.41247	stereotypic 0.41181	yobbish 0.40803	persecutory 0.40082	sado-masochistic 0.39933	self-injurious 0.39907

Generated lemmatized results
***************
GENERATED	strange.a 1658 ::: bizarre;weird;odd;freakish;stereotypic;yobbish;persecutory;unsavory;wierd;paradoxical

Filtered results
***************
RANKED	strange.a 1658	bizarre 0.44590	weird 0.43968	odd 0.43052	unusual 0.39494	peculiar 0.39080	unexpected 0.36746	abnormal 0.36243	surprising 0.35736	different 0.34458	alien 0.34304	unfamiliar 0.33322	foreign 0.30827	unknown 0.30754	unlikely 0.30496

Test context:
***************
strange.a	1659	9	there 's some other stuff about the club members __strange__ , distant , jumpy and evasive behavior at work , but i 'll share that with you later .
Contexts for target strange are: ['amodI_jumpy']
Contexts in vocabulary for target strange are: []
Top most similar embeddings: strange 1.00000	weird 0.85028	bizarre 0.83874	odd 0.82750	wierd 0.78651	unusual 0.76795	spooky 0.76412	freakish 0.76309	bizzare 0.76222	mysterious 0.76179

Generated lemmatized results
***************
GENERATED	strange.a 1659 ::: weird;bizarre;odd;wierd;unusual;spooky;freakish;bizzare;mysterious;eery

Filtered results
***************
RANKED	strange.a 1659	weird 0.85028	bizarre 0.83874	odd 0.82750	unusual 0.76795	peculiar 0.75345	surprising 0.74598	unexpected 0.69843	different 0.68807	alien 0.68502	unfamiliar 0.67621	unlikely 0.67047	abnormal 0.66147	foreign 0.64390	unknown 0.63835

Test context:
***************
strange.a	1660	42	more... [ more articles ] .net ie at core of microsoft next-generation web plan 21/03/2006 08:10:59 microsoft hopes to ' mix ' it up with expression 20/03/2006 13:03:45 microsoft alm server online this week 20/03/2006 08:01:50 microsoft , web 2.0 not so __strange__ bedfellows 20/03/2006 08:14:13 borland : interest , but no buyer for tools line 15/03/2006 15:46:40 quickstudy learn about the latest concepts and trends in it with technology and business quickstudies .
Contexts for target strange are: ['neg_not', 'advmod_so', 'amodI_borland']
Contexts in vocabulary for target strange are: ['neg_not', 'advmod_so']
Top most similar embeddings: strange 0.24176	farfetched 0.21119	unpleasing 0.20768	surprising 0.20491	tarty 0.20280	weird 0.20189	unusual 0.19867	big-headed 0.19846	far-fetched 0.19784	muche 0.19689

Generated lemmatized results
***************
GENERATED	strange.a 1660 ::: farfetched;unpleasing;surprising;tarty;weird;unusual;muche;goddamned;immodest;indelicate

Filtered results
***************
RANKED	strange.a 1660	surprising 0.20491	weird 0.20189	unusual 0.19867	bizarre 0.19280	odd 0.19025	peculiar 0.18985	unexpected 0.17941	alien 0.16229	different 0.16132	unfamiliar 0.15880	abnormal 0.15409	unlikely 0.14736	unknown 0.14643	foreign 0.13428

Test context:
***************
strike.v	1661	13	the cauldron in peter 's haversack rings faintly as one of the knives __strike__ against it .
Contexts for target strike are: ['mark_as', 'nsubj_one', 'depI_faintly', 'prep:against_it']
Contexts in vocabulary for target strike are: ['mark_as', 'nsubj_one', 'depI_faintly', 'prep:against_it']
Top most similar embeddings: strike 0.04451	strikes 0.04399	struck 0.03935	dangles 0.03934	croaks 0.03905	brandished 0.03843	thundered 0.03776	recoils 0.03726	screeched 0.03713	clattered 0.03677

Generated lemmatized results
***************
GENERATED	strike.v 1661 ::: dangle;croak;brandish;thunder;recoil;screech;clatter;rag;hurl;tremble

Filtered results
***************
RANKED	strike.v 1661	bang 0.03295	carve 0.03160	bash 0.03128	move 0.03073	knock 0.03072	hammer 0.03061	hit 0.03046	cast 0.02976	bump 0.02898	impress 0.02849	hitting 0.02830	thrust 0.02826	find 0.02783	get 0.02774	begin 0.02626	occur 0.02514	start 0.02449	surprise 0.02447	fail 0.02398	make 0.02354	affect 0.02352	achieve 0.02340	take 0.02335	pn 0.01552

Test context:
***************
strike.v	1662	2	riley is __struck__ by the zombie 's commitment to its old rituals ; but what gets his attention is that this itinerant corpse seems to be communicating with other zombies .
Contexts for target struck are: ['nsubjpass_riley', 'auxpass_is', 'rootI_*root*', 'prep:by_commitment', 'punct_;', 'cc_but', 'conj_is', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target struck are: ['auxpass_is', 'rootI_*root*', 'prep:by_commitment', 'punct_;', 'cc_but', 'conj_is', 'punct_.']
Top most similar embeddings: struck 0.00736	forearmed 0.00599	buttressed 0.00570	characterised 0.00563	underpinned 0.00563	hampered 0.00561	characterized 0.00560	irked 0.00552	unphased 0.00549	assailed 0.00548

Generated lemmatized results
***************
GENERATED	strike.v 1662 ::: forearm;buttress;characterise;underpin;hamper;characterize;irk;unphased;assail;appal

Filtered results
***************
RANKED	strike.v 1662	impress 0.00505	achieve 0.00451	make 0.00450	surprise 0.00449	affect 0.00433	move 0.00426	hammer 0.00422	knock 0.00421	carve 0.00414	take 0.00407	hit 0.00399	begin 0.00396	start 0.00389	find 0.00378	bash 0.00375	occur 0.00370	bump 0.00364	bang 0.00346	fail 0.00327	get 0.00327	cast 0.00312	thrust 0.00290	hitting 0.00249	pn 0.00164

Test context:
***************
strike.v	1663	13	except that big media is holding all the thunderbolts and choosing who gets __struck__ by them , and when they do strike , look out .
Contexts for target struck are: ['nsubjpass_who', 'auxpass_gets', 'ccompI_choosing', 'prep:by_them', 'punct_,', 'cc_and', 'conj_strike']
Contexts in vocabulary for target struck are: ['nsubjpass_who', 'auxpass_gets', 'ccompI_choosing', 'prep:by_them', 'punct_,', 'cc_and', 'conj_strike']
Top most similar embeddings: struck 0.00678	ambushed 0.00502	waylaid 0.00490	bitten 0.00486	humbled 0.00485	hit 0.00474	annoyed 0.00474	attacked 0.00473	fired 0.00472	assailed 0.00472

Generated lemmatized results
***************
GENERATED	strike.v 1663 ::: ambush;waylay;bite;humble;hit;annoy;attack;fire;assail;trap

Filtered results
***************
RANKED	strike.v 1663	hit 0.00474	knock 0.00457	hammer 0.00454	affect 0.00414	bash 0.00390	impress 0.00377	bump 0.00374	surprise 0.00355	cast 0.00354	bang 0.00352	take 0.00349	carve 0.00348	move 0.00347	start 0.00332	make 0.00316	thrust 0.00311	get 0.00295	fail 0.00292	begin 0.00278	find 0.00276	achieve 0.00270	occur 0.00270	hitting 0.00258	pn 0.00147

Test context:
***************
strike.v	1664	42	however , forewarned is forearmed , as they say , and if you know what kinds of curveballs might be thrown your way , you have a much better chance of hitting them out of the park ( or at least not __striking__ out ) .
Contexts for target striking are: ['dep_not', 'partmodI_park', 'prt_out', 'punct_-rrb-']
Contexts in vocabulary for target striking are: ['dep_not', 'partmodI_park', 'prt_out']
Top most similar embeddings: striking 0.10833	jutting 0.07755	laid 0.07650	knocking 0.07543	struck 0.07376	whacking 0.07309	decked 0.07293	hitting 0.07269	bailing 0.07267	prising 0.07170

Generated lemmatized results
***************
GENERATED	strike.v 1664 ::: jut;lay;knock;whack;deck;hit;bail;prise;rough;sweep

Filtered results
***************
RANKED	strike.v 1664	knock 0.07543	hitting 0.07269	hit 0.07269	carve 0.06970	bash 0.06689	bang 0.06666	thrust 0.06627	find 0.06501	hammer 0.06402	impress 0.06212	make 0.06209	get 0.06180	cast 0.06042	affect 0.05977	start 0.05976	take 0.05949	bump 0.05948	move 0.05937	surprise 0.05685	occur 0.05628	fail 0.05593	achieve 0.05297	begin 0.05013	pn 0.03998

Test context:
***************
strike.v	1665	3	we had to __strike__ the right balance .
Contexts for target strike are: ['aux_to', 'xcompI_had', 'dobj_balance']
Contexts in vocabulary for target strike are: ['aux_to', 'xcompI_had', 'dobj_balance']
Top most similar embeddings: strike 0.13958	readjust 0.09484	re-adjust 0.09367	re-structure 0.09298	re-negotiate 0.09166	manhandle 0.09127	reevaluate 0.09086	re-align 0.09082	struck 0.09001	re-draw 0.08990

Generated lemmatized results
***************
GENERATED	strike.v 1665 ::: readjust;manhandle;reevaluate;wheedle;revalidate;disgorge;liquidate;revalue;recalibrate;reconnoitre

Filtered results
***************
RANKED	strike.v 1665	knock 0.08259	move 0.08048	achieve 0.07986	find 0.07974	get 0.07887	make 0.07790	hit 0.07673	carve 0.07422	take 0.07371	bump 0.07191	impress 0.06637	hammer 0.06629	cast 0.06595	hitting 0.06548	bash 0.06531	begin 0.06526	start 0.06450	thrust 0.06442	bang 0.06353	occur 0.06295	affect 0.06189	fail 0.05796	surprise 0.05400	pn 0.04147

Test context:
***************
strike.v	1666	4	devils and imps , __struck__ into stone , clamber upon towers , prowl under cornices , peer out from bosses of foliage , perch upon capitals , nestle under benches , flame in windows .
Contexts for target struck are: ['partmodI_devils', 'prep:into_stone']
Contexts in vocabulary for target struck are: ['prep:into_stone']
Top most similar embeddings: struck 0.46079	chiselled 0.36446	turned 0.36274	carved 0.36018	gouged 0.35701	hewed 0.35544	tapped 0.35330	jolted 0.35191	pummelled 0.34936	hammered 0.34909

Generated lemmatized results
***************
GENERATED	strike.v 1666 ::: chisel;turn;carve;gouge;hew;tap;jolt;pummel;hammer;pierce

Filtered results
***************
RANKED	strike.v 1666	carve 0.36018	hammer 0.34909	bash 0.34525	knock 0.34146	bump 0.31887	bang 0.31830	thrust 0.31115	hit 0.30890	impress 0.29863	move 0.29392	hitting 0.29340	cast 0.28714	get 0.28160	affect 0.28022	make 0.27911	take 0.27667	find 0.27105	begin 0.27072	surprise 0.26858	start 0.26854	occur 0.26749	fail 0.25289	achieve 0.24975	pn 0.20871

Test context:
***************
strike.v	1667	7	jo looked as if she 'd been __struck__ in the back of the head with an eel .
Contexts for target struck are: ['mark_as', 'mark_if', 'nsubjpass_she', "aux_'d", 'auxpass_been', 'advclI_looked', 'prep:in_back', 'prep:with_eel']
Contexts in vocabulary for target struck are: ['mark_as', 'mark_if', 'nsubjpass_she', "aux_'d", 'auxpass_been', 'advclI_looked', 'prep:in_back']
Top most similar embeddings: struck 0.00791	knifed 0.00639	stabbed 0.00599	bitten 0.00597	electrocuted 0.00596	knocked 0.00594	scythed 0.00593	clobbered 0.00593	punched 0.00592	punted 0.00590

Generated lemmatized results
***************
GENERATED	strike.v 1667 ::: knife;stab;bite;electrocute;knock;scythe;clobber;punch;punt;clatter

Filtered results
***************
RANKED	strike.v 1667	knock 0.00594	hit 0.00583	bash 0.00565	bang 0.00548	hammer 0.00546	bump 0.00511	get 0.00450	move 0.00449	find 0.00426	take 0.00408	carve 0.00406	surprise 0.00400	thrust 0.00389	start 0.00386	impress 0.00382	make 0.00371	cast 0.00350	affect 0.00335	begin 0.00329	hitting 0.00319	achieve 0.00319	occur 0.00319	fail 0.00318	pn 0.00095

Test context:
***************
strike.v	1668	1	it __strikes__ me as odd that bob dole 's war record was germane then , but that john kerry 's , in a time of war , is not germane now .
Contexts for target strikes are: ['nsubj_it', 'rootI_*root*', 'dobj_me', 'advcl_germane', 'punct_,', 'cc_but', 'conj_germane', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target strikes are: ['nsubj_it', 'rootI_*root*', 'dobj_me', 'punct_,', 'cc_but', 'punct_.']
Top most similar embeddings: sickens 0.01630	strikes 0.01594	behooves 0.01559	disgusts 0.01417	seemes 0.01395	saddens 0.01393	astounds 0.01382	amuses 0.01371	struck 0.01345	disarms 0.01337

Generated lemmatized results
***************
GENERATED	strike.v 1668 ::: sicken;behoove;disgust;seem;sadden;astound;amuse;disarm;unsettle;astonish

Filtered results
***************
RANKED	strike.v 1668	impress 0.01146	make 0.01139	take 0.01136	affect 0.01037	get 0.01032	knock 0.01031	find 0.01002	start 0.00995	move 0.00988	fail 0.00977	surprise 0.00972	hit 0.00971	begin 0.00954	cast 0.00946	occur 0.00940	achieve 0.00924	carve 0.00921	bash 0.00858	bang 0.00848	bump 0.00829	hitting 0.00803	hammer 0.00791	thrust 0.00715	pn 0.00511

Test context:
***************
strike.v	1669	22	so he arranges for an ex-mormon or moonie to sit next to her on some occasion while traveling , and the ex-cultist __strikes__ up an informal conversation about what they used to be involved in , at the same time not asking the jw too many questions or being overly curious .
Contexts for target strikes are: ['det_the', 'amod_ex-cultist', 'conjI_arranges', 'prep:up_conversation']
Contexts in vocabulary for target strikes are: ['det_the', 'conjI_arranges']
Top most similar embeddings: strikes 0.22376	strike 0.18450	walkouts 0.17055	protests 0.16771	marches 0.16744	rallies 0.16534	sit-ins 0.16482	tortures 0.16446	purges 0.16249	revolts 0.16229

Generated lemmatized results
***************
GENERATED	strike.v 1669 ::: walkouts;protest;march;rally;torture;purge;revolt;fast;serenade;boycott

Filtered results
***************
RANKED	strike.v 1669	bash 0.15450	thrust 0.14859	bump 0.14825	move 0.14790	bang 0.14398	surprise 0.14314	hit 0.14270	cast 0.14208	hammer 0.14112	knock 0.13786	take 0.13227	make 0.13195	carve 0.12776	affect 0.12710	find 0.12703	start 0.12311	impress 0.12199	begin 0.12164	fail 0.12050	hitting 0.11693	achieve 0.11526	pn 0.11523	occur 0.11120	get 0.10734

Test context:
***************
strike.v	1670	14	designers and engineers use hand calculations or computer simulations to estimate the solar radiation __striking__ a collector .
Contexts for target striking are: ['nsubj_radiation', 'ccompI_estimate', 'dobj_collector']
Contexts in vocabulary for target striking are: ['nsubj_radiation', 'ccompI_estimate', 'dobj_collector']
Top most similar embeddings: striking 0.09674	affects 0.07583	damaging 0.07514	kills 0.07486	emitted 0.07481	infects 0.07441	emits 0.07415	reaching 0.07415	constitutes 0.07377	hitting 0.07336

Generated lemmatized results
***************
GENERATED	strike.v 1670 ::: affect;damage;kill;emit;infect;reach;constitute;hit;predispose;disturb

Filtered results
***************
RANKED	strike.v 1670	affect 0.07583	hitting 0.07336	hit 0.07336	occur 0.06451	knock 0.06337	take 0.06172	achieve 0.06167	move 0.06084	make 0.06069	impress 0.05908	cast 0.05873	find 0.05845	surprise 0.05800	carve 0.05713	get 0.05686	thrust 0.05684	hammer 0.05536	fail 0.05526	begin 0.05427	bump 0.05409	bash 0.05406	start 0.05309	bang 0.05065	pn 0.04655

Test context:
***************
suspect.v	1671	9	3 [ 432 u.s. 312 , 332 ] i __suspect__ that the only justification for the court 's decision today is its belief that the statute is unfair in its application .
Contexts for target suspect are: ['dep_i', 'rootI_*root*', 'ccomp_belief', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target suspect are: ['dep_i', 'rootI_*root*', 'ccomp_belief', 'punct_.']
Top most similar embeddings: suspect 0.06285	ddarllen 0.05078	suppose 0.04933	said 0.04694	avers 0.04690	presume 0.04677	daresay 0.04635	beleive 0.04575	alleges 0.04573	averred 0.04565

Generated lemmatized results
***************
GENERATED	suspect.v 1671 ::: ddarllen;suppose;say;aver;presume;daresay;beleive;allege;guess;contend

Filtered results
***************
RANKED	suspect.v 1671	presume 0.04677	guess 0.04552	reckon 0.04504	surmise 0.04423	assume 0.04243	believe 0.04202	think 0.04124	imagine 0.04100	postulate 0.03818	suspicious 0.03804	consider 0.03630	question 0.03301	expect 0.03263	feel 0.03240	mistrust 0.03018

Test context:
***************
suspect.v	1672	26	it is doubtful that many viewers who witness the process and effects of such nefarious and insidious " mind control " in their entertainment , ever __suspect__ that they themselves are the victims of similar programs of influence and plots of intrigue in real life .
Contexts for target suspect are: ['mark_that', 'nsubj_viewers', 'advmod_ever', 'ccompI_doubtful', 'ccomp_victims']
Contexts in vocabulary for target suspect are: ['mark_that', 'nsubj_viewers', 'advmod_ever', 'ccompI_doubtful', 'ccomp_victims']
Top most similar embeddings: suspect 0.02432	suspected 0.02222	doubted 0.02024	knew 0.01988	realized 0.01973	noticed 0.01945	twigged 0.01939	likely 0.01924	believed 0.01894	realised 0.01883

Generated lemmatized results
***************
GENERATED	suspect.v 1672 ::: doubt;know;realize;notice;twig;likely;believe;realise;divine;fantasise

Filtered results
***************
RANKED	suspect.v 1672	believe 0.01894	guess 0.01845	suspicious 0.01843	imagine 0.01840	think 0.01756	surmise 0.01751	assume 0.01749	feel 0.01712	question 0.01644	reckon 0.01612	mistrust 0.01580	presume 0.01579	postulate 0.01563	expect 0.01529	consider 0.01500

Test context:
***************
suspect.v	1673	23	this variable degree of symptoms can make the diagnosis of an oxidative metabolic disorder more difficult to recognize , but should be highly __suspected__ when myopathy and encephalopathy are present together .
Contexts for target suspected are: ['aux_should', 'auxpass_be', 'advmod_highly', 'conjI_make', 'advcl_present']
Contexts in vocabulary for target suspected are: ['aux_should', 'auxpass_be', 'advmod_highly', 'conjI_make', 'advcl_present']
Top most similar embeddings: suspected 0.02475	regarded 0.02068	presumed 0.02052	discouraged 0.01975	penalized 0.01959	avoided 0.01943	taxed 0.01935	decontaminated 0.01878	detected 0.01864	retested 0.01861

Generated lemmatized results
***************
GENERATED	suspect.v 1673 ::: regard;presume;discourage;penalize;avoid;tax;decontaminate;detect;retested;treat

Filtered results
***************
RANKED	suspect.v 1673	presume 0.02052	consider 0.01794	assume 0.01759	suspicious 0.01688	mistrust 0.01634	expect 0.01632	question 0.01530	imagine 0.01520	surmise 0.01498	postulate 0.01462	believe 0.01436	reckon 0.01416	guess 0.01393	think 0.01390	feel 0.01133

Test context:
***************
suspect.v	1674	2	if you __suspect__ something is out of the ordinary then its time to call the police and either pass on the information or request to see an officer if necessary .
Contexts for target suspect are: ['mark_if', 'nsubj_you', 'rootI_*root*', 'ccomp_is', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target suspect are: ['mark_if', 'nsubj_you', 'rootI_*root*', 'ccomp_is', 'punct_.']
Top most similar embeddings: suspect 0.03759	think 0.02791	believe 0.02699	know 0.02520	assume 0.02504	reckon 0.02484	suppose 0.02447	imagine 0.02414	allege 0.02399	guess 0.02396

Generated lemmatized results
***************
GENERATED	suspect.v 1674 ::: think;believe;know;assume;reckon;suppose;imagine;allege;guess;betcha

Filtered results
***************
RANKED	suspect.v 1674	think 0.02791	believe 0.02699	assume 0.02504	reckon 0.02484	imagine 0.02414	guess 0.02396	feel 0.02319	presume 0.02285	surmise 0.02209	consider 0.02133	suspicious 0.02075	postulate 0.02004	expect 0.01948	question 0.01875	mistrust 0.01522

Test context:
***************
suspect.v	1675	1	i __suspect__ that all the other committees will have an away day and that all of those will have a european element .
Contexts for target suspect are: ['nsubj_i', 'rootI_*root*', 'ccomp_have', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target suspect are: ['nsubj_i', 'rootI_*root*', 'ccomp_have', 'punct_.']
Top most similar embeddings: suspect 0.09491	2885557 0.09207	syph 0.08408	ddarllen 0.07965	harpoole 0.07660	said 0.07568	suppose 0.07563	tchiowa 0.07536	fitsfile 0.07504	resserved 0.07454

Generated lemmatized results
***************
GENERATED	suspect.v 1675 ::: syph;ddarllen;harpoole;say;suppose;tchiowa;fitsfile;resserved;laur;daresay

Filtered results
***************
RANKED	suspect.v 1675	think 0.07385	believe 0.07340	reckon 0.07237	guess 0.06965	assume 0.06946	surmise 0.06865	presume 0.06717	imagine 0.06475	feel 0.06044	consider 0.05915	question 0.05812	expect 0.05591	suspicious 0.05532	postulate 0.05469	mistrust 0.04940

Test context:
***************
suspect.v	1676	0	__suspected__ of conspiracy , securities fraud and obstruction of justice , stewart is ultimately indicted , found guilty of all charges and sentenced to five months in prison followed by five months of house arrest .
Contexts for target suspected are: ['rootI_*root*', 'prep:of_conspiracy', 'dep_fraud']
Contexts in vocabulary for target suspected are: ['rootI_*root*', 'prep:of_conspiracy', 'dep_fraud']
Top most similar embeddings: suspected 0.12927	convicted 0.09524	accused 0.09353	alleged 0.09296	guilty 0.08647	suspect 0.08616	alleges 0.08593	accuses 0.08590	indicted 0.08535	acquitted 0.08337

Generated lemmatized results
***************
GENERATED	suspect.v 1676 ::: convict;accuse;allege;guilty;indict;acquit;suspicious;implicate;indictable;exonerate

Filtered results
***************
RANKED	suspect.v 1676	suspicious 0.08272	presume 0.07729	believe 0.07631	surmise 0.07475	think 0.07135	question 0.06972	postulate 0.06757	assume 0.06528	consider 0.06261	imagine 0.06259	guess 0.06255	reckon 0.06241	mistrust 0.06240	expect 0.05739	feel 0.05253

Test context:
***************
suspect.v	1677	44	here 's a cross-section : --wizbang 's kevin alyward :"i remain skeptical of the argument the schindler 's lawyers have put forth ( they claimed that terri schiavo 's religious and due process rights have been violated ) in their federal case , and __suspect__ the supreme court may decided not to hear the case .
Contexts for target suspect are: ['conjI_claimed', 'dobj_court']
Contexts in vocabulary for target suspect are: ['conjI_claimed', 'dobj_court']
Top most similar embeddings: suspect 0.21971	accused 0.17337	suspects 0.17329	suspected 0.16627	allege 0.16510	convicted 0.16453	convict 0.16362	indicted 0.16216	acquitted 0.15984	exonerated 0.15959

Generated lemmatized results
***************
GENERATED	suspect.v 1677 ::: accuse;allege;convict;indict;acquit;exonerate;impugn;aver;dispute;assert

Filtered results
***************
RANKED	suspect.v 1677	presume 0.15265	question 0.15128	suspicious 0.14568	postulate 0.14508	mistrust 0.14488	surmise 0.14391	reckon 0.14222	assume 0.14090	believe 0.13773	imagine 0.13665	guess 0.13446	think 0.12630	consider 0.12624	expect 0.12080	feel 0.11942

Test context:
***************
suspect.v	1678	9	either way , it appears that the spdc commander __suspects__ that the rice has gone to the knla .
Contexts for target suspects are: ['mark_that', 'nsubj_commander', 'ccompI_appears', 'ccomp_gone']
Contexts in vocabulary for target suspects are: ['mark_that', 'nsubj_commander', 'ccompI_appears', 'ccomp_gone']
Top most similar embeddings: suspects 0.05499	realises 0.04253	suspect 0.04227	realizes 0.04215	thinks 0.04115	overstepped 0.03985	understands 0.03952	unaware 0.03945	believes 0.03922	deems 0.03906

Generated lemmatized results
***************
GENERATED	suspect.v 1678 ::: realise;realize;think;overstep;understand;unaware;believe;deem;disobey;know

Filtered results
***************
RANKED	suspect.v 1678	think 0.04115	believe 0.03922	assume 0.03699	presume 0.03658	consider 0.03640	feel 0.03638	imagine 0.03636	surmise 0.03600	expect 0.03393	question 0.03354	suspicious 0.03290	reckon 0.03080	mistrust 0.03003	guess 0.02994	postulate 0.02877

Test context:
***************
suspect.v	1679	1	i __suspect__ i will be able to nitpick all counterarguments .
Contexts for target suspect are: ['depI_able']
Contexts in vocabulary for target suspect are: ['depI_able']
Top most similar embeddings: suspect 0.44088	suspects 0.34203	order 0.31646	unfortunatley 0.31442	allthough 0.31323	unbeknown 0.31252	insomuch 0.31199	if/when 0.31175	daresay 0.31119	by-and-by 0.31116

Generated lemmatized results
***************
GENERATED	suspect.v 1679 ::: order;unfortunatley;allthough;unbeknown;insomuch;daresay;whereever;probable;wherby;whereas

Filtered results
***************
RANKED	suspect.v 1679	suspicious 0.30314	presume 0.30265	guess 0.29738	reckon 0.29688	imagine 0.29646	assume 0.29580	surmise 0.29576	think 0.28849	believe 0.28625	postulate 0.27749	feel 0.26688	question 0.26170	consider 0.25956	expect 0.25666	mistrust 0.25218

Test context:
***************
suspect.v	1680	19	plaintiff presents , as an example of " government spying , " an incident in which another person is __suspected__ , without factual basis , of being an infiltrator : on october 10 , 2001 , seattle central community college freedom socialists club held a form entitled " a speakout against war .
Contexts for target suspected are: ['prep:in_which', 'nsubjpass_person', 'auxpass_is', 'rcmodI_incident', 'punct_,', 'prep:without_basis', 'punct_,', 'punct_:', 'ccomp_held']
Contexts in vocabulary for target suspected are: ['prep:in_which', 'nsubjpass_person', 'auxpass_is', 'rcmodI_incident', 'punct_,', 'prep:without_basis', 'punct_,', 'punct_:', 'ccomp_held']
Top most similar embeddings: suspected 0.00157	alleged 0.00133	averred 0.00124	apprehended 0.00118	affirmed 0.00117	precluded 0.00117	asserted 0.00117	reported 0.00115	declared 0.00115	presumed 0.00114

Generated lemmatized results
***************
GENERATED	suspect.v 1680 ::: allege;aver;apprehend;affirm;preclude;assert;report;declare;presume;contend

Filtered results
***************
RANKED	suspect.v 1680	presume 0.00114	assume 0.00111	believe 0.00109	question 0.00107	postulate 0.00101	surmise 0.00097	imagine 0.00094	expect 0.00090	consider 0.00089	think 0.00085	mistrust 0.00082	reckon 0.00079	guess 0.00074	feel 0.00058	suspicious 0.00057

Test context:
***************
tender.a	1681	35	spaghettini with mullet roe and grated vegetables , and penne with sundried tomatoes and basil were both full of flavour and pleasantly light , which was lucky as i was almost defeated by an exceptionally __tender__ and tasty lamb shank to follow .
Contexts for target tender are: ['det_an', 'advmod_exceptionally', 'prep:byI_defeated', 'cc_and', 'conj_shank', 'infmod_follow']
Contexts in vocabulary for target tender are: ['det_an', 'advmod_exceptionally', 'prep:byI_defeated', 'cc_and', 'conj_shank', 'infmod_follow']
Top most similar embeddings: tender 0.01243	steak 0.00802	fillet 0.00788	stout 0.00766	brie 0.00765	asparagus 0.00762	aubergine 0.00759	scallops 0.00755	earnest 0.00746	eel 0.00734

Generated lemmatized results
***************
GENERATED	tender.a 1681 ::: steak;fillet;stout;brie;asparagus;aubergine;scallops;earnest;eel;squid

Filtered results
***************
RANKED	tender.a 1681	immature 0.00641	sore 0.00620	gentle 0.00575	delicate 0.00538	affectionate 0.00538	inexperienced 0.00535	soft 0.00525	kind 0.00497	loving 0.00485	fond 0.00478	young 0.00472	painful 0.00444	sensitive 0.00443	early 0.00395	sympathetic 0.00393	great 0.00367

Test context:
***************
tender.a	1682	25	women usually notice little change in their breasts , but if you are a man , your breasts may become slightly larger and may be __tender__ .
Contexts for target tender are: ['aux_may', 'cop_be', 'conjI_larger']
Contexts in vocabulary for target tender are: ['aux_may', 'cop_be', 'conjI_larger']
Top most similar embeddings: tender 0.10987	handier 0.09008	duplicative 0.08652	unwieldy 0.08573	hardier 0.08501	salvageable 0.08494	longer-lasting 0.08441	substitutable 0.08427	sturdier 0.08386	scaled-up 0.08372

Generated lemmatized results
***************
GENERATED	tender.a 1682 ::: handy;duplicative;unwieldy;hardy;salvageable;substitutable;sturdy;restorable;unsaleable;acurate

Filtered results
***************
RANKED	tender.a 1682	painful 0.07941	sensitive 0.07585	gentle 0.07295	delicate 0.07288	soft 0.07040	kind 0.06989	great 0.06950	sympathetic 0.06936	affectionate 0.06910	sore 0.06756	fond 0.06741	immature 0.06607	inexperienced 0.06547	young 0.06256	loving 0.05875	early 0.05506

Test context:
***************
tender.a	1683	18	" i can be very , very strong , but on the other hand , i have very __tender__ sentiments .
Contexts for target tender are: ['advmod_very', 'amodI_sentiments']
Contexts in vocabulary for target tender are: ['advmod_very', 'amodI_sentiments']
Top most similar embeddings: tender 0.24057	unmeaning 0.18562	fervid 0.18339	comradely 0.18252	uncomplimentary 0.18140	flavorful 0.18117	heart-felt 0.17958	high-flown 0.17957	vituperative 0.17955	soldierly 0.17949

Generated lemmatized results
***************
GENERATED	tender.a 1683 ::: unmeaning;fervid;comradely;uncomplimentary;flavorful;vituperative;soldierly;ingenuous;epigrammatic;gossipy

Filtered results
***************
RANKED	tender.a 1683	affectionate 0.17214	delicate 0.16492	painful 0.16002	soft 0.15696	fond 0.15657	gentle 0.15579	loving 0.15346	kind 0.15324	immature 0.14664	sore 0.14412	sympathetic 0.14397	sensitive 0.14314	young 0.13827	early 0.13408	great 0.13186	inexperienced 0.12498

Test context:
***************
tender.a	1684	6	rabbits often feed on young , __tender__ perennial growth as it emerges in spring , or on young transplants .
Contexts for target tender are: ['nnI_growth']
Contexts in vocabulary for target tender are: ['nnI_growth']
Top most similar embeddings: tender 0.49759	neurite 0.35344	haulm 0.34853	tenders 0.33461	smolt 0.33167	maturer 0.33126	chondrocyte 0.33015	warty 0.32850	dinoflagellate 0.32778	continuos 0.32734

Generated lemmatized results
***************
GENERATED	tender.a 1684 ::: neurite;haulm;tenders;smolt;mature;chondrocyte;warty;dinoflagellate;continuos;seedling

Filtered results
***************
RANKED	tender.a 1684	soft 0.29700	fond 0.27166	delicate 0.26781	great 0.26716	young 0.26612	immature 0.26237	loving 0.26168	sensitive 0.25916	sore 0.25905	kind 0.25805	affectionate 0.25776	painful 0.25230	gentle 0.25165	sympathetic 0.23933	early 0.23919	inexperienced 0.22916

Test context:
***************
tender.a	1685	5	the grilled octopus was very __tender__ .
Contexts for target tender are: ['nsubj_octopus', 'cop_was', 'advmod_very', 'rootI_*root*', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target tender are: ['nsubj_octopus', 'cop_was', 'advmod_very', 'rootI_*root*', 'punct_.']
Top most similar embeddings: tender 0.02718	well-done 0.02188	ho-hum 0.02155	hillarious 0.02125	un-english 0.02115	painfull 0.02075	flighty 0.02061	straighforward 0.02025	galled 0.02024	scrummy 0.02020

Generated lemmatized results
***************
GENERATED	tender.a 1685 ::: hillarious;painfull;flighty;straighforward;galled;scrummy;cagey;yummy;fond;fatiguing

Filtered results
***************
RANKED	tender.a 1685	fond 0.01990	painful 0.01940	sore 0.01792	affectionate 0.01754	immature 0.01743	delicate 0.01686	sensitive 0.01685	soft 0.01634	sympathetic 0.01627	gentle 0.01545	kind 0.01539	loving 0.01515	great 0.01415	inexperienced 0.01342	young 0.01315	early 0.01057

Test context:
***************
tender.a	1686	19	cook the rice , covered , over boiling water for about 30 minutes , or until the grains are __tender__ .
Contexts for target tender are: ['mark_until', 'nsubj_grains', 'cop_are', 'conjI_minutes']
Contexts in vocabulary for target tender are: ['mark_until', 'nsubj_grains', 'cop_are', 'conjI_minutes']
Top most similar embeddings: tender 0.06373	browned 0.05141	thickened 0.04483	translucent 0.04459	crispy 0.04345	caramelised 0.04307	cooked 0.04282	wilted 0.04241	rehydrated 0.04178	unfrozen 0.04129

Generated lemmatized results
***************
GENERATED	tender.a 1686 ::: browned;thickened;translucent;crispy;caramelised;cooked;wilted;rehydrated;unfrozen;opaque

Filtered results
***************
RANKED	tender.a 1686	soft 0.03843	delicate 0.03369	painful 0.03189	sore 0.03173	sensitive 0.02955	immature 0.02940	kind 0.02825	gentle 0.02736	affectionate 0.02733	young 0.02721	fond 0.02671	great 0.02596	loving 0.02499	sympathetic 0.02497	inexperienced 0.02284	early 0.02074

Test context:
***************
tender.a	1687	17	they feed at that period on the opening buds of maples , and others that are equally __tender__ and juicy .
Contexts for target tender are: ['nsubj_that', 'cop_are', 'advmod_equally', 'rcmodI_others', 'cc_and', 'conj_juicy']
Contexts in vocabulary for target tender are: ['nsubj_that', 'cop_are', 'advmod_equally', 'rcmodI_others', 'cc_and', 'conj_juicy']
Top most similar embeddings: tender 0.01375	plump 0.01016	crunchy 0.00984	absorbant 0.00978	insensate 0.00978	flabby 0.00969	ripe 0.00967	juicy 0.00962	teachable 0.00960	nutritious 0.00959

Generated lemmatized results
***************
GENERATED	tender.a 1687 ::: plump;crunchy;absorbant;insensate;flabby;ripe;juicy;teachable;nutritious;flaky

Filtered results
***************
RANKED	tender.a 1687	delicate 0.00893	sensitive 0.00877	fond 0.00863	soft 0.00853	affectionate 0.00850	sympathetic 0.00838	immature 0.00800	painful 0.00783	gentle 0.00736	inexperienced 0.00735	sore 0.00724	kind 0.00719	loving 0.00693	great 0.00597	young 0.00581	early 0.00417

Test context:
***************
tender.a	1688	6	anne bradstreet 's poetry is so __tender__ and poignant , cotton mather 's preaching is both ornery and passionate , richard baxter 's reformed pastor is one of the classics , and jonathan edwards , is , well , jonathan edwards ( if you consider him a puritan , not everyone does. ) oh , by the way , great article about puritans here .
Contexts for target tender are: ['nsubj_poetry', 'cop_is', 'advmod_so', 'rootI_*root*', 'cc_and', 'conj_poignant', 'punct_,', 'conj_ornery', 'punct_,', 'conj_one', 'punct_,', 'cc_and', 'conj_edwards', 'punct_,', 'conj_article', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target tender are: ['nsubj_poetry', 'cop_is', 'advmod_so', 'rootI_*root*', 'cc_and', 'conj_poignant', 'punct_,', 'punct_,', 'conj_one', 'punct_,', 'cc_and', 'conj_edwards', 'punct_,', 'conj_article', 'punct_.']
Top most similar embeddings: witty 0.00002	well-written 0.00002	unsentimental 0.00002	well-paced 0.00002	god-breathed 0.00002	half-human 0.00002	poignant 0.00002	quicke 0.00002	contrariwise 0.00002	quick-witted 0.00002

Generated lemmatized results
***************
GENERATED	tender.a 1688 ::: witty;unsentimental;poignant;quicke;contrariwise;pacy;unexceptionable;morose;humorous;flighty

Filtered results
***************
RANKED	tender.a 1688	affectionate 0.00002	gentle 0.00001	fond 0.00001	painful 0.00001	kind 0.00001	immature 0.00001	soft 0.00001	delicate 0.00001	loving 0.00001	sensitive 0.00001	sympathetic 0.00001	sore 0.00001	young 0.00001	inexperienced 0.00001	great 0.00001	early 0.00000

Test context:
***************
tender.a	1689	42	i fancy you would , perhaps , like the rule of the russians , who are very great friends of india and of mahomedans , and under whom the hindus will live in great comfort , and who will protect with the __tenderest__ care the wealth and property which they have acquired under english rule ?
Contexts for target tenderest are: ['amodI_care']
Contexts in vocabulary for target tenderest are: ['amodI_care']
Top most similar embeddings: tenderest 0.53094	motherly 0.42853	midwifery-led 0.42138	sisterly 0.42086	profoundest 0.41980	fatherly 0.41755	woman-centred 0.41425	post-surgical 0.41061	womanly 0.40438	filial 0.40318

Generated lemmatized results
***************
GENERATED	tender.a 1689 ::: motherly;sisterly;profound;fatherly;womanly;filial;unfeigned;psychologic;wonted;geniune

Filtered results
***************
RANKED	tender.a 1689	gentle 0.39080	kind 0.38045	loving 0.37435	great 0.36942	fond 0.36434	affectionate 0.36334	soft 0.35521	delicate 0.34683	early 0.32954	sympathetic 0.31808	painful 0.31782	sensitive 0.31599	young 0.30843	sore 0.30428	immature 0.30277	inexperienced 0.28124

Test context:
***************
tender.a	1690	9	after breaking though into the first team at the __tenderest__ of ages , the youngster received his full international call up shortly afterwards .
Contexts for target tenderest are: ['det_the', 'prep:atI_team', 'prep:of_ages']
Contexts in vocabulary for target tenderest are: ['det_the', 'prep:atI_team', 'prep:of_ages']
Top most similar embeddings: tenderest 0.08693	botanics 0.08675	questors 0.08566	tail-end 0.08398	hesperides 0.08363	rowans 0.08323	commonwealths 0.08319	bowmen 0.08315	wellsprings 0.08280	dinner-table 0.08280

Generated lemmatized results
***************
GENERATED	tender.a 1690 ::: botanics;questors;hesperides;rowans;commonwealths;bowmen;wellsprings;hellmouth;noble;mysteries

Filtered results
***************
RANKED	tender.a 1690	gentle 0.08103	early 0.07310	soft 0.07271	kind 0.07124	young 0.07028	great 0.07008	fond 0.06780	immature 0.05704	loving 0.05483	inexperienced 0.05412	sore 0.05393	delicate 0.05354	affectionate 0.05289	sensitive 0.04775	painful 0.04691	sympathetic 0.04636

Test context:
***************
test.n	1691	15	make yourself aware of what to expect , become familiar with the organization of the __tests__ and test-day procedures .
Contexts for target tests are: ['det_the', 'prep:ofI_organization', 'cc_and', 'conj_procedures']
Contexts in vocabulary for target tests are: ['det_the', 'prep:ofI_organization', 'cc_and', 'conj_procedures']
Top most similar embeddings: tests 0.05601	examinations 0.04471	self-tests 0.04467	self-assessments 0.04323	procedures 0.04318	sops 0.04305	checks 0.04277	testing 0.04255	terminologies 0.04230	auditees 0.04179

Generated lemmatized results
***************
GENERATED	test.n 1691 ::: examination;procedure;sop;check;testing;terminology;auditees;subtests;assessment;subprogram

Filtered results
***************
RANKED	test.n 1691	examination 0.04471	check 0.04277	assessment 0.04165	exam 0.04139	evaluation 0.03824	trial 0.03747	analysis 0.03589	scan 0.03510

Test context:
***************
test.n	1692	2	take the __tests__ repeatedly until you pass ; you do n't need to take all three each time , just those you need to pass .
Contexts for target tests are: ['det_the', 'dobjI_take']
Contexts in vocabulary for target tests are: ['det_the', 'dobjI_take']
Top most similar embeddings: tests 0.24970	test 0.21761	ukcat 0.20635	mini-pill 0.20558	cudgels 0.19966	bmat 0.19883	lnat 0.19797	exams 0.19182	breathalyser 0.18910	gmat 0.18882

Generated lemmatized results
***************
GENERATED	test.n 1692 ::: ukcat;cudgel;bmat;lnat;exam;breathalyser;gmat;examination;hastle;steriods

Filtered results
***************
RANKED	test.n 1692	exam 0.19182	examination 0.18664	assessment 0.17568	check 0.16864	evaluation 0.15886	scan 0.15671	trial 0.15292	analysis 0.14806

Test context:
***************
test.n	1693	23	initially , subjects will participate in a screening and pd-afo tuning visit that contains a neuromuscular screening examination , a preferred walking speed __test__ , and measurement for a custom fitting pd-afo .
Contexts for target test are: ['det_a', 'amod_preferred', 'amod_walking', 'nn_speed', 'conjI_examination']
Contexts in vocabulary for target test are: ['det_a', 'amod_preferred', 'amod_walking', 'nn_speed', 'conjI_examination']
Top most similar embeddings: test 0.02956	tests 0.02254	re-test 0.02121	tester 0.01974	retest 0.01948	mammogram 0.01878	technique 0.01871	testing 0.01841	radiograph 0.01840	assay 0.01790

Generated lemmatized results
***************
GENERATED	test.n 1693 ::: tester;retest;mammogram;technique;testing;radiograph;assay;enema;examination;mode

Filtered results
***************
RANKED	test.n 1693	examination 0.01754	trial 0.01728	exam 0.01611	assessment 0.01598	check 0.01535	scan 0.01446	analysis 0.01379	evaluation 0.01305

Test context:
***************
test.n	1694	15	springs tested positive in august , when all nfl players are given a mandatory drug __test__ at their training camps .
Contexts for target test are: ['det_a', 'amod_mandatory', 'nn_drug', 'dobjI_given', 'prep:at_camps']
Contexts in vocabulary for target test are: ['det_a', 'amod_mandatory', 'nn_drug', 'dobjI_given', 'prep:at_camps']
Top most similar embeddings: test 0.02631	tests 0.02168	testing 0.02043	retest 0.02014	check-up 0.01872	treatment 0.01870	enema 0.01850	checkup 0.01844	curfew 0.01835	ban 0.01813

Generated lemmatized results
***************
GENERATED	test.n 1694 ::: testing;retest;treatment;enema;checkup;curfew;ban;vaccine;screening;premedication

Filtered results
***************
RANKED	test.n 1694	trial 0.01710	check 0.01649	exam 0.01518	examination 0.01511	assessment 0.01463	evaluation 0.01361	scan 0.01347	analysis 0.01339

Test context:
***************
test.n	1695	19	cdc to study nucleic acid hiv test cdc this week at the conference announced plans to study an hiv __test__ -- called the nucleic acid amplification test , or naat , which is able to detect the virus weeks earlier than standard screening -- in order to determine whether the test would duplicate conventional testing methods and be cost-effective , the ap/las vegas sun reports .
Contexts for target test are: ['det_an', 'nn_hiv', 'dobjI_study']
Contexts in vocabulary for target test are: ['det_an', 'nn_hiv', 'dobjI_study']
Top most similar embeddings: test 0.11567	tests 0.09013	assay 0.08635	seroprevalence 0.08634	testing 0.08577	electrocardiogram 0.08440	radiograph 0.08409	microbicide 0.08375	autoantibody 0.08175	antibody 0.08065

Generated lemmatized results
***************
GENERATED	test.n 1695 ::: assay;seroprevalence;testing;electrocardiogram;radiograph;microbicide;autoantibody;antibody;crossmatch;echocardiogram

Filtered results
***************
RANKED	test.n 1695	exam 0.07717	examination 0.07408	trial 0.07148	assessment 0.07095	evaluation 0.06927	analysis 0.06454	scan 0.06313	check 0.05893

Test context:
***************
test.n	1696	12	entries typically identify the age or school grade levels for which the __test__ is appropriate , as well as any subtests .
Contexts for target test are: ['det_the', 'nsubjI_appropriate']
Contexts in vocabulary for target test are: ['det_the', 'nsubjI_appropriate']
Top most similar embeddings: test 0.24628	tests 0.20547	bmat 0.18986	ukcat 0.18842	retest 0.18464	arfd 0.18426	testing 0.18044	t-test 0.18002	escp 0.17830	mini-pill 0.17830

Generated lemmatized results
***************
GENERATED	test.n 1696 ::: bmat;ukcat;retest;arfd;testing;escp;crossmatch;assay;breathalyser;gastroscopy

Filtered results
***************
RANKED	test.n 1696	exam 0.16804	examination 0.16489	assessment 0.15908	trial 0.15819	check 0.14934	evaluation 0.14785	analysis 0.14600	scan 0.14217

Test context:
***************
test.n	1697	20	as part of dnv 's review of its own work in certifying the regatta thermo cruise life jacket , new __tests__ have been conducted .
Contexts for target tests are: ['amod_new', 'nsubjpassI_conducted']
Contexts in vocabulary for target tests are: ['amod_new', 'nsubjpassI_conducted']
Top most similar embeddings: tests 0.26164	test 0.20684	experiments 0.19957	testing 0.18744	assessments 0.18555	assays 0.18459	examinations 0.18244	surveys 0.18167	checks 0.18135	evaluations 0.18113

Generated lemmatized results
***************
GENERATED	test.n 1697 ::: experiment;testing;assessment;assay;examination;survey;check;evaluation;bioassay;scrutiny

Filtered results
***************
RANKED	test.n 1697	assessment 0.18555	examination 0.18244	check 0.18135	evaluation 0.18113	trial 0.17479	exam 0.17450	analysis 0.17325	scan 0.15758

Test context:
***************
test.n	1698	2	the 8 __test__ questions ( comprising question 1 and 7 others ) were all of a similar level of difficulty and concerned the direction of the main or total force on a freely moving object in linear motion .
Contexts for target test are: ['nnI_questions']
Contexts in vocabulary for target test are: ['nnI_questions']
Top most similar embeddings: test 0.52324	tests 0.40555	exam 0.39524	mcq 0.39436	lsat 0.39227	testing 0.38942	contact_person 0.38715	gmat 0.37750	lnat 0.37667	retest 0.37587

Generated lemmatized results
***************
GENERATED	test.n 1698 ::: exam;mcq;lsat;testing;gmat;lnat;retest;ukcat;quiz;bmat

Filtered results
***************
RANKED	test.n 1698	exam 0.39524	examination 0.35370	assessment 0.33270	evaluation 0.31085	analysis 0.30534	trial 0.30428	check 0.30192	scan 0.28382

Test context:
***************
test.n	1699	25	even when class material was completely understood , i often forgot dates , names , vocabulary words and other details which were necessary to pass __tests__ .
Contexts for target tests are: ['dobjI_pass']
Contexts in vocabulary for target tests are: ['dobjI_pass']
Top most similar embeddings: tests 0.53543	test 0.45542	exams 0.40465	examinations 0.39391	testing 0.39286	assessments 0.38356	checks 0.38155	plab 0.37595	retest 0.37476	exam 0.37472

Generated lemmatized results
***************
GENERATED	test.n 1699 ::: exam;examination;testing;assessment;check;plab;retest;iqe;ukcat;lnat

Filtered results
***************
RANKED	test.n 1699	exam 0.40465	examination 0.39391	assessment 0.38356	check 0.38155	evaluation 0.33636	scan 0.31767	trial 0.31577	analysis 0.31359

Test context:
***************
test.n	1700	10	update - - in the latest 2000 8th grade science __test__ the usa did not perform better .
Contexts for target test are: ['det_the', 'amod_latest', 'num_2000', 'amod_8th', 'nn_grade', 'nn_science', 'prep:inI_update']
Contexts in vocabulary for target test are: ['det_the', 'amod_latest', 'num_2000', 'amod_8th', 'nn_grade', 'nn_science', 'prep:inI_update']
Top most similar embeddings: edition 0.00466	olympiad 0.00464	test 0.00460	tests 0.00442	sats 0.00437	survey 0.00429	ebulletin 0.00405	bulletin 0.00402	exams 0.00399	exam 0.00397

Generated lemmatized results
***************
GENERATED	test.n 1700 ::: edition;olympiad;sat;survey;ebulletin;bulletin;exam;report;symposium;beta

Filtered results
***************
RANKED	test.n 1700	exam 0.00399	examination 0.00379	trial 0.00338	assessment 0.00327	evaluation 0.00295	scan 0.00278	analysis 0.00275	check 0.00240

Test context:
***************
throw.v	1701	16	processes of natural selection enabled this breed to survive the worst conditions that northern europe could __throw__ at them and survived in no small part due to their short legs ( fewer breakages there ) and small birth size ( out they pop , as easy as anything... ) as suggested by the title , the first breed book established in the 1800s was created for this hardy beast .
Contexts for target throw are: ['dobj_that', 'nsubj_europe', 'aux_could', 'rcmodI_conditions', 'prep:at_them', 'cc_and', 'conj_survived']
Contexts in vocabulary for target throw are: ['dobj_that', 'nsubj_europe', 'aux_could', 'rcmodI_conditions', 'prep:at_them', 'cc_and', 'conj_survived']
Top most similar embeddings: throw 0.00679	thrown 0.00502	threw 0.00458	hurl 0.00456	flung 0.00442	hurled 0.00441	endured 0.00432	crumble 0.00426	throws 0.00425	swung 0.00424

Generated lemmatized results
***************
GENERATED	throw.v 1701 ::: hurl;fling;endure;crumble;swing;flourish;thrive;topple;toss;shrivel

Filtered results
***************
RANKED	throw.v 1701	hurl 0.00456	fling 0.00442	toss 0.00411	fire 0.00402	chuck 0.00390	propel 0.00354	shoot 0.00346	cast 0.00340	pitch 0.00339	discard 0.00329	demand 0.00326	put 0.00312	bring 0.00312	punch 0.00310	place 0.00310	project 0.00301	deliver 0.00286	ask 0.00252	focus 0.00238

Test context:
***************
throw.v	1702	11	watch out for mass transport devices plummeting from the sky , __throw__ a wildebeest or other animal local to your country on the barbie , and as the national advertising campaign requires , ask yourself every day .
Contexts for target throw are: ['conjI_watch', 'dobj_wildebeest', 'prep:to_country', 'prep:on_barbie']
Contexts in vocabulary for target throw are: ['conjI_watch', 'prep:to_country']
Top most similar embeddings: throw 0.21173	throwing 0.17178	throws 0.16230	hurl 0.16075	threw 0.15976	flee 0.15975	smuggle 0.15940	listen 0.15760	betake 0.15682	consign 0.15657

Generated lemmatized results
***************
GENERATED	throw.v 1702 ::: hurl;flee;smuggle;listen;betake;consign;toss;bring;scurry;gloat

Filtered results
***************
RANKED	throw.v 1702	hurl 0.16075	toss 0.15609	bring 0.15599	fling 0.15370	chuck 0.14579	discard 0.14350	shoot 0.14178	cast 0.13316	propel 0.13254	deliver 0.13085	put 0.13081	fire 0.12781	pitch 0.12771	demand 0.12670	project 0.12517	punch 0.12294	ask 0.11945	place 0.11703	focus 0.11181

Test context:
***************
throw.v	1703	14	i guess what we 're protecting them from is the idea that beautiful women __throw__ themselves at sports stars -- because children , who have n't yet formed their values , might start valuing professional football after seeing this promo .
Contexts for target throw are: ['mark_that', 'nsubj_women', 'ccompI_idea', 'dobj_themselves', 'prep:at_stars']
Contexts in vocabulary for target throw are: ['mark_that', 'nsubj_women', 'ccompI_idea', 'dobj_themselves', 'prep:at_stars']
Top most similar embeddings: throw 0.02634	throwing 0.02164	hurl 0.02152	threw 0.02139	hurled 0.02047	masturbate 0.01999	crapping 0.01982	emancipate 0.01904	thrown 0.01884	behave 0.01878

Generated lemmatized results
***************
GENERATED	throw.v 1703 ::: hurl;masturbate;crap;emancipate;behave;fling;stare;outperform;mutilate;exert

Filtered results
***************
RANKED	throw.v 1703	hurl 0.02152	fling 0.01874	chuck 0.01773	propel 0.01660	toss 0.01635	shoot 0.01605	cast 0.01490	pitch 0.01484	project 0.01479	bring 0.01455	put 0.01454	fire 0.01396	punch 0.01377	discard 0.01338	place 0.01328	ask 0.01312	demand 0.01297	deliver 0.01265	focus 0.01155

Test context:
***************
throw.v	1704	20	only after i felt that i understood his theories and had a correct answer for every question that might be __thrown__ at me , did i start to help others by teaching them the correct way to train .
Contexts for target thrown are: ['nsubjpass_that', 'aux_might', 'auxpass_be', 'rcmodI_question', 'prep:at_me']
Contexts in vocabulary for target thrown are: ['nsubjpass_that', 'aux_might', 'auxpass_be', 'rcmodI_question', 'prep:at_me']
Top most similar embeddings: thrown 0.03273	chucked 0.02396	hurled 0.02374	tossed 0.02315	leveled 0.02124	bandied 0.02107	sneered 0.02065	answered 0.02060	frowned 0.02051	flung 0.02050

Generated lemmatized results
***************
GENERATED	throw.v 1704 ::: chuck;hurl;toss;level;bandy;sneer;answer;frown;fling;raise

Filtered results
***************
RANKED	throw.v 1704	chuck 0.02396	hurl 0.02374	toss 0.02315	fling 0.02050	discard 0.02002	fire 0.01950	propel 0.01948	pitch 0.01908	ask 0.01837	put 0.01825	bring 0.01779	place 0.01737	demand 0.01729	cast 0.01668	punch 0.01603	deliver 0.01557	shoot 0.01551	project 0.01549	focus 0.01483

Test context:
***************
throw.v	1705	12	for example , kareem kamel noted approvingly that : ...the prisoner swap __threw__ into sharp relief the futility of all ' peacemaking ' efforts in the region , and the importance of resistance and steadfastness .
Contexts for target threw are: ['punct_...', 'nsubj_swap', 'depI_<eol>', 'prep:into_relief', 'dobj_futility', 'punct_,', 'cc_and', 'conj_importance', 'punct_.']
Contexts in vocabulary for target threw are: ['punct_...', 'nsubj_swap', 'prep:into_relief', 'dobj_futility', 'punct_,', 'cc_and', 'conj_importance', 'punct_.']
Top most similar embeddings: threw 0.00267	brings 0.00231	throws 0.00224	contextualises 0.00207	puts 0.00205	sidesteps 0.00205	deconstructs 0.00205	distills 0.00204	symbolizes 0.00202	raises 0.00201

Generated lemmatized results
***************
GENERATED	throw.v 1705 ::: bring;contextualises;put;sidestep;deconstruct;distill;symbolize;raise;reaffirm;confront

Filtered results
***************
RANKED	throw.v 1705	bring 0.00231	put 0.00205	cast 0.00189	toss 0.00181	fling 0.00170	deliver 0.00169	hurl 0.00165	propel 0.00152	chuck 0.00152	discard 0.00147	focus 0.00147	shoot 0.00145	pitch 0.00144	punch 0.00141	place 0.00134	demand 0.00130	ask 0.00128	project 0.00126	fire 0.00123

Test context:
***************
throw.v	1706	21	he seemed to be in high spirits - in one shop a baby suit fell on his head and he started __throwing__ it about .
Contexts for target throwing are: ['xcompI_started', 'dobj_it', 'prt_about']
Contexts in vocabulary for target throwing are: ['xcompI_started', 'dobj_it', 'prt_about']
Top most similar embeddings: throwing 0.13876	chucking 0.11155	throw 0.10731	flinging 0.10695	hurling 0.10309	slinging 0.10187	shoving 0.10136	lobbing 0.10111	waggling 0.10039	tossing 0.10010

Generated lemmatized results
***************
GENERATED	throw.v 1706 ::: chuck;fling;hurl;sling;shove;lob;waggle;toss;manhandle;swat

Filtered results
***************
RANKED	throw.v 1706	chuck 0.11155	fling 0.10695	hurl 0.10309	toss 0.10010	put 0.09456	bring 0.08907	pitch 0.08180	discard 0.08152	punch 0.08150	cast 0.07960	propel 0.07838	shoot 0.07662	place 0.07656	ask 0.07617	deliver 0.07247	project 0.07196	fire 0.07114	demand 0.06581	focus 0.06533

Test context:
***************
throw.v	1707	11	cho proved too tough for the filipino , however , and __threw__ more gloves into the latter 's face than he had seen since leaving the philippines .
Contexts for target threw are: ['conjI_proved', 'dobj_gloves', 'prep:into_face', 'advcl_seen']
Contexts in vocabulary for target threw are: ['conjI_proved', 'dobj_gloves', 'prep:into_face', 'advcl_seen']
Top most similar embeddings: threw 0.05998	hurled 0.04494	flinging 0.04455	throwing 0.04446	thrown 0.04418	flung 0.04402	blew 0.04395	twirled 0.04345	tore 0.04291	swung 0.04200

Generated lemmatized results
***************
GENERATED	throw.v 1707 ::: hurl;fling;blow;twirl;tear;swing;wave;toss;shove;flap

Filtered results
***************
RANKED	throw.v 1707	hurl 0.04494	fling 0.04455	toss 0.04184	chuck 0.04051	propel 0.03674	punch 0.03521	fire 0.03499	cast 0.03392	bring 0.03356	put 0.03300	discard 0.03297	pitch 0.03282	place 0.03033	demand 0.03031	project 0.03009	shoot 0.02964	deliver 0.02758	ask 0.02626	focus 0.02247

Test context:
***************
throw.v	1708	13	i am of course open to new formats , but we should not __throw__ the baby out with the bath water .
Contexts for target throw are: ['nsubj_we', 'aux_should', 'neg_not', 'conjI_open', 'dobj_baby', 'prt_out', 'prep:with_water']
Contexts in vocabulary for target throw are: ['nsubj_we', 'aux_should', 'neg_not', 'conjI_open', 'dobj_baby', 'prt_out', 'prep:with_water']
Top most similar embeddings: throw 0.00799	throwing 0.00555	smother 0.00519	thrown 0.00504	wipe 0.00501	rinse 0.00486	drown 0.00485	rinsed 0.00482	re-fill 0.00475	manhandle 0.00474

Generated lemmatized results
***************
GENERATED	throw.v 1708 ::: smother;wipe;rinse;drown;manhandle;carry;toss;sterilize;wash;empty

Filtered results
***************
RANKED	throw.v 1708	toss 0.00470	chuck 0.00464	discard 0.00448	hurl 0.00445	fling 0.00442	put 0.00429	bring 0.00418	shoot 0.00404	cast 0.00365	punch 0.00346	propel 0.00337	place 0.00335	ask 0.00333	deliver 0.00322	fire 0.00322	pitch 0.00320	project 0.00297	demand 0.00282	focus 0.00255

Test context:
***************
throw.v	1709	5	now it 's time to __throw__ popsicles into the audience [ loud commotion ] and also introduce the other two members of our panel .
Contexts for target throw are: ['aux_to', 'infmodI_time', 'dobj_popsicles', 'prep:into_audience']
Contexts in vocabulary for target throw are: ['aux_to', 'infmodI_time', 'prep:into_audience']
Top most similar embeddings: throw 0.14341	hurl 0.10611	manhandle 0.09967	wheedle 0.09508	shoehorn 0.09361	sidle 0.09231	acclimatize 0.09194	gawp 0.09161	prussik 0.09129	contort 0.09064

Generated lemmatized results
***************
GENERATED	throw.v 1709 ::: hurl;manhandle;wheedle;shoehorn;sidle;acclimatize;gawp;prussik;contort;disgorge

Filtered results
***************
RANKED	throw.v 1709	hurl 0.10611	toss 0.08965	fling 0.08906	bring 0.08535	shoot 0.08528	propel 0.08395	chuck 0.08372	discard 0.08185	put 0.07948	punch 0.07516	cast 0.07307	deliver 0.07072	ask 0.06564	fire 0.06521	pitch 0.06517	focus 0.06045	place 0.05770	project 0.05577	demand 0.05127

Test context:
***************
throw.v	1710	8	he teased his sister until she cried , __threw__ the dog 's bone over the garden fence and frightened the cat by baying like a wolf .
Contexts for target threw are: ['conjI_teased', 'dobj_bone', 'prep:over_fence']
Contexts in vocabulary for target threw are: ['conjI_teased', 'dobj_bone', 'prep:over_fence']
Top most similar embeddings: threw 0.12486	thrown 0.10552	throwing 0.10485	hurled 0.10016	tossed 0.09976	chucked 0.09811	throw 0.09421	lobbing 0.09344	chewed 0.09210	jumped 0.09199

Generated lemmatized results
***************
GENERATED	throw.v 1710 ::: hurl;toss;chuck;lob;chew;jump;poke;yank;shove;jab

Filtered results
***************
RANKED	throw.v 1710	hurl 0.10016	toss 0.09976	chuck 0.09811	fling 0.08874	punch 0.07320	discard 0.07297	propel 0.06958	pitch 0.06944	put 0.06896	shoot 0.06832	fire 0.06818	project 0.06790	cast 0.06787	demand 0.06670	bring 0.06028	place 0.05961	ask 0.05932	deliver 0.05255	focus 0.04734

Test context:
***************
tremendous.a	1711	46	yes , this had happened : the pirates to windward and the pirates to leeward of the agra had found out , at one and the same moment , that the merchant captain they had lashed , and bullied , and tortured was a patient but __tremendous__ man .
Contexts for target tremendous are: ['amodI_man']
Contexts in vocabulary for target tremendous are: ['amodI_man']
Top most similar embeddings: tremendous 0.48042	fine-looking 0.42920	bald-headed 0.42159	wickedest 0.41405	cigarette-smoking 0.40988	incredible 0.40979	terrific 0.40972	great 0.40932	amazing 0.40742	right-minded 0.40705

Generated lemmatized results
***************
GENERATED	tremendous.a 1711 ::: wicked;incredible;terrific;great;amazing;enormous;phenomenal;wondeful;colossal;wonderful

Filtered results
***************
RANKED	tremendous.a 1711	terrific 0.40972	great 0.40932	enormous 0.40401	wonderful 0.39826	extraordinary 0.39440	huge 0.39396	marvellous 0.39143	terrible 0.37341	vast 0.34359

Test context:
***************
tremendous.a	1712	14	these occurrences are never reported to the general public because they would cause a __tremendous__ backlash against the present system .
Contexts for target tremendous are: ['amodI_backlash']
Contexts in vocabulary for target tremendous are: ['amodI_backlash']
Top most similar embeddings: tremendous 0.51792	enormous 0.42211	immense 0.41173	huge 0.41102	massive 0.41067	colossal 0.40576	terrific 0.40575	considerable 0.40090	ever-greater 0.39753	incredible 0.39541

Generated lemmatized results
***************
GENERATED	tremendous.a 1712 ::: enormous;immense;huge;massive;colossal;terrific;considerable;incredible;phenomenal;unwonted

Filtered results
***************
RANKED	tremendous.a 1712	enormous 0.42211	huge 0.41102	terrific 0.40575	terrible 0.37496	great 0.36974	marvellous 0.35544	vast 0.35326	extraordinary 0.35305	wonderful 0.34220

Test context:
***************
tremendous.a	1713	6	" it does not foster the __tremendous__ sense of accomplishment that a child receives when another person can read his writing , " she said .
Contexts for target tremendous are: ['amodI_sense']
Contexts in vocabulary for target tremendous are: ['amodI_sense']
Top most similar embeddings: tremendous 0.53828	terrific 0.43971	immense 0.43774	enormous 0.43626	incredible 0.42352	unwonted 0.41766	phenomenal 0.41294	unflagging 0.41090	great 0.40970	fantastic 0.40946

Generated lemmatized results
***************
GENERATED	tremendous.a 1713 ::: terrific;immense;enormous;incredible;unwonted;phenomenal;unflagging;great;fantastic;marvellous

Filtered results
***************
RANKED	tremendous.a 1713	terrific 0.43971	enormous 0.43626	great 0.40970	marvellous 0.40375	huge 0.40284	wonderful 0.40138	extraordinary 0.38483	terrible 0.37883	vast 0.35431

Test context:
***************
tremendous.a	1714	16	-- posted by jess on august 12 , 2003 12:23 pm i think this idea has __tremendous__ promise .
Contexts for target tremendous are: ['amodI_promise']
Contexts in vocabulary for target tremendous are: ['amodI_promise']
Top most similar embeddings: tremendous 0.53175	immense 0.45254	enormous 0.43524	terrific 0.42418	incredible 0.42251	great 0.42031	considerable 0.41510	amazing 0.41195	unwonted 0.41155	fantastic 0.40793

Generated lemmatized results
***************
GENERATED	tremendous.a 1714 ::: immense;enormous;terrific;incredible;great;considerable;amazing;unwonted;fantastic;phenomenal

Filtered results
***************
RANKED	tremendous.a 1714	enormous 0.43524	terrific 0.42418	great 0.42031	huge 0.40179	wonderful 0.40175	extraordinary 0.39886	marvellous 0.39594	terrible 0.37166	vast 0.36553

Test context:
***************
tremendous.a	1715	13	over the last several decades , both the town and county have seen __tremendous__ growth .
Contexts for target tremendous are: ['amodI_growth']
Contexts in vocabulary for target tremendous are: ['amodI_growth']
Top most similar embeddings: tremendous 0.53790	phenomenal 0.44564	immense 0.43890	enormous 0.43828	export-led 0.42913	phenominal 0.42454	incredible 0.42031	terrific 0.41891	ever-greater 0.41843	massive 0.41745

Generated lemmatized results
***************
GENERATED	tremendous.a 1715 ::: phenomenal;immense;enormous;phenominal;incredible;terrific;massive;considerable;huge;colossal

Filtered results
***************
RANKED	tremendous.a 1715	enormous 0.43828	terrific 0.41891	huge 0.41341	extraordinary 0.38564	great 0.37695	vast 0.37527	marvellous 0.36546	wonderful 0.36538	terrible 0.35001

Test context:
***************
tremendous.a	1716	21	organizational re-design we have seen the need in our transformation efforts to re-design some of our military organizations to harness the __tremendous__ power of new technologies and exploit the synergy of joint forces .
Contexts for target tremendous are: ['amodI_power']
Contexts in vocabulary for target tremendous are: ['amodI_power']
Top most similar embeddings: tremendous 0.54496	immense 0.45581	enormous 0.44773	terrific 0.43236	incredible 0.42756	ever-greater 0.42542	regulation-making 0.42125	awesome 0.42056	unwonted 0.41878	psychokinetic 0.41863

Generated lemmatized results
***************
GENERATED	tremendous.a 1716 ::: immense;enormous;terrific;incredible;awesome;unwonted;psychokinetic;phenomenal;unmatchable;prodigious

Filtered results
***************
RANKED	tremendous.a 1716	enormous 0.44773	terrific 0.43236	great 0.40604	huge 0.40153	extraordinary 0.39922	marvellous 0.39631	wonderful 0.38598	vast 0.38093	terrible 0.37226

Test context:
***************
tremendous.a	1717	19	listen to the kangaroo , to her low moans and sighs , she 's just so upset about her __tremendous__ thighs .
Contexts for target tremendous are: ['amodI_thighs']
Contexts in vocabulary for target tremendous are: ['amodI_thighs']
Top most similar embeddings: tremendous 0.48044	enormous 0.41890	immense 0.41376	huge 0.40737	massive 0.39218	terrific 0.39080	prehensile 0.38683	enourmous 0.38530	prodigious 0.38417	great 0.38198

Generated lemmatized results
***************
GENERATED	tremendous.a 1717 ::: enormous;immense;huge;massive;terrific;prehensile;enourmous;prodigious;great;sinewy

Filtered results
***************
RANKED	tremendous.a 1717	enormous 0.41890	huge 0.40737	terrific 0.39080	great 0.38198	vast 0.37196	wonderful 0.35293	marvellous 0.34621	terrible 0.34361	extraordinary 0.32073

Test context:
***************
tremendous.a	1718	1	the __tremendous__ mobilization of resources made the allied victory possible .
Contexts for target tremendous are: ['amodI_mobilization']
Contexts in vocabulary for target tremendous are: ['amodI_mobilization']
Top most similar embeddings: tremendous 0.50408	enormous 0.42632	immense 0.42507	massive 0.41564	ever-greater 0.40596	terrific 0.40070	huge 0.40033	considerable 0.39901	colossal 0.39217	prodigious 0.38553

Generated lemmatized results
***************
GENERATED	tremendous.a 1718 ::: enormous;immense;massive;terrific;huge;considerable;colossal;prodigious;incredible;phenomenal

Filtered results
***************
RANKED	tremendous.a 1718	enormous 0.42632	terrific 0.40070	huge 0.40033	vast 0.37528	great 0.36626	extraordinary 0.36177	marvellous 0.35901	wonderful 0.34925	terrible 0.33782

Test context:
***************
tremendous.a	1719	39	at the september groundbreaking for the new academic building at george mason university , larry czarda , vice president for operations , prince william campus said : the surge of economic development in the manassas/prince william county area offers __tremendous__ opportunities for growth and programming at the prince william campus as well as the potential for forging academic and research partnerships with our corporate neighbors .
Contexts for target tremendous are: ['amodI_opportunities']
Contexts in vocabulary for target tremendous are: ['amodI_opportunities']
Top most similar embeddings: tremendous 0.53224	immense 0.43710	enormous 0.43382	terrific 0.43037	fantastic 0.42891	incredible 0.41654	unparalled 0.41225	huge 0.40778	amazing 0.40628	considerable 0.40567

Generated lemmatized results
***************
GENERATED	tremendous.a 1719 ::: immense;enormous;terrific;fantastic;incredible;unparalled;huge;amazing;considerable;great

Filtered results
***************
RANKED	tremendous.a 1719	enormous 0.43382	terrific 0.43037	huge 0.40778	great 0.40556	wonderful 0.40328	marvellous 0.39741	vast 0.37942	extraordinary 0.37331	terrible 0.33901

Test context:
***************
tremendous.a	1720	3	there 's a __tremendous__ amount of information on the kitimat pipeline .
Contexts for target tremendous are: ['amodI_amount']
Contexts in vocabulary for target tremendous are: ['amodI_amount']
Top most similar embeddings: tremendous 0.55283	enormous 0.46170	immense 0.45638	terrific 0.44029	huge 0.43652	considerable 0.43641	incredible 0.43439	phenomenal 0.43273	phenominal 0.43215	prodigious 0.43050

Generated lemmatized results
***************
GENERATED	tremendous.a 1720 ::: enormous;immense;terrific;huge;considerable;incredible;phenomenal;phenominal;prodigious;enourmous

Filtered results
***************
RANKED	tremendous.a 1720	enormous 0.46170	terrific 0.44029	huge 0.43652	vast 0.40904	great 0.39995	extraordinary 0.39025	marvellous 0.38166	wonderful 0.37204	terrible 0.36303

Test context:
***************
true.a	1721	4	this much is basically __true__ , as it is founded on experimental observation .
Contexts for target true are: ['nsubj_much', 'cop_is', 'advmod_basically', 'rootI_*root*', 'punct_,', 'advcl_founded', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target true are: ['nsubj_much', 'cop_is', 'advmod_basically', 'rootI_*root*', 'punct_,', 'advcl_founded', 'punct_.']
Top most similar embeddings: true 0.00766	untrue 0.00612	tautological 0.00611	self-evident 0.00586	inconceivable 0.00582	unarguable 0.00571	unexceptionable 0.00563	debateable 0.00562	incontestable 0.00561	irrelevant 0.00556

Generated lemmatized results
***************
GENERATED	true.a 1721 ::: untrue;tautological;inconceivable;unarguable;unexceptionable;debateable;incontestable;irrelevant;unobjectionable;untypical

Filtered results
***************
RANKED	true.a 1721	unquestionable 0.00500	correct 0.00408	accurate 0.00377	verified 0.00320	genuine 0.00309	truth 0.00309	factual 0.00293	fact 0.00284	right 0.00278	real 0.00211	actual 0.00119

Test context:
***************
true.a	1722	10	but this narrative of the confederacy 's bravest is a __true__ inspiration , a balanced look at an ignored facet of american history .
Contexts for target true are: ['amodI_inspiration']
Contexts in vocabulary for target true are: ['amodI_inspiration']
Top most similar embeddings: true 0.51958	truer 0.38742	unalloyed 0.38714	truest 0.37910	geniune 0.37614	unfeigned 0.37273	delusive 0.37023	genuine 0.36976	indubitable 0.36745	many-sided 0.36355

Generated lemmatized results
***************
GENERATED	true.a 1722 ::: unalloyed;geniune;unfeigned;delusive;genuine;indubitable;real;mediumistic;monkish;fervid

Filtered results
***************
RANKED	true.a 1722	genuine 0.36976	real 0.36290	unquestionable 0.34992	accurate 0.31263	actual 0.31123	correct 0.30180	factual 0.29965	truth 0.28672	right 0.28618	verified 0.27226	fact 0.26766

Test context:
***************
true.a	1723	22	is this the reason for the equivocal bc04 response to the simple question about whether president bush thinks the allegations themselves are __true__ ?
Contexts for target true are: ['nsubj_themselves', 'cop_are', 'rcmodI_allegations']
Contexts in vocabulary for target true are: ['nsubj_themselves', 'cop_are', 'rcmodI_allegations']
Top most similar embeddings: true 0.10964	untrue 0.09801	culpable 0.09280	untrustworthy 0.09234	baseless 0.09152	inadmissible 0.09070	ill-founded 0.09066	groundless 0.09064	under-reported 0.08997	false 0.08937

Generated lemmatized results
***************
GENERATED	true.a 1723 ::: untrue;culpable;untrustworthy;baseless;inadmissible;groundless;false;unfounded;unsubstantiated;ungrounded

Filtered results
***************
RANKED	true.a 1723	genuine 0.08324	accurate 0.07589	correct 0.07387	verified 0.07127	unquestionable 0.06778	factual 0.06586	real 0.06579	right 0.05572	truth 0.05540	actual 0.05235	fact 0.04976

Test context:
***************
true.a	1724	13	truth is , therefore , useful because it is true , it is __true__ because it is useful .
Contexts for target true are: ['advmod_useful', 'advcl_true', 'punct_,', 'nsubj_it', 'cop_is', 'conjI_is', 'advcl_useful']
Contexts in vocabulary for target true are: ['advmod_useful', 'advcl_true', 'punct_,', 'nsubj_it', 'cop_is', 'conjI_is', 'advcl_useful']
Top most similar embeddings: true 0.00731	debateable 0.00623	questionable 0.00579	untrue 0.00565	arguable 0.00558	debatable 0.00552	truer 0.00538	counterintuitive 0.00537	understandable 0.00532	forgivable 0.00531

Generated lemmatized results
***************
GENERATED	true.a 1724 ::: debateable;questionable;untrue;arguable;debatable;counterintuitive;understandable;forgivable;undeniable;unsurprising

Filtered results
***************
RANKED	true.a 1724	unquestionable 0.00460	accurate 0.00428	correct 0.00395	genuine 0.00305	verified 0.00304	factual 0.00293	truth 0.00292	fact 0.00255	real 0.00239	right 0.00238	actual 0.00135

Test context:
***************
true.a	1725	72	joey is still with kelly his long time girlfriend of 10 years , but joey is joey and its very possible that he has a few dates on the side : ) question by anoymous i hear joey is married to a 41 year old woman named shirley this is her picture and she says she talks to joey online all the time and its a secret do you think this is __true__ ?
Contexts for target true are: ['nsubj_this', 'cop_is', 'ccompI_think']
Contexts in vocabulary for target true are: ['nsubj_this', 'cop_is', 'ccompI_think']
Top most similar embeddings: true 0.14417	untrue 0.11245	truer 0.10848	unforgiveable 0.10649	pardonable 0.10216	debateable 0.10104	x-file 0.10072	doable 0.10031	forgivable 0.09908	farfetched 0.09880

Generated lemmatized results
***************
GENERATED	true.a 1725 ::: untrue;unforgiveable;pardonable;debateable;doable;forgivable;farfetched;fixable;unneccesary;undisputable

Filtered results
***************
RANKED	true.a 1725	correct 0.08895	accurate 0.08511	genuine 0.08505	unquestionable 0.08420	right 0.07465	truth 0.07342	real 0.07266	factual 0.06658	verified 0.06607	fact 0.06422	actual 0.04870

Test context:
***************
true.a	1726	3	while it is __true__ that the majority of assaults are committed by males , it is not true that the majority of males are sexually violent - quote : victims bring it on themselves by the way they act or dress .
Contexts for target true are: ['mark_while', 'nsubj_it', 'cop_is', 'advclI_true', 'ccomp_committed']
Contexts in vocabulary for target true are: ['mark_while', 'nsubj_it', 'cop_is', 'advclI_true', 'ccomp_committed']
Top most similar embeddings: true 0.03777	arguable 0.02527	undeniable 0.02453	self-evident 0.02402	untrue 0.02387	probable 0.02386	indisputable 0.02380	plausible 0.02339	unarguable 0.02326	regrettable 0.02321

Generated lemmatized results
***************
GENERATED	true.a 1726 ::: arguable;undeniable;untrue;probable;indisputable;plausible;unarguable;regrettable;indubitable;conceivable

Filtered results
***************
RANKED	true.a 1726	unquestionable 0.02042	correct 0.01882	genuine 0.01797	accurate 0.01731	verified 0.01633	real 0.01456	fact 0.01440	truth 0.01439	factual 0.01438	right 0.01309	actual 0.00790

Test context:
***************
true.a	1727	27	then similarly , at least initially when she lacks beliefs in such contingent connections , she could at best be lucky if she discriminates whether c is __true__ .
Contexts for target true are: ['mark_whether', 'nsubj_c', 'cop_is', 'ccompI_discriminates']
Contexts in vocabulary for target true are: ['mark_whether', 'nsubj_c', 'cop_is']
Top most similar embeddings: true 0.13232	decidable 0.10220	invertible 0.10128	hermitian 0.09852	isomorphic 0.09767	non-empty 0.09661	derivable 0.09615	commutative 0.09609	untrue 0.09599	non-zero 0.09556

Generated lemmatized results
***************
GENERATED	true.a 1727 ::: decidable;invertible;hermitian;isomorphic;derivable;commutative;untrue;vectorizable;provable;false

Filtered results
***************
RANKED	true.a 1727	correct 0.08650	genuine 0.08586	accurate 0.08193	real 0.07228	unquestionable 0.07056	factual 0.06736	verified 0.06611	right 0.06514	truth 0.06132	fact 0.05566	actual 0.05163

Test context:
***************
true.a	1728	7	unfortunately for historians and naturalists , the __true__ identity of louisiana 's first sea monster may never be known .
Contexts for target true are: ['amodI_identity']
Contexts in vocabulary for target true are: ['amodI_identity']
Top most similar embeddings: true 0.52445	false 0.38991	truer 0.37695	undisputable 0.37090	judaeo-christian 0.37081	monistic 0.37072	self-defined 0.37070	self-professed 0.37004	truest 0.36911	judeo-christian 0.36898

Generated lemmatized results
***************
GENERATED	true.a 1728 ::: false;undisputable;monistic;egoic;pantheistic;countercultural;syncretistic;untrue;veridical;syncretic

Filtered results
***************
RANKED	true.a 1728	genuine 0.35996	real 0.35495	unquestionable 0.34107	correct 0.32967	accurate 0.32432	actual 0.32214	factual 0.30280	verified 0.29271	truth 0.28331	right 0.28119	fact 0.25339

Test context:
***************
true.a	1729	8	" let us see whether these opinions are __true__ .
Contexts for target true are: ['mark_whether', 'nsubj_opinions', 'cop_are', 'ccompI_see']
Contexts in vocabulary for target true are: ['mark_whether', 'nsubj_opinions', 'cop_are', 'ccompI_see']
Top most similar embeddings: true 0.06000	reconcilable 0.04748	veridical 0.04588	untrue 0.04555	ill-founded 0.04552	falsifiable 0.04458	unfounded 0.04413	valid 0.04412	derivable 0.04408	substitutable 0.04401

Generated lemmatized results
***************
GENERATED	true.a 1729 ::: reconcilable;veridical;untrue;falsifiable;unfounded;valid;derivable;substitutable;genuine;incommensurate

Filtered results
***************
RANKED	true.a 1729	genuine 0.04342	correct 0.04220	accurate 0.04078	real 0.03379	unquestionable 0.03262	right 0.03221	verified 0.03170	factual 0.03120	truth 0.02643	fact 0.02179	actual 0.02029

Test context:
***************
true.a	1730	4	but pastor ted 's __true__ genius lies in his organizational hierarchy , which ensures ideological rigidity even as it allows for individual expression .
Contexts for target true are: ['amodI_genius']
Contexts in vocabulary for target true are: ['amodI_genius']
Top most similar embeddings: true 0.52468	monkish 0.38803	self-professed 0.38654	chameleon-like 0.38392	many-sided 0.38381	truest 0.38324	tutelary 0.38280	down-home 0.38203	tragi-comic 0.37915	imperturbable 0.37596

Generated lemmatized results
***************
GENERATED	true.a 1730 ::: monkish;tutelary;imperturbable;undoubted;unselfconscious;fervid;geniune;indubitable;pianistic;unalloyed

Filtered results
***************
RANKED	true.a 1730	genuine 0.36430	real 0.35466	unquestionable 0.34811	accurate 0.31863	actual 0.31290	correct 0.30170	factual 0.29342	right 0.28044	truth 0.27114	verified 0.26871	fact 0.26119

Test context:
***************
truly.r	1731	5	the worm could have done __truly__ random ip generation and that would have allowed it to infect many more systems much faster .
Contexts for target truly are: ['advmodI_random']
Contexts in vocabulary for target truly are: ['advmodI_random']
Top most similar embeddings: truly 0.55174	truely 0.41674	ineffably 0.41041	beguilingly 0.39835	trully 0.39646	diabolically 0.39382	viscerally 0.39238	irredeemably 0.39178	unspeakably 0.39142	seemingly 0.39107

Generated lemmatized results
***************
GENERATED	truly.r 1731 ::: truely;ineffably;beguilingly;trully;diabolically;viscerally;irredeemably;unspeakably;seemingly;indescribably

Filtered results
***************
RANKED	truly.r 1731	really 0.38771	genuinely 0.38735	fully 0.35657	actually 0.35391	unquestionably 0.35185	definitely 0.34875	absolutely 0.34793	perfectly 0.33783	truthfully 0.33358	strictly 0.33051	honestly 0.32631	undoubtedly 0.32630	unequivocally 0.32096

Test context:
***************
truly.r	1732	10	in the end , it spend and performance must be __truly__ visible and transparent .
Contexts for target truly are: ['advmodI_visible']
Contexts in vocabulary for target truly are: ['advmodI_visible']
Top most similar embeddings: truly 0.49904	truely 0.40327	trully 0.39219	clearly 0.39218	ineffably 0.39164	viscerally 0.38337	tiresomely 0.38336	everlastingly 0.38220	horrifyingly 0.38204	still 0.38190

Generated lemmatized results
***************
GENERATED	truly.r 1732 ::: truely;trully;clearly;ineffably;viscerally;tiresomely;everlastingly;horrifyingly;still;genuinely

Filtered results
***************
RANKED	truly.r 1732	genuinely 0.38169	really 0.37187	actually 0.36543	fully 0.35995	unquestionably 0.35171	definitely 0.34670	perfectly 0.34222	unequivocally 0.33322	undoubtedly 0.33288	absolutely 0.32979	truthfully 0.31567	honestly 0.30894	strictly 0.30547

Test context:
***************
truly.r	1733	5	if all of this is __truly__ real -- if the energy body is a living , tangible phenomenon whose manipulation can directly affect the physical body -- its acceptance and integration into western culture would necessarily revolutionalize our views of reality .
Contexts for target truly are: ['advmodI_real']
Contexts in vocabulary for target truly are: ['advmodI_real']
Top most similar embeddings: truly 0.51585	ineffably 0.41433	truely 0.41007	heartbreakingly 0.40493	trully 0.40254	horrifyingly 0.39932	viscerally 0.39840	extrememly 0.39734	diabolically 0.39696	chillingly 0.39634

Generated lemmatized results
***************
GENERATED	truly.r 1733 ::: ineffably;truely;heartbreakingly;trully;horrifyingly;viscerally;extrememly;diabolically;chillingly;searingly

Filtered results
***************
RANKED	truly.r 1733	really 0.38507	unquestionably 0.37453	genuinely 0.37148	actually 0.36430	definitely 0.36346	absolutely 0.35902	fully 0.35042	undoubtedly 0.35038	perfectly 0.34532	truthfully 0.33587	unequivocally 0.33078	honestly 0.32479	strictly 0.29756

Test context:
***************
truly.r	1734	27	-- josh marshall ( april 05 , 2004 -- 07:06 pm edt / / link ) hats off to anthony shadid of the washington post for a __truly__ well-deserved pulitzer awarded today for coverage from iraq .
Contexts for target truly are: ['advmodI_well-deserved']
Contexts in vocabulary for target truly are: []
Top most similar embeddings: truly 1.00000	truely 0.81586	trully 0.78248	ineffably 0.77148	viscerally 0.76401	beguilingly 0.75936	jaw-droppingly 0.75447	genuinely 0.75326	searingly 0.75207	everlastingly 0.74876

Generated lemmatized results
***************
GENERATED	truly.r 1734 ::: truely;trully;ineffably;viscerally;beguilingly;genuinely;searingly;everlastingly;genuinly;really

Filtered results
***************
RANKED	truly.r 1734	genuinely 0.75326	really 0.74827	definitely 0.71331	actually 0.70693	fully 0.70015	unquestionably 0.69985	absolutely 0.69694	truthfully 0.68233	undoubtedly 0.67951	honestly 0.67771	perfectly 0.66770	unequivocally 0.66171	strictly 0.64233

Test context:
***************
truly.r	1735	5	intellectual property is also a __truly__ national practice and it does n't hurt to have bodies that can cover depositions and motions across the country .
Contexts for target truly are: ['advmodI_national']
Contexts in vocabulary for target truly are: ['advmodI_national']
Top most similar embeddings: truly 0.56810	truely 0.42189	genuinely 0.40373	trully 0.38814	ineffably 0.38802	essentially 0.38495	fearsomely 0.38169	searingly 0.38153	viscerally 0.37776	innately 0.37726

Generated lemmatized results
***************
GENERATED	truly.r 1735 ::: truely;genuinely;trully;ineffably;essentially;fearsomely;searingly;viscerally;innately;unabashedly

Filtered results
***************
RANKED	truly.r 1735	genuinely 0.40373	really 0.36690	fully 0.35849	definitely 0.35701	unquestionably 0.35586	actually 0.35137	absolutely 0.33266	unequivocally 0.33194	strictly 0.33125	undoubtedly 0.33003	truthfully 0.32872	honestly 0.32560	perfectly 0.31517

Test context:
***************
truly.r	1736	49	rudolph , santa , frosty , and of course the bright shining star of christmas , jesus , are all gathered in your home , as you and your loved ones ( including your four legged family members ) can , over and over again , enjoy watching what __truly__ is , " the ultimate dvd christmas pack " .
Contexts for target truly are: ['advmodI_is']
Contexts in vocabulary for target truly are: ['advmodI_is']
Top most similar embeddings: truly 0.52599	defintely 0.42354	truely 0.42267	proably 0.40858	trully 0.40398	viscerally 0.40189	really 0.40179	ineffably 0.40046	futhermore 0.39974	apprently 0.39506

Generated lemmatized results
***************
GENERATED	truly.r 1736 ::: defintely;truely;proably;trully;viscerally;really;ineffably;futhermore;apprently;beguilingly

Filtered results
***************
RANKED	truly.r 1736	really 0.40179	unquestionably 0.38434	actually 0.38111	definitely 0.38003	genuinely 0.37765	undoubtedly 0.36499	absolutely 0.35621	fully 0.34714	truthfully 0.34367	unequivocally 0.33907	honestly 0.33820	perfectly 0.33274	strictly 0.32857

Test context:
***************
truly.r	1737	6	first of all , ms. duval __truly__ loves springstead high school .
Contexts for target truly are: ['advmodI_loves']
Contexts in vocabulary for target truly are: ['advmodI_loves']
Top most similar embeddings: truly 0.53586	truely 0.44689	trully 0.42508	ineffably 0.41764	everlastingly 0.40605	genuinly 0.40512	really 0.40151	genuinely 0.40082	absolutly 0.39943	defintely 0.38987

Generated lemmatized results
***************
GENERATED	truly.r 1737 ::: truely;trully;ineffably;everlastingly;genuinly;really;genuinely;absolutly;defintely;viscerally

Filtered results
***************
RANKED	truly.r 1737	really 0.40151	genuinely 0.40082	absolutely 0.37862	actually 0.36318	definitely 0.35866	honestly 0.35180	truthfully 0.34406	unquestionably 0.34370	perfectly 0.33994	fully 0.33827	undoubtedly 0.33727	unequivocally 0.32472	strictly 0.30382

Test context:
***************
truly.r	1738	0	__truly__ family-friendly amendments to the flsa would bring more workers under its protection , reduce hours of work , expand minimum paid-leave times , and limit if not ban mandatory overtime .
Contexts for target truly are: ['advmodI_family-friendly']
Contexts in vocabulary for target truly are: ['advmodI_family-friendly']
Top most similar embeddings: truly 0.54778	truely 0.41661	ineffably 0.40215	genuinely 0.39780	unspeakably 0.39095	viscerally 0.39065	unabashedly 0.38553	innately 0.38310	indescribably 0.38284	stupendously 0.38179

Generated lemmatized results
***************
GENERATED	truly.r 1738 ::: truely;ineffably;genuinely;unspeakably;viscerally;unabashedly;innately;indescribably;stupendously;searingly

Filtered results
***************
RANKED	truly.r 1738	genuinely 0.39780	really 0.36826	absolutely 0.33916	unquestionably 0.33889	definitely 0.33618	fully 0.33480	perfectly 0.32964	unequivocally 0.32204	actually 0.31907	undoubtedly 0.31815	truthfully 0.31756	honestly 0.31680	strictly 0.29434

Test context:
***************
truly.r	1739	2	one cannot __truly__ understand something unless it is so , because understanding involves thinking from an underlying principle until a conclusion is reached .
Contexts for target truly are: ['advmodI_understand']
Contexts in vocabulary for target truly are: ['advmodI_understand']
Top most similar embeddings: truly 0.53872	truely 0.43581	trully 0.42571	really 0.41395	viscerally 0.39884	genuinely 0.39829	proably 0.39550	defintely 0.39291	futhermore 0.38784	fully 0.38688

Generated lemmatized results
***************
GENERATED	truly.r 1739 ::: truely;trully;really;viscerally;genuinely;proably;defintely;futhermore;fully;genuinly

Filtered results
***************
RANKED	truly.r 1739	really 0.41395	genuinely 0.39829	fully 0.38688	actually 0.37302	honestly 0.36456	definitely 0.36139	truthfully 0.35174	unquestionably 0.35090	perfectly 0.35034	absolutely 0.35033	undoubtedly 0.33760	unequivocally 0.33430	strictly 0.31083

Test context:
***************
truly.r	1740	0	__truly__ i understand and am in agreement with your thesis in this regard .
Contexts for target truly are: ['advmodI_i']
Contexts in vocabulary for target truly are: ['advmodI_i']
Top most similar embeddings: truly 0.50741	truely 0.42005	trully 0.41264	ineffably 0.40343	proably 0.39839	defintely 0.38984	absolutly 0.38590	beguilingly 0.38584	genuinly 0.38540	really 0.38460

Generated lemmatized results
***************
GENERATED	truly.r 1740 ::: truely;trully;ineffably;proably;defintely;absolutly;beguilingly;genuinly;really;probaly

Filtered results
***************
RANKED	truly.r 1740	really 0.38460	genuinely 0.37608	actually 0.37036	definitely 0.35022	absolutely 0.34968	unquestionably 0.34085	fully 0.33868	truthfully 0.33480	honestly 0.33457	perfectly 0.32920	undoubtedly 0.31882	unequivocally 0.31593	strictly 0.29880

Test context:
***************
vital.a	1741	40	a first negative social effect of retrenchment programmes is the redistribution of incentives given for voluntary retirement ; these tend to attract the most skilled employees who have the best chances for advancement in the private sector but who are __vital__ to the successful implementation of the reform .
Contexts for target vital are: ['nsubj_who', 'cop_are', 'conjI_tend', 'prep:to_implementation']
Contexts in vocabulary for target vital are: ['nsubj_who', 'cop_are', 'conjI_tend', 'prep:to_implementation']
Top most similar embeddings: vital 0.05077	crucial 0.04953	pre-disposed 0.04624	antipathetic 0.04556	essential 0.04445	critical 0.04426	averse 0.04400	amenable 0.04343	pivotal 0.04342	prone 0.04336

Generated lemmatized results
***************
GENERATED	vital.a 1741 ::: crucial;antipathetic;essential;critical;averse;amenable;pivotal;prone;attuned;susceptible

Filtered results
***************
RANKED	vital.a 1741	crucial 0.04953	essential 0.04445	critical 0.04426	indispensable 0.04168	important 0.03927	fundamental 0.03843	integral 0.03797	necessary 0.03484	requisite 0.03059

Test context:
***************
vital.a	1742	14	4. ) bone is being reabsorbed from the skeleton in order to keep the __vital__ blood level of calcium normal .
Contexts for target vital are: ['amodI_level']
Contexts in vocabulary for target vital are: ['amodI_level']
Top most similar embeddings: vital 0.46927	crucial 0.43503	essential 0.40343	fundamental 0.39450	all-important 0.39157	unprecendented 0.38654	fundemental 0.38583	approriate 0.38268	important 0.38035	economy-wide 0.37870

Generated lemmatized results
***************
GENERATED	vital.a 1742 ::: crucial;essential;fundamental;unprecendented;fundemental;approriate;important;critical;lowish;resonable

Filtered results
***************
RANKED	vital.a 1742	crucial 0.43503	essential 0.40343	fundamental 0.39450	important 0.38035	critical 0.37847	necessary 0.36663	indispensable 0.35083	requisite 0.34922	integral 0.32999

Test context:
***************
vital.a	1743	14	it says that it has been inundated by correspondence from clubs that risk losing __vital__ income that helps to keep their organisations alive .
Contexts for target vital are: ['amodI_income']
Contexts in vocabulary for target vital are: ['amodI_income']
Top most similar embeddings: vital 0.49479	crucial 0.42586	essential 0.41113	equivalised 0.39933	all-important 0.38851	superannuable 0.38836	non-taxable 0.38797	non-recurrent 0.38796	important 0.38443	valuable 0.38252

Generated lemmatized results
***************
GENERATED	vital.a 1743 ::: crucial;essential;equivalised;superannuable;important;valuable;unutilised;sufficent;undistributed;nonessential

Filtered results
***************
RANKED	vital.a 1743	crucial 0.42586	essential 0.41113	important 0.38443	fundamental 0.36561	necessary 0.35563	indispensable 0.35187	critical 0.34817	requisite 0.32916	integral 0.32863

Test context:
***************
vital.a	1744	8	( see resources. ) consulting them is a __vital__ piece of the selection process as you 'll get a good idea of what 's appropriate or historic for your area .
Contexts for target vital are: ['amodI_piece']
Contexts in vocabulary for target vital are: ['amodI_piece']
Top most similar embeddings: vital 0.51575	crucial 0.46611	essential 0.43807	important 0.42592	long-neglected 0.40559	pivotal 0.39675	indispensable 0.39423	all-important 0.39422	valuable 0.39281	invaluable 0.38963

Generated lemmatized results
***************
GENERATED	vital.a 1744 ::: crucial;essential;important;pivotal;indispensable;valuable;invaluable;fundemental;indispensible;inessential

Filtered results
***************
RANKED	vital.a 1744	crucial 0.46611	essential 0.43807	important 0.42592	indispensable 0.39423	fundamental 0.37613	critical 0.37447	necessary 0.34887	integral 0.34578	requisite 0.32726

Test context:
***************
vital.a	1745	13	information technology keeping out the wrong people tightened visa rules are slowing the __vital__ flow of professionals into the u.s. like a forlorn estragon from samuel beckett 's waiting for godot , zubair malik has been waiting .
Contexts for target vital are: ['amodI_flow']
Contexts in vocabulary for target vital are: ['amodI_flow']
Top most similar embeddings: vital 0.48483	crucial 0.41961	essential 0.41503	diffusional 0.39235	pulsatile 0.38695	geostrophic 0.38692	wind-driven 0.38530	seemless 0.38148	fully-developed 0.38057	important 0.37851

Generated lemmatized results
***************
GENERATED	vital.a 1745 ::: crucial;essential;diffusional;pulsatile;geostrophic;seemless;important;baroclinic;inviscid;nonessential

Filtered results
***************
RANKED	vital.a 1745	crucial 0.41961	essential 0.41503	important 0.37851	critical 0.36848	fundamental 0.36537	indispensable 0.35284	necessary 0.35238	integral 0.33552	requisite 0.32837

Test context:
***************
vital.a	1746	8	if anything , the mission understates its own __vital__ role in order to keep the focus on local churches and their missionaries , but those of us who are served so well by gfa can testify that we would not be anywhere near as effective without these skilled , dedicated yoke-fellows in the lord 's work .
Contexts for target vital are: ['amodI_role']
Contexts in vocabulary for target vital are: ['amodI_role']
Top most similar embeddings: vital 0.54994	crucial 0.49855	important 0.44953	essential 0.44537	pivotal 0.43653	fundemental 0.40390	fundamental 0.40333	client-facing 0.40215	invaluable 0.39966	all-important 0.39640

Generated lemmatized results
***************
GENERATED	vital.a 1746 ::: crucial;important;essential;pivotal;fundemental;fundamental;invaluable;valuable;indispensable;critical

Filtered results
***************
RANKED	vital.a 1746	crucial 0.49855	important 0.44953	essential 0.44537	fundamental 0.40333	indispensable 0.39356	critical 0.39226	integral 0.36915	necessary 0.35289	requisite 0.32091

Test context:
***************
vital.a	1747	4	replacing mideast oil is __vital__ , but not by substituting equally or more vulnerable domestic sources .
Contexts for target vital are: ['csubj_replacing', 'cop_is', 'rootI_*root*', 'punct_,', 'cc_but', 'conj_by', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target vital are: ['csubj_replacing', 'cop_is', 'rootI_*root*', 'punct_,', 'cc_but', 'conj_by', 'punct_.']
Top most similar embeddings: vital 0.00703	self-working 0.00646	debateable 0.00642	crucial 0.00635	unarguable 0.00625	essential 0.00614	counterintuitive 0.00594	unobjectionable 0.00569	debatable 0.00565	forearmed 0.00565

Generated lemmatized results
***************
GENERATED	vital.a 1747 ::: debateable;crucial;unarguable;essential;counterintuitive;unobjectionable;debatable;forearmed;fixable;incontestable

Filtered results
***************
RANKED	vital.a 1747	crucial 0.00635	essential 0.00614	important 0.00557	indispensable 0.00506	necessary 0.00498	critical 0.00451	fundamental 0.00393	integral 0.00351	requisite 0.00313

Test context:
***************
vital.a	1748	2	protest is __vital__ , but small , incessant protests are impotent. *** what do you do when the message wo n't get through ?
Contexts for target vital are: ['nsubj_protest', 'cop_is', 'rootI_*root*', 'punct_,', 'cc_but', 'conj_impotent', 'punct_.', 'dep_***']
Contexts in vocabulary for target vital are: ['nsubj_protest', 'cop_is', 'rootI_*root*', 'punct_,', 'cc_but', 'conj_impotent', 'punct_.', 'dep_***']
Top most similar embeddings: vital 0.00287	debateable 0.00287	unarguable 0.00275	useless 0.00271	unforgiveable 0.00271	pointless 0.00268	unbelieveable 0.00267	futile 0.00264	hillarious 0.00263	forgivable 0.00262

Generated lemmatized results
***************
GENERATED	vital.a 1748 ::: debateable;unarguable;useless;unforgiveable;pointless;unbelieveable;futile;hillarious;forgivable;unrepentant

Filtered results
***************
RANKED	vital.a 1748	crucial 0.00251	essential 0.00248	important 0.00237	indispensable 0.00226	necessary 0.00204	critical 0.00186	fundamental 0.00174	requisite 0.00148	integral 0.00126

Test context:
***************
vital.a	1749	14	hearing aid wearers were provided access to the telephone system because congress recognized the __vital__ nature of the phone system and the importance of everyone , including people with hearing loss , being able to access it .
Contexts for target vital are: ['amodI_nature']
Contexts in vocabulary for target vital are: ['amodI_nature']
Top most similar embeddings: vital 0.47966	essential 0.44326	crucial 0.43212	fundemental 0.41278	fundamental 0.40049	many-sided 0.39472	ever-evolving 0.39115	multi-jurisdictional 0.39101	far-ranging 0.39039	countercultural 0.38623

Generated lemmatized results
***************
GENERATED	vital.a 1749 ::: essential;crucial;fundemental;fundamental;countercultural;important;inessential;epileptogenic;protean;syncretic

Filtered results
***************
RANKED	vital.a 1749	essential 0.44326	crucial 0.43212	fundamental 0.40049	important 0.38457	critical 0.37429	indispensable 0.36527	integral 0.34699	necessary 0.33585	requisite 0.31867

Test context:
***************
vital.a	1750	7	" troops continue to work to provide __vital__ infrastructure throughout iraq .
Contexts for target vital are: ['amodI_infrastructure']
Contexts in vocabulary for target vital are: ['amodI_infrastructure']
Top most similar embeddings: vital 0.50922	crucial 0.44702	essential 0.44134	business-critical 0.40474	critical 0.39751	important 0.39077	mission-critical 0.38802	highly-developed 0.38771	demand-driven 0.38768	long-neglected 0.38672

Generated lemmatized results
***************
GENERATED	vital.a 1750 ::: crucial;essential;critical;important;necessary;fundemental;fundamental;indispensable;unutilised;approriate

Filtered results
***************
RANKED	vital.a 1750	crucial 0.44702	essential 0.44134	critical 0.39751	important 0.39077	necessary 0.38471	fundamental 0.38070	indispensable 0.37615	requisite 0.33769	integral 0.33567

Test context:
***************
worldwide.a	1751	14	china , india , latin america and the rest of asia will help grow __worldwide__ demand for electric power by 59 percent over the next two decades. ' the hydrogen economy is based on the idea that fuel cells that run on hydrogen have the potential to replace current energy systems in all forms , from vehicle propulsion to stationary power generation to mobile phone batteries .
Contexts for target worldwide are: ['amodI_demand']
Contexts in vocabulary for target worldwide are: ['amodI_demand']
Top most similar embeddings: worldwide 0.52342	world-wide 0.46050	worlwide 0.38923	nationwide 0.38366	nation-wide 0.38357	ever-rising 0.37315	countrywide 0.37143	global 0.37000	europe-wide 0.36698	continent-wide 0.36580

Generated lemmatized results
***************
GENERATED	worldwide.a 1751 ::: worlwide;nationwide;countrywide;global;statewide;unsustainably;widescale;multibillion;overseas;growing

Filtered results
***************
RANKED	worldwide.a 1751	global 0.37000	international 0.34112	universal 0.30682	total 0.30418

Test context:
***************
worldwide.a	1752	36	this has been , at times , merely an effort to gain greater public renown for their group or cause , but more troubling have been the groups seeking to push forward al-qaida 's agenda of __worldwide__ terror .
Contexts for target worldwide are: ['amodI_terror']
Contexts in vocabulary for target worldwide are: ['amodI_terror']
Top most similar embeddings: worldwide 0.49982	world-wide 0.44346	global 0.37273	nation-wide 0.36893	europe-wide 0.36815	continent-wide 0.36689	worlwide 0.36363	nationwide 0.36328	country-wide 0.36062	countrywide 0.35654

Generated lemmatized results
***************
GENERATED	worldwide.a 1752 ::: global;worlwide;nationwide;countrywide;globally;interethnic;international;intercommunal;unreasoning;statewide

Filtered results
***************
RANKED	worldwide.a 1752	global 0.37273	international 0.34555	universal 0.30583	total 0.29267

Test context:
***************
worldwide.a	1753	36	this is where the information revolution is happening -- and our share of these voices is smaller and smaller -- so america must find way to reach and engage a wider , younger , more diverse __worldwide__ audience .
Contexts for target worldwide are: ['amodI_audience']
Contexts in vocabulary for target worldwide are: ['amodI_audience']
Top most similar embeddings: worldwide 0.52462	world-wide 0.46918	nation-wide 0.40032	nationwide 0.38904	uk-wide 0.38345	worlwide 0.38136	country-wide 0.37889	global 0.37032	europe-wide 0.36839	cross-generational 0.36378

Generated lemmatized results
***************
GENERATED	worldwide.a 1753 ::: nationwide;worlwide;global;international;statewide;countrywide;wide;predominently;countywide;overseas

Filtered results
***************
RANKED	worldwide.a 1753	global 0.37032	international 0.35712	total 0.29876	universal 0.29520

Test context:
***************
worldwide.a	1754	17	that same thing could happen if we had a manhattan type project focusing on renewables , potential __worldwide__ markets , if we are the leader , and we have every reason to be the leader because we have the biggest problem .
Contexts for target worldwide are: ['amodI_markets']
Contexts in vocabulary for target worldwide are: ['amodI_markets']
Top most similar embeddings: worldwide 0.50952	world-wide 0.45559	nation-wide 0.38125	worlwide 0.38098	nationwide 0.37798	country-wide 0.37732	rapidly-growing 0.37728	global 0.37722	multibillion 0.37597	intra-regional 0.37398

Generated lemmatized results
***************
GENERATED	worldwide.a 1754 ::: worlwide;nationwide;global;multibillion;overseas;countrywide;international;statewide;oligopolistic;globally

Filtered results
***************
RANKED	worldwide.a 1754	global 0.37722	international 0.36236	universal 0.28563	total 0.27997

Test context:
***************
worldwide.a	1755	18	at the time of writing , the anti-semitic policies of the soviet union are also a subject of __worldwide__ protest .
Contexts for target worldwide are: ['amodI_protest']
Contexts in vocabulary for target worldwide are: ['amodI_protest']
Top most similar embeddings: worldwide 0.51205	world-wide 0.45967	nation-wide 0.41156	europe-wide 0.40720	nationwide 0.40126	continent-wide 0.38903	country-wide 0.38143	european-wide 0.38096	countrywide 0.37961	anti-poll 0.37903

Generated lemmatized results
***************
GENERATED	worldwide.a 1755 ::: nationwide;countrywide;worlwide;countywide;statewide;widescale;global;citywide;antiwar;interethnic

Filtered results
***************
RANKED	worldwide.a 1755	global 0.35857	international 0.34587	universal 0.30163	total 0.26778

Test context:
***************
worldwide.a	1756	11	he suggested building an experimental hypertext ' web ' for the __worldwide__ community of physicists who used cern and its publications .
Contexts for target worldwide are: ['amodI_community']
Contexts in vocabulary for target worldwide are: ['amodI_community']
Top most similar embeddings: worldwide 0.51930	world-wide 0.46893	nation-wide 0.38927	worlwide 0.38821	anglo-jewish 0.38326	europe-wide 0.38308	country-wide 0.38166	nationwide 0.38092	uk-wide 0.37870	continent-wide 0.37390

Generated lemmatized results
***************
GENERATED	worldwide.a 1756 ::: worlwide;nationwide;global;international;multiethnic;countrywide;wizarding;eritrean;pastoralist;statewide

Filtered results
***************
RANKED	worldwide.a 1756	global 0.37288	international 0.37147	universal 0.29729	total 0.28255

Test context:
***************
worldwide.a	1757	25	furthermore , non-residents can apply to be treated like a resident if his/her income from german sources is either at least 90 percent of his/her __worldwide__ income or his/her non-german source income is less than dm12,000 ( 24,000 for married couples ) .
Contexts for target worldwide are: ['amodI_income']
Contexts in vocabulary for target worldwide are: ['amodI_income']
Top most similar embeddings: worldwide 0.51272	world-wide 0.44890	worlwide 0.39814	per-capita 0.39284	nation-wide 0.38169	nationwide 0.37624	after-tax 0.37557	post-tax 0.37444	equivalised 0.37006	countrywide 0.36905

Generated lemmatized results
***************
GENERATED	worldwide.a 1757 ::: worlwide;nationwide;equivalised;countrywide;statewide;pretax;overseas;global;undistributed;globally

Filtered results
***************
RANKED	worldwide.a 1757	global 0.35028	international 0.32576	total 0.31719	universal 0.29516

Test context:
***************
worldwide.a	1758	27	after adding the separate partnerships of jlw ireland and jlw scotland , the combined total of our european and north american businesses represented approximately 75 % of __worldwide__ revenue in 1998 , up from approximately 63 % in 1997 .
Contexts for target worldwide are: ['amodI_revenue']
Contexts in vocabulary for target worldwide are: ['amodI_revenue']
Top most similar embeddings: worldwide 0.49909	world-wide 0.43893	worlwide 0.39652	nationwide 0.38756	nation-wide 0.37965	country-wide 0.36830	uk-wide 0.36310	second-quarter 0.36076	statewide 0.36024	globally 0.35987

Generated lemmatized results
***************
GENERATED	worldwide.a 1758 ::: worlwide;nationwide;statewide;globally;countrywide;global;overseas;pretax;multibillion;internationally

Filtered results
***************
RANKED	worldwide.a 1758	global 0.34986	international 0.32345	total 0.31361	universal 0.29109

Test context:
***************
worldwide.a	1759	20	osis also provides its users with direct , yet protected , access to the internet and its broad range of __worldwide__ open source information resources .
Contexts for target worldwide are: ['amodI_resources']
Contexts in vocabulary for target worldwide are: ['amodI_resources']
Top most similar embeddings: worldwide 0.49848	world-wide 0.45341	www.englishresources.co.uk 0.39030	worlwide 0.38945	nationwide 0.36622	uk-wide 0.36551	country-wide 0.36536	countrywide 0.36502	non-book 0.36464	curriculum-linked 0.36367

Generated lemmatized results
***************
GENERATED	worldwide.a 1759 ::: worlwide;nationwide;countrywide;global;statewide;ecodesign;largescale;lexicographical;globally;online

Filtered results
***************
RANKED	worldwide.a 1759	global 0.36145	international 0.33434	total 0.29457	universal 0.28738

Test context:
***************
worldwide.a	1760	38	like maypoles , wreaths too , as she points out , figure in may day as well as summer solstice celebrations. http://www.schooloftheseasons.com/signssummer.html [ link updated 5/20/02 ] [ added 26 may 2000 ] : this fun page collects __worldwide__ insights from people who write to waverly and comment on how summer begins for them .
Contexts for target worldwide are: ['amodI_insights']
Contexts in vocabulary for target worldwide are: ['amodI_insights']
Top most similar embeddings: worldwide 0.46805	world-wide 0.40439	nation-wide 0.36482	worlwide 0.36278	uk-wide 0.35122	nationwide 0.34874	global 0.34611	country-wide 0.34568	europe-wide 0.34428	industry-wide 0.34069

Generated lemmatized results
***************
GENERATED	worldwide.a 1760 ::: worlwide;nationwide;global;firsthand;anthroposophical;countrywide;unparalleled;comparitive;profound;historiographic

Filtered results
***************
RANKED	worldwide.a 1760	global 0.34611	international 0.31861	universal 0.28664	total 0.26658

Test context:
***************
yet.r	1761	13	conclusion for farmers , the benefits of trade agreements and increased exports have __yet__ to arrive .
Contexts for target yet are: ['advmodI_arrive']
Contexts in vocabulary for target yet are: ['advmodI_arrive']
Top most similar embeddings: yet 0.50530	apprently 0.37615	eventualy 0.37557	duely 0.37508	proably 0.37453	eventually 0.37264	still 0.37220	imediately 0.37220	soon 0.37111	co-incidentally 0.36998

Generated lemmatized results
***************
GENERATED	yet.r 1761 ::: apprently;eventualy;duely;proably;eventually;still;imediately;soon;bascially;finally

Filtered results
***************
RANKED	yet.r 1761	still 0.37220	however 0.35770	nevertheless 0.34300	already 0.34118	before 0.32288	lately 0.31625	hitherto 0.30010	but 0.28212	although 0.26774

Test context:
***************
yet.r	1762	0	__yet__ , believe it or not , the epa cites a lack of data for chronic toxicity .
Contexts for target yet are: ['advmodI_believe']
Contexts in vocabulary for target yet are: ['advmodI_believe']
Top most similar embeddings: yet 0.51199	still 0.40018	apprently 0.39485	nonetheless 0.39305	futhermore 0.39278	proably 0.39052	really 0.38514	however 0.38425	actaully 0.38288	certainly 0.38185

Generated lemmatized results
***************
GENERATED	yet.r 1762 ::: still;apprently;nonetheless;futhermore;proably;really;however;actaully;certainly;now

Filtered results
***************
RANKED	yet.r 1762	still 0.40018	however 0.38425	nevertheless 0.37473	already 0.35713	hitherto 0.32305	lately 0.31073	before 0.30820	but 0.28755	although 0.26736

Test context:
***************
yet.r	1763	7	the most dramatic changes in education are __yet__ to come .
Contexts for target yet are: ['nsubj_changes', 'cop_are', 'rootI_*root*', 'xcomp_come', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target yet are: ['nsubj_changes', 'cop_are', 'rootI_*root*', 'xcomp_come', 'punct_.']
Top most similar embeddings: likely 0.02508	yet 0.02488	afoot 0.02390	unlikely 0.02321	pre-announced 0.02290	unlikley 0.02188	welcome 0.02157	well-advised 0.02129	due 0.02096	unforgiveable 0.02057

Generated lemmatized results
***************
GENERATED	yet.r 1763 ::: likely;afoot;unlikely;unlikley;welcome;due;unforgiveable;uncommon;likley;grandfathered

Filtered results
***************
RANKED	yet.r 1763	nevertheless 0.01255	hitherto 0.01135	however 0.01015	lately 0.00967	before 0.00926	but 0.00812	still 0.00762	although 0.00686	already 0.00597

Test context:
***************
yet.r	1764	14	the effect was psychologically devastating to the finns , which had n't seen combat __yet__ .
Contexts for target yet are: ['advmodI_seen']
Contexts in vocabulary for target yet are: ['advmodI_seen']
Top most similar embeddings: yet 0.54085	proably 0.39846	apprently 0.39751	still 0.39723	standardly 0.39216	often 0.39194	heretofore 0.38843	intially 0.38841	futhermore 0.38802	alledgedly 0.38599

Generated lemmatized results
***************
GENERATED	yet.r 1764 ::: proably;apprently;still;standardly;often;heretofore;intially;futhermore;alledgedly;regretably

Filtered results
***************
RANKED	yet.r 1764	still 0.39723	already 0.38316	however 0.37356	nevertheless 0.35852	before 0.35826	hitherto 0.35094	lately 0.35027	but 0.28061	although 0.27386

Test context:
***************
yet.r	1765	5	warning of a force not __yet__ " broken " but " bent , " they are rushing to add 30,000 soldiers to the 482,000-strong active-duty force and increase the number of active brigades - from 33 when the iraq war began to 43 by 2006 , with another five possible by 2007 .
Contexts for target yet are: ['neg_not', 'depI_warning', "punct_''"]
Contexts in vocabulary for target yet are: ['neg_not', 'depI_warning']
Top most similar embeddings: yet 0.21006	neccessarily 0.18461	neccesarily 0.17236	falsifiable 0.16441	uncommonly 0.16156	representable 0.16130	withstanding 0.16125	infrequently 0.16111	fool-proof 0.16096	unfrequently 0.16089

Generated lemmatized results
***************
GENERATED	yet.r 1765 ::: neccessarily;neccesarily;falsifiable;uncommonly;representable;withstanding;infrequently;unfrequently;merely;fail

Filtered results
***************
RANKED	yet.r 1765	before 0.13703	hitherto 0.13626	lately 0.12661	already 0.12229	nevertheless 0.11456	still 0.11172	however 0.11169	although 0.11154	but 0.09958

Test context:
***************
yet.r	1766	20	those who understand the concepts , appear to have a better understanding of the theory behind modern comptrollership principles , __yet__ how to fully implement or to integrate into their daily operations is unclear. * given the unpredictability of number of cases during the year , there appears to be some reluctance to give up resources during the planning process .
Contexts for target yet are: ['advmodI_how']
Contexts in vocabulary for target yet are: ['advmodI_how']
Top most similar embeddings: yet 0.48654	just 0.38011	exactly 0.37016	even 0.36861	precisely 0.36625	so 0.35735	quite 0.35598	finally 0.34878	bascially 0.34738	perhaps 0.34713

Generated lemmatized results
***************
GENERATED	yet.r 1766 ::: just;exactly;even;precisely;so;quite;finally;bascially;perhaps;really

Filtered results
***************
RANKED	yet.r 1766	still 0.33532	already 0.32924	however 0.31875	nevertheless 0.30758	before 0.29788	lately 0.29592	hitherto 0.28836	but 0.27541	although 0.25758

Test context:
***************
yet.r	1767	3	we have not __yet__ found any mud/moo environments that handle nl processing .
Contexts for target yet are: ['advmodI_found']
Contexts in vocabulary for target yet are: ['advmodI_found']
Top most similar embeddings: yet 0.53089	apprently 0.39410	still 0.39305	proably 0.39220	also 0.38938	eventualy 0.38918	unfortuantely 0.38857	often 0.38717	nonetheless 0.38560	serendipitously 0.38520

Generated lemmatized results
***************
GENERATED	yet.r 1767 ::: apprently;still;proably;also;eventualy;unfortuantely;often;nonetheless;serendipitously;alledgedly

Filtered results
***************
RANKED	yet.r 1767	still 0.39305	however 0.38080	already 0.36993	nevertheless 0.36618	hitherto 0.34485	lately 0.33879	before 0.32139	but 0.27715	although 0.26916

Test context:
***************
yet.r	1768	0	__yet__ the result is an odd sentence that no one would say : ( a ) john saw mary with her best friend 's husband .
Contexts for target yet are: ['advmodI_result']
Contexts in vocabulary for target yet are: ['advmodI_result']
Top most similar embeddings: yet 0.51175	often 0.39109	nonetheless 0.38683	futhermore 0.38656	apprently 0.38637	certainly 0.38504	standardly 0.38363	proably 0.38351	probably 0.38140	dually 0.38045

Generated lemmatized results
***************
GENERATED	yet.r 1768 ::: often;nonetheless;futhermore;apprently;certainly;standardly;proably;probably;dually;surely

Filtered results
***************
RANKED	yet.r 1768	still 0.37914	however 0.37686	nevertheless 0.36310	already 0.34479	hitherto 0.32788	lately 0.31746	before 0.30331	but 0.28794	although 0.27785

Test context:
***************
yet.r	1769	33	march 8 , 2005 in ufos and aliens | permalink | comments ( 2 ) | trackback ( 0 ) march 02 , 2005 catching up is hard to do have i mentioned __yet__ that being a new father chews up a lot of one 's time ?
Contexts for target yet are: ['advmodI_mentioned']
Contexts in vocabulary for target yet are: ['advmodI_mentioned']
Top most similar embeddings: yet 0.51985	heretofore 0.39175	already 0.38895	parenthetically 0.38824	also 0.37821	previously 0.37818	even 0.37619	proably 0.37604	intially 0.37504	futhermore 0.37450

Generated lemmatized results
***************
GENERATED	yet.r 1769 ::: heretofore;already;parenthetically;also;previously;even;proably;intially;futhermore;often

Filtered results
***************
RANKED	yet.r 1769	already 0.38895	still 0.36089	however 0.36034	before 0.34724	nevertheless 0.34133	hitherto 0.33857	lately 0.33168	although 0.27404	but 0.26975

Test context:
***************
yet.r	1770	21	for those one or two doug/clooney worshippers out there , there 's yet hope : first , he 's not gone __yet__ [ repeat after me : " *end* of the fifth season...*end* of the fifth season ... " now , breathe...good... *uh , make that the end of february .
Contexts for target yet are: ['advmodI_repeat']
Contexts in vocabulary for target yet are: ['advmodI_repeat']
Top most similar embeddings: yet 0.50473	often 0.38186	proably 0.38146	then 0.37923	now 0.37775	apprently 0.37664	inexcusably 0.37084	certainly 0.37014	again 0.37010	futhermore 0.37004

Generated lemmatized results
***************
GENERATED	yet.r 1770 ::: often;proably;then;now;apprently;inexcusably;certainly;again;futhermore;everlastingly

Filtered results
***************
RANKED	yet.r 1770	however 0.36182	still 0.36033	already 0.34152	nevertheless 0.34151	before 0.31767	lately 0.30808	hitherto 0.30009	but 0.28256	although 0.26907

Test context:
***************
blow.n	1771	7	you can now deliver a heavy right-handed __blow__ with your fist upon his chin , or over his heart , which will render him unconscious .
Contexts for target blow are: ['det_a', 'amod_heavy', 'amod_right-handed', 'dobjI_deliver']
Contexts in vocabulary for target blow are: ['det_a', 'amod_heavy', 'amod_right-handed', 'dobjI_deliver']
Top most similar embeddings: blow 0.05868	blows 0.04777	blast 0.04247	hitter 0.04238	sidearm 0.04202	uppercut 0.04175	punch 0.04129	thump 0.04111	puncher 0.04096	slap 0.04078

Generated lemmatized results
***************
GENERATED	blow.n 1771 ::: blast;hitter;sidearm;uppercut;punch;thump;puncher;slap;wrench;blunderbuss

Filtered results
***************
RANKED	blow.n 1771	punch 0.04129	thump 0.04111	attack 0.03912	shock 0.03804	setback 0.03645	rebuff 0.03630	knock 0.03365	thrust 0.03284	clout 0.03253	strike 0.03181	wind 0.03096	hit 0.02978	criticism 0.02974	movement 0.02910	disaster 0.02810	air 0.02802	hair 0.02644	reverse 0.02497

Test context:
***************
blow.n	1772	21	i might merely offer this advice once more , comrades - in connection with every event in international life , every __blow__ , shove and even major flick dealt us , let us cut , so to speak , a notch in our memory .
Contexts for target blow are: ['det_every', 'conjI_comrades']
Contexts in vocabulary for target blow are: ['det_every', 'conjI_comrades']
Top most similar embeddings: blow 0.20794	blows 0.16596	comrade 0.15505	faction 0.15235	rebuff 0.15201	punch 0.15124	reprobate 0.15102	revolutionist 0.15090	inroad 0.14987	calumny 0.14976

Generated lemmatized results
***************
GENERATED	blow.n 1772 ::: comrade;faction;rebuff;punch;reprobate;revolutionist;inroad;calumny;turncoat;shout

Filtered results
***************
RANKED	blow.n 1772	rebuff 0.15201	punch 0.15124	attack 0.14686	setback 0.14569	strike 0.14152	thump 0.14085	clout 0.13873	movement 0.13872	shock 0.13627	knock 0.13514	wind 0.12927	thrust 0.12825	disaster 0.12651	criticism 0.12581	hit 0.12478	hair 0.12366	air 0.11603	reverse 0.11181

Test context:
***************
blow.n	1773	43	more than a decade after lyndon larouche first warned that a collapse of the speculative bubble in " derivatives " was inevitable , and it would crash the global financial system , the general motors/ford debt downgrade appears to have dealt a savage __blow__ to the main players in the derivatives bubble , global hedge funds , with as-yet unmeasurable consequences .
Contexts for target blow are: ['det_a', 'amod_savage', 'dobjI_dealt']
Contexts in vocabulary for target blow are: ['det_a', 'amod_savage', 'dobjI_dealt']
Top most similar embeddings: blow 0.15353	blows 0.11676	setback 0.09744	set-back 0.09723	head-butt 0.09676	rebuff 0.09662	slap 0.09640	rebuke 0.09632	sideswipe 0.09462	blast 0.09434

Generated lemmatized results
***************
GENERATED	blow.n 1773 ::: setback;rebuff;slap;rebuke;sideswipe;blast;mauling;headbutt;drubbing;stab

Filtered results
***************
RANKED	blow.n 1773	setback 0.09744	rebuff 0.09662	punch 0.08981	thump 0.08395	attack 0.08279	shock 0.08096	knock 0.07992	strike 0.07503	thrust 0.06978	wind 0.06950	disaster 0.06846	criticism 0.06826	clout 0.06712	hit 0.06481	reverse 0.05993	air 0.05871	movement 0.05701	hair 0.05554

Test context:
***************
blow.n	1774	14	i. national news newspapers suffer when local stores close local newspapers suffer a double __blow__ when giant chains like home depot or wal-mart come to town .
Contexts for target blow are: ['det_a', 'amod_double', 'dobjI_suffer']
Contexts in vocabulary for target blow are: ['det_a', 'amod_double', 'dobjI_suffer']
Top most similar embeddings: blow 0.13901	whammy 0.10928	setback 0.10265	blows 0.10235	set-back 0.09960	blow-out 0.09446	heart-attack 0.09399	nosebleed 0.09269	bollocking 0.09150	blast 0.09073

Generated lemmatized results
***************
GENERATED	blow.n 1774 ::: whammy;setback;nosebleed;bollocking;blast;headbutt;laceration;snub;rebuff;shock

Filtered results
***************
RANKED	blow.n 1774	setback 0.10265	rebuff 0.08996	shock 0.08893	attack 0.08420	punch 0.08311	knock 0.08064	thump 0.07933	disaster 0.07800	strike 0.07555	hit 0.07262	clout 0.06865	reverse 0.06716	thrust 0.06626	wind 0.06488	criticism 0.06466	hair 0.06376	movement 0.06076	air 0.05835

Test context:
***************
blow.n	1775	20	block frizz development one of the major complaints with air-drying strands is that when strands are not controlled by a __blow__ dryer they develop more frizz .
Contexts for target blow are: ['det_a', 'prep:byI_controlled', 'amod_dryer']
Contexts in vocabulary for target blow are: ['det_a', 'prep:byI_controlled']
Top most similar embeddings: blow 0.23386	blows 0.18280	gaar 0.17642	photocell 0.17554	blowtorch 0.17500	blast 0.17456	handwheel 0.17398	raditech 0.17273	wrench 0.17201	water-wheel 0.17143

Generated lemmatized results
***************
GENERATED	blow.n 1775 ::: gaar;photocell;blowtorch;blast;handwheel;raditech;wrench;dampener;magnetron;waterspout

Filtered results
***************
RANKED	blow.n 1775	punch 0.16434	setback 0.16433	shock 0.15768	thump 0.15318	rebuff 0.14847	attack 0.14777	wind 0.14694	knock 0.14656	movement 0.14311	strike 0.14264	clout 0.14009	thrust 0.13514	disaster 0.13332	hair 0.13000	hit 0.12974	criticism 0.12393	air 0.12291	reverse 0.11763

Test context:
***************
blow.n	1776	31	but in the final analysis , if we 're successful 99.9 percent of the time on defense , they only have to get through once in order to deal a devastating __blow__ .
Contexts for target blow are: ['det_a', 'amod_devastating', 'dobjI_deal']
Contexts in vocabulary for target blow are: ['det_a', 'amod_devastating', 'dobjI_deal']
Top most similar embeddings: blow 0.15416	blows 0.11633	setback 0.10284	set-back 0.09825	whammy 0.09396	rebuff 0.09119	drubbing 0.08884	snub 0.08847	double-whammy 0.08753	catastrophe 0.08747

Generated lemmatized results
***************
GENERATED	blow.n 1776 ::: setback;whammy;rebuff;drubbing;snub;catastrophe;headbutt;defeat;shock;sideswipe

Filtered results
***************
RANKED	blow.n 1776	setback 0.10284	rebuff 0.09119	shock 0.08617	attack 0.08043	punch 0.08025	knock 0.07654	strike 0.07538	disaster 0.07506	thump 0.07157	criticism 0.07002	clout 0.06950	hit 0.06637	thrust 0.06617	wind 0.06576	movement 0.05885	reverse 0.05844	hair 0.05483	air 0.05169

Test context:
***************
blow.n	1777	5	' this constitutes a strong __blow__ to the palestinian national consensus ' said the palestinian union of university teachers and employees ( puute ) .
Contexts for target blow are: ['det_a', 'amod_strong', 'dobjI_constitutes', 'prep:to_consensus']
Contexts in vocabulary for target blow are: ['det_a', 'amod_strong', 'dobjI_constitutes', 'prep:to_consensus']
Top most similar embeddings: blow 0.05303	counter-argument 0.04971	counterexample 0.04526	rebuff 0.04460	counterpoise 0.04455	counter-example 0.04437	stumbling-block 0.04434	setback 0.04382	set-back 0.04320	inroad 0.04316

Generated lemmatized results
***************
GENERATED	blow.n 1777 ::: counterexample;rebuff;counterpoise;setback;inroad;riposte;roadblock;rebuke;rebuttal;threat

Filtered results
***************
RANKED	blow.n 1777	rebuff 0.04460	setback 0.04382	attack 0.03639	shock 0.03578	strike 0.03434	thrust 0.03302	criticism 0.03296	thump 0.03260	punch 0.03233	knock 0.03227	clout 0.03033	wind 0.02989	movement 0.02919	disaster 0.02884	hit 0.02600	reverse 0.02425	air 0.02279	hair 0.02232

Test context:
***************
blow.n	1778	11	these bits have cutting edges that cut with light , breaking __blows__ while they rotate .
Contexts for target blows are: ['dobjI_breaking']
Contexts in vocabulary for target blows are: ['dobjI_breaking']
Top most similar embeddings: blows 0.46842	blow 0.38715	blowing 0.35114	clods 0.35059	winds 0.34843	punches 0.34351	splinters 0.34031	somersaults 0.33838	billows 0.33758	gashes 0.33676

Generated lemmatized results
***************
GENERATED	blow.n 1778 ::: blowing;clod;wind;punch;splinter;somersault;billow;gash;shatters;kneecap

Filtered results
***************
RANKED	blow.n 1778	wind 0.34843	punch 0.34351	thrust 0.32639	thump 0.32613	attack 0.32316	knock 0.32232	strike 0.32053	shock 0.31099	hit 0.30286	setback 0.30157	hair 0.29961	clout 0.29704	rebuff 0.29559	air 0.28025	disaster 0.27922	movement 0.27904	criticism 0.26476	reverse 0.24123

Test context:
***************
blow.n	1779	25	after 55 days and nights the general offensive and popular uprising , thanks to our overwhelming political and military strength , used three key strategic __blows__ in combination with attacks and uprisings in the cuu long ( mekong ) delta to put out of action over a million troops of the sai gon regime .
Contexts for target blows are: ['num_three', 'amod_key', 'amod_strategic', 'dobjI_used', 'prep:in_combination']
Contexts in vocabulary for target blows are: ['num_three', 'amod_key', 'amod_strategic', 'dobjI_used', 'prep:in_combination']
Top most similar embeddings: blows 0.02193	thrusts 0.01957	levers 0.01899	elements 0.01886	combinations 0.01796	slashes 0.01790	positions 0.01779	words/phrases 0.01772	strokes 0.01768	themes 0.01768

Generated lemmatized results
***************
GENERATED	blow.n 1779 ::: thrust;lever;element;combination;slash;position;stroke;theme;blast;posture

Filtered results
***************
RANKED	blow.n 1779	thrust 0.01957	punch 0.01752	shock 0.01664	attack 0.01641	strike 0.01589	wind 0.01535	movement 0.01460	criticism 0.01399	hit 0.01383	setback 0.01383	clout 0.01297	disaster 0.01257	knock 0.01251	hair 0.01192	thump 0.01177	rebuff 0.01107	air 0.01083	reverse 0.00895

Test context:
***************
blow.n	1780	9	he actually has some very valuable information on avoiding __blows__ , redirecting energy , and the propper way to kick someone 's feet out from under them .
Contexts for target blows are: ['dobjI_avoiding']
Contexts in vocabulary for target blows are: ['dobjI_avoiding']
Top most similar embeddings: blows 0.47861	blow 0.37850	short-circuits 0.35871	insults 0.35741	air-raids 0.35680	sniffles 0.35167	gunshots 0.35092	capsizes 0.35080	sandstorms 0.35068	dead-ends 0.35006

Generated lemmatized results
***************
GENERATED	blow.n 1780 ::: insult;sniffle;gunshot;capsizes;sandstorm;overload;slight;binge;gash;altercation

Filtered results
***************
RANKED	blow.n 1780	knock 0.34370	shock 0.34285	punch 0.34279	wind 0.33729	thump 0.33595	thrust 0.33005	attack 0.32582	rebuff 0.32537	strike 0.32162	disaster 0.31821	setback 0.31427	hair 0.30937	hit 0.30149	criticism 0.29640	movement 0.29597	air 0.28180	clout 0.27926	reverse 0.24721

Test context:
***************
board.n	1781	16	appointed by the cdfa , public members are chosen for their usefulness in helping the commodity __board__ carry out its purpose and to represent the public interest .
Contexts for target board are: ['det_the', 'nn_commodity', 'nsubjI_carry']
Contexts in vocabulary for target board are: ['det_the', 'nn_commodity', 'nsubjI_carry']
Top most similar embeddings: board 0.11055	boards 0.10138	aidb 0.08771	infracos 0.08718	bundesrechnungshof 0.08689	cmcu 0.08629	committe 0.08620	comittee 0.08605	glmca 0.08576	spcb 0.08537

Generated lemmatized results
***************
GENERATED	board.n 1781 ::: aidb;infracos;bundesrechnungshof;cmcu;committe;comittee;glmca;spcb;concessionaire;shipper

Filtered results
***************
RANKED	board.n 1781	committee 0.08376	panel 0.08107	management 0.07332	group 0.07257	motherboard 0.07202	directorate 0.07152	forum 0.06995	screen 0.06992	executive 0.06862	card 0.06751	organisation 0.06656	blackboard 0.06648	table 0.06570	administration 0.06537	whiteboard 0.06175	site 0.06119	game 0.05652	display 0.05296

Test context:
***************
board.n	1782	11	all content is reviewed by an advisory board made up of __board__ certified physicians and healthcare education experts with expertise in the areas that we cover on the network .
Contexts for target board are: ['prep:ofI_made']
Contexts in vocabulary for target board are: ['prep:ofI_made']
Top most similar embeddings: board 0.46236	boards 0.41591	chipboard 0.36537	hardboard 0.35801	plywood 0.35667	melamine 0.35552	fibreboard 0.35429	sub-panels 0.35290	plasterboard 0.35037	plexiglass 0.34995

Generated lemmatized results
***************
GENERATED	board.n 1782 ::: chipboard;hardboard;plywood;melamine;fibreboard;plasterboard;plexiglas;mountboard;wickerwork;paperboard

Filtered results
***************
RANKED	board.n 1782	panel 0.34238	committee 0.32488	executive 0.32458	directorate 0.31047	blackboard 0.30595	forum 0.30556	whiteboard 0.30394	motherboard 0.30116	card 0.29800	group 0.29314	screen 0.29077	organisation 0.28677	management 0.27711	table 0.27565	site 0.26968	administration 0.26420	game 0.26164	display 0.25536

Test context:
***************
board.n	1783	11	she then selected a student to write the solution on the __board__ .
Contexts for target board are: ['det_the', 'prep:onI_solution']
Contexts in vocabulary for target board are: ['det_the', 'prep:onI_solution']
Top most similar embeddings: board 0.24299	otherhand 0.21252	winline 0.19633	boards 0.19559	backburner 0.18815	copperbelt 0.18705	backbenches 0.18500	warpath 0.18123	quarter-deck 0.17868	off-chance 0.17791

Generated lemmatized results
***************
GENERATED	board.n 1783 ::: otherhand;winline;backburner;copperbelt;backbench;warpath;interweb;breadline;goalline;subfloor

Filtered results
***************
RANKED	board.n 1783	panel 0.16717	motherboard 0.16326	whiteboard 0.16121	committee 0.15740	table 0.15717	site 0.15545	forum 0.15350	card 0.15036	screen 0.14876	blackboard 0.14833	executive 0.14234	group 0.14190	management 0.13784	administration 0.13523	directorate 0.13020	game 0.12703	display 0.12598	organisation 0.12496

Test context:
***************
board.n	1784	34	frederick copleston believed that it was difficult to respond to hume and russell when they both refused to stick their necks out , ` if one refuses to even sit down at the chess __board__ and make a move , one cannot , of course , be checkmated. ' however , the argument is flawed in other ways .
Contexts for target board are: ['det_the', 'nn_chess', 'prep:atI_sit']
Contexts in vocabulary for target board are: ['det_the', 'nn_chess', 'prep:atI_sit']
Top most similar embeddings: board 0.13497	boards 0.10438	comittee 0.08852	bench 0.08543	chessboard 0.08417	dartboard 0.08397	teamsheet 0.08361	committee 0.08350	riph 0.08344	table 0.08302

Generated lemmatized results
***************
GENERATED	board.n 1784 ::: comittee;bench;chessboard;dartboard;teamsheet;committee;riph;table;foundery;desk

Filtered results
***************
RANKED	board.n 1784	committee 0.08350	table 0.08302	panel 0.08256	whiteboard 0.07856	motherboard 0.07695	forum 0.07530	screen 0.07351	executive 0.07286	site 0.07078	game 0.07075	blackboard 0.06888	group 0.06464	card 0.06241	directorate 0.06202	administration 0.06144	management 0.05899	organisation 0.05755	display 0.05643

Test context:
***************
board.n	1785	17	benefits to students- itp students will be able to access information quickly and effectively- an electronic bulletin __board__ format may be an effective strategy to encourage students to work with peers- articles on reserve can be accessed on-line 24 hours a day- course information including assignments and announcements will be readily accessible long-range benefit currently a large , central web site of information on educational interpreting does not exist .
Contexts for target board are: ['nnI_format']
Contexts in vocabulary for target board are: ['nnI_format']
Top most similar embeddings: board 0.45933	hardback/dustjacket 0.37918	boards 0.37879	acrobat/pdf 0.37619	shapefile 0.36573	question/answer 0.36383	gff 0.36366	dng 0.36306	dgn 0.35818	djvu 0.35748

Generated lemmatized results
***************
GENERATED	board.n 1785 ::: shapefile;gff;dng;dgn;djvu;mmcif;weblab;welmill;opendocument;framebuffer

Filtered results
***************
RANKED	board.n 1785	panel 0.33667	whiteboard 0.32617	committee 0.31827	blackboard 0.31552	forum 0.30850	table 0.30641	screen 0.30578	card 0.30575	game 0.30489	motherboard 0.29952	executive 0.29518	group 0.29391	organisation 0.28716	management 0.28600	directorate 0.28304	display 0.28199	site 0.27323	administration 0.26541

Test context:
***************
board.n	1786	20	to deal with these problems , the institutions should be streamlined ( by merging the national and local labour market __boards__ , for example ) , local case offices need to apply the rules consistently , sanctions on those who are not actively looking for work should be strengthened , and the activity guarantee should be of limited duration and offered only to those who need intensive programmes .
Contexts for target boards are: ['det_the', 'amod_national', 'nn_labour', 'nn_market', 'dobjI_merging']
Contexts in vocabulary for target boards are: ['det_the', 'amod_national', 'nn_labour', 'nn_market', 'dobjI_merging']
Top most similar embeddings: boards 0.02660	federations 0.02262	board 0.02179	committees 0.02105	inspectorates 0.02064	rigidities 0.02064	leaderships 0.02030	incumbents 0.02024	bureaucracies 0.02021	regulators 0.02019

Generated lemmatized results
***************
GENERATED	board.n 1786 ::: federation;committee;inspectorate;rigidity;leadership;incumbent;bureaucracy;regulator;force;forum

Filtered results
***************
RANKED	board.n 1786	committee 0.02105	forum 0.01996	administration 0.01912	organisation 0.01846	panel 0.01841	directorate 0.01788	group 0.01691	table 0.01668	executive 0.01603	site 0.01547	card 0.01540	management 0.01483	screen 0.01471	blackboard 0.01256	game 0.01248	display 0.01138	motherboard 0.01103	whiteboard 0.01066

Test context:
***************
board.n	1787	11	but on march 20 , the local elected officials on the __board__ of the capital area metropolitan planning organization ( campo ) , the arbiters of all central texas transportation planning , will be asked to include sh 130 in the official " transportation improvement program " or tip , without which nothing gets built anywhere .
Contexts for target board are: ['det_the', 'prep:onI_officials', 'prep:of_area']
Contexts in vocabulary for target board are: ['det_the', 'prep:onI_officials', 'prep:of_area']
Top most similar embeddings: board 0.11392	copperbelt 0.09523	sea-coast 0.08961	otherside 0.08914	otherhand 0.08838	quarter-deck 0.08805	outskirts 0.08607	right-hand-side 0.08590	boards 0.08511	upperside 0.08479

Generated lemmatized results
***************
GENERATED	board.n 1787 ::: copperbelt;otherside;otherhand;outskirt;upperside;side;fringe;periphery;committee;border

Filtered results
***************
RANKED	board.n 1787	committee 0.08277	panel 0.07646	executive 0.07191	directorate 0.06887	administration 0.06836	forum 0.06765	site 0.06479	screen 0.06460	table 0.06410	motherboard 0.06180	blackboard 0.06134	whiteboard 0.06123	management 0.06103	group 0.05871	display 0.05757	organisation 0.05524	card 0.05435	game 0.04934

Test context:
***************
board.n	1788	6	and open chat rooms and bulletin __boards__ for unfettered telling and listening , for the creation of a high tech electronic ( virtual ) " community " to bolster high touch solidarity among real folk .
Contexts for target boards are: ['nn_bulletin', 'conjI_rooms']
Contexts in vocabulary for target boards are: ['nn_bulletin', 'conjI_rooms']
Top most similar embeddings: boards 0.29295	board 0.21979	forums 0.18901	notice-boards 0.18676	noticeboards 0.18438	chatrooms 0.17239	panels 0.17220	listservs 0.17138	restrooms 0.17023	newsgroups 0.17010

Generated lemmatized results
***************
GENERATED	board.n 1788 ::: forum;noticeboards;chatroom;panel;listservs;restroom;newsgroups;guestbooks;washroom;whiteboards

Filtered results
***************
RANKED	board.n 1788	forum 0.18901	panel 0.17220	screen 0.15705	committee 0.15606	table 0.15199	blackboard 0.15199	whiteboard 0.14221	site 0.13679	card 0.13442	executive 0.13424	directorate 0.12950	management 0.12889	group 0.12833	administration 0.12797	game 0.12439	display 0.12039	motherboard 0.11992	organisation 0.11739

Test context:
***************
board.n	1789	5	among the semiconductor and pc __board__ manufacturers , both warranty claims and accruals have lately taken a downturn .
Contexts for target board are: ['nnI_manufacturers']
Contexts in vocabulary for target board are: ['nnI_manufacturers']
Top most similar embeddings: board 0.48295	boards 0.39607	paperboard 0.38270	sailcloth 0.36644	wallboard 0.36060	micro-chip 0.35914	aeroengine 0.35704	pwb 0.35585	crtc 0.35580	igu 0.35416

Generated lemmatized results
***************
GENERATED	board.n 1789 ::: paperboard;sailcloth;wallboard;aeroengine;pwb;crtc;igu;countertop;motherboard;panel

Filtered results
***************
RANKED	board.n 1789	motherboard 0.35186	panel 0.35171	whiteboard 0.31758	card 0.31498	committee 0.30484	screen 0.30032	executive 0.29569	forum 0.29482	blackboard 0.29224	table 0.28216	management 0.28193	site 0.27860	group 0.27585	game 0.27334	display 0.27108	directorate 0.26920	organisation 0.26387	administration 0.26306

Test context:
***************
board.n	1790	8	pam works with the livingston county development corporation __board__ to maintain and develop the main street chillicothe program .
Contexts for target board are: ['det_the', 'nn_livingston', 'nn_county', 'nn_development', 'nn_corporation', 'prep:withI_works']
Contexts in vocabulary for target board are: ['det_the', 'nn_livingston', 'nn_county', 'nn_development', 'nn_corporation', 'prep:withI_works']
Top most similar embeddings: board 0.01381	counci 0.01104	corporation 0.01096	council 0.01030	department 0.00990	office 0.00985	boards 0.00985	committee 0.00974	division 0.00951	rdc 0.00949

Generated lemmatized results
***************
GENERATED	board.n 1790 ::: counci;corporation;council;department;office;committee;division;rdc;directorate;coucil

Filtered results
***************
RANKED	board.n 1790	committee 0.00974	directorate 0.00948	executive 0.00913	group 0.00831	forum 0.00794	panel 0.00767	administration 0.00753	management 0.00741	site 0.00720	organisation 0.00694	card 0.00638	table 0.00621	motherboard 0.00618	blackboard 0.00613	screen 0.00601	game 0.00595	whiteboard 0.00580	display 0.00420

Test context:
***************
cap.n	1791	15	up to 50,000 people may have lost money in supposedly " low risk " split __cap__ funds .
Contexts for target cap are: ['nnI_funds']
Contexts in vocabulary for target cap are: ['nnI_funds']
Top most similar embeddings: cap 0.51001	caps 0.38317	rpp 0.37486	coif 0.37331	alsf 0.37325	eaggf 0.36157	dcms/wolfson 0.35943	seedcorn 0.35854	with-profit 0.35806	ring-fence 0.35783

Generated lemmatized results
***************
GENERATED	cap.n 1791 ::: rpp;coif;alsf;eaggf;seedcorn;nlcb;risingstars;rcsa;fifg;sportlot

Filtered results
***************
RANKED	cap.n 1791	capital 0.31571	top 0.31304	lid 0.29779	hat 0.29659	ceiling 0.29421	limit 0.29236	headdress 0.28514	pn 0.27635	restriction 0.27177	tip 0.26962	nozzle 0.25987

Test context:
***************
cap.n	1792	13	however , we treat reproductions of more up-to-date firearms , beginning with percussion __cap__ , muzzle-loading rifles such as the springfield rifles ( the originals of which would have been used in the american civil war ) , as firearms .
Contexts for target cap are: ['nn_percussion', 'prep:withI_beginning', 'punct_,', 'appos_rifles']
Contexts in vocabulary for target cap are: ['nn_percussion', 'prep:withI_beginning', 'punct_,', 'appos_rifles']
Top most similar embeddings: cap 0.04610	caps 0.04178	revolvers 0.04080	carbine 0.04078	carbines 0.04047	bassoons 0.04042	rifles 0.04033	muskets 0.04012	cowbells 0.03992	veni 0.03989

Generated lemmatized results
***************
GENERATED	cap.n 1792 ::: revolver;carbine;bassoon;rifle;musket;cowbell;veni;bugle;fanfare;maraca

Filtered results
***************
RANKED	cap.n 1792	hat 0.03300	headdress 0.02913	lid 0.02897	top 0.02780	ceiling 0.02727	capital 0.02723	pn 0.02663	nozzle 0.02522	tip 0.02427	restriction 0.02425	limit 0.02375

Test context:
***************
cap.n	1793	4	q : is the __cap__ on a recyclable plastic bottle also recyclable ?
Contexts for target cap are: ['nsubj_q', 'cop_is', 'det_the', 'nsubjI_recyclable', 'prep:on_bottle']
Contexts in vocabulary for target cap are: ['nsubj_q', 'cop_is', 'det_the', 'nsubjI_recyclable', 'prep:on_bottle']
Top most similar embeddings: cap 0.02343	infusor 0.01771	caps 0.01706	insulator 0.01702	label 0.01681	sealant 0.01648	nib 0.01642	bottle 0.01641	towbar 0.01641	gasket 0.01626

Generated lemmatized results
***************
GENERATED	cap.n 1793 ::: infusor;insulator;label;sealant;nib;bottle;towbar;gasket;casing;lid

Filtered results
***************
RANKED	cap.n 1793	lid 0.01619	top 0.01546	nozzle 0.01504	tip 0.01438	ceiling 0.01403	limit 0.01397	hat 0.01371	restriction 0.01333	headdress 0.01204	capital 0.01153	pn 0.01136

Test context:
***************
cap.n	1794	21	options involving existing user fees include raising the diesel differential by 1 cent or 6 cents per gallon , eliminating the __cap__ on the heavy-vehicle use tax , and adjusting the hvut rate schedule along with lifting the cap. new user-fee options include imposing a weight distance tax ( wdt ) and an axle-wdt .
Contexts for target cap are: ['det_the', 'dobjI_eliminating', 'prep:on_tax']
Contexts in vocabulary for target cap are: ['det_the', 'dobjI_eliminating', 'prep:on_tax']
Top most similar embeddings: cap 0.11743	caps 0.08872	impost 0.08485	disallowance 0.08410	imposts 0.08385	rebate 0.08249	over-dependence 0.08143	ring-fencing 0.08100	underspend 0.08008	draw-down 0.07992

Generated lemmatized results
***************
GENERATED	cap.n 1794 ::: impost;disallowance;rebate;underspend;deductibility;deutschmark;embargo;proscription;burden;middleman

Filtered results
***************
RANKED	cap.n 1794	limit 0.07793	ceiling 0.07735	restriction 0.07551	lid 0.07179	top 0.07016	hat 0.06596	capital 0.06399	nozzle 0.06358	tip 0.06345	headdress 0.06190	pn 0.06055

Test context:
***************
cap.n	1795	20	to discourage the commercialization of these community-based institutions , class sizes may be limited , and if necessary , a __cap__ could be set on the fees arranged between teachers and students .
Contexts for target cap are: ['det_a', 'nsubjpassI_set']
Contexts in vocabulary for target cap are: ['det_a', 'nsubjpassI_set']
Top most similar embeddings: cap 0.25752	caps 0.18112	gaar 0.18095	time-limit 0.18003	circlet 0.17974	lampshade 0.17646	taximeter 0.17473	jumper 0.17447	helmet 0.17403	visor 0.17316

Generated lemmatized results
***************
GENERATED	cap.n 1795 ::: gaar;circlet;lampshade;taximeter;jumper;helmet;visor;coif;togglebutton;restrictor

Filtered results
***************
RANKED	cap.n 1795	ceiling 0.17084	limit 0.16823	hat 0.16692	lid 0.16213	headdress 0.15709	nozzle 0.15035	restriction 0.14909	tip 0.13939	pn 0.13336	capital 0.13306	top 0.12773

Test context:
***************
cap.n	1796	21	blasting refers to the gratuitous nature of the hit , and is typified by the extreme proximity of the hitter 's __cap__ to the victim 's , and the extreme distance that the victim 's cap travels .
Contexts for target cap are: ['poss_hitter', 'prep:ofI_proximity']
Contexts in vocabulary for target cap are: ['prep:ofI_proximity']
Top most similar embeddings: cap 0.45312	caps 0.35566	ice-cap 0.33116	kopje 0.32755	icecap 0.32751	umbilicus 0.32739	nipple 0.32662	seacoast 0.32631	mineshafts 0.32491	ice-caps 0.32394

Generated lemmatized results
***************
GENERATED	cap.n 1796 ::: kopje;icecap;umbilicus;nipple;seacoast;mineshaft;blockhouse;estrela;epiglottis;standpipe

Filtered results
***************
RANKED	cap.n 1796	lid 0.30994	ceiling 0.30856	hat 0.30520	top 0.30147	limit 0.29735	nozzle 0.29622	capital 0.29288	tip 0.29055	headdress 0.28555	restriction 0.26676	pn 0.25958

Test context:
***************
cap.n	1797	21	he does not plan to change his mind on his rejection of the kyoto international climate treaty that would impose mandatory __caps__ on carbon dioxide emissions .
Contexts for target caps are: ['amod_mandatory', 'dobjI_impose', 'prep:on_emissions']
Contexts in vocabulary for target caps are: ['amod_mandatory', 'dobjI_impose', 'prep:on_emissions']
Top most similar embeddings: caps 0.12679	cap 0.11366	curbs 0.09674	levies 0.09494	time-limits 0.09257	quotas 0.09102	curfews 0.09027	moratoria 0.09019	proscriptions 0.08829	limits 0.08821

Generated lemmatized results
***************
GENERATED	cap.n 1797 ::: curb;levy;quota;curfew;moratorium;proscription;limit;restriction;embargo;restraint

Filtered results
***************
RANKED	cap.n 1797	limit 0.08821	restriction 0.08764	ceiling 0.07017	hat 0.06130	lid 0.05890	top 0.05839	capital 0.05629	pn 0.05606	nozzle 0.05586	headdress 0.05120	tip 0.04701

Test context:
***************
cap.n	1798	31	one chef stopped by to tell anna lee and the company 's phd food scientist , laurence lee , that he chops the smoked tofu and uses it to stuff mushroom __caps__ .
Contexts for target caps are: ['nn_mushroom', 'dobjI_stuff']
Contexts in vocabulary for target caps are: ['nn_mushroom', 'dobjI_stuff']
Top most similar embeddings: caps 0.25851	cap 0.20338	tarts 0.18355	punnets 0.18300	mushrooms 0.17797	cheerios 0.17790	dumplings 0.17771	tartlets 0.17731	rinds 0.17653	giblets 0.17601

Generated lemmatized results
***************
GENERATED	cap.n 1798 ::: tart;punnet;mushroom;cheerio;dumpling;tartlet;rind;giblet;hat;croquette

Filtered results
***************
RANKED	cap.n 1798	hat 0.17432	lid 0.16478	top 0.15620	headdress 0.15344	nozzle 0.14468	capital 0.13051	ceiling 0.12830	tip 0.12800	restriction 0.12012	limit 0.11379	pn 0.11318

Test context:
***************
cap.n	1799	17	a piece of cloth that involves a complicated design could require as many as ten sets of __cap__ .
Contexts for target cap are: ['prep:ofI_sets']
Contexts in vocabulary for target cap are: ['prep:ofI_sets']
Top most similar embeddings: cap 0.44039	caps 0.40637	earmuffs 0.35667	cleats 0.34542	doublets 0.34394	suspenders 0.34318	coveralls 0.34057	deflectors 0.34012	headbands 0.33869	armbands 0.33853

Generated lemmatized results
***************
GENERATED	cap.n 1799 ::: earmuff;cleat;doublet;suspender;coverall;deflector;headband;armband;stirrup;chainrings

Filtered results
***************
RANKED	cap.n 1799	hat 0.31894	lid 0.31401	top 0.30915	nozzle 0.30440	ceiling 0.29843	headdress 0.29699	restriction 0.29671	limit 0.29609	tip 0.28298	capital 0.27196	pn 0.26927

Test context:
***************
cap.n	1800	26	posted at 7:17am on may 25th 2005 by henrooo 0 stars 4. folks , i have just been told by bill gates that the dealer 's __cap__ is really an xbox 360 expansion device .
Contexts for target cap are: ['poss_dealer', 'nsubjI_device']
Contexts in vocabulary for target cap are: ['poss_dealer', 'nsubjI_device']
Top most similar embeddings: cap 0.23364	caps 0.18426	visor 0.16590	bandanna 0.15868	keycard 0.15833	carabiner 0.15807	kitbag 0.15656	muffler 0.15632	shelf 0.15621	ipod 0.15547

Generated lemmatized results
***************
GENERATED	cap.n 1800 ::: visor;bandanna;keycard;carabiner;kitbag;muffler;shelf;ipod;blazer;satchel

Filtered results
***************
RANKED	cap.n 1800	hat 0.15502	lid 0.15323	ceiling 0.14645	limit 0.13531	pn 0.13190	top 0.12790	nozzle 0.12762	headdress 0.12727	restriction 0.12366	tip 0.11974	capital 0.11852

Test context:
***************
change.v	1801	12	' as of september 1 , 2001 , the domain registrant was __changed__ once again to ' na. ' ' ' the administrative contact was tom mann .
Contexts for target changed are: ['nsubjpass_registrant', 'auxpass_was', 'rcmodI_september', 'advmod_again', 'prep:to_na']
Contexts in vocabulary for target changed are: ['auxpass_was', 'rcmodI_september', 'advmod_again']
Top most similar embeddings: changed 0.11937	altered 0.09244	revived 0.09005	moved 0.08956	postponed 0.08905	freshened 0.08860	shifted 0.08856	wrecked 0.08825	tweaked 0.08774	visted 0.08765

Generated lemmatized results
***************
GENERATED	change.v 1801 ::: alter;revive;move;postpone;freshen;shift;wreck;tweak;visted;raid

Filtered results
***************
RANKED	change.v 1801	alter 0.09244	move 0.08956	shift 0.08856	switch 0.08406	transform 0.08294	amend 0.07942	update 0.07748	modify 0.07320	adjust 0.07116	evolve 0.07089	vary 0.06555

Test context:
***************
change.v	1802	11	( as a general rule , point of view should not __change__ during a scene .
Contexts for target change are: ['prep:as_rule', 'punct_,', 'nsubj_point', 'aux_should', 'neg_not', 'rootI_*root*', 'prep:during_scene', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target change are: ['prep:as_rule', 'punct_,', 'nsubj_point', 'aux_should', 'neg_not', 'rootI_*root*', 'prep:during_scene', 'punct_.']
Top most similar embeddings: re-occur 0.00242	prevail 0.00230	reoccur 0.00229	demur 0.00228	occur 0.00226	suffice 0.00224	overemphasised 0.00224	divulged 0.00221	appear 0.00218	excusable 0.00217

Generated lemmatized results
***************
GENERATED	change.v 1802 ::: prevail;reoccur;demur;occur;suffice;overemphasise;divulge;appear;excusable;transpire

Filtered results
***************
RANKED	change.v 1802	vary 0.00197	alter 0.00187	adjust 0.00178	shift 0.00176	evolve 0.00163	switch 0.00158	modify 0.00153	move 0.00147	transform 0.00137	amend 0.00136	update 0.00132

Test context:
***************
change.v	1803	4	" that has to __change__ ultimately by getting people to embrace a new way of doing business .
Contexts for target change are: ['aux_to', 'xcompI_has', 'advmod_ultimately']
Contexts in vocabulary for target change are: ['aux_to', 'xcompI_has', 'advmod_ultimately']
Top most similar embeddings: change 0.11847	readjust 0.09507	re-assert 0.09352	actualize 0.09339	re-shape 0.09113	alter 0.09091	suceed 0.09081	determine 0.08957	predetermine 0.08947	reorient 0.08939

Generated lemmatized results
***************
GENERATED	change.v 1803 ::: readjust;actualize;alter;suceed;determine;predetermine;reorient;revalue;reinvent;redefine

Filtered results
***************
RANKED	change.v 1803	alter 0.09091	evolve 0.08740	transform 0.08327	shift 0.08046	modify 0.08026	move 0.07963	adjust 0.07868	amend 0.07537	switch 0.07294	vary 0.06877	update 0.05952

Test context:
***************
change.v	1804	22	there are , i believe , those at the tate who would be happy to see the hayward close , or to __change__ its identity so radically as to be barely recognisable as a space for serious art .
Contexts for target change are: ['aux_to', 'conjI_hayward', 'dobj_identity', 'advmod_radically']
Contexts in vocabulary for target change are: ['aux_to', 'conjI_hayward', 'dobj_identity', 'advmod_radically']
Top most similar embeddings: change 0.05379	alter 0.04564	rethink 0.04343	re-think 0.04228	re-structure 0.04185	redefine 0.04149	remodel 0.04118	re-define 0.04100	refashion 0.03998	reorganize 0.03997

Generated lemmatized results
***************
GENERATED	change.v 1804 ::: alter;rethink;redefine;remodel;refashion;reorganize;readjust;reinterpret;restructure;reformulate

Filtered results
***************
RANKED	change.v 1804	alter 0.04564	transform 0.03696	amend 0.03673	evolve 0.03600	modify 0.03595	shift 0.03575	adjust 0.03237	update 0.03085	switch 0.02993	vary 0.02898	move 0.02716

Test context:
***************
change.v	1805	0	__change__ the color of each piece of the pie on the chart by clicking once on square , then double click on the color square in the legend and selecting the appropriate color from the pattern tab color chart .
Contexts for target change are: ['rootI_*root*', 'dobj_color', 'prep:on_chart', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target change are: ['rootI_*root*', 'dobj_color', 'prep:on_chart', 'punct_.']
Top most similar embeddings: change 0.04991	vg/f 0.04564	over-write 0.04326	interpolates 0.04288	truncates 0.04268	tabulates 0.04224	annotates 0.04216	changed 0.04209	rescale 0.04178	colorize 0.04172

Generated lemmatized results
***************
GENERATED	change.v 1805 ::: interpolate;truncate;tabulate;annotate;rescale;colorize;vary;uncomment;borderwidth;toggle

Filtered results
***************
RANKED	change.v 1805	vary 0.04158	alter 0.04060	adjust 0.03970	modify 0.03813	shift 0.03586	transform 0.03440	amend 0.03372	move 0.03333	switch 0.03288	update 0.03237	evolve 0.03082

Test context:
***************
change.v	1806	35	[ back to top ] 6. read thermometer and record result after hearing the three rapid beeps that signal completion , remove thermometer from mouth and read temperature on display ; temperature reading will not __change__ while the power remains on .
Contexts for target change are: ['nsubj_reading', 'aux_will', 'neg_not', 'parataxisI_read', 'advcl_remains']
Contexts in vocabulary for target change are: ['nsubj_reading', 'aux_will', 'neg_not', 'parataxisI_read', 'advcl_remains']
Top most similar embeddings: change 0.02024	disappear 0.01885	diminish 0.01808	reveal 0.01805	alter 0.01805	recur 0.01797	changed 0.01766	redrawn 0.01757	reoccur 0.01756	disappoint 0.01741

Generated lemmatized results
***************
GENERATED	change.v 1806 ::: disappear;diminish;reveal;alter;recur;redrawn;reoccur;disappoint;invalidate;overwrite

Filtered results
***************
RANKED	change.v 1806	alter 0.01805	evolve 0.01722	vary 0.01616	transform 0.01577	update 0.01470	shift 0.01458	move 0.01431	amend 0.01417	modify 0.01413	switch 0.01406	adjust 0.01367

Test context:
***************
change.v	1807	15	the similarities to cultures are striking here , as cultures are also constantly evolving and __changing__ as dynamic changes take place in the component parts that comprise them .
Contexts for target changing are: ['conjI_evolving', 'advcl_take']
Contexts in vocabulary for target changing are: ['conjI_evolving', 'advcl_take']
Top most similar embeddings: changing 0.25355	evolving 0.21208	expanding 0.18637	shifting 0.18587	mutating 0.18302	altering 0.18256	reconfiguring 0.17799	diversifying 0.17500	re-evaluating 0.17386	reorganising 0.17295

Generated lemmatized results
***************
GENERATED	change.v 1807 ::: evolve;expand;shift;mutate;alter;reconfiguring;diversify;reorganise;readjust;fluctuate

Filtered results
***************
RANKED	change.v 1807	evolve 0.21208	shift 0.18587	alter 0.18256	update 0.16793	transform 0.16465	move 0.16129	adjust 0.16128	modify 0.16095	amend 0.15506	vary 0.15237	switch 0.14540

Test context:
***************
change.v	1808	26	but with marquee clients such as universal warranty on board and a focus on meeting and greeting all the industry players , that 's about to __change__ .
Contexts for target change are: ['aux_to', 'xcompI_about']
Contexts in vocabulary for target change are: ['aux_to', 'xcompI_about']
Top most similar embeddings: change 0.26842	re-shoot 0.20054	downshift 0.19636	re-activate 0.19555	re-draw 0.19499	readjust 0.19460	re-define 0.19258	re-impose 0.19105	refashion 0.19050	reorganize 0.19042

Generated lemmatized results
***************
GENERATED	change.v 1808 ::: downshift;readjust;refashion;reorganize;revalidate;uprate;alter;disaffiliate;remodel;industrialise

Filtered results
***************
RANKED	change.v 1808	alter 0.18844	move 0.18161	shift 0.17850	switch 0.17508	transform 0.17146	amend 0.17017	evolve 0.16895	modify 0.16774	adjust 0.16455	vary 0.15025	update 0.14692

Test context:
***************
change.v	1809	19	each subclass can define other applet parameters , and might even choose to ignore some of these or to __change__ the defaults listed here .
Contexts for target change are: ['aux_to', 'conjI_ignore', 'dobj_defaults']
Contexts in vocabulary for target change are: ['aux_to', 'conjI_ignore', 'dobj_defaults']
Top most similar embeddings: change 0.12201	reassign 0.09662	alter 0.09615	recalibrate 0.09610	override 0.09592	over-ride 0.09310	readjust 0.09242	ignore 0.09186	re-draw 0.09140	modify 0.09135

Generated lemmatized results
***************
GENERATED	change.v 1809 ::: reassign;alter;recalibrate;override;readjust;ignore;modify;reprogram;overwrite;retype

Filtered results
***************
RANKED	change.v 1809	alter 0.09615	modify 0.09135	adjust 0.08728	shift 0.08299	amend 0.08267	switch 0.07527	transform 0.07500	move 0.07230	evolve 0.07166	update 0.06860	vary 0.06793

Test context:
***************
change.v	1810	0	__changing__ your details to change your details with the store , just click on the registration/edit details button on the left of the main page .
Contexts for target changing are: ['partmodI_click', 'dobj_details']
Contexts in vocabulary for target changing are: ['partmodI_click', 'dobj_details']
Top most similar embeddings: changing 0.24510	altering 0.18886	updating 0.17879	giving 0.17752	adding 0.17669	divulging 0.17643	abbreviating 0.17426	retyping 0.17356	re-entering 0.17278	entering 0.17266

Generated lemmatized results
***************
GENERATED	change.v 1810 ::: alter;update;give;add;divulge;abbreviate;retyping;enter;intersperse;inputting

Filtered results
***************
RANKED	change.v 1810	alter 0.18886	update 0.17879	modify 0.17124	shift 0.16931	amend 0.16917	evolve 0.16263	transform 0.16124	adjust 0.16095	vary 0.15436	switch 0.15216	move 0.14738

Test context:
***************
charge.n	1811	34	in the event of a chemical spill , 3/4 's of the children know that they should " evacuate ( leave area ) as advised on radio , tv , or by people in __charge__ .
Contexts for target charge are: ['prep:inI_by']
Contexts in vocabulary for target charge are: ['prep:inI_by']
Top most similar embeddings: charge 0.46450	charges 0.34807	arrear 0.33423	1634 0.32964	surcharge 0.32878	countie 0.32833	1297 0.32781	fee-farm 0.32681	pupillari 0.32530	1278 0.32463

Generated lemmatized results
***************
GENERATED	charge.n 1811 ::: arrear;surcharge;countie;pupillari;contradistinction;charging;extremis;absentia;sheriffdom;instalment

Filtered results
***************
RANKED	charge.n 1811	fee 0.30922	indictment 0.30135	accusation 0.29623	payment 0.29482	tariff 0.28382	prosecution 0.28086	allegation 0.28065	issue 0.28035	expense 0.27846	command 0.27361	cost 0.27133	criticism 0.26878	control 0.26822	offence 0.26691	authority 0.26395	power 0.25123

Test context:
***************
charge.n	1812	17	some payments occurred " after the traffickers had been indicted by federal law enforcement agencies on drug __charges__ , in others while traffickers were under active investigation by these same agencies .
Contexts for target charges are: ['nn_drug', 'prep:onI_indicted']
Contexts in vocabulary for target charges are: ['nn_drug', 'prep:onI_indicted']
Top most similar embeddings: charges 0.28368	charge 0.20212	offences 0.17874	surcharges 0.17837	counts 0.17536	fines 0.17453	felonies 0.17141	offenses 0.16983	indictments 0.16918	allegations 0.16691

Generated lemmatized results
***************
GENERATED	charge.n 1812 ::: offence;surcharge;count;fine;felony;offense;indictment;allegation;fee;penalty

Filtered results
***************
RANKED	charge.n 1812	offence 0.17874	indictment 0.16918	allegation 0.16691	fee 0.16599	cost 0.16150	tariff 0.16015	accusation 0.15792	prosecution 0.14352	expense 0.13765	payment 0.13501	control 0.12381	issue 0.11957	authority 0.11555	criticism 0.11397	power 0.11115	command 0.10797

Test context:
***************
charge.n	1813	28	we study the methods and concepts that each writer uses to defend the cogency of legal , deliberative , or more generally political prudence against explicit or implicit __charges__ that practical thinking is merely a knack or form of cleverness .
Contexts for target charges are: ['amod_explicit', 'prep:againstI_prudence', 'rcmod_knack']
Contexts in vocabulary for target charges are: ['amod_explicit']
Top most similar embeddings: charges 0.48799	charge 0.39006	surcharges 0.36983	markups 0.35349	cutoffs 0.35233	accusations 0.34793	fees 0.34738	averments 0.34499	prohibitions 0.34325	surcharge 0.34266

Generated lemmatized results
***************
GENERATED	charge.n 1813 ::: surcharge;markup;cutoff;accusation;fee;averment;prohibition;encumbrance;proscription;allegation

Filtered results
***************
RANKED	charge.n 1813	accusation 0.34793	fee 0.34738	allegation 0.33963	tariff 0.32953	cost 0.32786	indictment 0.32505	offence 0.32053	payment 0.30957	control 0.30625	expense 0.30602	criticism 0.30602	command 0.30165	power 0.30146	prosecution 0.29858	authority 0.29287	issue 0.27282

Test context:
***************
charge.n	1814	12	this month its former president and financial-aid director were indicted on fraud __charges__ , including using federal grants to pay $ 5m in back loans and taking student aid for students not actually enrolled .
Contexts for target charges are: ['nn_fraud', 'prep:onI_indicted', 'punct_,']
Contexts in vocabulary for target charges are: ['nn_fraud', 'prep:onI_indicted', 'punct_,']
Top most similar embeddings: charges 0.14218	charge 0.09894	surcharges 0.09402	counts 0.08903	indictments 0.08668	offences 0.08632	felonies 0.08525	racketeering 0.08423	fines 0.08410	embezzlement 0.08386

Generated lemmatized results
***************
GENERATED	charge.n 1814 ::: surcharge;count;indictment;offence;felony;racketeering;fine;embezzlement;perjury;allegation

Filtered results
***************
RANKED	charge.n 1814	indictment 0.08668	offence 0.08632	allegation 0.08205	fee 0.07788	accusation 0.07613	prosecution 0.07537	cost 0.07502	expense 0.07081	tariff 0.06994	payment 0.06405	control 0.05864	issue 0.05508	authority 0.05383	command 0.05292	criticism 0.05263	power 0.05153

Test context:
***************
charge.n	1815	13	grass clippings can be brought out to the landfill at anytime for no __charge__ and may not be placed in city cans .
Contexts for target charge are: ['det_no', 'prep:forI_brought']
Contexts in vocabulary for target charge are: ['det_no', 'prep:forI_brought']
Top most similar embeddings: charge 0.24215	charges 0.19236	surcharge 0.18276	fee 0.18272	demurrage 0.17425	refund 0.17363	expiation 0.16952	outlay 0.16901	surcharges 0.16862	expences 0.16809

Generated lemmatized results
***************
GENERATED	charge.n 1815 ::: surcharge;fee;demurrage;refund;expiation;outlay;expences;disallowance;arraignment;encumbrance

Filtered results
***************
RANKED	charge.n 1815	fee 0.18272	offence 0.16392	payment 0.15509	accusation 0.15017	cost 0.14902	prosecution 0.14885	allegation 0.14652	expense 0.14476	indictment 0.14187	criticism 0.13666	control 0.13648	command 0.13280	power 0.12978	authority 0.12806	tariff 0.12748	issue 0.12563

Test context:
***************
charge.n	1816	21	besigye still faces trial for treason , and after that , the possible resumption of military trial for terrorism and weapon __charges__ .
Contexts for target charges are: ['nn_terrorism', 'prep:forI_resumption']
Contexts in vocabulary for target charges are: ['nn_terrorism']
Top most similar embeddings: charges 0.51655	charge 0.37904	surcharges 0.36459	fees 0.35258	offences 0.35104	accusations 0.35041	allegations 0.34578	taxes 0.34469	offenses 0.34275	felonies 0.34073

Generated lemmatized results
***************
GENERATED	charge.n 1816 ::: surcharge;fee;offence;accusation;allegation;tax;offense;felony;levy;bill

Filtered results
***************
RANKED	charge.n 1816	fee 0.35258	offence 0.35104	accusation 0.35041	allegation 0.34578	cost 0.33696	indictment 0.33459	tariff 0.33034	prosecution 0.32511	expense 0.31971	power 0.30731	payment 0.30418	control 0.30075	issue 0.29547	criticism 0.28327	authority 0.27494	command 0.26680

Test context:
***************
charge.n	1817	25	simply follow your credit card company 's reporting procedures , and aol will reimburse you up to $ 50 for any remaining liability for unauthorized __charges__ .
Contexts for target charges are: ['amod_unauthorized', 'prep:forI_liability']
Contexts in vocabulary for target charges are: ['amod_unauthorized', 'prep:forI_liability']
Top most similar embeddings: charges 0.26197	chargebacks 0.19669	surcharges 0.18372	charge 0.18029	non-arrival 0.17999	demurrage 0.17932	fees 0.17719	levies 0.17540	incumbrances 0.17492	infractions 0.17418

Generated lemmatized results
***************
GENERATED	charge.n 1817 ::: chargebacks;surcharge;demurrage;fee;levy;incumbrance;infraction;disbursement;outlay;disclosure

Filtered results
***************
RANKED	charge.n 1817	fee 0.17719	cost 0.17004	tariff 0.16494	expense 0.16287	accusation 0.16042	allegation 0.15999	payment 0.15910	offence 0.14890	indictment 0.14731	prosecution 0.14667	criticism 0.12769	control 0.12700	power 0.12481	authority 0.11844	command 0.11826	issue 0.11724

Test context:
***************
charge.n	1818	17	" ) detainees who are american citizens have the advantage of constitutional protections against being held without __charges__ , and have the right to legal counsel .
Contexts for target charges are: ['prep:withoutI_held']
Contexts in vocabulary for target charges are: ['prep:withoutI_held']
Top most similar embeddings: charges 0.51427	charge 0.44554	surcharges 0.37239	surcharge 0.35712	demurrage 0.35673	fines 0.35407	penalties 0.35153	accusations 0.35119	fee 0.34975	fees 0.34929

Generated lemmatized results
***************
GENERATED	charge.n 1818 ::: surcharge;demurrage;fine;penalty;accusation;fee;encumbrance;summons;levy;allegation

Filtered results
***************
RANKED	charge.n 1818	accusation 0.35119	fee 0.34975	allegation 0.33645	indictment 0.33409	payment 0.32251	cost 0.32135	tariff 0.31549	expense 0.30593	prosecution 0.30404	offence 0.29358	authority 0.29121	control 0.28888	power 0.28248	issue 0.28094	criticism 0.27682	command 0.25424

Test context:
***************
charge.n	1819	1	the __charge__ for noncredit courses or for audited courses is the same as for credit courses .
Contexts for target charge are: ['det_the', 'nsubjI_same', 'prep:for_courses', 'cc_or', 'conj_for', 'conj:for_courses']
Contexts in vocabulary for target charge are: ['det_the', 'nsubjI_same', 'prep:for_courses', 'cc_or', 'conj_for', 'conj:for_courses']
Top most similar embeddings: charge 0.01161	charges 0.00942	fee 0.00846	re-sits 0.00845	fees 0.00831	stipend 0.00820	remission 0.00799	rent 0.00784	ineligibility 0.00782	admissions@londonmet.ac.uk 0.00781

Generated lemmatized results
***************
GENERATED	charge.n 1819 ::: fee;stipend;remission;rent;ineligibility;precept;summons;coursework;refund;shortlisting

Filtered results
***************
RANKED	charge.n 1819	fee 0.00846	payment 0.00736	tariff 0.00711	cost 0.00701	offence 0.00668	expense 0.00665	prosecution 0.00607	command 0.00545	indictment 0.00544	criticism 0.00540	issue 0.00530	allegation 0.00524	accusation 0.00520	control 0.00510	authority 0.00496	power 0.00487

Test context:
***************
charge.n	1820	8	eleven cira members have been convicted of criminal __charges__ and others are awaiting trial .
Contexts for target charges are: ['amod_criminal', 'prep:ofI_convicted', 'cc_and', 'conj_others']
Contexts in vocabulary for target charges are: ['amod_criminal', 'prep:ofI_convicted', 'cc_and', 'conj_others']
Top most similar embeddings: charges 0.05664	felonies 0.04826	gbh 0.04564	perjury 0.04470	offences 0.04437	racketeering 0.04429	misdemeanor 0.04360	misdemeanors 0.04352	embezzlement 0.04321	affray 0.04306

Generated lemmatized results
***************
GENERATED	charge.n 1820 ::: felony;gbh;perjury;offence;racketeering;misdemeanor;embezzlement;affray;trafficker;karadzic

Filtered results
***************
RANKED	charge.n 1820	offence 0.04437	prosecution 0.03872	indictment 0.03855	accusation 0.03749	allegation 0.03742	tariff 0.03448	fee 0.03378	authority 0.03347	cost 0.03156	expense 0.02875	payment 0.02826	power 0.02811	control 0.02624	criticism 0.02578	command 0.02506	issue 0.02502

Test context:
***************
execution.n	1821	7	may 13 , 2002 - dunn 's __execution__ , scheduled for may 14th , was stayed by the fifth circuit pending resolution of the appeal .
Contexts for target execution are: ['num_2002', 'punct_-', 'poss_dunn', 'apposI_13', 'punct_,', 'partmod_scheduled']
Contexts in vocabulary for target execution are: ['num_2002', 'punct_-', 'poss_dunn', 'apposI_13', 'punct_,', 'partmod_scheduled']
Top most similar embeddings: execution 0.00982	eurocon 0.00909	sep/oct 0.00833	july/august 0.00817	jul/aug 0.00817	mar/apr 0.00816	tosca 0.00805	july-september 0.00801	alpamayo 0.00801	aconcagua 0.00796

Generated lemmatized results
***************
GENERATED	execution.n 1821 ::: eurocon;tosca;alpamayo;aconcagua;huascaran;documenta;andromache;pagliacci;march;sept

Filtered results
***************
RANKED	execution.n 1821	completion 0.00722	performance 0.00636	implementation 0.00604	production 0.00598	killing 0.00596	running 0.00582	death 0.00574	fulfilment 0.00572	administration 0.00552	discharge 0.00541	enforcement 0.00536	transaction 0.00523	actualisation 0.00499	application 0.00480	method 0.00458

Test context:
***************
execution.n	1822	26	no. 19504 regents action date : december 20 , 2001 action : application for consent order granted ; penalty agreed upon : 2 year suspension , __execution__ of suspension stayed , probation 2 years , $ 5,000 fine .
Contexts for target execution are: ['nsubjI_stayed', 'prep:of_suspension']
Contexts in vocabulary for target execution are: ['nsubjI_stayed', 'prep:of_suspension']
Top most similar embeddings: execution 0.20621	timing 0.14629	executions 0.14513	remainder 0.14473	sentence 0.14447	postponement 0.14203	imposition 0.14147	enactment 0.14131	invocation 0.14126	promulgation 0.14110

Generated lemmatized results
***************
GENERATED	execution.n 1822 ::: timing;remainder;sentence;postponement;imposition;enactment;invocation;promulgation;offender;brunt

Filtered results
***************
RANKED	execution.n 1822	implementation 0.13583	completion 0.13552	performance 0.13222	enforcement 0.13175	discharge 0.13136	administration 0.12930	fulfilment 0.12317	production 0.12217	death 0.12060	application 0.12008	killing 0.11933	actualisation 0.11779	transaction 0.11188	method 0.10993	running 0.10398

Test context:
***************
execution.n	1823	12	more broadly , it provides context for the question of what immediate __executions__ are worth to investors .
Contexts for target executions are: ['det_what', 'amod_immediate', 'prep:ofI_question']
Contexts in vocabulary for target executions are: ['det_what', 'amod_immediate', 'prep:ofI_question']
Top most similar embeddings: executions 0.10647	reprisals 0.09095	punishment 0.08961	reparations 0.08910	retaliation 0.08586	reparation 0.08469	retribution 0.08431	proscriptions 0.08378	killings 0.08342	punishments 0.08326

Generated lemmatized results
***************
GENERATED	execution.n 1823 ::: reprisal;punishment;reparation;retaliation;retribution;proscription;killing;restitution;deportation;gassing

Filtered results
***************
RANKED	execution.n 1823	killing 0.08342	death 0.07516	actualisation 0.07447	fulfilment 0.06891	method 0.06837	enforcement 0.06820	implementation 0.06619	transaction 0.06501	discharge 0.06334	completion 0.06241	performance 0.06121	application 0.06103	administration 0.06101	production 0.05847	running 0.05032

Test context:
***************
execution.n	1824	15	especially in a legislature such as the english , in which the responsibility for the __execution__ of the laws is and must be felt .
Contexts for target execution are: ['det_the', 'prep:forI_responsibility', 'prep:of_laws']
Contexts in vocabulary for target execution are: ['det_the', 'prep:forI_responsibility', 'prep:of_laws']
Top most similar embeddings: execution 0.13655	promulgation 0.10286	perpetration 0.10268	implementation 0.10069	constitutionality 0.09769	non-observance 0.09565	finalization 0.09555	imposition 0.09316	operationalisation 0.09303	enactment 0.09290

Generated lemmatized results
***************
GENERATED	execution.n 1824 ::: promulgation;perpetration;implementation;constitutionality;finalization;imposition;operationalisation;enactment;permissibility;enforcement

Filtered results
***************
RANKED	execution.n 1824	implementation 0.10069	enforcement 0.09166	fulfilment 0.08853	administration 0.08639	killing 0.08061	completion 0.07992	actualisation 0.07828	application 0.07649	discharge 0.07640	death 0.07278	performance 0.07162	production 0.06914	transaction 0.06669	running 0.05960	method 0.05831

Test context:
***************
execution.n	1825	34	found is set this way when the for loop exits ; inside the execution of the loop , found is not modified by the for statement , although it may be changed by the __execution__ of other statements within the loop body .
Contexts for target execution are: ['det_the', 'prep:byI_changed', 'prep:of_statements']
Contexts in vocabulary for target execution are: ['det_the', 'prep:byI_changed', 'prep:of_statements']
Top most similar embeddings: execution 0.12275	finalization 0.09960	promulgation 0.09329	enactment 0.09207	decipherment 0.09152	finalisation 0.08850	imposition 0.08815	invocation 0.08807	inculcation 0.08654	bucketload 0.08611

Generated lemmatized results
***************
GENERATED	execution.n 1825 ::: finalization;promulgation;enactment;decipherment;finalisation;imposition;invocation;inculcation;bucketload;declassification

Filtered results
***************
RANKED	execution.n 1825	implementation 0.08585	completion 0.08216	fulfilment 0.08155	actualisation 0.08054	production 0.07421	administration 0.07407	application 0.07260	transaction 0.06964	performance 0.06912	killing 0.06866	enforcement 0.06847	death 0.06698	method 0.06602	discharge 0.06372	running 0.06060

Test context:
***************
execution.n	1826	7	of course , this approach requires good __execution__ including strong encryption and authentication , and secure key management .
Contexts for target execution are: ['amod_good', 'dobjI_requires', 'prep:including_encryption']
Contexts in vocabulary for target execution are: ['amod_good', 'dobjI_requires']
Top most similar embeddings: execution 0.23585	recompilation 0.17326	substantiation 0.17309	collimation 0.16814	invocation 0.16688	explainations 0.16657	airmanship 0.16642	acclimatization 0.16618	penmanship 0.16615	reapplication 0.16579

Generated lemmatized results
***************
GENERATED	execution.n 1826 ::: recompilation;substantiation;collimation;invocation;explainations;airmanship;acclimatization;penmanship;reapplication;footwork

Filtered results
***************
RANKED	execution.n 1826	implementation 0.16286	completion 0.16037	enforcement 0.15374	performance 0.15164	fulfilment 0.14944	administration 0.14682	discharge 0.14561	application 0.14366	production 0.13711	actualisation 0.13644	method 0.13218	death 0.13111	killing 0.13094	transaction 0.12923	running 0.11092

Test context:
***************
execution.n	1827	7	but a new survey shows that the __execution__ of ms. tucker and the resulting debate led some residents of the lone star state to have second thoughts about capital punishment .
Contexts for target execution are: ['det_the', 'nsubjI_led', 'prep:of_tucker', 'cc_and', 'conj_debate']
Contexts in vocabulary for target execution are: ['det_the', 'nsubjI_led', 'prep:of_tucker', 'cc_and', 'conj_debate']
Top most similar embeddings: execution 0.02710	assassination 0.02020	impeachment 0.01990	demobilisation 0.01967	interrogations 0.01956	instigation 0.01937	jailing 0.01914	ingenuity 0.01910	beatification 0.01908	interrogation 0.01893

Generated lemmatized results
***************
GENERATED	execution.n 1827 ::: assassination;impeachment;demobilisation;interrogation;instigation;jailing;ingenuity;beatification;speech;emergence

Filtered results
***************
RANKED	execution.n 1827	death 0.01728	killing 0.01597	implementation 0.01592	performance 0.01577	administration 0.01561	completion 0.01497	production 0.01441	discharge 0.01439	fulfilment 0.01428	actualisation 0.01425	enforcement 0.01388	application 0.01266	method 0.01214	running 0.01118	transaction 0.01096

Test context:
***************
execution.n	1828	22	i understand that the presence of those individuals that came to the congress to testify about the years they had spent awaiting __execution__ before having being declared innocent was particularly moving and valuable .
Contexts for target execution are: ['dobjI_awaiting']
Contexts in vocabulary for target execution are: ['dobjI_awaiting']
Top most similar embeddings: execution 0.53088	finalization 0.39972	reassembly 0.37348	finalisation 0.37232	arraignment 0.37135	executions 0.36541	canonisation 0.36519	re-assembly 0.36415	deployment 0.35882	declassification 0.35791

Generated lemmatized results
***************
GENERATED	execution.n 1828 ::: finalization;reassembly;finalisation;arraignment;canonisation;deployment;declassification;exhumation;promulgation;completion

Filtered results
***************
RANKED	execution.n 1828	completion 0.35165	fulfilment 0.35134	implementation 0.34901	discharge 0.33490	actualisation 0.32901	death 0.31501	enforcement 0.31367	application 0.30708	performance 0.30634	killing 0.29927	production 0.29535	transaction 0.29243	administration 0.28391	running 0.26173	method 0.24809

Test context:
***************
execution.n	1829	47	the most poignant part of the book is when we learn of raw 's loss of his 15-year old daughter to a murderer and how he dealt with the pain and grief ( it was not , incidentally , by calling the murderer names and demanding his __execution__ ) .
Contexts for target execution are: ['poss_his', 'dobjI_demanding', 'punct_-rrb-']
Contexts in vocabulary for target execution are: ['poss_his', 'dobjI_demanding']
Top most similar embeddings: execution 0.25600	canonisation 0.18888	ouster 0.18755	detainment 0.18727	exoneration 0.18456	come-uppance 0.18346	acquittal 0.18284	comeuppance 0.18169	reelection 0.17925	re-trial 0.17836

Generated lemmatized results
***************
GENERATED	execution.n 1829 ::: canonisation;ouster;detainment;exoneration;acquittal;comeuppance;reelection;canonization;demobilisation;arraignment

Filtered results
***************
RANKED	execution.n 1829	death 0.16439	discharge 0.15783	fulfilment 0.15765	performance 0.15752	actualisation 0.15413	implementation 0.15148	completion 0.14667	killing 0.14583	application 0.14459	administration 0.14142	enforcement 0.14103	production 0.13480	method 0.13304	transaction 0.12681	running 0.12183

Test context:
***************
execution.n	1830	40	although i told you after the program how pleased i was and how successful i felt everything went , what i did n't tell you after the program was this : on a scale of 1 to 10 , your __execution__ was also a"10 !
Contexts for target execution are: ['poss_your', 'nsubjI_10']
Contexts in vocabulary for target execution are: ['poss_your', 'nsubjI_10']
Top most similar embeddings: execution 0.20402	milage 0.15862	birthdate 0.15812	ncd 0.15747	subscription 0.15651	rmerge 0.15648	rfree 0.15643	paychecks 0.15556	item/s 0.15502	user-id 0.15480

Generated lemmatized results
***************
GENERATED	execution.n 1830 ::: milage;birthdate;ncd;subscription;rmerge;rfree;paycheck;dgt;payment;battels

Filtered results
***************
RANKED	execution.n 1830	transaction 0.14916	discharge 0.14553	application 0.14511	performance 0.14480	fulfilment 0.14081	completion 0.13997	implementation 0.13887	death 0.13606	production 0.13077	actualisation 0.12637	administration 0.12509	enforcement 0.12113	killing 0.11924	method 0.11887	running 0.11230

Test context:
***************
fall.v	1831	29	the log in the doorway turned out to be the body of a man , obviously dead for some weeks , his flesh rotten with maggots and beginning to __fall__ away from the bones .
Contexts for target fall are: ['aux_to', 'xcompI_beginning', 'advmod_away']
Contexts in vocabulary for target fall are: ['aux_to', 'xcompI_beginning', 'advmod_away']
Top most similar embeddings: fall 0.13547	dwindle 0.10510	totter 0.09961	seep 0.09820	fade 0.09800	wither 0.09790	acclimatize 0.09634	evaporate 0.09597	skulk 0.09587	crumble 0.09570

Generated lemmatized results
***************
GENERATED	fall.v 1831 ::: dwindle;totter;seep;fade;wither;acclimatize;evaporate;skulk;crumble;encroach

Filtered results
***************
RANKED	fall.v 1831	drop 0.08951	slip 0.08842	descend 0.08452	tumble 0.08383	plunge 0.08340	take 0.08274	come 0.08191	undershoot 0.07716	fail 0.06944	disappoint 0.06664	land 0.06245	become 0.05622

Test context:
***************
fall.v	1832	14	not only are we forced to acknowledge that we , as a country , __fell__ short , but we also realize that the cup wo n't be coming home any time soon .
Contexts for target fell are: ['mark_that', 'nsubj_we', 'punct_,', 'prep:as_country', 'punct_,', 'ccompI_acknowledge', 'advmod_short']
Contexts in vocabulary for target fell are: ['mark_that', 'nsubj_we', 'punct_,', 'prep:as_country', 'punct_,', 'ccompI_acknowledge', 'advmod_short']
Top most similar embeddings: fell 0.00689	fallen 0.00606	fall 0.00509	sinned 0.00506	slumbered 0.00490	under-performed 0.00476	falling 0.00475	tumbled 0.00472	succeeded 0.00471	overreacted 0.00468

Generated lemmatized results
***************
GENERATED	fall.v 1832 ::: sin;slumber;tumble;succeed;overreact;lag;shrink;quarrel;slip;plunge

Filtered results
***************
RANKED	fall.v 1832	tumble 0.00472	slip 0.00445	plunge 0.00445	drop 0.00439	come 0.00426	fail 0.00413	descend 0.00398	take 0.00388	land 0.00388	become 0.00358	disappoint 0.00318	undershoot 0.00302

Test context:
***************
fall.v	1833	4	mary burroughs , having __fallen__ ill , resigned .
Contexts for target fallen are: ['aux_having', 'partmodI_burroughs', 'advmod_ill']
Contexts in vocabulary for target fallen are: ['aux_having', 'advmod_ill']
Top most similar embeddings: fallen 0.27846	falling 0.20025	fell 0.19831	risen 0.19447	fall 0.17927	tumbled 0.17702	taken 0.17627	slumped 0.17609	plateaued 0.17593	dropped 0.17527

Generated lemmatized results
***************
GENERATED	fall.v 1833 ::: fell;rise;tumble;take;slump;plateaued;drop;go;jump;get

Filtered results
***************
RANKED	fall.v 1833	tumble 0.17702	take 0.17627	drop 0.17527	slip 0.16980	plunge 0.16313	fail 0.15823	descend 0.15756	come 0.15451	land 0.14487	become 0.13907	disappoint 0.13418	undershoot 0.12428

Test context:
***************
fall.v	1834	9	here the novices performed well , getting lost , __falling__ through holes in the floor and refusing to climb pitches .
Contexts for target falling are: ['conjI_lost', 'prep:through_holes']
Contexts in vocabulary for target falling are: ['conjI_lost', 'prep:through_holes']
Top most similar embeddings: falling 0.24560	slipping 0.20194	fallen 0.19996	plummeting 0.19649	tumbling 0.18995	fell 0.18946	fall 0.18665	seeping 0.18505	tumbled 0.18449	slumping 0.18208

Generated lemmatized results
***************
GENERATED	fall.v 1834 ::: slip;plummet;tumble;fell;seep;slump;plunge;collapse;drift;drop

Filtered results
***************
RANKED	fall.v 1834	slip 0.20194	tumble 0.18995	plunge 0.18208	drop 0.17823	descend 0.15939	come 0.15274	fail 0.14190	undershoot 0.14105	become 0.13999	land 0.13646	take 0.12649	disappoint 0.11781

Test context:
***************
fall.v	1835	29	inevitably , you may find that , at a later date , you 'll get a phone call from that same prospect explaining that the writer they hired " __fell__ short of their expectations .
Contexts for target fell are: ['mark_that', 'nsubj_writer', 'ccompI_explaining', 'advmod_short']
Contexts in vocabulary for target fell are: ['mark_that', 'nsubj_writer', 'ccompI_explaining', 'advmod_short']
Top most similar embeddings: fell 0.05894	fallen 0.04737	falls 0.04736	falling 0.04265	fall 0.04229	intends 0.04037	strayed 0.03960	slipped 0.03915	came 0.03816	feels 0.03797

Generated lemmatized results
***************
GENERATED	fall.v 1835 ::: intend;stray;slip;come;feel;drop;blunder;foresee;wish;violate

Filtered results
***************
RANKED	fall.v 1835	slip 0.03915	come 0.03816	drop 0.03755	tumble 0.03588	plunge 0.03530	land 0.03414	fail 0.03405	take 0.03364	descend 0.03324	disappoint 0.02849	become 0.02801	undershoot 0.02511

Test context:
***************
fall.v	1836	10	even if snow was the only type of precipitation to __fall__ on the previous day , the snow is melted and the water equivalent is reported in millimetres .
Contexts for target fall are: ['aux_to', 'infmodI_type', 'prep:on_day']
Contexts in vocabulary for target fall are: ['aux_to', 'infmodI_type', 'prep:on_day']
Top most similar embeddings: fall 0.11461	salivate 0.08561	descend 0.08554	plummet 0.08534	convalesce 0.08524	urinate 0.08448	expire 0.08278	matriculate 0.08276	re-book 0.08256	fledge 0.08225

Generated lemmatized results
***************
GENERATED	fall.v 1836 ::: salivate;descend;plummet;convalesce;urinate;expire;matriculate;fledge;calve;defecate

Filtered results
***************
RANKED	fall.v 1836	descend 0.08554	tumble 0.07623	drop 0.07607	come 0.07385	slip 0.07378	plunge 0.07322	undershoot 0.07270	take 0.07171	disappoint 0.06620	fail 0.06445	land 0.05921	become 0.05092

Test context:
***************
fall.v	1837	4	unfortunately , the results __fell__ far short of their expectations .
Contexts for target fell are: ['advmod_unfortunately', 'punct_,', 'nsubj_results', 'rootI_*root*', 'acomp_short', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target fell are: ['advmod_unfortunately', 'punct_,', 'nsubj_results', 'rootI_*root*', 'acomp_short', 'punct_.']
Top most similar embeddings: fell 0.01790	fallen 0.01313	falls 0.01270	came 0.01189	tumbled 0.01181	flopped 0.01147	showed 0.01140	proved 0.01134	plummeted 0.01134	slumped 0.01117

Generated lemmatized results
***************
GENERATED	fall.v 1837 ::: come;tumble;flop;show;prove;plummet;slump;pal;skyrocket;drop

Filtered results
***************
RANKED	fall.v 1837	come 0.01189	tumble 0.01181	drop 0.01115	slip 0.01100	plunge 0.01047	disappoint 0.01003	take 0.00956	land 0.00940	fail 0.00918	become 0.00851	descend 0.00780	undershoot 0.00714

Test context:
***************
fall.v	1838	38	so once i found out where it was me and my fiance and aunt with her baby started walking towards where this day care was at and this huge , and i mean like a bus size bird __fell__ from the sky and its wing was broken .
Contexts for target fell are: ['nsubjpassI_broken', 'prep:from_sky']
Contexts in vocabulary for target fell are: ['nsubjpassI_broken', 'prep:from_sky']
Top most similar embeddings: fell 0.22239	falls 0.19261	falling 0.19241	fall 0.18844	fallen 0.18183	falleth 0.17082	plummets 0.16282	tumbled 0.15908	drips 0.15718	splatters 0.15651

Generated lemmatized results
***************
GENERATED	fall.v 1838 ::: falleth;plummet;tumble;drip;splatter;jut;limply;crash;plunge;gleam

Filtered results
***************
RANKED	fall.v 1838	tumble 0.15908	plunge 0.15180	drop 0.14946	slip 0.14849	descend 0.14354	land 0.13364	come 0.13313	take 0.12550	undershoot 0.11874	disappoint 0.11482	fail 0.10972	become 0.10968

Test context:
***************
fall.v	1839	7	if i see a man who has __fallen__ into a well , i would wish to help him out ; but if there is a greater probability that he shall pull me in , than that i shall pull him out , i would not attempt it .
Contexts for target fallen are: ['nsubj_who', 'aux_has', 'rcmodI_man', 'prep:into_well']
Contexts in vocabulary for target fallen are: ['nsubj_who', 'aux_has', 'rcmodI_man', 'prep:into_well']
Top most similar embeddings: fallen 0.07516	tumbled 0.05163	fell 0.05072	urinated 0.05028	collapsed 0.04850	spiraled 0.04827	slipped 0.04807	jumped 0.04804	leapt 0.04776	trespassed 0.04721

Generated lemmatized results
***************
GENERATED	fall.v 1839 ::: tumble;fell;urinate;collapse;spiral;slip;jump;leap;trespass;stray

Filtered results
***************
RANKED	fall.v 1839	tumble 0.05163	slip 0.04807	drop 0.04571	plunge 0.04484	descend 0.04174	land 0.03703	come 0.03588	fail 0.03513	take 0.03342	undershoot 0.02967	become 0.02659	disappoint 0.02518

Test context:
***************
fall.v	1840	17	when he was inside , he flopped down on his bed letting out a heavy sigh and __fell__ asleep with thoughts of the fabulous harry potter he had just met .
Contexts for target fell are: ['conjI_letting', 'advmod_asleep', 'prep:with_thoughts']
Contexts in vocabulary for target fell are: ['conjI_letting', 'advmod_asleep', 'prep:with_thoughts']
Top most similar embeddings: fell 0.11904	fallen 0.09085	falling 0.09027	tumbled 0.08383	fall 0.08348	falls 0.08096	slumped 0.07771	crept 0.07732	jumped 0.07670	dozed 0.07661

Generated lemmatized results
***************
GENERATED	fall.v 1840 ::: tumble;slump;creep;jump;doze;leap;bounce;lie;collapse;slip

Filtered results
***************
RANKED	fall.v 1840	tumble 0.08383	slip 0.07533	plunge 0.07300	drop 0.06846	come 0.06820	take 0.06264	land 0.06140	descend 0.06068	become 0.05970	fail 0.05686	disappoint 0.05452	undershoot 0.04661

Test context:
***************
figure.n	1841	2	no single __figure__ is more central to each of these struggles than microsoft , as exemplified by the following mostly bilateral conflicts : apple vs. microsoft ; ibm vs. microsoft ; wordperfect vs. microsoft ; netscape vs. microsoft ; and america online , et al , vs. microsoft .
Contexts for target figure are: ['det_no', 'amod_single', 'nsubjI_central']
Contexts in vocabulary for target figure are: ['det_no', 'amod_single', 'nsubjI_central']
Top most similar embeddings: figure 0.10958	figures 0.09218	deity 0.07815	concept 0.07647	personage 0.07579	figurehead 0.07516	referent 0.07498	definition 0.07451	statistic 0.07416	periodization 0.07415

Generated lemmatized results
***************
GENERATED	figure.n 1841 ::: deity;concept;personage;figurehead;referent;definition;statistic;periodization;question;point

Filtered results
***************
RANKED	figure.n 1841	personage 0.07579	statistic 0.07416	person 0.07347	image 0.07130	character 0.07072	entity 0.07044	illustration 0.06840	calculation 0.06819	value 0.06786	individual 0.06543	diagram 0.06359	picture 0.06355	total 0.06273	account 0.06234	numeral 0.06185	data 0.05986	amount 0.05880	organisation 0.05850	number 0.05745	leader 0.05595	people 0.05538	representative 0.05337

Test context:
***************
figure.n	1842	3	use facts , __figures__ , documents , appraisals , industry awards etc. why are you a key player ?
Contexts for target figures are: ['conjI_facts']
Contexts in vocabulary for target figures are: ['conjI_facts']
Top most similar embeddings: figures 0.56599	statistics 0.41424	personages 0.38147	stats 0.38096	facts 0.37722	figure 0.37290	projections 0.36929	forecasts 0.36222	prognostications 0.35285	suppositions 0.35213

Generated lemmatized results
***************
GENERATED	figure.n 1842 ::: statistic;personage;stats;fact;projection;forecast;prognostication;supposition;personality;phantasy

Filtered results
***************
RANKED	figure.n 1842	statistic 0.41424	personage 0.38147	calculation 0.34541	total 0.32608	number 0.32260	picture 0.31968	character 0.31845	illustration 0.31777	data 0.31732	diagram 0.31484	value 0.31423	image 0.31391	account 0.30102	entity 0.28928	person 0.28336	amount 0.28282	individual 0.27497	representative 0.27095	numeral 0.27049	people 0.26600	leader 0.26520	organisation 0.25560

Test context:
***************
figure.n	1843	2	the corresponding __figures__ for women are 27 respectively 33 hours .
Contexts for target figures are: ['det_the', 'amod_corresponding', 'nsubjI_hours', 'prep:for_women']
Contexts in vocabulary for target figures are: ['det_the', 'amod_corresponding', 'nsubjI_hours', 'prep:for_women']
Top most similar embeddings: figures 0.06230	figure 0.04863	totals 0.04564	percentages 0.04417	averages 0.04193	ptwi 0.04186	out-turn 0.03937	statistics 0.03935	rni 0.03915	half-lives 0.03908

Generated lemmatized results
***************
GENERATED	figure.n 1843 ::: total;percentage;average;ptwi;statistic;rni;ratio;scaling;prevalence;estimate

Filtered results
***************
RANKED	figure.n 1843	total 0.04564	statistic 0.03935	calculation 0.03662	value 0.03578	number 0.03494	amount 0.03445	personage 0.03248	character 0.03183	data 0.03070	picture 0.03031	account 0.03018	diagram 0.02999	numeral 0.02948	image 0.02933	illustration 0.02802	leader 0.02706	organisation 0.02682	representative 0.02628	person 0.02628	entity 0.02601	individual 0.02509	people 0.02446

Test context:
***************
figure.n	1844	8	comment : latex , 3 pages , 5 __figures__ .
Contexts for target figures are: ['num_5', 'apposI_latex']
Contexts in vocabulary for target figures are: ['num_5']
Top most similar embeddings: figures 0.48845	figure 0.42617	nc6 0.36890	statistics 0.35477	view/apply 0.35132	totals 0.35091	bordars 0.35072	figs 0.35044	view/appy 0.34712	nf6 0.34572

Generated lemmatized results
***************
GENERATED	figure.n 1844 ::: statistic;total;bordars;fig;stats;projection;topos;outturn;table;semitone

Filtered results
***************
RANKED	figure.n 1844	statistic 0.35477	total 0.35091	character 0.32189	personage 0.32153	number 0.31955	calculation 0.31836	diagram 0.30419	image 0.30354	person 0.29820	account 0.29723	picture 0.29711	illustration 0.29587	value 0.29503	numeral 0.29382	people 0.29333	representative 0.29247	data 0.29031	leader 0.28481	individual 0.28476	amount 0.27378	organisation 0.27036	entity 0.26662

Test context:
***************
figure.n	1845	18	the target set by heads of government at successive european councils is 1.5 %. the next set of __figures__ will be published in january 2004 and early indications are that they are unlikely to show a substantial improvement .
Contexts for target figures are: ['prep:ofI_set']
Contexts in vocabulary for target figures are: ['prep:ofI_set']
Top most similar embeddings: figures 0.51303	statistics 0.38484	projections 0.37033	spectrograms 0.36372	catchwords 0.36327	bvpis 0.36303	keysyms 0.36295	outturns 0.36267	data-sets 0.36241	benchmarks 0.36218

Generated lemmatized results
***************
GENERATED	figure.n 1845 ::: statistic;projection;spectrogram;catchword;bvpis;keysyms;outturn;benchmark;csfs;hypocentres

Filtered results
***************
RANKED	figure.n 1845	statistic 0.38484	calculation 0.35114	number 0.34553	personage 0.34394	total 0.34112	value 0.33979	character 0.33975	image 0.33402	data 0.32876	diagram 0.32754	account 0.32609	picture 0.32119	illustration 0.31888	entity 0.30948	numeral 0.30800	individual 0.29978	representative 0.29609	leader 0.28584	people 0.28346	amount 0.28203	person 0.27965	organisation 0.27785

Test context:
***************
figure.n	1846	19	some suggest that children are simply more willing to accept the values of parents and teachers when these authority __figures__ are affectionate .
Contexts for target figures are: ['det_these', 'nn_authority', 'nsubjI_affectionate']
Contexts in vocabulary for target figures are: ['det_these', 'nn_authority', 'nsubjI_affectionate']
Top most similar embeddings: figures 0.12139	statistics 0.08227	ragdolls 0.07915	projections 0.07853	spokespeople 0.07583	figure 0.07563	spokespersons 0.07483	personages 0.07455	estimates 0.07446	spokesmen 0.07413

Generated lemmatized results
***************
GENERATED	figure.n 1846 ::: statistic;ragdolls;projection;spokespeople;spokesperson;personage;estimate;spokesman;boss;average

Filtered results
***************
RANKED	figure.n 1846	statistic 0.08227	personage 0.07455	account 0.07209	total 0.07080	number 0.06812	character 0.06752	calculation 0.06592	leader 0.06510	picture 0.06476	representative 0.06397	image 0.06376	entity 0.06206	diagram 0.06190	value 0.06179	person 0.06070	individual 0.06060	data 0.06025	illustration 0.06011	people 0.05891	numeral 0.05876	organisation 0.05676	amount 0.05400

Test context:
***************
figure.n	1847	8	councillor campbell : i do not have the __figures__ .
Contexts for target figures are: ['det_the', 'dobjI_have']
Contexts in vocabulary for target figures are: ['det_the', 'dobjI_have']
Top most similar embeddings: figures 0.24610	figure 0.18806	truth-conditions 0.18741	r_speeds 0.18364	c-word 0.18355	temerity 0.18344	makings 0.18046	prevalences 0.18039	followings 0.17795	nomber 0.17727

Generated lemmatized results
***************
GENERATED	figure.n 1847 ::: temerity;making;prevalence;following;nomber;raditech;percentage;personality;statistic;boundries

Filtered results
***************
RANKED	figure.n 1847	statistic 0.17551	number 0.16925	character 0.16405	total 0.16304	personage 0.16099	value 0.16094	picture 0.16012	amount 0.15905	data 0.15581	account 0.15491	calculation 0.15461	image 0.15434	diagram 0.14935	leader 0.14901	representative 0.14885	numeral 0.14824	illustration 0.14653	person 0.14429	people 0.14033	individual 0.13405	entity 0.13212	organisation 0.13171

Test context:
***************
figure.n	1848	41	the share of historical fact in it , indeed , is not large , but the action takes place so near to great events that the characters are all invested with something of the dusky light of heroes , while the __figure__ of washington , disguised as mr. harper and yet always looming gigantically through his disguise , moves among the other personages like a half-suspected god .
Contexts for target figure are: ['det_the', 'prep:whileI_large', 'prep:of_washington', 'punct_,', 'partmod_disguised']
Contexts in vocabulary for target figure are: ['det_the', 'prep:of_washington', 'punct_,', 'partmod_disguised']
Top most similar embeddings: figure 0.05304	statue 0.04266	proconsul 0.04240	figures 0.04181	byshop 0.04177	mansion-house 0.04164	apparition 0.04162	autocrat 0.04146	personages 0.04115	she-wolf 0.04115

Generated lemmatized results
***************
GENERATED	figure.n 1848 ::: statue;proconsul;byshop;apparition;autocrat;personage;bogeyman;ealdorman;tribune;charioteer

Filtered results
***************
RANKED	figure.n 1848	personage 0.04115	statistic 0.03269	character 0.03263	diagram 0.03243	image 0.03142	picture 0.03088	leader 0.03034	illustration 0.02984	entity 0.02921	numeral 0.02860	individual 0.02854	value 0.02833	amount 0.02786	person 0.02757	representative 0.02733	account 0.02709	people 0.02684	total 0.02616	calculation 0.02593	number 0.02587	organisation 0.02579	data 0.02383

Test context:
***************
figure.n	1849	0	__figures__ published by the government last year suggest that white boys and girls who qualify for free school meals make less progress in the two years up to gcse than any other group .
Contexts for target figures are: ['nsubjI_suggest', 'partmod_published']
Contexts in vocabulary for target figures are: ['nsubjI_suggest', 'partmod_published']
Top most similar embeddings: figures 0.28832	statistics 0.20717	projections 0.19908	estimates 0.19258	findings 0.18819	forecasts 0.18459	demographers 0.18325	meta-analyses 0.17995	outturns 0.17982	tabulations 0.17932

Generated lemmatized results
***************
GENERATED	figure.n 1849 ::: statistic;projection;estimate;finding;forecast;demographer;outturn;tabulation;result;stats

Filtered results
***************
RANKED	figure.n 1849	statistic 0.20717	calculation 0.16900	data 0.16305	total 0.16202	illustration 0.15642	personage 0.15559	account 0.15535	number 0.15053	diagram 0.14912	image 0.14525	picture 0.14377	character 0.13553	value 0.13509	leader 0.12989	amount 0.12357	numeral 0.12357	people 0.12145	organisation 0.12066	representative 0.11747	individual 0.11723	person 0.11648	entity 0.11557

Test context:
***************
figure.n	1850	13	the vieth-muller circle assumes there is angular symmetry of the corresponding points ( __figure__ 8 ) .
Contexts for target figure are: ['punct_-lrb-', 'depI_<eol>', 'dep_8', 'punct_.']
Contexts in vocabulary for target figure are: ['dep_8', 'punct_.']
Top most similar embeddings: figure 0.24579	fig 0.20833	fitsfile 0.20622	nf3 0.20537	fig. 0.19931	neuroreport 0.19471	nc3 0.19427	lxv 0.19334	rebolted 0.19316	epilepsia 0.18937

Generated lemmatized results
***************
GENERATED	figure.n 1850 ::: fig;fitsfile;neuroreport;lxv;rebolted;epilepsia;angl;neuroimage;apoc;bodl

Filtered results
***************
RANKED	figure.n 1850	diagram 0.14962	statistic 0.14893	total 0.14881	personage 0.13947	illustration 0.13707	picture 0.12965	person 0.12893	image 0.12819	numeral 0.12750	leader 0.12237	value 0.12217	character 0.12165	entity 0.12064	number 0.11978	account 0.11958	calculation 0.11937	representative 0.11494	amount 0.11325	organisation 0.10524	individual 0.10501	data 0.10002	people 0.09465

Test context:
***************
fire.v	1851	2	the panther __fired__ at the bridge and hit a truck .
Contexts for target fired are: ['nsubj_panther', 'rootI_*root*', 'prep:at_bridge', 'cc_and', 'conj_hit', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target fired are: ['nsubj_panther', 'rootI_*root*', 'prep:at_bridge', 'cc_and', 'conj_hit', 'punct_.']
Top most similar embeddings: fired 0.01533	lunged 0.01285	jinked 0.01208	skidded 0.01204	arced 0.01198	scowled 0.01194	glared 0.01182	clanged 0.01174	glanced 0.01171	swooped 0.01161

Generated lemmatized results
***************
GENERATED	fire.v 1851 ::: lunge;jinked;skid;arc;scowl;glare;clang;glance;swoop;huff

Filtered results
***************
RANKED	fire.v 1851	shoot 0.00856	launch 0.00833	sack 0.00795	dismiss 0.00731	discharge 0.00725

Test context:
***************
fire.v	1852	7	they shot more blobs of gelfire , __fired__ explosive projectiles .
Contexts for target fired are: ['conjI_shot', 'dobj_projectiles']
Contexts in vocabulary for target fired are: ['conjI_shot', 'dobj_projectiles']
Top most similar embeddings: fired 0.29861	lobbed 0.21564	firing 0.21260	strafed 0.20408	rifled 0.20233	hurled 0.20023	lobbing 0.19963	detonated 0.19586	machine-gunned 0.19400	smashed 0.19367

Generated lemmatized results
***************
GENERATED	fire.v 1852 ::: lob;strafe;rifle;hurl;detonate;smash;fizz;blast;manhandle;bayonet

Filtered results
***************
RANKED	fire.v 1852	shoot 0.17913	discharge 0.15659	launch 0.15065	dismiss 0.14270	sack 0.14154

Test context:
***************
fire.v	1853	4	stern : i was __fired__ from the avengers , and with the exception of jim salicrup , no marvel editor would return my calls .
Contexts for target fired are: ['nsubjpass_i', 'auxpass_was', 'parataxisI_stern', 'prep:from_avengers']
Contexts in vocabulary for target fired are: ['nsubjpass_i', 'auxpass_was']
Top most similar embeddings: fired 0.26317	strafed 0.20244	manhandled 0.20034	sniped 0.19903	frisked 0.19762	propositioned 0.19445	struck 0.19215	demobbed 0.19041	buddied 0.19017	ambushed 0.19016

Generated lemmatized results
***************
GENERATED	fire.v 1853 ::: strafe;manhandle;snip;frisk;proposition;strike;demob;buddied;ambush;disembowel

Filtered results
***************
RANKED	fire.v 1853	sack 0.18650	discharge 0.18453	dismiss 0.17894	shoot 0.16954	launch 0.16167

Test context:
***************
fire.v	1854	15	at least eight other railroad systems followed suit , bringing the total of railroad workers __fired__ to more than 200,000 in 1986 alone .
Contexts for target fired are: ['nsubj_total', 'ccompI_bringing', 'prep:to_200,000']
Contexts in vocabulary for target fired are: ['nsubj_total', 'ccompI_bringing', 'prep:to_200,000']
Top most similar embeddings: fired 0.09811	amounted 0.08637	ballooned 0.08302	skyrocketed 0.08293	risen 0.08236	rocketed 0.08071	soared 0.08062	doubled 0.07987	tripled 0.07823	totaled 0.07810

Generated lemmatized results
***************
GENERATED	fire.v 1854 ::: amount;balloon;skyrocket;rise;rocket;soar;double;triple;total;surge

Filtered results
***************
RANKED	fire.v 1854	dismiss 0.05799	discharge 0.05747	shoot 0.05590	launch 0.05531	sack 0.05124

Test context:
***************
fire.v	1855	15	threat to use force threat by one state to use its regular armed forces to __fire__ upon the armed forces or violate the territory of another state .
Contexts for target fire are: ['prep:toI_use']
Contexts in vocabulary for target fire are: ['prep:toI_use']
Top most similar embeddings: fire 0.46490	fires 0.39573	blaze 0.33874	stove 0.33593	flame 0.33111	woodburner 0.32719	fuse 0.32497	bankline 0.32376	eavesdroppers 0.32311	flames 0.32311

Generated lemmatized results
***************
GENERATED	fire.v 1855 ::: blaze;stave;flame;woodburner;fuse;bankline;eavesdroppers;pyres;logoff;moisturise

Filtered results
***************
RANKED	fire.v 1855	shoot 0.27680	sack 0.27363	discharge 0.26739	launch 0.25595	dismiss 0.21854

Test context:
***************
fire.v	1856	9	at the cincinatti enquirer , reporter mike gallagher was __fired__ for stealing voice mail messages in the course of writing a piece on the chiquita banana company , aided , it seems , by an employee of the company .
Contexts for target fired are: ['prep:at_enquirer', 'punct_,', 'nsubjpass_gallagher', 'auxpass_was', 'rootI_*root*', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target fired are: ['punct_,', 'auxpass_was', 'rootI_*root*', 'punct_.']
Top most similar embeddings: fired 0.06608	laureated 0.05357	chorused 0.05272	disjoined 0.05264	sniped 0.05220	amerced 0.05171	said 0.05103	bayoneted 0.05103	rebolted 0.05087	strafed 0.05061

Generated lemmatized results
***************
GENERATED	fire.v 1856 ::: laureated;chorus;disjoin;snip;amerce;say;bayonet;rebolted;strafe;sputter

Filtered results
***************
RANKED	fire.v 1856	dismiss 0.04825	launch 0.04677	sack 0.04493	discharge 0.04214	shoot 0.03958

Test context:
***************
fire.v	1857	5	centerfire rifles can be accurately __fired__ to great distances , but the greater the distance , the steadier the rifle must be during the aiming .
Contexts for target fired are: ['nsubjpass_rifles', 'aux_can', 'auxpass_be', 'advmod_accurately', 'rootI_*root*', 'prep:to_distances', 'punct_,', 'cc_but', 'conj_distance', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target fired are: ['nsubjpass_rifles', 'aux_can', 'auxpass_be', 'advmod_accurately', 'rootI_*root*', 'prep:to_distances', 'punct_,', 'cc_but', 'conj_distance', 'punct_.']
Top most similar embeddings: fired 0.00080	measured 0.00063	calibrated 0.00063	pinpointed 0.00060	recovered 0.00059	converted 0.00059	swivelled 0.00059	gauged 0.00059	rotated 0.00059	adjusted 0.00059

Generated lemmatized results
***************
GENERATED	fire.v 1857 ::: measure;calibrate;pinpoint;recover;convert;swivel;gauge;rotate;adjust;image

Filtered results
***************
RANKED	fire.v 1857	discharge 0.00049	shoot 0.00045	dismiss 0.00041	sack 0.00037	launch 0.00034

Test context:
***************
fire.v	1858	10	while both he and the white house deny he was __fired__ , frum is so insistent on the fact that he quit on his own that it really makes you wonder .
Contexts for target fired are: ['nsubjpass_he', 'auxpass_was', 'ccompI_deny']
Contexts in vocabulary for target fired are: ['nsubjpass_he', 'auxpass_was', 'ccompI_deny']
Top most similar embeddings: fired 0.13232	manhandled 0.09622	libelled 0.09398	fouled 0.09302	gassed 0.09300	bested 0.09295	hurled 0.09248	court-martialled 0.09235	sacked 0.09226	upended 0.09184

Generated lemmatized results
***************
GENERATED	fire.v 1858 ::: manhandle;libel;foul;gas;best;hurl;sack;upend;proposition;murder

Filtered results
***************
RANKED	fire.v 1858	sack 0.09226	dismiss 0.09013	discharge 0.08440	shoot 0.07999	launch 0.07315

Test context:
***************
fire.v	1859	28	cattle to be killed are driven single file into a roofless metal box one at a time , the pistol is placed against their forehead and the bolt __fired__ into their brain .
Contexts for target fired are: ['depI_placed', 'prep:into_brain']
Contexts in vocabulary for target fired are: ['depI_placed', 'prep:into_brain']
Top most similar embeddings: fired 0.24295	blasted 0.18062	drilled 0.17882	squirted 0.17766	poured 0.17764	pumped 0.17645	arced 0.17449	rifled 0.17440	arrowed 0.17331	firing 0.17322

Generated lemmatized results
***************
GENERATED	fire.v 1859 ::: blast;drill;squirt;pour;pump;arc;rifle;arrowed;fizz;lob

Filtered results
***************
RANKED	fire.v 1859	discharge 0.15241	shoot 0.13414	sack 0.13241	launch 0.12375	dismiss 0.11704

Test context:
***************
fire.v	1860	16	don 's second caller was purportedly a former neighbor of tropper norman , the office that __fired__ the shot that killed erin hamley. he said that norman is a good guy and has to be going through hell right now .
Contexts for target fired are: ['nsubj_that', 'rcmodI_office', 'dobj_shot']
Contexts in vocabulary for target fired are: ['nsubj_that', 'rcmodI_office', 'dobj_shot']
Top most similar embeddings: fired 0.11961	fizzed 0.09734	blasted 0.09119	blazed 0.08976	lobbed 0.08850	cannoned 0.08815	rifled 0.08685	ejects 0.08660	thundered 0.08463	deflects 0.08455

Generated lemmatized results
***************
GENERATED	fire.v 1860 ::: fizz;blast;blaze;lob;cannon;rifle;eject;thunder;deflect;inflate

Filtered results
***************
RANKED	fire.v 1860	shoot 0.07262	launch 0.07049	discharge 0.06836	dismiss 0.06650	sack 0.06514

Test context:
***************
function.n	1861	5	happiness is a by-product of __function__ .
Contexts for target function are: ['prep:ofI_by-product']
Contexts in vocabulary for target function are: ['prep:ofI_by-product']
Top most similar embeddings: function 0.48120	functions 0.41123	funtion 0.35695	homeostasis 0.35258	functioning 0.35148	catabolism 0.34672	neurotransmission 0.34603	reinnervation 0.34398	subroutine 0.34380	tumorigenesis 0.34343

Generated lemmatized results
***************
GENERATED	function.n 1861 ::: funtion;homeostasis;functioning;catabolism;neurotransmission;reinnervation;subroutine;tumorigenesis;photosynthesis;metabolism

Filtered results
***************
RANKED	function.n 1861	subroutine 0.34380	operation 0.33797	activity 0.33531	phenomenon 0.31413	calculation 0.30902	transformation 0.30707	working 0.30641	purpose 0.30548	role 0.30420	equation 0.30126	task 0.30081	feature 0.29763	mapping 0.28852	sequence 0.28823	performance 0.27605	relation 0.27507	result 0.27306	job 0.26822	correspondence 0.26238

Test context:
***************
function.n	1862	8	4 how can one generate the probability density __function__ of an erlang distribution using stella ?
Contexts for target function are: ['det_the', 'nn_probability', 'nn_density', 'dobjI_generate', 'prep:of_distribution']
Contexts in vocabulary for target function are: ['det_the', 'nn_probability', 'nn_density', 'dobjI_generate', 'prep:of_distribution']
Top most similar embeddings: function 0.03316	functions 0.02765	histogram 0.02522	isosurface 0.02520	wavefunctions 0.02495	wavefunction 0.02484	funtion 0.02476	functionals 0.02452	eigenfunctions 0.02445	histograms 0.02441

Generated lemmatized results
***************
GENERATED	function.n 1862 ::: histogram;isosurface;wavefunctions;wavefunction;funtion;functionals;eigenfunctions;distribution;coefficient;dependence

Filtered results
***************
RANKED	function.n 1862	mapping 0.02174	calculation 0.02157	equation 0.02015	subroutine 0.01890	transformation 0.01866	sequence 0.01625	phenomenon 0.01594	operation 0.01567	correspondence 0.01534	activity 0.01525	result 0.01514	purpose 0.01481	task 0.01432	working 0.01424	relation 0.01407	feature 0.01403	role 0.01367	job 0.01365	performance 0.01316

Test context:
***************
function.n	1863	1	these __functions__ also use scheduling priority to decide which thread gets to execute when there is contention .
Contexts for target functions are: ['det_these', 'nsubjI_use']
Contexts in vocabulary for target functions are: ['det_these', 'nsubjI_use']
Top most similar embeddings: functions 0.24698	functionalities 0.20021	subprograms 0.19401	charsets 0.19074	subcommands 0.18934	subroutines 0.18925	formatters 0.18765	functors 0.18646	ioctls 0.18536	microtasks 0.18460

Generated lemmatized results
***************
GENERATED	function.n 1863 ::: functionality;subprogram;charsets;subcommands;subroutine;formatters;functors;ioctls;microtasks;bioses

Filtered results
***************
RANKED	function.n 1863	subroutine 0.18925	task 0.17039	mapping 0.16626	operation 0.16086	calculation 0.15812	activity 0.15744	transformation 0.15474	role 0.15310	feature 0.15186	equation 0.15118	sequence 0.14568	correspondence 0.14506	purpose 0.14215	phenomenon 0.14208	result 0.13853	working 0.13609	job 0.13592	performance 0.13065	relation 0.12297

Test context:
***************
function.n	1864	0	__functions__ of the presidency one way of bringing focus to the presidency is to determine what the functions of the position should be .
Contexts for target functions are: ['rootI_*root*', 'prep:of_presidency', 'rcmod_is', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target functions are: ['rootI_*root*', 'prep:of_presidency', 'rcmod_is', 'punct_.']
Top most similar embeddings: functions 0.04591	doct 0.04122	aims 0.04046	function 0.04034	epis 0.03981	3.4.2 0.03971	q23 0.03957	4.1.6 0.03951	q20 0.03922	6.1.4 0.03903

Generated lemmatized results
***************
GENERATED	function.n 1864 ::: doct;aim;epi;selah;acknowledgment;counc;pandarus;severability;tchiowa;wherwith

Filtered results
***************
RANKED	function.n 1864	feature 0.03616	subroutine 0.03332	task 0.03289	phenomenon 0.03088	purpose 0.02971	transformation 0.02928	role 0.02888	result 0.02800	calculation 0.02793	equation 0.02766	correspondence 0.02734	operation 0.02677	activity 0.02654	mapping 0.02615	job 0.02596	performance 0.02471	working 0.02413	sequence 0.02364	relation 0.02269

Test context:
***************
function.n	1865	8	the orientation of unionids in rivers as a __function__ of the hydrological variability .
Contexts for target function are: ['det_a', 'prep:asI_orientation', 'prep:of_variability']
Contexts in vocabulary for target function are: ['det_a', 'prep:of_variability']
Top most similar embeddings: function 0.23864	funtion 0.18939	biomarker 0.18237	determinant 0.18143	parameterization 0.17609	parametrization 0.17576	scatterplot 0.17312	fraction 0.17172	predictor 0.17166	mechanism 0.17147

Generated lemmatized results
***************
GENERATED	function.n 1865 ::: funtion;biomarker;determinant;parameterization;parametrization;scatterplot;fraction;predictor;mechanism;covariate

Filtered results
***************
RANKED	function.n 1865	role 0.16848	result 0.16536	calculation 0.16390	phenomenon 0.15992	feature 0.15826	subroutine 0.15547	sequence 0.15343	equation 0.14900	operation 0.14814	mapping 0.14291	task 0.14010	purpose 0.14003	relation 0.13761	activity 0.13745	transformation 0.13023	job 0.12877	performance 0.12632	working 0.11932	correspondence 0.11740

Test context:
***************
function.n	1866	14	because of the obvious incapacity of these bourgeois classes to fulfill the normal economic __function__ of a bourgeoisie , each of them faces a subversion based on the bureaucratic model , more or less adapted to local peculiarities , and eager to seize the heritage of this bourgeoisie .
Contexts for target function are: ['det_the', 'amod_normal', 'amod_economic', 'dobjI_fulfill', 'prep:of_bourgeoisie']
Contexts in vocabulary for target function are: ['det_the', 'amod_normal', 'amod_economic', 'dobjI_fulfill', 'prep:of_bourgeoisie']
Top most similar embeddings: function 0.03077	functions 0.02570	functioning 0.02077	role 0.02025	destructiveness 0.01966	imperatives 0.01966	exigency 0.01959	self-interests 0.01957	potentialities 0.01945	propensities 0.01932

Generated lemmatized results
***************
GENERATED	function.n 1866 ::: functioning;role;destructiveness;imperative;exigency;potentiality;propensity;machination;propriety;prerogative

Filtered results
***************
RANKED	function.n 1866	role 0.02025	task 0.01889	activity 0.01872	equation 0.01804	purpose 0.01791	transformation 0.01749	working 0.01674	subroutine 0.01672	calculation 0.01659	operation 0.01644	relation 0.01581	mapping 0.01538	performance 0.01501	sequence 0.01471	phenomenon 0.01437	job 0.01365	feature 0.01285	correspondence 0.01268	result 0.01249

Test context:
***************
function.n	1867	5	the composition , structure , __function__ and distribution of populations and the biology of population communities ( producers , consumers , and decomposers ) , ecosystems , nutrient cycles , energy flow , bio-geographical cycles , human impact on environment will be covered .
Contexts for target function are: ['conjI_structure']
Contexts in vocabulary for target function are: ['conjI_structure']
Top most similar embeddings: function 0.55203	functions 0.45732	functioning 0.39041	compartmentation 0.38315	funtion 0.37782	linearisation 0.37387	hydrophobicity 0.37201	homeostasis 0.36463	contractility 0.36368	crystallinity 0.36330

Generated lemmatized results
***************
GENERATED	function.n 1867 ::: functioning;compartmentation;funtion;linearisation;hydrophobicity;homeostasis;contractility;crystallinity;bioactivity;aromaticity

Filtered results
***************
RANKED	function.n 1867	subroutine 0.35878	operation 0.33201	role 0.32282	activity 0.32120	equation 0.31733	mapping 0.31539	purpose 0.31509	sequence 0.31220	calculation 0.31019	task 0.30687	transformation 0.30135	working 0.30083	feature 0.29827	performance 0.29371	phenomenon 0.28628	relation 0.28518	correspondence 0.28216	result 0.25974	job 0.25903

Test context:
***************
function.n	1868	7	however , their arguments are identical in __function__ to the creationists ' arguments : rather than provide positive evidence for their own position , they mainly try to find weaknesses in natural selection .
Contexts for target function are: ['prep:inI_identical', 'prep:to_arguments']
Contexts in vocabulary for target function are: ['prep:inI_identical', 'prep:to_arguments']
Top most similar embeddings: function 0.22852	functions 0.17697	relation 0.16148	attribute 0.15874	functionality 0.15646	pertinence 0.15627	irreducibility 0.15577	funtion 0.15477	correspond 0.15412	contradistinction 0.15401

Generated lemmatized results
***************
GENERATED	function.n 1868 ::: relation;attribute;functionality;pertinence;irreducibility;funtion;correspond;contradistinction;predicate;functioning

Filtered results
***************
RANKED	function.n 1868	relation 0.16148	subroutine 0.14710	mapping 0.14447	operation 0.13918	correspondence 0.13194	equation 0.13041	feature 0.12935	working 0.12856	purpose 0.12663	calculation 0.12486	sequence 0.12470	task 0.11659	phenomenon 0.11656	result 0.11639	role 0.11450	transformation 0.11357	activity 0.11356	performance 0.11053	job 0.10269

Test context:
***************
function.n	1869	2	its main __function__ is to act as a bridge between your hi-fi and computer , so that you can stream music from one to the other .
Contexts for target function are: ['poss_its', 'amod_main', 'nsubjI_is']
Contexts in vocabulary for target function are: ['poss_its', 'amod_main', 'nsubjI_is']
Top most similar embeddings: function 0.13420	funtion 0.09975	functions 0.09919	d'etre 0.09692	purpose 0.09535	aim 0.09311	intension 0.09156	remit 0.09117	objective 0.09043	down-side 0.08984

Generated lemmatized results
***************
GENERATED	function.n 1869 ::: funtion;purpose;aim;intension;remit;objective;drawback;stopcock;raison;role

Filtered results
***************
RANKED	function.n 1869	purpose 0.09535	role 0.08765	task 0.08466	feature 0.08128	subroutine 0.07906	activity 0.07868	operation 0.07691	sequence 0.07232	job 0.07051	equation 0.06973	calculation 0.06948	working 0.06716	result 0.06700	relation 0.06692	mapping 0.06612	transformation 0.06462	performance 0.06437	phenomenon 0.06299	correspondence 0.05949

Test context:
***************
function.n	1870	42	where most experiments show only " shadows " of the wave function in the form of measurement outcomes , konrad was able to go one step further , designing and implementing a measurement scheme that is sensitive enough to reveal the complete __function__ .
Contexts for target function are: ['det_the', 'amod_complete', 'dobjI_reveal']
Contexts in vocabulary for target function are: ['det_the', 'amod_complete', 'dobjI_reveal']
Top most similar embeddings: function 0.11214	functions 0.09319	flowgraph 0.08738	falseness 0.08712	hollowness 0.08710	synchronism 0.08693	wavefunction 0.08668	implausibility 0.08597	vacuity 0.08594	uselessness 0.08550

Generated lemmatized results
***************
GENERATED	function.n 1870 ::: flowgraph;falseness;hollowness;synchronism;wavefunction;implausibility;vacuity;uselessness;delocalisation;oligomer

Filtered results
***************
RANKED	function.n 1870	subroutine 0.08234	sequence 0.08072	working 0.07974	equation 0.07799	mapping 0.07788	transformation 0.07630	operation 0.07566	correspondence 0.07550	task 0.07347	phenomenon 0.07216	role 0.07171	calculation 0.07163	purpose 0.07068	result 0.06927	activity 0.06927	feature 0.06697	performance 0.06458	relation 0.06116	job 0.06043

Test context:
***************
jam.n	1871	12	on some of the waggons we found klinkers ( biscuits ) , __jam__ , milk , sardines , salmon , cases of corned beef , and other such provisions in great variety .
Contexts for target jam are: ['apposI_klinkers', 'punct_,', 'conj_milk', 'punct_,', 'conj_sardines', 'punct_,', 'conj_salmon', 'punct_,', 'conj_cases', 'punct_,', 'cc_and', 'conj_provisions']
Contexts in vocabulary for target jam are: ['punct_,', 'conj_milk', 'punct_,', 'conj_sardines', 'punct_,', 'conj_salmon', 'punct_,', 'conj_cases', 'punct_,', 'cc_and', 'conj_provisions']
Top most similar embeddings: salsify 0.00063	wholegrains 0.00062	plantains 0.00058	paninis 0.00055	tofu 0.00054	sauerkraut 0.00054	hummus 0.00054	bourguignon 0.00053	bovril 0.00053	tuna 0.00053

Generated lemmatized results
***************
GENERATED	jam.n 1871 ::: salsify;wholegrains;plantain;panini;tofu;sauerkraut;hummus;bourguignon;bovril;tuna

Filtered results
***************
RANKED	jam.n 1871	jelly 0.00044	preserve 0.00031	conserve 0.00024	riff 0.00019	malfunction 0.00015	congestion 0.00015	blockage 0.00014	gig 0.00012	seizure 0.00012	queue 0.00011	improv 0.00011	session 0.00009

Test context:
***************
jam.n	1872	17	" in the early eighties wilson moved to new york and became a regular in various local __jam__ sessions .
Contexts for target jam are: ['nnI_sessions']
Contexts in vocabulary for target jam are: ['nnI_sessions']
Top most similar embeddings: jam 0.53380	sugarhill 0.38015	question/answer 0.37681	question-and-answer 0.37408	rollerski 0.36868	jams 0.36061	break-out 0.36035	jamming 0.35812	fartlek 0.35677	aquafit 0.35373

Generated lemmatized results
***************
GENERATED	jam.n 1872 ::: sugarhill;rollerski;jamming;fartlek;aquafit;kirtan;tryout;gymboree;lambada;democs

Filtered results
***************
RANKED	jam.n 1872	session 0.30955	improv 0.30876	jelly 0.30541	riff 0.28437	gig 0.28111	blockage 0.27401	congestion 0.27381	malfunction 0.27103	queue 0.26835	preserve 0.25814	conserve 0.25355	seizure 0.25263

Test context:
***************
jam.n	1873	17	joe customer who prefers not to be named says : " well i went to a small __jam__ last night and got a really favorable response to the phantom .
Contexts for target jam are: ['det_a', 'amod_small', 'prep:toI_went']
Contexts in vocabulary for target jam are: ['det_a', 'amod_small', 'prep:toI_went']
Top most similar embeddings: jam 0.11229	sweetshop 0.10441	pawnshop 0.09833	waterhole 0.09455	toyshop 0.09392	boarding-house 0.09369	teashop 0.09312	public-house 0.09264	meeting-house 0.09229	trattoria 0.09185

Generated lemmatized results
***************
GENERATED	jam.n 1873 ::: sweetshop;pawnshop;waterhole;toyshop;teashop;trattoria;snowdrift;phonebox;tepee;bodega

Filtered results
***************
RANKED	jam.n 1873	gig 0.08020	jelly 0.07394	session 0.07200	queue 0.06820	blockage 0.06783	malfunction 0.06764	riff 0.06651	seizure 0.06327	improv 0.06116	congestion 0.05215	preserve 0.05007	conserve 0.04415

Test context:
***************
jam.n	1874	2	i have __jam__ inside of me and i am fried in hot oil .
Contexts for target jam are: ['dobjI_have']
Contexts in vocabulary for target jam are: ['dobjI_have']
Top most similar embeddings: jam 0.47908	mojito 0.38103	jams 0.37739	ribeye 0.36249	chapatti 0.35799	strudel 0.35458	dibs 0.35340	habbit 0.35295	sizzler 0.35196	chinwag 0.35189

Generated lemmatized results
***************
GENERATED	jam.n 1874 ::: mojito;ribeye;chapatti;strudel;dibs;habbit;sizzler;chinwag;baklava;disfigurement

Filtered results
***************
RANKED	jam.n 1874	jelly 0.31335	queue 0.30297	gig 0.30237	malfunction 0.30017	session 0.29802	blockage 0.29605	riff 0.29462	seizure 0.29246	congestion 0.29023	preserve 0.26834	improv 0.26807	conserve 0.24611

Test context:
***************
jam.n	1875	31	in north america , the carotenoid pigment canthaxanthin is approved for use as a colorant to many food products , including , soft drinks , salad dressings , fruit juices , __jams__ and jellies , cheese products , imitation crab , soups , candies , tomato products , relishes , and packaged and/or smoked fish and meat to name just a few .
Contexts for target jams are: ['conjI_drinks']
Contexts in vocabulary for target jams are: ['conjI_drinks']
Top most similar embeddings: jams 0.52855	sodas 0.41912	ice-creams 0.40471	savouries 0.40441	sorbets 0.40342	pretzels 0.40246	sundaes 0.40227	toasties 0.40149	teacakes 0.39931	snacks 0.39881

Generated lemmatized results
***************
GENERATED	jam.n 1875 ::: soda;savoury;sorbet;pretzel;sundae;toasties;teacake;snack;custard;samosa

Filtered results
***************
RANKED	jam.n 1875	jelly 0.36751	queue 0.34272	preserve 0.33771	congestion 0.31780	riff 0.30528	conserve 0.30460	session 0.29840	gig 0.29569	malfunction 0.28732	blockage 0.27649	seizure 0.26997	improv 0.26640

Test context:
***************
jam.n	1876	8	cleaned after every shoot , fires great no __jams__ no misfires .
Contexts for target jams are: ['amod_great', 'det_no', 'dobjI_fires', 'dep_misfires']
Contexts in vocabulary for target jams are: ['amod_great', 'det_no', 'dobjI_fires']
Top most similar embeddings: jams 0.10754	jam 0.08454	arguements 0.08443	wheelspin 0.08356	explosions 0.08274	fireballs 0.08203	enthusiam 0.08177	gashes 0.08148	tussles 0.08143	rejoicings 0.08136

Generated lemmatized results
***************
GENERATED	jam.n 1876 ::: arguements;wheelspin;explosion;fireball;enthusiam;gash;tussle;rejoicing;outcry;cliffhanger

Filtered results
***************
RANKED	jam.n 1876	queue 0.07694	riff 0.07637	gig 0.07333	blockage 0.06850	jelly 0.06807	congestion 0.06752	malfunction 0.06359	improv 0.06009	seizure 0.05975	session 0.05878	preserve 0.05240	conserve 0.04850

Test context:
***************
jam.n	1877	21	that group is highly affluent , highly educated white suburbanites , and they really do care about getting stuck in traffic __jams__ more than they care about the 40 percent unemployment rate in roxbury .
Contexts for target jams are: ['nn_traffic', 'prep:inI_stuck']
Contexts in vocabulary for target jams are: ['nn_traffic', 'prep:inI_stuck']
Top most similar embeddings: jams 0.30122	jam 0.23255	tailbacks 0.21978	gridlock 0.20360	tailback 0.20059	queues 0.19968	congestion 0.19272	bottlenecks 0.18661	traffic 0.18376	chicanes 0.18324

Generated lemmatized results
***************
GENERATED	jam.n 1877 ::: tailback;gridlock;queue;congestion;bottleneck;traffic;chicane;rut;delay;chaos

Filtered results
***************
RANKED	jam.n 1877	queue 0.19968	congestion 0.19272	jelly 0.15536	blockage 0.15092	malfunction 0.13481	gig 0.13402	riff 0.13256	session 0.12888	seizure 0.12485	preserve 0.12031	improv 0.11695	conserve 0.11502

Test context:
***************
jam.n	1878	5	with their transcendent , improvisational __jams__ and mayan-inspired sense of a higher , metaphysical purpose , the band 's music delivers a spiritual sustenance that has earned them a very devoted core following .
Contexts for target jams are: ['poss_their', 'amod_transcendent', 'punct_,', 'amod_improvisational', 'prep:withI_delivers', 'cc_and', 'conj_sense']
Contexts in vocabulary for target jams are: ['poss_their', 'amod_transcendent', 'punct_,', 'amod_improvisational', 'prep:withI_delivers', 'cc_and', 'conj_sense']
Top most similar embeddings: flamboyance 0.00656	virtuosity 0.00651	lyricism 0.00642	musicality 0.00632	deftness 0.00624	quirkiness 0.00618	rawness 0.00614	expressivity 0.00610	directness 0.00608	earthiness 0.00606

Generated lemmatized results
***************
GENERATED	jam.n 1878 ::: flamboyance;virtuosity;lyricism;musicality;deftness;quirkiness;rawness;expressivity;directness;earthiness

Filtered results
***************
RANKED	jam.n 1878	riff 0.00551	improv 0.00378	gig 0.00320	malfunction 0.00316	congestion 0.00308	blockage 0.00289	jelly 0.00273	preserve 0.00266	queue 0.00265	seizure 0.00255	conserve 0.00246	session 0.00245

Test context:
***************
jam.n	1879	19	create systems to give accurate internet " weather reports " will track anomalous slowdowns , stoppages , and traffic __jams__ .
Contexts for target jams are: ['nn_traffic', 'conjI_slowdowns']
Contexts in vocabulary for target jams are: ['nn_traffic']
Top most similar embeddings: jams 0.55379	jam 0.43321	tailbacks 0.41049	congestion 0.39741	rat-running 0.37797	queues 0.37797	gridlock 0.37722	bottlenecks 0.37632	tailback 0.37410	hold-ups 0.37067

Generated lemmatized results
***************
GENERATED	jam.n 1879 ::: tailback;congestion;queue;gridlock;bottleneck;chicane;delay;crash;snarl;routings

Filtered results
***************
RANKED	jam.n 1879	congestion 0.39741	queue 0.37797	jelly 0.33789	blockage 0.31667	malfunction 0.30106	gig 0.29100	riff 0.29043	session 0.28294	seizure 0.27808	preserve 0.27730	conserve 0.27525	improv 0.25720

Test context:
***************
jam.n	1880	28	so stretch ' what if you put these information-carrying patterns on your copier , and you could pop your interface on and figure out how to clear a __jam__ ?
Contexts for target jam are: ['det_a', 'dobjI_clear']
Contexts in vocabulary for target jam are: ['det_a', 'dobjI_clear']
Top most similar embeddings: jam 0.25396	mess 0.18893	tailback 0.18864	snowdrift 0.18605	jams 0.17913	zit 0.17799	letter-box 0.17733	plughole 0.17671	habbit 0.17546	u-bend 0.17502

Generated lemmatized results
***************
GENERATED	jam.n 1880 ::: mess;tailback;snowdrift;zit;plughole;habbit;bottleneck;wobbler;chockstone;blockage

Filtered results
***************
RANKED	jam.n 1880	blockage 0.17328	jelly 0.16792	queue 0.15741	malfunction 0.15367	session 0.14447	riff 0.14445	gig 0.13989	seizure 0.13823	congestion 0.13600	improv 0.12043	preserve 0.11701	conserve 0.10082

Test context:
***************
lead.n	1881	14	today , there are much simpler licenses in use that are available to spec __leads__ .
Contexts for target leads are: ['nsubj_licenses', 'ccompI_are']
Contexts in vocabulary for target leads are: ['nsubj_licenses', 'ccompI_are']
Top most similar embeddings: leads 0.20647	lead 0.17089	led 0.15786	entitles 0.15783	entitle 0.15575	feeds 0.15549	infringes 0.15471	availible 0.15424	interchangable 0.15335	substitutable 0.15334

Generated lemmatized results
***************
GENERATED	lead.n 1881 ::: led;entitles;entitle;feed;infringes;availible;interchangable;substitutable;ensue;require

Filtered results
***************
RANKED	lead.n 1881	conduct 0.12945	flex 0.12514	head 0.11681	wire 0.11512	hint 0.11461	cable 0.11363	clue 0.11316	influential 0.11216	example 0.11209	leash 0.11130	tip 0.10670	direction 0.10367	leader 0.10351	enticement 0.10245	opportunity 0.10232	ahead 0.10141	prospect 0.10086	foray 0.09898	star 0.09705	halter 0.09162	guidance 0.09153	precedence 0.09085	story 0.09013	forefront 0.08903	initiative 0.08570

Test context:
***************
lead.n	1882	10	it 's really a small world tommy palamone , future __lead__ of the pittsburghers , took a community-sponsored ceramics course during junior high school .
Contexts for target lead are: ['amod_future', 'apposI_palamone', 'prep:of_pittsburghers']
Contexts in vocabulary for target lead are: ['amod_future']
Top most similar embeddings: lead 0.42851	leads 0.34772	cashflows 0.32716	co-lead 0.32118	prosperity 0.31365	shape 0.31251	beckons 0.31250	development 0.31120	developments 0.31052	expeditioners 0.30966

Generated lemmatized results
***************
GENERATED	lead.n 1882 ::: cashflows;prosperity;shape;beckons;development;expeditioners;leader;devolvement;breakout;ascendance

Filtered results
***************
RANKED	lead.n 1882	leader 0.30943	direction 0.30030	opportunity 0.29644	conduct 0.28864	prospect 0.28822	initiative 0.28770	star 0.27801	foray 0.27593	guidance 0.27554	cable 0.27416	head 0.27258	forefront 0.27070	clue 0.26950	flex 0.26893	leash 0.26799	influential 0.26308	enticement 0.26062	wire 0.25953	hint 0.25767	ahead 0.25612	tip 0.25394	story 0.25304	precedence 0.25115	example 0.24811	halter 0.24010

Test context:
***************
lead.n	1883	8	some people start a new goat on the __lead__ by tying it the first few times and letting the goat fight against the rope until it gives up .
Contexts for target lead are: ['det_the', 'prep:onI_goat']
Contexts in vocabulary for target lead are: ['det_the']
Top most similar embeddings: lead 0.48503	side-netting 0.37532	a189 0.35669	minerva-press 0.35653	d666 0.35621	holeshot 0.35538	homesters 0.35520	otherhand 0.35457	a696 0.35430	co-lead 0.35371

Generated lemmatized results
***************
GENERATED	lead.n 1883 ::: holeshot;homesters;otherhand;erlle;winline;snazzmattazz;backburner;adenda;hastle;pouder

Filtered results
***************
RANKED	lead.n 1883	forefront 0.31595	leader 0.31415	leash 0.31087	opportunity 0.30611	wire 0.30533	halter 0.30406	cable 0.30277	clue 0.29995	enticement 0.29837	direction 0.29706	prospect 0.29399	head 0.29150	tip 0.29063	initiative 0.29032	story 0.28940	conduct 0.28370	star 0.28335	flex 0.28243	influential 0.28082	hint 0.27737	precedence 0.27595	guidance 0.27480	example 0.27006	foray 0.26190	ahead 0.24235

Test context:
***************
lead.n	1884	15	after a year or two of stage-two rises , general investors follow the contrarians ' __lead__ into gold and push it even higher .
Contexts for target lead are: ['poss_contrarians', 'dobjI_follow', 'prep:into_gold']
Contexts in vocabulary for target lead are: ['dobjI_follow', 'prep:into_gold']
Top most similar embeddings: lead 0.26923	leads 0.18789	leading 0.15975	led 0.15367	rightwards 0.14970	a90 0.14923	inexorably 0.14879	transmute 0.14784	blindly 0.14762	turn 0.14749

Generated lemmatized results
***************
GENERATED	lead.n 1884 ::: leading;led;rightwards;inexorably;transmute;blindly;turn;arsenic;metamorphose;plunge

Filtered results
***************
RANKED	lead.n 1884	clue 0.13643	leader 0.12924	leash 0.12904	flex 0.12791	direction 0.12771	wire 0.12702	halter 0.12650	tip 0.12468	head 0.12386	hint 0.12327	foray 0.12325	conduct 0.12125	example 0.11853	cable 0.11813	influential 0.11784	precedence 0.11715	star 0.11585	guidance 0.11168	forefront 0.11013	story 0.11012	initiative 0.10816	ahead 0.10811	enticement 0.10655	opportunity 0.10362	prospect 0.10047

Test context:
***************
lead.n	1885	18	and the family may absorb those depravity principles with time , and then it will soon follow their __leads__ , imitate their way of thinking , morals and style of clothing .
Contexts for target leads are: ['poss_their', 'dobjI_follow']
Contexts in vocabulary for target leads are: ['poss_their', 'dobjI_follow']
Top most similar embeddings: leads 0.22196	lead 0.19447	zags 0.17636	hunches 0.17572	waymarks 0.17316	self-interests 0.17310	peregrinations 0.16950	zigzags 0.16650	specialisations 0.16573	zig-zags 0.16551

Generated lemmatized results
***************
GENERATED	lead.n 1885 ::: zag;hunch;waymarks;peregrination;zigzag;specialisation;lifecycles;lust;instuctions;conscience

Filtered results
***************
RANKED	lead.n 1885	head 0.16366	clue 0.15601	leader 0.15266	direction 0.14738	story 0.14364	leash 0.14184	cable 0.14139	tip 0.14040	wire 0.13910	enticement 0.13675	foray 0.13615	halter 0.13412	prospect 0.13360	conduct 0.13267	hint 0.13233	flex 0.13094	example 0.13089	guidance 0.13072	star 0.12962	initiative 0.12926	opportunity 0.12732	precedence 0.12196	forefront 0.11031	influential 0.10727	ahead 0.10519

Test context:
***************
lead.n	1886	26	my students perform a wide variety of music and they can be found singing leading roles in their high school and college musical productions , singing __lead__ in rock and wedding bands , winning classical music competitions , singing at the summer conservatory of the papermill playhouse , and learning to sing so they can sing with local choirs .
Contexts for target lead are: ['nn_singing', 'conjI_roles', 'prep:in_bands']
Contexts in vocabulary for target lead are: ['nn_singing', 'conjI_roles', 'prep:in_bands']
Top most similar embeddings: lead 0.09340	roles 0.08011	vocalists 0.07251	animateurs 0.07199	repertoires 0.07159	co-lead 0.07023	positions 0.06967	harmonies 0.06911	ragas 0.06907	responsibilities 0.06900

Generated lemmatized results
***************
GENERATED	lead.n 1886 ::: role;vocalist;animateurs;repertoire;position;harmony;ragas;responsibility;cameo;proficiency

Filtered results
***************
RANKED	lead.n 1886	opportunity 0.06431	direction 0.06082	leader 0.06035	star 0.05836	cable 0.05730	head 0.05636	flex 0.05541	clue 0.05448	wire 0.05445	conduct 0.05427	tip 0.05265	prospect 0.05034	foray 0.05027	story 0.05020	influential 0.04964	leash 0.04964	example 0.04949	guidance 0.04912	precedence 0.04865	hint 0.04850	initiative 0.04795	enticement 0.04553	halter 0.04490	ahead 0.04351	forefront 0.04129

Test context:
***************
lead.n	1887	11	obtain an alligator clip-lead , and connect it to the gate __lead__ of the fet .
Contexts for target lead are: ['det_the', 'nn_gate', 'prep:toI_connect', 'prep:of_fet']
Contexts in vocabulary for target lead are: ['det_the', 'nn_gate', 'prep:toI_connect']
Top most similar embeddings: lead 0.10039	t-piece 0.08599	connector 0.08411	halyard 0.08271	headshunt 0.08270	stopcock 0.08186	substation 0.08156	fileserver 0.08140	socket 0.08124	m90 0.08112

Generated lemmatized results
***************
GENERATED	lead.n 1887 ::: connector;halyard;headshunt;stopcock;substation;fileserver;socket;lubricator;balun;multiplexor

Filtered results
***************
RANKED	lead.n 1887	wire 0.07816	cable 0.07494	leash 0.06631	halter 0.06261	direction 0.06059	head 0.06057	leader 0.06029	story 0.06024	clue 0.06024	opportunity 0.05905	flex 0.05856	tip 0.05811	initiative 0.05786	forefront 0.05734	star 0.05634	enticement 0.05557	precedence 0.05545	prospect 0.05426	example 0.05323	guidance 0.05275	hint 0.05261	foray 0.05172	conduct 0.05123	ahead 0.04772	influential 0.04239

Test context:
***************
lead.n	1888	6	meet for coffee early , swap __leads__ and get permission to contact if possible .
Contexts for target leads are: ['dep_meet', 'nsubj_swap', 'rootI_*root*', 'cc_and', 'conj_get', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target leads are: ['dep_meet', 'nsubj_swap', 'rootI_*root*', 'cc_and', 'conj_get', 'punct_.']
Top most similar embeddings: leads 0.01305	meets 0.01027	ensues 0.00955	organises 0.00953	helps 0.00948	lets 0.00947	starts 0.00936	lasts 0.00934	widens 0.00933	relents 0.00933

Generated lemmatized results
***************
GENERATED	lead.n 1888 ::: meet;ensues;organises;help;let;start;last;widens;relents;liaises

Filtered results
***************
RANKED	lead.n 1888	conduct 0.00877	flex 0.00743	head 0.00659	hint 0.00626	tip 0.00616	direction 0.00570	clue 0.00542	opportunity 0.00519	star 0.00512	foray 0.00507	leader 0.00494	example 0.00490	enticement 0.00479	prospect 0.00477	influential 0.00473	story 0.00469	wire 0.00447	cable 0.00432	leash 0.00428	ahead 0.00426	initiative 0.00422	guidance 0.00376	halter 0.00329	precedence 0.00327	forefront 0.00199

Test context:
***************
lead.n	1889	35	and as a result of president bush 's initiative , which he took as part of the g-8 presidency , and also the other changes in which the us , uk has been in the __lead__ , not least in afghanistan and iraq , you can now feel the winds of change blowing through the arab world .
Contexts for target lead are: ['det_the', 'prep:inI_been']
Contexts in vocabulary for target lead are: ['det_the', 'prep:inI_been']
Top most similar embeddings: lead 0.22369	offing 0.18539	hot-seat 0.18471	semi-darkness 0.18243	side-netting 0.18146	in-goal 0.18128	sin-bin 0.18112	mid-fifties 0.18020	doldrums 0.17828	ascendancy 0.17751

Generated lemmatized results
***************
GENERATED	lead.n 1889 ::: offing;doldrums;ascendancy;heavenlies;ascendency;woodshed;backseat;endzone;drydock;ascendance

Filtered results
***************
RANKED	lead.n 1889	forefront 0.16719	direction 0.14685	leash 0.14163	wire 0.14023	halter 0.13808	prospect 0.13751	head 0.13640	cable 0.13134	leader 0.13115	story 0.13068	conduct 0.12833	clue 0.12725	initiative 0.12654	flex 0.12602	opportunity 0.12596	precedence 0.12453	star 0.12445	tip 0.12392	enticement 0.12268	foray 0.12040	hint 0.11991	example 0.11966	guidance 0.11765	influential 0.11277	ahead 0.10625

Test context:
***************
lead.n	1890	26	iraqi security forces wo n't be able to handle major security challenges for some time to come , and wo n't be able to take the __lead__ in attacking insurgent strongholds before elections scheduled for january , senior iraqi officials and politicians said last week .
Contexts for target lead are: ['det_the', 'dobjI_take']
Contexts in vocabulary for target lead are: ['det_the', 'dobjI_take']
Top most similar embeddings: lead 0.25065	hindmost 0.19966	cudgels 0.19953	hastle 0.19679	a697 0.19610	holeshot 0.19567	backseat 0.19279	m275 0.19244	a435 0.19237	mini-pill 0.19081

Generated lemmatized results
***************
GENERATED	lead.n 1890 ::: hindmost;cudgel;hastle;holeshot;backseat;sliproad;bridlepath;rein;rowboat;advantage

Filtered results
***************
RANKED	lead.n 1890	opportunity 0.15979	precedence 0.15524	initiative 0.14720	leash 0.14691	halter 0.14647	direction 0.14594	wire 0.14492	cable 0.14322	forefront 0.14218	tip 0.14156	clue 0.14142	leader 0.14127	hint 0.14056	head 0.13894	enticement 0.13779	story 0.13448	example 0.13407	prospect 0.13373	star 0.13173	conduct 0.13149	flex 0.12862	guidance 0.12635	foray 0.12620	influential 0.11641	ahead 0.10603

Test context:
***************
paper.n	1891	20	it would seem that the downing street minutes are n't dead yet as the sunday times sourced a british briefing __paper__ stating ' that since regime change was illegal it was " necessary to create the conditions " which would make it legal. ' the philadelphia inquirer featured a thorough dick polman analysis of the downing street minutes .
Contexts for target paper are: ['det_a', 'amod_british', 'nn_briefing', 'dobjI_sourced', 'partmod_stating', 'rcmod_illegal']
Contexts in vocabulary for target paper are: ['det_a', 'amod_british', 'nn_briefing', 'dobjI_sourced', 'partmod_stating', 'rcmod_illegal']
Top most similar embeddings: paper 0.01279	papers 0.00901	pamphlet 0.00891	handbill 0.00891	memo 0.00886	non-paper 0.00880	dossier 0.00878	article 0.00834	document 0.00833	placard 0.00833

Generated lemmatized results
***************
GENERATED	paper.n 1891 ::: pamphlet;handbill;memo;dossier;article;document;placard;referendum;broadsheet;guideline

Filtered results
***************
RANKED	paper.n 1891	article 0.00834	document 0.00833	newspaper 0.00789	report 0.00737	essay 0.00731	publication 0.00716	thesis 0.00691	presentation 0.00687	papyrus 0.00670	manuscript 0.00670	treatise 0.00608	journal 0.00584	stationery 0.00576	study 0.00512	roll 0.00491

Test context:
***************
paper.n	1892	10	now ari fleischer , in a pitiful letter to the __paper__ , tries to cast milbank as the one getting his facts wrong .
Contexts for target paper are: ['det_the', 'prep:toI_letter']
Contexts in vocabulary for target paper are: ['det_the', 'prep:toI_letter']
Top most similar embeddings: paper 0.25179	uscc 0.19913	ctpa 0.19851	mca/csm 0.19447	r.c.s. 0.19228	strb 0.19124	torygraph 0.19078	wftu 0.19052	jyllands-posten 0.19013	uctl 0.18827

Generated lemmatized results
***************
GENERATED	paper.n 1892 ::: uscc;ctpa;strb;torygraph;wftu;uctl;fhsaa;izvestia;spcb;mhac

Filtered results
***************
RANKED	paper.n 1892	newspaper 0.18354	papyrus 0.16374	journal 0.15948	essay 0.15941	report 0.15920	manuscript 0.15760	thesis 0.15666	document 0.15661	publication 0.15427	article 0.15243	treatise 0.14866	roll 0.14414	presentation 0.13104	stationery 0.12608	study 0.12297

Test context:
***************
paper.n	1893	3	for a fremstad __paper__ with a sidebar that gives raw numbers , but not rates , to try to make it look as if poverty has increased sharply , go here .
Contexts for target paper are: ['det_a', 'amod_fremstad', 'prep:forI_try', 'prep:with_sidebar']
Contexts in vocabulary for target paper are: ['det_a', 'prep:forI_try']
Top most similar embeddings: paper 0.22328	sarnie 0.17582	nightcap 0.17184	re-match 0.17109	daytrip 0.17068	blotter 0.17019	fiver 0.17001	payrise 0.16993	hankie 0.16952	sickie 0.16906

Generated lemmatized results
***************
GENERATED	paper.n 1893 ::: sarnie;nightcap;daytrip;blotter;fiver;payrise;hankie;sickie;suntan;pullback

Filtered results
***************
RANKED	paper.n 1893	essay 0.15987	thesis 0.15773	publication 0.15295	newspaper 0.15294	presentation 0.15002	treatise 0.14982	document 0.14917	report 0.14892	papyrus 0.14560	article 0.14536	manuscript 0.14271	study 0.13962	roll 0.13824	stationery 0.13141	journal 0.12961

Test context:
***************
paper.n	1894	1	the __paper__ examines how " the party " uses every possible method to induce this control , including both positive and negative reinforcement , conformity , and the need for group identification .
Contexts for target paper are: ['det_the', 'nsubjI_examines']
Contexts in vocabulary for target paper are: ['det_the', 'nsubjI_examines']
Top most similar embeddings: paper 0.27844	snazzmattazz 0.18530	pamphlet 0.18461	report 0.18350	thesis 0.18260	wcd 0.18228	monograph 0.18225	papers 0.18059	bmla 0.18057	bhagavad-gita 0.18005

Generated lemmatized results
***************
GENERATED	paper.n 1894 ::: snazzmattazz;pamphlet;report;thesis;wcd;monograph;bmla;module;dayschool;edukators

Filtered results
***************
RANKED	paper.n 1894	report 0.18350	thesis 0.18260	article 0.17764	essay 0.17730	document 0.17581	publication 0.16924	newspaper 0.16381	study 0.16262	manuscript 0.16149	papyrus 0.16095	presentation 0.15927	treatise 0.15743	journal 0.15304	stationery 0.12864	roll 0.12595

Test context:
***************
paper.n	1895	6	there also wasn 't any toilet __paper__ left in any of the bathrooms .
Contexts for target paper are: ['det_any', 'nn_toilet', 'dobjI_t', 'partmod_left']
Contexts in vocabulary for target paper are: ['det_any', 'nn_toilet', 'dobjI_t', 'partmod_left']
Top most similar embeddings: paper 0.05043	papers 0.03935	debris 0.03826	stains 0.03811	scraps 0.03728	tissue 0.03713	pus 0.03580	off-cuts 0.03555	gunk 0.03548	goop 0.03515

Generated lemmatized results
***************
GENERATED	paper.n 1895 ::: debris;stain;scrap;tissue;pu;gunk;goop;residue;mug;offcuts

Filtered results
***************
RANKED	paper.n 1895	document 0.03309	newspaper 0.03144	article 0.03135	manuscript 0.02976	roll 0.02948	essay 0.02927	publication 0.02911	papyrus 0.02911	treatise 0.02867	stationery 0.02812	report 0.02672	thesis 0.02586	journal 0.02518	presentation 0.02425	study 0.02324

Test context:
***************
paper.n	1896	14	that is why virgin paper fiber is usually mixed with recycled paper when new __paper__ products are made .
Contexts for target paper are: ['nnI_products']
Contexts in vocabulary for target paper are: ['nnI_products']
Top most similar embeddings: paper 0.49122	paperboard 0.41083	ondistributor 0.39284	onimporter 0.39263	toiletry 0.38100	tyvek 0.37725	packet8 0.37672	freefoam 0.37596	burts 0.37593	snugglesafe 0.37582

Generated lemmatized results
***************
GENERATED	paper.n 1896 ::: paperboard;ondistributor;onimporter;toiletry;tyvek;freefoam;burt;snugglesafe;bioflow;petfood

Filtered results
***************
RANKED	paper.n 1896	newspaper 0.32796	papyrus 0.32371	stationery 0.31965	document 0.30450	publication 0.29810	essay 0.29523	presentation 0.29263	article 0.29053	thesis 0.28644	report 0.28378	manuscript 0.28304	journal 0.27590	study 0.26975	roll 0.26917	treatise 0.26342

Test context:
***************
paper.n	1897	2	the local __papers__ took photographs of the footprint .
Contexts for target papers are: ['det_the', 'amod_local', 'nsubjI_took']
Contexts in vocabulary for target papers are: ['det_the', 'amod_local', 'nsubjI_took']
Top most similar embeddings: papers 0.11064	emirs 0.09018	paper 0.08969	newspapers 0.08965	augustinians 0.08931	carabinieri 0.08882	ironmasters 0.08732	villagers 0.08714	bolsheviki 0.08712	govenment 0.08698

Generated lemmatized results
***************
GENERATED	paper.n 1897 ::: emir;newspaper;augustinian;carabinieri;ironmasters;villager;bolshevik;govenment;authorites;bigwig

Filtered results
***************
RANKED	paper.n 1897	newspaper 0.08965	presentation 0.07324	document 0.07179	manuscript 0.07053	publication 0.06909	essay 0.06895	journal 0.06841	report 0.06821	study 0.06796	treatise 0.06674	papyrus 0.06502	thesis 0.06445	article 0.06418	roll 0.06401	stationery 0.05658

Test context:
***************
paper.n	1898	27	such a shipment came from columbia , but bakers and retailers had to wait over two weeks as it remained on the kingston docks awaiting special clearance __papers__ from caricom .
Contexts for target papers are: ['amod_special', 'nn_clearance', 'dobjI_awaiting', 'prep:from_caricom']
Contexts in vocabulary for target papers are: ['amod_special', 'nn_clearance', 'dobjI_awaiting']
Top most similar embeddings: papers 0.11011	clearance 0.08483	clearances 0.08156	paper 0.08038	briefs 0.07965	verdicts 0.07963	certificates 0.07892	orders 0.07817	rulings 0.07798	determinations 0.07769

Generated lemmatized results
***************
GENERATED	paper.n 1898 ::: clearance;brief;verdict;certificate;order;ruling;determination;delivery;procedure;approval

Filtered results
***************
RANKED	paper.n 1898	document 0.07486	report 0.07478	manuscript 0.07036	publication 0.06995	article 0.06848	presentation 0.06759	essay 0.06581	stationery 0.06569	study 0.06563	journal 0.06509	papyrus 0.06493	newspaper 0.06308	roll 0.06223	thesis 0.06195	treatise 0.05962

Test context:
***************
paper.n	1899	10	this book is more than just a compendium of conference __papers__ , however .
Contexts for target papers are: ['nn_conference', 'prep:ofI_compendium']
Contexts in vocabulary for target papers are: ['nn_conference', 'prep:ofI_compendium']
Top most similar embeddings: papers 0.27513	preprints 0.20138	abstracts 0.19039	paper 0.18567	documents 0.18106	memoranda 0.17982	presentations 0.17835	summaries 0.17478	speeches 0.17333	pre-prints 0.17313

Generated lemmatized results
***************
GENERATED	paper.n 1899 ::: preprints;abstract;document;memoranda;presentation;summary;speech;report;monograph;webcasts

Filtered results
***************
RANKED	paper.n 1899	document 0.18106	presentation 0.17835	report 0.17197	article 0.16778	essay 0.16775	manuscript 0.16702	publication 0.16647	thesis 0.15820	treatise 0.15753	journal 0.15548	newspaper 0.15188	study 0.14995	papyrus 0.14234	roll 0.13366	stationery 0.13295

Test context:
***************
paper.n	1900	1	this __paper__ builds on the work of neil a. manson in order to show that the precautionary principle , in all of its forms , is fraught with vagueness and ambiguity .
Contexts for target paper are: ['det_this', 'nsubjI_builds']
Contexts in vocabulary for target paper are: ['det_this', 'nsubjI_builds']
Top most similar embeddings: paper 0.27078	half-module 0.21379	tlp 0.18726	one-pager 0.18694	module 0.18659	document 0.18456	chaper 0.18163	essay 0.17769	dayschool 0.17732	vmp 0.17647

Generated lemmatized results
***************
GENERATED	paper.n 1900 ::: tlp;module;document;chaper;essay;dayschool;vmp;pamphlet;report;article

Filtered results
***************
RANKED	paper.n 1900	document 0.18456	essay 0.17769	report 0.17526	article 0.17418	thesis 0.16972	publication 0.16717	study 0.15706	papyrus 0.15681	treatise 0.15443	manuscript 0.15327	newspaper 0.15000	presentation 0.14773	journal 0.13971	roll 0.12611	stationery 0.12555

Test context:
***************
pass.v	1901	4	a year before congress __passed__ the 1970 legislation , it enacted the federal coal mine health and safety act of 1969 .
Contexts for target passed are: ['dep_year', 'mark_before', 'nsubj_congress', 'advclI_enacted', 'dobj_legislation']
Contexts in vocabulary for target passed are: ['dep_year', 'mark_before', 'nsubj_congress', 'advclI_enacted', 'dobj_legislation']
Top most similar embeddings: passed 0.03167	enacted 0.02692	repealed 0.02240	ratifies 0.02167	vetoed 0.02114	reconvenes 0.02103	prorogued 0.02094	passes 0.02079	finalises 0.02075	enact 0.02072

Generated lemmatized results
***************
GENERATED	pass.v 1901 ::: enact;repeal;ratify;veto;reconvene;prorogue;finalise;introduce;legislate;abolish

Filtered results
***************
RANKED	pass.v 1901	ratify 0.02167	approve 0.01974	adopt 0.01859	elapse 0.01698	authorise 0.01677	expire 0.01668	hand 0.01602	skirt 0.01508	succeed 0.01503	proceed 0.01499	occur 0.01476	navigate 0.01471	approach 0.01464	flow 0.01445	finish 0.01432	see 0.01421	give 0.01420	satisfy 0.01417	transfer 0.01357	go 0.01321	send 0.01313	deliver 0.01312	leak 0.01306	disappear 0.01304	traverse 0.01228	transpire 0.01212	experience 0.01069

Test context:
***************
pass.v	1902	30	at the turn of the century , the school inspector and leading educationalist joshua fitch noted that between 1878 and 1898 a higher percentage of women than of men had __passed__ the university of london 's matriculation examination .
Contexts for target passed are: ['mark_than', 'aux_had', 'depI_between', 'dobj_university']
Contexts in vocabulary for target passed are: ['mark_than', 'aux_had', 'depI_between', 'dobj_university']
Top most similar embeddings: passed 0.04864	contracted 0.03893	elapsed 0.03750	imagined 0.03732	quitted 0.03681	entered 0.03624	defied 0.03603	defrauded 0.03594	inherited 0.03582	voted 0.03581

Generated lemmatized results
***************
GENERATED	pass.v 1902 ::: contract;elapse;imagine;quit;enter;defy;defraud;inherit;vote;attend

Filtered results
***************
RANKED	pass.v 1902	elapse 0.03750	succeed 0.03513	approach 0.03349	transfer 0.03262	experience 0.03261	traverse 0.03259	expire 0.03225	flow 0.03211	finish 0.03187	occur 0.03178	adopt 0.03152	proceed 0.03149	approve 0.03138	see 0.03138	ratify 0.03128	go 0.03120	satisfy 0.03075	disappear 0.03043	hand 0.03028	skirt 0.02988	navigate 0.02953	leak 0.02915	deliver 0.02911	authorise 0.02900	send 0.02867	transpire 0.02800	give 0.02790

Test context:
***************
pass.v	1903	10	as you walked out to the mailbox , you would __pass__ two white birch seedlings on your left , a douglas fir to the right , and pass between two holly bushes...one male and the other female .
Contexts for target pass are: ['advcl_walked', 'punct_,', 'nsubj_you', 'aux_would', 'rootI_*root*', 'dobj_seedlings', 'prep:on_left', 'punct_,', 'dobj_fir', 'punct_,', 'cc_and', 'conj_pass', 'punct_...', 'dep_male', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target pass are: ['advcl_walked', 'punct_,', 'nsubj_you', 'aux_would', 'rootI_*root*', 'dobj_seedlings', 'prep:on_left', 'punct_,', 'dobj_fir', 'punct_,', 'cc_and', 'conj_pass', 'punct_...', 'dep_male', 'punct_.']
Top most similar embeddings: pass 0.00002	cower 0.00002	loitered 0.00001	loll 0.00001	exhale 0.00001	unwrap 0.00001	hissed 0.00001	tutted 0.00001	ascend 0.00001	skirted 0.00001

Generated lemmatized results
***************
GENERATED	pass.v 1903 ::: cower;loiter;loll;exhale;unwrap;hiss;tutted;ascend;skirt;blink

Filtered results
***************
RANKED	pass.v 1903	skirt 0.00001	traverse 0.00001	approach 0.00001	see 0.00001	disappear 0.00001	succeed 0.00001	flow 0.00001	transpire 0.00001	hand 0.00001	proceed 0.00001	navigate 0.00001	finish 0.00001	authorise 0.00001	expire 0.00001	go 0.00001	give 0.00001	send 0.00001	occur 0.00001	experience 0.00001	approve 0.00001	elapse 0.00001	transfer 0.00001	adopt 0.00001	leak 0.00001	deliver 0.00001	satisfy 0.00001	ratify 0.00000

Test context:
***************
pass.v	1904	57	i would be the first to capture not only the haggis on film , but to be able to record this event for all to see - future generations would remember my name - women would flock to my door , i 'd tour the world giving lectures on haggis , heads of state would nod while __passing__ me in the street !
Contexts for target passing are: ['pcompI_while', 'dobj_me', 'prep:in_street']
Contexts in vocabulary for target passing are: ['pcompI_while', 'dobj_me', 'prep:in_street']
Top most similar embeddings: passing 0.12367	burgling 0.09331	harrassing 0.09125	ogling 0.09102	serenading 0.08987	reproaching 0.08817	pawing 0.08750	plonking 0.08742	spooking 0.08695	plying 0.08676

Generated lemmatized results
***************
GENERATED	pass.v 1904 ::: burgle;harrassing;ogle;serenade;reproach;paw;plonk;spook;ply;snog

Filtered results
***************
RANKED	pass.v 1904	hand 0.08468	approach 0.07153	skirt 0.07132	see 0.07101	traverse 0.06906	flow 0.06845	finish 0.06663	send 0.06611	transpire 0.06606	transfer 0.06553	expire 0.06466	navigate 0.06455	authorise 0.06234	give 0.06161	disappear 0.06134	proceed 0.05991	leak 0.05966	deliver 0.05964	succeed 0.05927	satisfy 0.05876	approve 0.05827	adopt 0.05717	occur 0.05672	ratify 0.05670	experience 0.05391	go 0.05389	elapse 0.05026

Test context:
***************
pass.v	1905	21	i ai n't promisin ' a date just yet , but come back ' round in a fortnight and i 'll __pass__ along more information about the establishments in vol .
Contexts for target pass are: ['nsubj_round', "aux_'ll", 'depI_promisin', 'prep:along_information']
Contexts in vocabulary for target pass are: ['nsubj_round', "aux_'ll"]
Top most similar embeddings: pass 0.23003	passes 0.17340	passed 0.16609	passing 0.16508	kick 0.15581	shove 0.15559	fizzle 0.15436	take 0.15312	dissapoint 0.15282	knock 0.15256

Generated lemmatized results
***************
GENERATED	pass.v 1905 ::: kick;shove;fizzle;take;dissapoint;knock;throw;wend;slip;stumble

Filtered results
***************
RANKED	pass.v 1905	finish 0.14598	see 0.14495	disappear 0.14474	go 0.14310	give 0.14255	hand 0.14106	succeed 0.13717	deliver 0.13643	expire 0.13561	approach 0.13460	elapse 0.13434	send 0.13400	skirt 0.13320	satisfy 0.13303	transpire 0.13199	traverse 0.13195	proceed 0.13157	ratify 0.12694	navigate 0.12621	flow 0.12610	approve 0.12359	adopt 0.12209	occur 0.12007	authorise 0.11792	transfer 0.11722	leak 0.11547	experience 0.11323

Test context:
***************
pass.v	1906	28	test this by cloning toy and printing the result. [ add comment ] change checkcloneable.java so that all of the clone( ) methods catch the clonenotsupportedexception rather than __passing__ it to the caller. [ add comment ] using the mutable-companion-class technique , make an immutable class containing an int , a double and an array of char .
Contexts for target passing are: ['pcompI_than', 'dobj_it', 'prep:to_caller']
Contexts in vocabulary for target passing are: ['pcompI_than', 'dobj_it', 'prep:to_caller']
Top most similar embeddings: passing 0.13068	passed 0.09172	handing 0.08946	offloading 0.08894	scrawling 0.08884	pass 0.08825	bequeathing 0.08790	allotting 0.08682	plonking 0.08647	ramming 0.08646

Generated lemmatized results
***************
GENERATED	pass.v 1906 ::: hand;offload;scrawl;bequeath;allot;plonk;ram;legging;swipe;return

Filtered results
***************
RANKED	pass.v 1906	hand 0.08946	transfer 0.08103	send 0.08086	give 0.07684	ratify 0.07535	traverse 0.07155	see 0.07008	approve 0.06991	flow 0.06929	finish 0.06839	approach 0.06816	deliver 0.06804	expire 0.06782	navigate 0.06693	skirt 0.06679	authorise 0.06679	leak 0.06529	satisfy 0.06509	adopt 0.06357	disappear 0.06172	proceed 0.06170	succeed 0.06164	experience 0.06001	transpire 0.05954	elapse 0.05751	go 0.05718	occur 0.05661

Test context:
***************
pass.v	1907	11	the fourth cup raises a slight perspiration,--all the wrong of life __passes__ away through my pores .
Contexts for target passes are: ['nsubj_wrong', 'parataxisI_raises', 'advmod_away', 'prep:through_pores']
Contexts in vocabulary for target passes are: ['nsubj_wrong', 'parataxisI_raises', 'advmod_away', 'prep:through_pores']
Top most similar embeddings: passes 0.05635	pass 0.04589	percolates 0.04094	evaporates 0.04015	migrates 0.03962	diffuses 0.03880	diverts 0.03855	pours 0.03842	disappears 0.03834	propagates 0.03829

Generated lemmatized results
***************
GENERATED	pass.v 1907 ::: percolate;evaporate;migrate;diffuse;divert;pour;disappear;propagate;dissipate;melt

Filtered results
***************
RANKED	pass.v 1907	disappear 0.03834	flow 0.03733	traverse 0.03326	go 0.03275	leak 0.03234	occur 0.03206	navigate 0.03057	send 0.03004	transpire 0.02836	deliver 0.02786	elapse 0.02738	proceed 0.02663	see 0.02620	expire 0.02615	transfer 0.02614	give 0.02580	approve 0.02563	skirt 0.02536	finish 0.02517	succeed 0.02485	ratify 0.02478	adopt 0.02430	hand 0.02429	satisfy 0.02375	approach 0.02285	authorise 0.02142	experience 0.01946

Test context:
***************
pass.v	1908	7	well , i 'm sure it will __pass__ .
Contexts for target pass are: ['nsubj_it', 'aux_will', 'ccompI_sure']
Contexts in vocabulary for target pass are: ['nsubj_it', 'aux_will', 'ccompI_sure']
Top most similar embeddings: pass 0.11821	curdle 0.09216	passed 0.08946	passes 0.08942	apear 0.08888	reoccur 0.08860	over-write 0.08795	re-occur 0.08773	happen 0.08720	dissapoint 0.08514

Generated lemmatized results
***************
GENERATED	pass.v 1908 ::: curdle;apear;reoccur;happen;dissapoint;fizzle;percolate;outlast;vaporize;suceed

Filtered results
***************
RANKED	pass.v 1908	transpire 0.08132	disappear 0.07941	expire 0.07757	succeed 0.07690	satisfy 0.07655	give 0.07510	deliver 0.07394	leak 0.07340	go 0.07325	occur 0.07205	proceed 0.07130	elapse 0.07112	ratify 0.07046	approve 0.06984	traverse 0.06936	navigate 0.06800	finish 0.06784	send 0.06767	adopt 0.06675	flow 0.06629	transfer 0.06616	hand 0.06583	see 0.06542	authorise 0.06482	approach 0.06356	skirt 0.05893	experience 0.05885

Test context:
***************
pass.v	1909	11	arguably , the expected renaissance of the 30-year treasury bond must __pass__ muster with the foreigners , a group that 's been more than accommodating in buyer lesser-maturity instruments in recent years and thereby financing america 's trade and fiscal deficits .
Contexts for target pass are: ['advmod_arguably', 'punct_,', 'nsubj_renaissance', 'aux_must', 'rootI_*root*', 'dobj_muster', 'prep:with_foreigners', 'punct_,', 'npadvmod_group', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target pass are: ['advmod_arguably', 'punct_,', 'nsubj_renaissance', 'aux_must', 'rootI_*root*', 'dobj_muster', 'prep:with_foreigners', 'punct_,', 'npadvmod_group', 'punct_.']
Top most similar embeddings: passed 0.00049	pass 0.00048	passes 0.00045	re-established 0.00039	retaken 0.00039	flowed 0.00038	bypassed 0.00038	intensified 0.00038	endowed 0.00037	prospered 0.00037

Generated lemmatized results
***************
GENERATED	pass.v 1909 ::: retake;flow;bypass;intensify;endow;prosper;succeed;rest;linger;ensue

Filtered results
***************
RANKED	pass.v 1909	flow 0.00038	succeed 0.00036	traverse 0.00034	skirt 0.00034	proceed 0.00032	transpire 0.00031	approach 0.00031	elapse 0.00031	occur 0.00030	hand 0.00029	adopt 0.00028	satisfy 0.00027	ratify 0.00027	navigate 0.00027	see 0.00027	expire 0.00027	experience 0.00026	transfer 0.00026	leak 0.00026	deliver 0.00026	go 0.00026	disappear 0.00026	finish 0.00025	approve 0.00025	give 0.00024	authorise 0.00023	send 0.00023

Test context:
***************
pass.v	1910	9	this makes the reader realize that what they just __passed__ through , is just fiction , the writer , its creator , is like god in the fictional world and we are at the end not any closer to the truth than we were at the beginning .
Contexts for target passed are: ['dobj_what', 'nsubj_they', 'advmod_just', 'advclI_is', 'advmod_through', 'dep_fiction']
Contexts in vocabulary for target passed are: ['dobj_what', 'nsubj_they', 'advmod_just', 'advclI_is', 'advmod_through', 'dep_fiction']
Top most similar embeddings: passed 0.01144	gotten 0.00923	passing 0.00908	percieve 0.00907	pass 0.00894	whizzed 0.00882	gone 0.00879	got 0.00870	lusted 0.00849	deem 0.00846

Generated lemmatized results
***************
GENERATED	pass.v 1910 ::: get;percieve;whiz;go;lust;deem;come;stumble;overhear;think

Filtered results
***************
RANKED	pass.v 1910	go 0.00879	flow 0.00791	see 0.00761	disappear 0.00734	succeed 0.00707	navigate 0.00704	experience 0.00680	transpire 0.00678	finish 0.00675	leak 0.00674	occur 0.00673	approach 0.00664	proceed 0.00649	traverse 0.00648	skirt 0.00640	hand 0.00638	send 0.00638	expire 0.00629	approve 0.00624	deliver 0.00623	transfer 0.00616	give 0.00612	satisfy 0.00606	elapse 0.00583	adopt 0.00558	ratify 0.00540	authorise 0.00525

Test context:
***************
poor.a	1911	12	many of the jokes fall flat in this movie due to the __poor__ delivery of lines .
Contexts for target poor are: ['amodI_delivery']
Contexts in vocabulary for target poor are: ['amodI_delivery']
Top most similar embeddings: poor 0.50274	less-than-perfect 0.38603	much-improved 0.37820	poor-quality 0.37206	sub-standard 0.37002	poorer 0.36881	lousy 0.36851	near-perfect 0.36648	poorest 0.36522	ever-improving 0.36381

Generated lemmatized results
***************
GENERATED	poor.a 1911 ::: lousy;lackluster;mediocre;inadequate;timeous;shoddy;underprivileged;speedy;apalling;suboptimal

Filtered results
***************
RANKED	poor.a 1911	mediocre 0.35760	inadequate 0.35594	underprivileged 0.35186	substandard 0.34913	weak 0.34597	impoverished 0.34062	unsatisfactory 0.33636	needy 0.33379	deficient 0.33286	bad 0.33001	indigent 0.32683	low 0.32176	wretched 0.32002	incompetent 0.32000	miserable 0.31174	hapless 0.31156	pitiable 0.30696	destitute 0.30691	inferior 0.29671	unlucky 0.29641	unfortunate 0.29234	unhappy 0.28749	deprived 0.27991	infertile 0.27044	developing 0.26556	sorry 0.26202

Test context:
***************
poor.a	1912	28	do n't let all that flash and glitter blind you to the fact that there 's quite a lot of fun to be had without cruelly murdering your __poor__ piggy bank .
Contexts for target poor are: ['amodI_bank']
Contexts in vocabulary for target poor are: ['amodI_bank']
Top most similar embeddings: poor 0.46946	account-holding 0.37952	poorest 0.36861	high-income 0.36358	resource-rich 0.36260	kent-based 0.36231	much-improved 0.36144	non-poor 0.36122	ever-improving 0.36070	poverty-stricken 0.36041

Generated lemmatized results
***************
GENERATED	poor.a 1912 ::: lousy;necessitous;ailing;mediocre;weak;dismal;bermudian;underprivileged;indigent;monied

Filtered results
***************
RANKED	poor.a 1912	mediocre 0.34748	weak 0.34640	underprivileged 0.34359	indigent 0.34175	impoverished 0.34105	low 0.33724	wretched 0.33449	needy 0.32946	inadequate 0.32815	hapless 0.32721	bad 0.32603	substandard 0.32124	miserable 0.31689	incompetent 0.31600	destitute 0.31407	unsatisfactory 0.31403	deficient 0.31237	pitiable 0.30277	inferior 0.29758	unfortunate 0.29611	infertile 0.29591	deprived 0.29140	unlucky 0.28702	unhappy 0.28599	developing 0.26951	sorry 0.26199

Test context:
***************
poor.a	1913	22	i was groaning to a friend that we ca n't go in sept or oct any more since that would mean pulling __poor__ liza out of a very demanding middle school , so that 's it , we just ca n't go and she finally said to me " irene , there are other tour operators ... " no , no there are n't .
Contexts for target poor are: ['amodI_liza']
Contexts in vocabulary for target poor are: []
Top most similar embeddings: poor 1.00000	poorest 0.79061	poorer 0.76873	non-poor 0.75987	necessitous 0.75787	underprivileged 0.75030	down-trodden 0.74807	less-than-perfect 0.74228	under-privileged 0.73809	weak 0.73702

Generated lemmatized results
***************
GENERATED	poor.a 1913 ::: necessitous;underprivileged;weak;indigent;downtrodden;impoverished;poors;needy;mediocre;lousy

Filtered results
***************
RANKED	poor.a 1913	underprivileged 0.75030	weak 0.73702	indigent 0.72782	impoverished 0.71907	needy 0.71781	mediocre 0.71670	inadequate 0.70552	wretched 0.69358	bad 0.69202	deficient 0.68754	destitute 0.68482	substandard 0.68379	unsatisfactory 0.67959	miserable 0.66612	pitiable 0.66133	low 0.65801	hapless 0.65642	incompetent 0.64401	inferior 0.63546	unlucky 0.63413	unfortunate 0.63016	infertile 0.62586	deprived 0.61974	unhappy 0.61708	sorry 0.58141	developing 0.57753

Test context:
***************
poor.a	1914	9	we also concluded that abstracts alone might be a __poor__ resource for identifying genes in a paper ( see table 6 ) : for fly , only 25 % of genes on the full text gene list were mentioned in the abstract .
Contexts for target poor are: ['amodI_resource']
Contexts in vocabulary for target poor are: ['amodI_resource']
Top most similar embeddings: poor 0.46923	patient-oriented 0.36385	underutilised 0.36359	much-valued 0.36038	poorer 0.36007	excellent 0.36001	highly-developed 0.35979	much-improved 0.35946	rich 0.35913	www-based 0.35891

Generated lemmatized results
***************
GENERATED	poor.a 1914 ::: underutilised;excellent;rich;downtrodden;lousy;excelent;impoverished;suberb;unutilised;superb

Filtered results
***************
RANKED	poor.a 1914	impoverished 0.34755	underprivileged 0.34206	inadequate 0.33903	weak 0.33871	indigent 0.33629	needy 0.33340	mediocre 0.32735	deficient 0.32698	unsatisfactory 0.32464	wretched 0.31873	substandard 0.31795	low 0.31582	pitiable 0.31169	bad 0.30551	destitute 0.30498	miserable 0.29868	incompetent 0.29853	inferior 0.29784	hapless 0.29777	unfortunate 0.29051	infertile 0.28869	deprived 0.28509	unlucky 0.27488	developing 0.27057	unhappy 0.26587	sorry 0.26381

Test context:
***************
poor.a	1915	9	brian disilvestro ( verity ) made the point that __poor__ quality metadata can make search worse , and that metadata needs to be kept up to date using dynamic classification tools .
Contexts for target poor are: ['amodI_metadata']
Contexts in vocabulary for target poor are: ['amodI_metadata']
Top most similar embeddings: poor 0.47321	poorest 0.36552	poorer 0.36476	item-level 0.35967	poor-quality 0.35915	rich 0.35580	publicly-available 0.35574	non-numerical 0.35502	non-textual 0.35386	low-quality 0.35093

Generated lemmatized results
***************
GENERATED	poor.a 1915 ::: rich;inadequate;weak;unprivileged;impoverished;deficient;untagged;unindexed;shoddy;underprivileged

Filtered results
***************
RANKED	poor.a 1915	inadequate 0.34959	weak 0.34357	impoverished 0.33829	deficient 0.33574	underprivileged 0.33417	mediocre 0.32856	needy 0.32060	bad 0.32046	unsatisfactory 0.32040	low 0.30968	substandard 0.30926	wretched 0.30858	indigent 0.30803	destitute 0.30454	inferior 0.29927	incompetent 0.29212	miserable 0.28306	hapless 0.28163	pitiable 0.27322	unfortunate 0.26969	deprived 0.26933	infertile 0.26841	sorry 0.26617	unhappy 0.26235	unlucky 0.26152	developing 0.25426

Test context:
***************
poor.a	1916	6	it was too much for the __poor__ reporter from our paper of record : what does that make you? he asked in uncomprehending exasperation .
Contexts for target poor are: ['amodI_reporter']
Contexts in vocabulary for target poor are: ['amodI_reporter']
Top most similar embeddings: poor 0.47857	impecunious 0.38204	irish-born 0.38094	dim-witted 0.37812	luckless 0.37542	76-year-old 0.37527	hapless 0.37498	cretinous 0.37486	72-year-old 0.37473	poorest 0.37335

Generated lemmatized results
***************
GENERATED	poor.a 1916 ::: impecunious;luckless;hapless;cretinous;untalented;downtrodden;mediocre;youngish;mousy;innumerate

Filtered results
***************
RANKED	poor.a 1916	hapless 0.37498	mediocre 0.36653	underprivileged 0.35270	indigent 0.34790	impoverished 0.34752	weak 0.34406	needy 0.34080	wretched 0.33996	bad 0.33055	incompetent 0.32188	inadequate 0.32138	substandard 0.31937	miserable 0.31534	pitiable 0.31386	destitute 0.31355	unsatisfactory 0.31297	unfortunate 0.30709	unlucky 0.30564	low 0.29823	deficient 0.29713	infertile 0.29215	inferior 0.29200	unhappy 0.29065	deprived 0.28203	sorry 0.27857	developing 0.24821

Test context:
***************
poor.a	1917	15	sow direct onto the soil , with a bit of compost if the soil is __poor__ , then water and let nature do the rest .
Contexts for target poor are: ['mark_if', 'nsubj_soil', 'cop_is', 'advclI_sow', 'punct_,', 'advmod_then', 'dep_water', 'cc_and', 'conj_let']
Contexts in vocabulary for target poor are: ['mark_if', 'nsubj_soil', 'cop_is', 'advclI_sow', 'punct_,', 'advmod_then', 'dep_water', 'cc_and', 'conj_let']
Top most similar embeddings: poor 0.00130	moist 0.00127	aerated 0.00120	wet 0.00117	acidic 0.00116	parched 0.00114	manured 0.00114	weak 0.00113	moistened 0.00113	thirsty 0.00113

Generated lemmatized results
***************
GENERATED	poor.a 1917 ::: moist;aerated;wet;acidic;parched;manured;weak;moistened;thirsty;mulched

Filtered results
***************
RANKED	poor.a 1917	weak 0.00113	deficient 0.00100	infertile 0.00099	substandard 0.00089	mediocre 0.00089	inadequate 0.00087	unsatisfactory 0.00086	bad 0.00083	destitute 0.00082	wretched 0.00080	miserable 0.00078	inferior 0.00078	impoverished 0.00078	unlucky 0.00076	unhappy 0.00074	low 0.00073	needy 0.00072	unfortunate 0.00066	incompetent 0.00064	indigent 0.00063	pitiable 0.00057	deprived 0.00055	underprivileged 0.00052	sorry 0.00051	hapless 0.00036	developing 0.00030

Test context:
***************
poor.a	1918	19	document history date reason september 14 , 2005 added sections on tax avoidance , havens , their impacts on __poor__ countries , etc. june 3 , 2005 added a section on us tax shelters and the impact to the us economy .
Contexts for target poor are: ['amodI_countries']
Contexts in vocabulary for target poor are: ['amodI_countries']
Top most similar embeddings: poor 0.53569	poorest 0.43826	least-developed 0.42893	poorer 0.42358	resource-rich 0.41782	less-developed 0.41684	non-annex 0.41534	non-english-speaking 0.41000	high-income 0.40784	non-poor 0.40527

Generated lemmatized results
***************
GENERATED	poor.a 1918 ::: needy;impoverished;underprivileged;underdeveloped;wealthy;malarious;necessitous;affluent;weak;rich

Filtered results
***************
RANKED	poor.a 1918	needy 0.39294	impoverished 0.38490	underprivileged 0.38374	weak 0.36232	indigent 0.36088	wretched 0.34218	low 0.34049	destitute 0.33841	mediocre 0.33074	deficient 0.32745	inadequate 0.32316	developing 0.32228	hapless 0.32066	bad 0.31757	miserable 0.31032	unsatisfactory 0.31029	substandard 0.30960	deprived 0.30710	pitiable 0.30387	inferior 0.30299	incompetent 0.30255	unlucky 0.30075	infertile 0.30072	unfortunate 0.29501	unhappy 0.29274	sorry 0.26523

Test context:
***************
poor.a	1919	9	i am convinced , that the spirit of the __poorer__ classes being as represented , prevalent drunkenness would have led unavoidably to the gravest disorders .
Contexts for target poorer are: ['amodI_classes']
Contexts in vocabulary for target poorer are: ['amodI_classes']
Top most similar embeddings: poorer 0.53417	wealthier 0.42567	mixed-age 0.41038	richer 0.40888	propertied 0.40854	upper-middle 0.40618	lower-income 0.40491	poorest 0.40455	better-off 0.39919	mixed-ability 0.39618

Generated lemmatized results
***************
GENERATED	poor.a 1919 ::: wealthy;rich;propertied;humble;monied;underprivileged;impoverished;weak;affluent;leisured

Filtered results
***************
RANKED	poor.a 1919	underprivileged 0.38747	impoverished 0.38564	weak 0.38091	needy 0.37098	low 0.36343	inferior 0.35156	destitute 0.33522	substandard 0.33410	indigent 0.33320	wretched 0.33291	mediocre 0.33101	bad 0.32902	deficient 0.32224	miserable 0.32164	infertile 0.31341	deprived 0.31202	hapless 0.30693	unsatisfactory 0.30197	pitiable 0.29305	inadequate 0.29132	incompetent 0.28979	unfortunate 0.28708	unhappy 0.28270	developing 0.27776	unlucky 0.26792	sorry 0.25950

Test context:
***************
poor.a	1920	6	to thee do we cry , __poor__ banished children of eve , to thee do we send up our sighs , mourning and weeping in this valley of tears .
Contexts for target poor are: ['amodI_children']
Contexts in vocabulary for target poor are: ['amodI_children']
Top most similar embeddings: poor 0.52437	under-privileged 0.43534	life-limited 0.43145	necessitous 0.42912	underprivileged 0.42700	poorest 0.42223	terminally-ill 0.41458	primary-aged 0.41350	indigent 0.40879	poorer 0.40857

Generated lemmatized results
***************
GENERATED	poor.a 1920 ::: necessitous;underprivileged;indigent;needy;maladjusted;unchurched;nonworking;nonpoor;teenaged;fatherless

Filtered results
***************
RANKED	poor.a 1920	underprivileged 0.42700	indigent 0.40879	needy 0.40278	impoverished 0.38114	destitute 0.36594	weak 0.35857	deficient 0.35551	wretched 0.35470	mediocre 0.35315	substandard 0.34016	inadequate 0.33790	hapless 0.33489	bad 0.33376	pitiable 0.33345	miserable 0.32944	deprived 0.32650	unsatisfactory 0.31658	low 0.31630	incompetent 0.31511	unfortunate 0.31452	infertile 0.31261	unlucky 0.31236	inferior 0.30715	unhappy 0.30684	sorry 0.27910	developing 0.27693

Test context:
***************
rest.n	1921	36	since the mid-1990s , india also boasts a much-larger number of software facilities certified to the " gold standard " of the u.s. defense department-inspired cmm capability maturity model , than america , europe and the __rest__ of the world combined .
Contexts for target rest are: ['det_the', 'conjI_america', 'prep:of_world']
Contexts in vocabulary for target rest are: ['det_the', 'conjI_america', 'prep:of_world']
Top most similar embeddings: rest 0.14699	remainder 0.10345	antipodes 0.09560	nordics 0.09170	baltics 0.08999	breadbasket 0.08868	far-east 0.08795	parts 0.08653	continent 0.08551	hurly-burly 0.08516

Generated lemmatized results
***************
GENERATED	rest.n 1921 ::: remainder;antipode;nordic;baltic;breadbasket;part;continent;phillipines;toiler;seaboard

Filtered results
***************
RANKED	rest.n 1921	remainder 0.10345	repose 0.07140	comfort 0.07133	base 0.06630	inactivity 0.06172	balance 0.06003	remains 0.05913	convenience 0.05868	prop 0.05649	sleep 0.05627	leisure 0.05359	respite 0.05309	quiet 0.05109	layby 0.05069	break 0.04998	service 0.04995	stand 0.04712	stick 0.04633	support 0.04559

Test context:
***************
rest.n	1922	1	the __rest__ is up to you .
Contexts for target rest are: ['det_the', 'nsubjI_is']
Contexts in vocabulary for target rest are: ['det_the', 'nsubjI_is']
Top most similar embeddings: rest 0.26075	remainder 0.21198	erlle 0.18651	down-side 0.18518	tathagata 0.18493	upshot 0.18479	chillow 0.18366	coachee 0.18254	e-ram 0.18178	twin-center 0.18117

Generated lemmatized results
***************
GENERATED	rest.n 1922 ::: remainder;erlle;tathagata;upshot;chillow;coachee;lycosa;jobholder;onus;otherside

Filtered results
***************
RANKED	rest.n 1922	remainder 0.21198	repose 0.15989	layby 0.15485	comfort 0.15172	balance 0.14811	respite 0.14666	base 0.14451	convenience 0.13980	service 0.13832	inactivity 0.13804	sleep 0.13407	break 0.12943	remains 0.12938	prop 0.12660	support 0.12658	leisure 0.12000	stick 0.11981	stand 0.11863	quiet 0.10992

Test context:
***************
rest.n	1923	9	king 's room ) where the offset of the __rest__ of the rooms begins .
Contexts for target rest are: ['det_the', 'prep:ofI_offset', 'prep:of_rooms']
Contexts in vocabulary for target rest are: ['det_the', 'prep:ofI_offset', 'prep:of_rooms']
Top most similar embeddings: rest 0.11994	remainder 0.10356	subarray 0.08316	y-coordinate 0.08067	start/end 0.08067	subregion 0.08038	interstices 0.08008	recesses 0.07893	centroid 0.07833	centre-line 0.07787

Generated lemmatized results
***************
GENERATED	rest.n 1923 ::: remainder;subarray;subregion;interstice;recess;centroid;vastness;subsequence;paucity;linewidth

Filtered results
***************
RANKED	rest.n 1923	remainder 0.10356	repose 0.06845	comfort 0.06734	base 0.06439	layby 0.06433	remains 0.06404	convenience 0.06278	balance 0.06178	inactivity 0.05813	sleep 0.05781	respite 0.05614	prop 0.05563	break 0.05454	service 0.05256	quiet 0.04942	stick 0.04840	stand 0.04668	support 0.04639	leisure 0.04580

Test context:
***************
rest.n	1924	4	a little bit of __rest__ and relaxation is waiting for michelle after the college national finals rodeo ( cnfr ) .
Contexts for target rest are: ['prep:ofI_bit']
Contexts in vocabulary for target rest are: ['prep:ofI_bit']
Top most similar embeddings: rest 0.48625	remainder 0.35705	muchness 0.35440	faff 0.34643	bitchiness 0.34570	wackiness 0.34499	kip 0.34454	r&r 0.34323	philosophising 0.34193	legwork 0.34174

Generated lemmatized results
***************
GENERATED	rest.n 1924 ::: remainder;muchness;faff;bitchiness;wackiness;kip;philosophising;legwork;excitment;blather

Filtered results
***************
RANKED	rest.n 1924	remainder 0.35705	repose 0.32855	respite 0.32702	sleep 0.31912	comfort 0.30686	inactivity 0.29146	break 0.28879	stick 0.28694	prop 0.28372	quiet 0.27692	leisure 0.27378	balance 0.26997	support 0.26659	base 0.26569	stand 0.26484	convenience 0.26157	layby 0.25920	remains 0.25589	service 0.24969

Test context:
***************
rest.n	1925	8	it also crossed as a seat or shooting __rest__ when i stalked within range i would load an arrow or have the gun on my shoulder and the bucket in the other hand .
Contexts for target rest are: ['mark_as', 'nsubj_seat', 'advclI_load']
Contexts in vocabulary for target rest are: ['mark_as', 'nsubj_seat', 'advclI_load']
Top most similar embeddings: rest 0.09144	rests 0.08332	recline 0.08197	rested 0.07901	reclines 0.07812	dims 0.07750	reclined 0.07741	rotates 0.07707	slid 0.07647	follows 0.07596

Generated lemmatized results
***************
GENERATED	rest.n 1925 ::: recline;rested;reclines;dims;reclined;rotates;slid;follows;pinged;retracts

Filtered results
***************
RANKED	rest.n 1925	repose 0.06459	remains 0.06456	stand 0.06455	sleep 0.06440	stick 0.06317	prop 0.05931	support 0.05909	quiet 0.05663	break 0.05507	remainder 0.05339	base 0.05074	balance 0.05039	comfort 0.04976	respite 0.04950	convenience 0.04525	layby 0.04390	leisure 0.04281	inactivity 0.04111	service 0.02929

Test context:
***************
rest.n	1926	11	on some of the major a roads , you will find __rest__ stops , just like on the motorways .
Contexts for target rest are: ['nnI_stops']
Contexts in vocabulary for target rest are: ['nnI_stops']
Top most similar embeddings: rest 0.49829	remainder 0.36871	resting 0.35282	refreshment 0.34183	rested 0.34171	refuelling 0.33279	hoodmoulds 0.33270	hoodmould 0.32892	recuperation 0.32545	rests 0.32322

Generated lemmatized results
***************
GENERATED	rest.n 1926 ::: remainder;resting;refreshment;rested;refuelling;hoodmould;recuperation;vaporetto;scuffling;chamfer

Filtered results
***************
RANKED	rest.n 1926	remainder 0.36871	comfort 0.30670	sleep 0.30100	repose 0.29906	respite 0.29756	layby 0.29338	leisure 0.28124	convenience 0.27515	base 0.27004	prop 0.26845	balance 0.26250	break 0.26142	support 0.26053	service 0.26028	inactivity 0.26016	quiet 0.25704	stick 0.25326	remains 0.24864	stand 0.24791

Test context:
***************
rest.n	1927	2	traded the __rest__ of my misery for a new option ... " " option this , *bleep* !
Contexts for target rest are: ['det_the', 'dobjI_traded', 'prep:of_misery']
Contexts in vocabulary for target rest are: ['det_the', 'dobjI_traded', 'prep:of_misery']
Top most similar embeddings: rest 0.10844	remainder 0.09039	bucketload 0.08546	mundanity 0.08235	winepress 0.08233	clutches 0.08174	bucketful 0.08111	shackles 0.08102	deeps 0.08080	coat-tails 0.07993

Generated lemmatized results
***************
GENERATED	rest.n 1927 ::: remainder;bucketload;mundanity;winepress;clutch;bucketful;shackle;deep;drudgery;toil

Filtered results
***************
RANKED	rest.n 1927	remainder 0.09039	comfort 0.07095	repose 0.06788	convenience 0.06171	balance 0.06139	base 0.06092	sleep 0.06061	inactivity 0.05838	layby 0.05823	remains 0.05755	prop 0.05666	respite 0.05655	break 0.05533	stick 0.05260	leisure 0.05065	stand 0.05018	service 0.05004	support 0.04726	quiet 0.04615

Test context:
***************
rest.n	1928	41	faced with a surfeit of both ads and world news , arthur [ sulzberger , publisher of the new york times ] made the critical choice not to accept all the ads the times was offered , instead filling up the __rest__ of the paper with breaking stories .
Contexts for target rest are: ['det_the', 'dobjI_filling', 'prep:of_paper']
Contexts in vocabulary for target rest are: ['det_the', 'dobjI_filling', 'prep:of_paper']
Top most similar embeddings: rest 0.13146	remainder 0.11166	interstices 0.09049	rootball 0.08935	insides 0.08778	bilges 0.08670	recesses 0.08405	butt-end 0.08339	makings 0.08335	underside 0.08294

Generated lemmatized results
***************
GENERATED	rest.n 1928 ::: remainder;interstice;rootball;inside;bilge;recess;making;underside;corrugation;counterfoil

Filtered results
***************
RANKED	rest.n 1928	remainder 0.11166	repose 0.06970	base 0.06881	comfort 0.06475	layby 0.06370	convenience 0.06264	balance 0.06207	remains 0.06137	stick 0.05823	prop 0.05807	sleep 0.05789	inactivity 0.05751	respite 0.05530	break 0.05489	service 0.05473	stand 0.05260	leisure 0.04994	support 0.04938	quiet 0.04594

Test context:
***************
rest.n	1929	30	the gardeners and the homeowners association oversee crops and efforts such as the control of mosquitoes and other pests ; they stock year-round creeks with mosquito fish and design the __rest__ of the streams to drain within two or three days. one of the streams that is part of the system of natural filters a reasonable yearly fee goes towards the care of village homes ' green belts , swimming pool , community center , and open spaces .
Contexts for target rest are: ['det_the', 'nsubjI_drain', 'prep:of_streams']
Contexts in vocabulary for target rest are: ['det_the', 'nsubjI_drain', 'prep:of_streams']
Top most similar embeddings: rest 0.10765	remainder 0.09358	headwaters 0.09024	floodwaters 0.08681	corrugations 0.08395	floodwater 0.08318	bilges 0.08297	shallows 0.08142	rivulets 0.08138	filtrate 0.08124

Generated lemmatized results
***************
GENERATED	rest.n 1929 ::: remainder;headwater;floodwaters;corrugation;floodwater;bilge;shallow;rivulet;filtrate;supernatant

Filtered results
***************
RANKED	rest.n 1929	remainder 0.09358	repose 0.06577	base 0.06219	balance 0.06210	layby 0.06198	convenience 0.06076	comfort 0.06025	inactivity 0.05954	remains 0.05762	sleep 0.05699	break 0.05412	respite 0.05383	service 0.05379	prop 0.05145	leisure 0.04950	quiet 0.04849	stick 0.04775	support 0.04736	stand 0.04707

Test context:
***************
rest.n	1930	1	the __rest__ is tinkering , magic , forbidden games .
Contexts for target rest are: ['det_the', 'nsubjI_tinkering']
Contexts in vocabulary for target rest are: ['det_the', 'nsubjI_tinkering']
Top most similar embeddings: rest 0.25876	remainder 0.19630	glazers 0.17931	powers-that-be 0.17061	bolsheviki 0.16955	tremere 0.16826	strs 0.16676	beckhams 0.16429	sontarans 0.16312	eurocrats 0.16304

Generated lemmatized results
***************
GENERATED	rest.n 1930 ::: remainder;glazer;bolshevik;tremere;strs;beckhams;sontarans;eurocrats;missus;kaptain

Filtered results
***************
RANKED	rest.n 1930	remainder 0.19630	repose 0.13789	respite 0.12650	inactivity 0.12328	comfort 0.12232	sleep 0.12196	convenience 0.12118	balance 0.12108	break 0.11577	leisure 0.11550	prop 0.11478	remains 0.11365	base 0.11344	layby 0.11263	service 0.11203	stick 0.10965	quiet 0.10501	stand 0.10399	support 0.10315

Test context:
***************
right.r	1931	11	spin of getting its politics out there , getting its politics __right__ .
Contexts for target right are: ['advmodI_getting']
Contexts in vocabulary for target right are: ['advmodI_getting']
Top most similar embeddings: right 0.51334	proably 0.36304	actaully 0.35933	belly-up 0.35853	somwhere 0.35416	eventualy 0.35409	defintely 0.35319	acutally 0.35305	scot-free 0.35274	probally 0.34995

Generated lemmatized results
***************
GENERATED	right.r 1931 ::: proably;actaully;somwhere;eventualy;defintely;acutally;probally;probly;tiddly;sleepily

Filtered results
***************
RANKED	right.r 1931	well 0.33903	just 0.32805	straight 0.31623	immediately 0.30433	directly 0.30074	exactly 0.30037	correct 0.29923	properly 0.29760	correctly 0.29518	totally 0.28918	accurately 0.27153	straightaway 0.26177	appropriate 0.26003

Test context:
***************
right.r	1932	8	i 've got to get them to market __right__ away .
Contexts for target right are: ['advmodI_away']
Contexts in vocabulary for target right are: ['advmodI_away']
Top most similar embeddings: right 0.53566	sullenly 0.36077	worriedly 0.35735	imediately 0.35665	straight 0.35106	yerself 0.35081	absent-mindedly 0.35006	noiselessly 0.34830	unerringly 0.34685	nimbly 0.34625

Generated lemmatized results
***************
GENERATED	right.r 1932 ::: sullenly;worriedly;imediately;straight;yerself;noiselessly;unerringly;nimbly;precipitously;somwhere

Filtered results
***************
RANKED	right.r 1932	straight 0.35106	well 0.31314	just 0.29835	totally 0.29672	correctly 0.29428	immediately 0.29384	directly 0.29296	properly 0.29116	correct 0.28855	exactly 0.28018	straightaway 0.27980	accurately 0.26929	appropriate 0.25707

Test context:
***************
right.r	1933	3	the compass pointed __right__ towards this land .
Contexts for target right are: ['advmodI_pointed', 'prep:towards_land']
Contexts in vocabulary for target right are: ['advmodI_pointed', 'prep:towards_land']
Top most similar embeddings: right 0.19946	sleepily 0.17853	unerringly 0.17611	languidly 0.17584	imperiously 0.17553	menacingly 0.17498	obliquely 0.17344	noiselessly 0.17285	heavenward 0.17264	dejectedly 0.17255

Generated lemmatized results
***************
GENERATED	right.r 1933 ::: sleepily;unerringly;languidly;imperiously;menacingly;obliquely;noiselessly;heavenward;dejectedly;unsteadily

Filtered results
***************
RANKED	right.r 1933	straight 0.15211	correctly 0.14411	directly 0.13871	immediately 0.13749	accurately 0.13452	properly 0.12357	just 0.12004	exactly 0.11858	well 0.11839	correct 0.11772	totally 0.11197	straightaway 0.11118	appropriate 0.10603

Test context:
***************
right.r	1934	22	the clever little fella made a web near the back light so when all the moths circle the light they just fly __right__ into his web .
Contexts for target right are: ['advmodI_fly']
Contexts in vocabulary for target right are: ['advmodI_fly']
Top most similar embeddings: right 0.47596	belly-up 0.36028	imediately 0.35450	absent-mindedly 0.35365	proably 0.34993	sleepily 0.34886	acrobatically 0.34874	noiselessly 0.34869	jauntily 0.34815	nimbly 0.34574

Generated lemmatized results
***************
GENERATED	right.r 1934 ::: imediately;proably;sleepily;acrobatically;noiselessly;jauntily;nimbly;dejectedly;breezily;temptingly

Filtered results
***************
RANKED	right.r 1934	straight 0.33039	directly 0.31695	just 0.31169	correctly 0.30806	well 0.30576	immediately 0.30316	properly 0.30094	correct 0.29761	exactly 0.29220	accurately 0.28588	totally 0.28001	straightaway 0.27969	appropriate 0.27142

Test context:
***************
right.r	1935	17	if you take the time to work on a problem , take the time to do it __right__ .
Contexts for target right are: ['advmodI_do']
Contexts in vocabulary for target right are: ['advmodI_do']
Top most similar embeddings: right 0.49482	proably 0.37549	defintely 0.36717	actaully 0.36468	probally 0.36255	imediately 0.36085	usally 0.36063	acutally 0.35523	deffinately 0.35460	wrong 0.35445

Generated lemmatized results
***************
GENERATED	right.r 1935 ::: proably;defintely;actaully;probally;imediately;usally;acutally;deffinately;wrong;doubtlessly

Filtered results
***************
RANKED	right.r 1935	well 0.33694	just 0.32429	properly 0.31817	straightaway 0.31696	correctly 0.31286	exactly 0.31178	straight 0.30865	immediately 0.30818	directly 0.29976	correct 0.29208	totally 0.28589	accurately 0.28581	appropriate 0.26981

Test context:
***************
right.r	1936	13	everyone in business is guilty of wasting time , be they the receptionist __right__ through to the ceo .
Contexts for target right are: ['nsubj_receptionist', 'rcmodI_they']
Contexts in vocabulary for target right are: ['nsubj_receptionist', 'rcmodI_they']
Top most similar embeddings: right 0.19324	bawled 0.15178	purposed 0.14859	hearkened 0.14787	correct 0.14765	exclaim 0.14661	sayd 0.14611	teachable 0.14576	nosy 0.14557	importunate 0.14537

Generated lemmatized results
***************
GENERATED	right.r 1936 ::: bawled;purposed;hearkened;correct;exclaim;sayd;teachable;nosy;importunate;wrong

Filtered results
***************
RANKED	right.r 1936	correct 0.14765	straight 0.12466	totally 0.11717	well 0.11569	straightaway 0.11549	appropriate 0.11490	correctly 0.11159	exactly 0.10349	accurately 0.10172	immediately 0.09981	directly 0.09963	properly 0.09445	just 0.09186

Test context:
***************
right.r	1937	11	it means freedom to choose the setting for birth that is __right__ for you and your family without regard for the prevailing political or cultural climate .
Contexts for target right are: ['nsubj_that', 'cop_is', 'rcmodI_birth', 'prep:for_you', 'prep:without_regard']
Contexts in vocabulary for target right are: ['nsubj_that', 'cop_is', 'rcmodI_birth', 'prep:for_you', 'prep:without_regard']
Top most similar embeddings: right 0.02612	needful 0.01875	wrong 0.01784	birthright 0.01775	correct 0.01765	prerogative 0.01758	convenient 0.01743	predestined 0.01740	imputed 0.01728	sanctified 0.01721

Generated lemmatized results
***************
GENERATED	right.r 1937 ::: needful;wrong;birthright;correct;prerogative;convenient;predestined;imputed;sanctified;permissible

Filtered results
***************
RANKED	right.r 1937	correct 0.01765	appropriate 0.01638	well 0.01365	straight 0.01263	straightaway 0.01171	totally 0.01167	correctly 0.01123	accurately 0.01002	exactly 0.00892	immediately 0.00797	just 0.00789	properly 0.00778	directly 0.00721

Test context:
***************
right.r	1938	10	my baby son started acting far more confidently and independently __right__ after the name change to zale .
Contexts for target right are: ['advmod_confidently', 'advmodI_acting', 'prep:after_change']
Contexts in vocabulary for target right are: ['advmod_confidently', 'advmodI_acting', 'prep:after_change']
Top most similar embeddings: right 0.08646	unilaterally 0.07195	decisively 0.07169	pre-emptively 0.07134	unpredictably 0.07129	involuntarily 0.07122	calmly 0.07115	rationally 0.07108	arrogantly 0.07018	courageously 0.06996

Generated lemmatized results
***************
GENERATED	right.r 1938 ::: unilaterally;decisively;unpredictably;involuntarily;calmly;rationally;arrogantly;courageously;ominously;noiselessly

Filtered results
***************
RANKED	right.r 1938	immediately 0.06622	correctly 0.06592	straight 0.06337	accurately 0.06243	totally 0.05906	correct 0.05887	well 0.05757	properly 0.05619	exactly 0.05446	directly 0.05395	straightaway 0.05139	just 0.05091	appropriate 0.04861

Test context:
***************
right.r	1939	0	__right__ from the beginning of training , a dog should never be permitted to ignore a command or fail to carry it out completely .
Contexts for target right are: ['advmodI_from']
Contexts in vocabulary for target right are: ['advmodI_from']
Top most similar embeddings: right 0.51892	precariously 0.34886	straight 0.34256	imediately 0.34178	involuntarily 0.33766	precipitously 0.33689	appreciably 0.33606	belly-up 0.33572	disproportionately 0.33292	proably 0.33272

Generated lemmatized results
***************
GENERATED	right.r 1939 ::: precariously;straight;imediately;involuntarily;precipitously;appreciably;disproportionately;proably;horizontally;actaully

Filtered results
***************
RANKED	right.r 1939	straight 0.34256	directly 0.32238	just 0.31931	immediately 0.31238	totally 0.30137	well 0.30029	exactly 0.29443	correct 0.29306	properly 0.29225	correctly 0.28134	appropriate 0.26543	accurately 0.26044	straightaway 0.25399

Test context:
***************
right.r	1940	4	stand on the platform __right__ under him .
Contexts for target right are: ['depI_stand', 'prep:under_him']
Contexts in vocabulary for target right are: ['depI_stand', 'prep:under_him']
Top most similar embeddings: right 0.19793	cross-legged 0.15616	upside-down 0.15544	hunched 0.15473	bared 0.15296	unmoving 0.15111	upright 0.15095	slouched 0.15070	diagonally 0.15012	stiffly 0.14942

Generated lemmatized results
***************
GENERATED	right.r 1940 ::: hunched;bared;unmoving;upright;slouched;diagonally;stiffly;whereon;straighter;rycht

Filtered results
***************
RANKED	right.r 1940	straight 0.13195	straightaway 0.13152	correct 0.12906	well 0.12786	correctly 0.11886	accurately 0.11272	exactly 0.11184	immediately 0.11071	directly 0.11031	totally 0.10989	appropriate 0.10599	properly 0.10237	just 0.10215

Test context:
***************
ring.n	1941	26	6. smartklamp ( picture of the smartklamp ) this works in the same general way as the tara klamp by trapping the foreskin between an outer __ring__ and an inner tube , and thus cutting off the blood supply to the foreskin .
Contexts for target ring are: ['det_an', 'amod_outer', 'prep:betweenI_foreskin', 'cc_and', 'conj_tube']
Contexts in vocabulary for target ring are: ['det_an', 'amod_outer', 'cc_and', 'conj_tube']
Top most similar embeddings: ring 0.05840	annulus 0.04665	rings 0.04559	chainring 0.04495	operculum 0.04491	forestay 0.04435	baseplate 0.04434	crankcase 0.04411	armature 0.04384	tube 0.04376

Generated lemmatized results
***************
GENERATED	ring.n 1941 ::: annulus;chainring;operculum;forestay;baseplate;crankcase;armature;tube;atomiser;gusset

Filtered results
***************
RANKED	ring.n 1941	rim 0.04056	coil 0.04022	loop 0.03976	hoop 0.03777	circle 0.03675	orbit 0.03614	fob 0.03406	chime 0.03372	circlet 0.03346	bell 0.03211	chain 0.03104	tone 0.03024	holder 0.02963	band 0.02955	sound 0.02872	shadow 0.02795	call 0.02654	network 0.02569	level 0.02557	feel 0.02469	connotation 0.02432	syndicate 0.02416	group 0.02368	association 0.02212

Test context:
***************
ring.n	1942	30	the handle incorporates a wire spring gated clip , what schrade calls a ' plunger device, ' to allow you to quickly clip or unclip the knife from a key __ring__ .
Contexts for target ring are: ['det_a', 'amod_key', 'prep:fromI_clip']
Contexts in vocabulary for target ring are: ['det_a', 'amod_key', 'prep:fromI_clip']
Top most similar embeddings: ring 0.11430	rings 0.08311	fob 0.08094	strop 0.08010	earring 0.07949	paperclip 0.07798	clip 0.07786	bracelet 0.07684	locket 0.07664	jig 0.07650

Generated lemmatized results
***************
GENERATED	ring.n 1942 ::: fob;strop;earring;paperclip;clip;bracelet;locket;jig;sequence;strongpoint

Filtered results
***************
RANKED	ring.n 1942	fob 0.08094	hoop 0.07333	chain 0.06936	circle 0.06908	bell 0.06771	loop 0.06739	coil 0.06681	circlet 0.06591	tone 0.06554	rim 0.06509	chime 0.06363	shadow 0.06232	call 0.06231	band 0.06128	syndicate 0.06109	group 0.06009	holder 0.05977	orbit 0.05976	sound 0.05868	network 0.05789	connotation 0.05787	level 0.05195	association 0.04667	feel 0.04516

Test context:
***************
ring.n	1943	3	there were dark __rings__ under his eyes , and , somehow , in some indefinable manner , he seemed years older , a broken old man .
Contexts for target rings are: ['amod_dark', 'nsubjI_were', 'prep:under_eyes']
Contexts in vocabulary for target rings are: ['amod_dark', 'nsubjI_were', 'prep:under_eyes']
Top most similar embeddings: rings 0.12747	ringlets 0.09018	blotches 0.09013	gashes 0.09009	ear-rings 0.09005	festoons 0.08993	speckles 0.08949	streaks 0.08920	circles 0.08851	haloes 0.08830

Generated lemmatized results
***************
GENERATED	ring.n 1943 ::: ringlet;blotch;gash;festoon;speckle;streak;circle;halo;cloak;cartouch

Filtered results
***************
RANKED	ring.n 1943	circle 0.08851	shadow 0.08457	hoop 0.08016	tone 0.07368	band 0.07149	circlet 0.07140	rim 0.06994	chain 0.06882	loop 0.06833	coil 0.06708	chime 0.06691	orbit 0.06649	bell 0.06587	syndicate 0.05933	fob 0.05898	level 0.05853	call 0.05799	connotation 0.05654	association 0.05520	sound 0.05431	network 0.05325	group 0.05272	holder 0.05191	feel 0.04001

Test context:
***************
ring.n	1944	1	this __ring__ is open to all sites with a product or service to sell online .
Contexts for target ring are: ['det_this', 'nsubjI_open']
Contexts in vocabulary for target ring are: ['det_this', 'nsubjI_open']
Top most similar embeddings: ring 0.22565	rings 0.17882	locket 0.16387	floodgate 0.16288	exhibtion 0.16095	hatchway 0.16038	amulet 0.15998	wormhole 0.15905	snowpark 0.15882	pousada 0.15874

Generated lemmatized results
***************
GENERATED	ring.n 1944 ::: locket;floodgate;exhibtion;hatchway;amulet;wormhole;snowpark;pousada;tlp;exhibition

Filtered results
***************
RANKED	ring.n 1944	circle 0.15115	call 0.14689	coil 0.14635	loop 0.14480	rim 0.14318	hoop 0.14289	chime 0.14162	chain 0.14002	band 0.13991	bell 0.13973	circlet 0.13858	fob 0.13696	group 0.13685	orbit 0.13501	network 0.13335	tone 0.13278	sound 0.12635	holder 0.12605	syndicate 0.12370	shadow 0.12295	connotation 0.11989	level 0.11765	association 0.11662	feel 0.09918

Test context:
***************
ring.n	1945	6	try saying " give me a __ring__ " to the next brit you meet .
Contexts for target ring are: ['det_a', 'dobjI_give', "punct_''"]
Contexts in vocabulary for target ring are: ['det_a', 'dobjI_give']
Top most similar embeddings: ring 0.26713	once-over 0.20577	conformer 0.19651	bollocking 0.19242	head-start 0.19133	leg-up 0.18702	shedload 0.18399	sackful 0.18242	hankie 0.18165	payrise 0.18036

Generated lemmatized results
***************
GENERATED	ring.n 1945 ::: conformer;bollocking;shedload;sackful;hankie;payrise;locket;titbit;pessary;tinkle

Filtered results
***************
RANKED	ring.n 1945	call 0.17756	circlet 0.17430	hoop 0.15990	bell 0.15580	fob 0.15536	tone 0.15301	rim 0.15211	loop 0.15191	chime 0.15114	circle 0.15069	sound 0.14475	chain 0.14329	band 0.14307	coil 0.14232	connotation 0.14219	feel 0.13963	orbit 0.13628	shadow 0.13596	network 0.13402	holder 0.13273	level 0.13203	group 0.13108	syndicate 0.13014	association 0.10929

Test context:
***************
ring.n	1946	6	does n't quite have the same __ring__ to it ... june 28 - m.s.s. announces that he is going to write a book about his experiences in which he will reveal details about the collapse of the ba'athist regime .
Contexts for target ring are: ['det_the', 'amod_same', 'dobjI_have']
Contexts in vocabulary for target ring are: ['det_the', 'amod_same', 'dobjI_have']
Top most similar embeddings: ring 0.11917	rings 0.09390	facepiece 0.09036	conformer 0.09036	chainwheel 0.09010	x-chromosome 0.08996	gumption 0.08966	pinout 0.08955	truth-value 0.08712	raditech 0.08675

Generated lemmatized results
***************
GENERATED	ring.n 1946 ::: facepiece;conformer;chainwheel;gumption;pinout;raditech;habbit;effect;centromere;symtoms

Filtered results
***************
RANKED	ring.n 1946	hoop 0.07815	rim 0.07779	bell 0.07761	circlet 0.07759	loop 0.07717	circle 0.07712	tone 0.07632	connotation 0.07603	fob 0.07530	coil 0.07485	orbit 0.07291	band 0.07258	chain 0.07208	level 0.07014	network 0.06986	sound 0.06967	group 0.06852	chime 0.06768	syndicate 0.06620	shadow 0.06495	call 0.06486	holder 0.06410	association 0.06090	feel 0.05265

Test context:
***************
ring.n	1947	7	the myelin sheath appears as a dark __ring__ .
Contexts for target ring are: ['det_a', 'amod_dark', 'prep:asI_appears']
Contexts in vocabulary for target ring are: ['det_a', 'amod_dark', 'prep:asI_appears']
Top most similar embeddings: ring 0.12083	circlet 0.10294	semi-circle 0.09993	supergiant 0.09649	blotch 0.09591	topknot 0.09492	necktie 0.09470	aureole 0.09406	semicircle 0.09383	snowdrift 0.09356

Generated lemmatized results
***************
GENERATED	ring.n 1947 ::: circlet;supergiant;blotch;topknot;necktie;aureole;semicircle;snowdrift;halo;blob

Filtered results
***************
RANKED	ring.n 1947	circlet 0.10294	circle 0.08341	shadow 0.08340	hoop 0.07833	rim 0.07618	tone 0.07501	loop 0.07471	band 0.07406	coil 0.07390	chime 0.06911	bell 0.06886	chain 0.06854	orbit 0.06802	fob 0.06739	connotation 0.06693	holder 0.06433	sound 0.06360	network 0.06066	call 0.06022	syndicate 0.05970	group 0.05938	level 0.05297	feel 0.04947	association 0.04731

Test context:
***************
ring.n	1948	19	besides that notable contribution , in just a few years time military bloggers - whether a part of the __ring__ or not - have helped raise funds for iraqi children and wounded veterans alike , brought attention to efforts to support the troops , inspired songs , helped launch film projects , and signed book deals .
Contexts for target ring are: ['det_the', 'prep:ofI_part', 'cc_or', 'conj_not']
Contexts in vocabulary for target ring are: ['det_the', 'prep:ofI_part', 'cc_or', 'conj_not']
Top most similar embeddings: ring 0.05174	assignor 0.04403	fqdn 0.04288	hypocotyl 0.04114	gerund 0.04074	jiva 0.04052	rings 0.04046	grantor 0.03999	burka 0.03968	wagonway 0.03962

Generated lemmatized results
***************
GENERATED	ring.n 1948 ::: assignor;fqdn;hypocotyl;gerund;jiva;grantor;burka;wagonway;gullet;hereditament

Filtered results
***************
RANKED	ring.n 1948	rim 0.03708	loop 0.03491	circle 0.03472	hoop 0.03384	chain 0.03365	circlet 0.03339	chime 0.03230	bell 0.03157	coil 0.03132	call 0.03090	fob 0.03079	tone 0.03040	syndicate 0.03035	orbit 0.03010	band 0.02985	network 0.02951	group 0.02905	holder 0.02898	sound 0.02851	shadow 0.02740	connotation 0.02666	association 0.02486	level 0.02460	feel 0.01937

Test context:
***************
ring.n	1949	8	we have done away with quarterstraps , spider __rings__ and hair cinches and substituted a girth , which , buckling to leather billets , reduces the weight and reduced the time needed in saddling .
Contexts for target rings are: ['nn_spider', 'conjI_quarterstraps']
Contexts in vocabulary for target rings are: ['nn_spider']
Top most similar embeddings: rings 0.46025	ring 0.39334	splats 0.35732	filaments 0.34457	bracelet 0.34444	ear-rings 0.34413	bracelets 0.34090	naevi 0.34045	lockets 0.34009	golems 0.33969

Generated lemmatized results
***************
GENERATED	ring.n 1949 ::: splat;filament;bracelet;naevi;locket;golem;necklace;brooch;vibrator;bangle

Filtered results
***************
RANKED	ring.n 1949	circle 0.31911	coil 0.31814	circlet 0.31102	fob 0.30927	loop 0.30912	bell 0.30700	hoop 0.30524	rim 0.30470	chain 0.30429	network 0.30340	band 0.29868	chime 0.29359	tone 0.29191	orbit 0.29064	syndicate 0.28198	shadow 0.27828	group 0.27045	sound 0.26641	holder 0.26377	connotation 0.26135	call 0.25820	association 0.25384	level 0.25154	feel 0.24382

Test context:
***************
ring.n	1950	20	you could say that the atom is " balanced " because it has an even number of electrons on each __ring__ .
Contexts for target ring are: ['det_each', 'prep:onI_number']
Contexts in vocabulary for target ring are: ['det_each', 'prep:onI_number']
Top most similar embeddings: ring 0.23335	forewing 0.18043	payline 0.17950	x-chromosome 0.17703	rings 0.17358	sheave 0.17073	rung 0.16994	dial 0.16897	subcarrier 0.16745	stalk 0.16626

Generated lemmatized results
***************
GENERATED	ring.n 1950 ::: forewing;payline;sheave;rung;dial;subcarrier;stalk;floorboard;plate;weeknight

Filtered results
***************
RANKED	ring.n 1950	hoop 0.15774	rim 0.15354	circle 0.15282	loop 0.15222	coil 0.15129	call 0.14934	fob 0.14710	circlet 0.14463	bell 0.14225	chime 0.14094	orbit 0.13817	band 0.13812	network 0.13653	chain 0.13540	syndicate 0.13076	holder 0.13029	level 0.12829	group 0.12726	tone 0.12431	shadow 0.11664	sound 0.11586	connotation 0.11451	association 0.10595	feel 0.09348

Test context:
***************
scrap.n	1951	6	increased quality= less quality costs ( __scrap__ , customer returns ) =increased margins .
Contexts for target scrap are: ['punct_-lrb-', 'depI_costs', 'punct_,', 'appos_returns', 'dep_margins']
Contexts in vocabulary for target scrap are: ['depI_costs', 'punct_,', 'appos_returns', 'dep_margins']
Top most similar embeddings: scrap 0.03874	e0 0.03654	1p 0.03625	i.e. 0.03599	wsje 0.03525	p/kwh 0.03502	depreciation 0.03500	9k 0.03471	31p 0.03466	law-now 0.03465

Generated lemmatized results
***************
GENERATED	scrap.n 1951 ::: wsje;depreciation;skr;npv;isk;xmin;nett;ebitda;perm;roce

Filtered results
***************
RANKED	scrap.n 1951	waste 0.02917	crumb 0.02890	shred 0.02753	clipping 0.02718	rubbish 0.02711	recycling 0.02595	remainder 0.02561	morsel 0.02523	bit 0.02473	leftover 0.02438	collage 0.02398	fragment 0.02393	piece 0.02370	album 0.02255

Test context:
***************
scrap.n	1952	24	general update #3 wednesday , 24th september , 2003 : : 03:56 edt - sidenotes - perplexed a little more of the general boring __scrap__ , nothing to get too excited about .
Contexts for target scrap are: ['det_the', 'amod_general', 'amod_boring', 'prep:ofI_more']
Contexts in vocabulary for target scrap are: ['det_the', 'amod_general', 'amod_boring', 'prep:ofI_more']
Top most similar embeddings: scrap 0.04898	wackiness 0.04304	chit-chat 0.04265	rigmarole 0.04262	dross 0.04165	blather 0.04149	chitchat 0.04144	runaround 0.04108	rubbish 0.04078	stuff 0.04073

Generated lemmatized results
***************
GENERATED	scrap.n 1952 ::: wackiness;rigmarole;dross;blather;chitchat;runaround;rubbish;stuff;blandness;frippery

Filtered results
***************
RANKED	scrap.n 1952	rubbish 0.04078	waste 0.03950	bit 0.03847	piece 0.03276	leftover 0.03268	remainder 0.03193	crumb 0.03149	shred 0.03085	morsel 0.03063	collage 0.03050	clipping 0.03041	fragment 0.02878	recycling 0.02842	album 0.02840

Test context:
***************
scrap.n	1953	21	indeed this would only be feeding the opposites of good and bad and , as we are reminded by that little __scrap__ of paper on the wall at the maenllwyd , " when the opposites arise , the buddha mind is lost " .
Contexts for target scrap are: ['amod_little', 'depI_lost', 'prep:of_paper', 'prep:on_wall', 'prep:at_maenllwyd', 'punct_,', "punct_''"]
Contexts in vocabulary for target scrap are: ['amod_little', 'depI_lost', 'prep:of_paper', 'prep:on_wall', 'punct_,']
Top most similar embeddings: scrap 0.02488	scraps 0.02133	piece 0.01846	peice 0.01800	speck 0.01772	shreds 0.01766	bit 0.01761	bobbles 0.01760	squiggles 0.01752	slivers 0.01751

Generated lemmatized results
***************
GENERATED	scrap.n 1953 ::: piece;peice;speck;shred;bit;bobble;squiggle;sliver;smudge;scuffing

Filtered results
***************
RANKED	scrap.n 1953	piece 0.01846	shred 0.01766	bit 0.01761	morsel 0.01723	fragment 0.01684	crumb 0.01612	collage 0.01553	clipping 0.01451	waste 0.01436	leftover 0.01408	rubbish 0.01408	recycling 0.01306	remainder 0.01248	album 0.01068

Test context:
***************
scrap.n	1954	19	now each day the central banker taxes the other asians on the island by confiscating a portion of the __scraps__ of food the american throws them each day from his table .
Contexts for target scraps are: ['det_the', 'prep:ofI_portion', 'prep:of_food']
Contexts in vocabulary for target scraps are: ['det_the', 'prep:ofI_portion', 'prep:of_food']
Top most similar embeddings: scraps 0.12588	left-overs 0.09382	morsel 0.09218	leftovers 0.09065	endosperm 0.08964	crumbs 0.08952	morsels 0.08941	husks 0.08828	plateful 0.08808	carcass 0.08792

Generated lemmatized results
***************
GENERATED	scrap.n 1954 ::: morsel;leftover;endosperm;crumb;husk;plateful;carcass;fragment;ration;sliver

Filtered results
***************
RANKED	scrap.n 1954	morsel 0.09218	leftover 0.09065	crumb 0.08952	fragment 0.08774	bit 0.08263	shred 0.08098	remainder 0.07894	piece 0.07882	waste 0.07072	clipping 0.07040	collage 0.06595	rubbish 0.06532	recycling 0.05859	album 0.05348

Test context:
***************
scrap.n	1955	23	" saying this , rikiu stepped into the garden , shook a tree and scattered over the garden gold and crimson leaves , __scraps__ of the brocade of autumn !
Contexts for target scraps are: ['conjI_saying', 'prep:of_brocade']
Contexts in vocabulary for target scraps are: ['conjI_saying']
Top most similar embeddings: scraps 0.43924	scrap 0.34108	crumbs 0.33521	leftovers 0.32075	morsel 0.32016	buts 0.31686	reams 0.31681	spuds 0.31635	titbits 0.31613	peelings 0.31405

Generated lemmatized results
***************
GENERATED	scrap.n 1955 ::: crumb;leftover;morsel;buts;ream;spud;titbit;peeling;snatch;rubbish

Filtered results
***************
RANKED	scrap.n 1955	crumb 0.33521	leftover 0.32075	morsel 0.32016	rubbish 0.31239	shred 0.30965	clipping 0.30531	remainder 0.30040	waste 0.29902	fragment 0.29032	bit 0.28941	piece 0.28306	recycling 0.25890	collage 0.25075	album 0.22644

Test context:
***************
scrap.n	1956	7	6 cut a nose shape from a __scrap__ of felt the same colour as your nose thread .
Contexts for target scrap are: ['det_a', 'prep:fromI_cut']
Contexts in vocabulary for target scrap are: ['det_a', 'prep:fromI_cut']
Top most similar embeddings: scrap 0.24277	gatepost 0.18248	scraps 0.18096	plateful 0.17588	ingot 0.17347	peice 0.17341	sackful 0.17317	dunghill 0.17245	piece 0.17243	handcart 0.17223

Generated lemmatized results
***************
GENERATED	scrap.n 1956 ::: gatepost;plateful;ingot;peice;sackful;dunghill;piece;handcart;spacesuit;molehill

Filtered results
***************
RANKED	scrap.n 1956	piece 0.17243	morsel 0.16306	fragment 0.16000	shred 0.15947	waste 0.15940	bit 0.15017	collage 0.14988	crumb 0.14719	leftover 0.14710	rubbish 0.13982	clipping 0.13713	album 0.13414	remainder 0.12962	recycling 0.12690

Test context:
***************
scrap.n	1957	26	he saw the spark of an explosion where the main bridge section would have been and smiled in satisfaction as his brain started counting up the __scrap__ value of an imperial customs frigate .
Contexts for target scrap are: ['nnI_value']
Contexts in vocabulary for target scrap are: ['nnI_value']
Top most similar embeddings: scrap 0.51516	trade-in 0.36159	clob 0.35498	scrapping 0.35425	ysize 0.35014	max_value 0.34884	juliandate 0.34677	minium 0.34443	surplus 0.34355	teq 0.34283

Generated lemmatized results
***************
GENERATED	scrap.n 1957 ::: clob;scrapping;ysize;juliandate;minium;surplus;teq;pyobject;bordercolor;rmerge

Filtered results
***************
RANKED	scrap.n 1957	waste 0.32091	recycling 0.31093	bit 0.30957	fragment 0.30120	shred 0.30068	crumb 0.29778	morsel 0.29586	leftover 0.29450	rubbish 0.28883	remainder 0.28531	piece 0.28269	collage 0.27130	clipping 0.26217	album 0.22911

Test context:
***************
scrap.n	1958	2	recycled ferrous __scrap__ consumes 75 percent less energy than new ore .
Contexts for target scrap are: ['amod_recycled', 'amod_ferrous', 'nsubjI_consumes']
Contexts in vocabulary for target scrap are: ['amod_recycled', 'amod_ferrous', 'nsubjI_consumes']
Top most similar embeddings: scrap 0.11953	waste 0.08473	metal 0.08378	plastics 0.08360	scraps 0.08311	feedstock 0.08164	newsprint 0.08160	bagasse 0.08151	wastes 0.08150	off-cuts 0.08111

Generated lemmatized results
***************
GENERATED	scrap.n 1958 ::: waste;metal;plastic;feedstock;newsprint;bagasse;recyclate;aluminium;slurry;aluminum

Filtered results
***************
RANKED	scrap.n 1958	waste 0.08473	recycling 0.07512	rubbish 0.07168	fragment 0.06907	shred 0.06818	clipping 0.06532	crumb 0.06405	leftover 0.06249	bit 0.06240	remainder 0.06189	morsel 0.06145	piece 0.05989	collage 0.05772	album 0.04355

Test context:
***************
scrap.n	1959	26	at the opposite end of the chopping board from the chopped food hopper is located another hopper which is used specifically for collecting the cut food __scraps__ .
Contexts for target scraps are: ['det_the', 'nn_cut', 'nn_food', 'dobjI_collecting']
Contexts in vocabulary for target scraps are: ['det_the', 'nn_cut', 'nn_food', 'dobjI_collecting']
Top most similar embeddings: scraps 0.07075	off-cuts 0.04986	leftovers 0.04855	left-overs 0.04808	punnets 0.04781	tins 0.04732	scrapings 0.04695	offcuts 0.04671	wrappings 0.04654	slivers 0.04571

Generated lemmatized results
***************
GENERATED	scrap.n 1959 ::: leftover;punnet;tin;scraping;offcuts;wrapping;sliver;crumb;mowings;sweeping

Filtered results
***************
RANKED	scrap.n 1959	leftover 0.04855	crumb 0.04543	fragment 0.04346	clipping 0.04291	morsel 0.04271	piece 0.04194	bit 0.04142	waste 0.04046	shred 0.03929	remainder 0.03902	rubbish 0.03730	collage 0.03165	album 0.03000	recycling 0.02960

Test context:
***************
scrap.n	1960	11	find out what type of scrap booking sheets fit in their __scrap__ book and create a page or two for them !
Contexts for target scrap are: ['nnI_book']
Contexts in vocabulary for target scrap are: ['nnI_book']
Top most similar embeddings: scrap 0.52016	paying-in 0.36002	entring 0.35734	hard-back 0.35728	sex.com 0.35687	readingmatters 0.35412	gramercy 0.35398	usbourne 0.34597	acutab 0.34513	shannara 0.34328

Generated lemmatized results
***************
GENERATED	scrap.n 1960 ::: entring;readingmatters;gramercy;usbourne;acutab;shannara;interpet;ration;thsi;leatherette

Filtered results
***************
RANKED	scrap.n 1960	waste 0.32148	shred 0.31064	recycling 0.30610	leftover 0.29660	crumb 0.29567	rubbish 0.29173	fragment 0.29031	collage 0.28922	remainder 0.28399	morsel 0.28220	clipping 0.28017	piece 0.27924	bit 0.27530	album 0.24630

Test context:
***************
secret.a	1961	13	" chalabi is still on the defense intelligence agency 's budget for a __secret__ stipend of $ 340,000 a month .
Contexts for target secret are: ['amodI_stipend']
Contexts in vocabulary for target secret are: ['amodI_stipend']
Top most similar embeddings: secret 0.44300	top-secret 0.35605	seven-figure 0.33989	undisclosed 0.33537	non-pensionable 0.33489	five-figure 0.33382	four-figure 0.33146	closed-door 0.33144	much-reduced 0.32815	clandestine 0.32754

Generated lemmatized results
***************
GENERATED	secret.a 1961 ::: undisclosed;clandestine;paltry;unreduced;basic;meagre;munificent;unearned;princely;valedictory

Filtered results
***************
RANKED	secret.a 1961	undisclosed 0.33537	clandestine 0.32754	hidden 0.30964	confidential 0.30321	unspoken 0.30013	private 0.29743	concealed 0.29184	unpublished 0.29094	undercover 0.28912	unrevealed 0.28661	unknown 0.28344	unseen 0.28225	inner 0.26623	innermost 0.26304	classified 0.26082	closed 0.25107	intelligence 0.23376	coded 0.23351	spying 0.23343

Test context:
***************
secret.a	1962	14	but there was a secret core group based on the knowledge of existence of __secret__ partnerships .
Contexts for target secret are: ['amodI_partnerships']
Contexts in vocabulary for target secret are: ['amodI_partnerships']
Top most similar embeddings: secret 0.47595	private-public 0.38158	clandestine 0.35369	secrets 0.35346	multi-partner 0.34970	inter-sectoral 0.34876	us-russian 0.34743	top-secret 0.34740	public-private 0.34677	regionally-based 0.34583

Generated lemmatized results
***************
GENERATED	secret.a 1962 ::: clandestine;secrets;private;consortial;intersectoral;conjugal;confidential;collusive;strategic;trilateral

Filtered results
***************
RANKED	secret.a 1962	clandestine 0.35369	private 0.33900	confidential 0.32972	concealed 0.31054	hidden 0.30900	unspoken 0.30717	undisclosed 0.30429	unseen 0.30230	unpublished 0.29722	unrevealed 0.29663	undercover 0.29618	unknown 0.29202	inner 0.28358	innermost 0.26751	classified 0.26342	closed 0.26235	spying 0.24747	coded 0.24554	intelligence 0.23248

Test context:
***************
secret.a	1963	44	i think we 've really got to know whether the hookworm of political corruption in the form of secret campaign funds had invaded the premier 's office in this province , and the premier 's got to answer with a full explanation of those __secret__ trust funds .
Contexts for target secret are: ['amodI_funds']
Contexts in vocabulary for target secret are: ['amodI_funds']
Top most similar embeddings: secret 0.49145	closed-end 0.38532	top-secret 0.38142	non-public 0.37680	clandestine 0.36400	equity-based 0.36158	unspent 0.35860	undistributed 0.35443	undesignated 0.35194	non-formula 0.35116

Generated lemmatized results
***************
GENERATED	secret.a 1963 ::: clandestine;unspent;undistributed;undesignated;seedcorn;secrets;concessional;undeclared;unutilised;multibillion

Filtered results
***************
RANKED	secret.a 1963	clandestine 0.36400	private 0.33611	confidential 0.33543	hidden 0.33522	undisclosed 0.33335	unrevealed 0.32513	concealed 0.32182	unspoken 0.31476	undercover 0.31372	closed 0.29909	unknown 0.29181	unseen 0.29088	inner 0.28557	unpublished 0.28467	innermost 0.27812	classified 0.27009	coded 0.25528	intelligence 0.25097	spying 0.25037

Test context:
***************
secret.a	1964	4	is there a devious __secret__ government ?
Contexts for target secret are: ['amodI_government']
Contexts in vocabulary for target secret are: ['amodI_government']
Top most similar embeddings: secret 0.49446	u.s.-backed 0.37953	third-term 0.37690	labour-led 0.37437	synodical 0.37425	czechoslovak 0.37020	top-secret 0.36980	cantonal 0.36730	czarist 0.36566	us-backed 0.36464

Generated lemmatized results
***************
GENERATED	secret.a 1964 ::: synodical;czechoslovak;cantonal;czarist;ivorian;clandestine;salvadoran;presbyterial;angolan;montenegrin

Filtered results
***************
RANKED	secret.a 1964	clandestine 0.36142	hidden 0.31334	undisclosed 0.31287	confidential 0.31196	unrevealed 0.30836	private 0.30692	concealed 0.30664	unspoken 0.30490	undercover 0.29964	unknown 0.29322	unseen 0.29299	innermost 0.28942	inner 0.28704	unpublished 0.28687	closed 0.27549	intelligence 0.26448	spying 0.25883	classified 0.25451	coded 0.23188

Test context:
***************
secret.a	1965	6	among her accomplishments was the ten-word __secret__ message she sent to general pierre g.t. beauregard which ultimately caused him to win the battle of bull run .
Contexts for target secret are: ['amodI_message']
Contexts in vocabulary for target secret are: ['amodI_message']
Top most similar embeddings: secret 0.51497	top-secret 0.41356	unsent 0.37976	jls@netverk.com.ar 0.36320	high-priority 0.36043	hush-hush 0.36012	congratulatory 0.35993	valedictory 0.35760	long-delayed 0.35716	mysterious 0.35616

Generated lemmatized results
***************
GENERATED	secret.a 1965 ::: unsent;congratulatory;valedictory;mysterious;unspoken;clandestine;hidden;private;cabalistic;secrets

Filtered results
***************
RANKED	secret.a 1965	unspoken 0.35553	clandestine 0.35183	hidden 0.35115	private 0.34975	unrevealed 0.34598	confidential 0.34577	undisclosed 0.34226	concealed 0.32633	unknown 0.31999	undercover 0.31161	unseen 0.30861	unpublished 0.30801	coded 0.29584	innermost 0.29406	inner 0.28456	classified 0.27604	closed 0.26797	spying 0.26039	intelligence 0.24976

Test context:
***************
secret.a	1966	11	sometimes i spy on him snacking , or peek at his __secret__ projects and feel mild shame that , yes , he is n't doing anything wrong .
Contexts for target secret are: ['amodI_projects']
Contexts in vocabulary for target secret are: ['amodI_projects']
Top most similar embeddings: secret 0.49733	top-secret 0.40633	multi-partner 0.39494	european-funded 0.38467	ec-funded 0.38214	people-based 0.37740	youth-led 0.37482	externally-funded 0.37478	clandestine 0.37438	dfid-funded 0.36879

Generated lemmatized results
***************
GENERATED	secret.a 1966 ::: clandestine;consortial;yearlong;nonmilitary;unpublicised;geoscientific;largescale;covert;secrets;multibillion

Filtered results
***************
RANKED	secret.a 1966	clandestine 0.37438	confidential 0.32868	undercover 0.32702	private 0.32563	hidden 0.32112	undisclosed 0.32094	unpublished 0.31583	unrevealed 0.31496	unseen 0.31141	unspoken 0.30397	concealed 0.30289	unknown 0.29892	inner 0.29570	classified 0.27897	innermost 0.27846	closed 0.27533	spying 0.26962	coded 0.25723	intelligence 0.24808

Test context:
***************
secret.a	1967	33	after poking around on the web to see what the big deal is about visual changes , and coming across things like " pituitary bleeding " -- which just calls to mind my __secret__ fear the last time i had visual symptoms , that i have a pituitary tumor too small to be detected on mri -- i think i 'm fine with not taking any chances .
Contexts for target secret are: ['amodI_fear']
Contexts in vocabulary for target secret are: ['amodI_fear']
Top most similar embeddings: secret 0.50835	unutterable 0.37656	conspiratorial 0.36408	secrets 0.36186	decades-old 0.36108	long-cherished 0.35813	unreasoning 0.35725	unrevealed 0.35668	atavistic 0.35626	pent-up 0.35574

Generated lemmatized results
***************
GENERATED	secret.a 1967 ::: unutterable;conspiratorial;secrets;unreasoning;unrevealed;atavistic;unspoken;profound;pestilential;undisguised

Filtered results
***************
RANKED	secret.a 1967	unrevealed 0.35668	unspoken 0.35509	hidden 0.34260	concealed 0.33927	clandestine 0.33772	undisclosed 0.32545	unknown 0.32077	unseen 0.31400	private 0.31175	confidential 0.31167	inner 0.30178	innermost 0.30069	undercover 0.29976	unpublished 0.27154	closed 0.26090	classified 0.25814	intelligence 0.25284	spying 0.25030	coded 0.24392

Test context:
***************
secret.a	1968	13	election : in the event of a contest , election shall be by __secret__ ballot , and a plurality vote shall be required for election .
Contexts for target secret are: ['amodI_ballot']
Contexts in vocabulary for target secret are: ['amodI_ballot']
Top most similar embeddings: secret 0.55433	top-secret 0.40644	secrets 0.38292	clandestine 0.37586	all-postal 0.37379	hush-hush 0.36096	long-delayed 0.36087	closed-door 0.35692	confidential 0.35423	semi-official 0.34473

Generated lemmatized results
***************
GENERATED	secret.a 1968 ::: secrets;clandestine;confidential;gubernatorial;timeous;unsanctioned;secretive;unpublicised;covert;surreptitious

Filtered results
***************
RANKED	secret.a 1968	clandestine 0.37586	confidential 0.35423	unspoken 0.32411	undisclosed 0.31826	private 0.31773	undercover 0.31599	hidden 0.31413	concealed 0.31308	unpublished 0.30732	unseen 0.30506	unknown 0.29585	unrevealed 0.29444	closed 0.28547	innermost 0.27981	inner 0.27214	spying 0.26573	classified 0.26489	coded 0.25662	intelligence 0.25511

Test context:
***************
secret.a	1969	41	an intriguing series of events are described , from the knowledge taught to enoch by the angel uriel , through the construction of megalithic monuments , to the creation and shaping of nations and religions , and the formation of modern __secret__ societies - even the mysterious agenda of the new world order .
Contexts for target secret are: ['amodI_societies']
Contexts in vocabulary for target secret are: ['amodI_societies']
Top most similar embeddings: secret 0.53031	clandestine 0.37663	pre-capitalist 0.36981	top-secret 0.36273	rapidly-expanding 0.36216	secrets 0.36146	secretive 0.35713	non-islamic 0.35581	ex-colonial 0.35362	dog-eat-dog 0.35322

Generated lemmatized results
***************
GENERATED	secret.a 1969 ::: clandestine;secrets;secretive;linnaean;conspiratorial;indiginous;multiethnic;anthroposophical;melanesian;cabalistic

Filtered results
***************
RANKED	secret.a 1969	clandestine 0.37663	unrevealed 0.32001	confidential 0.31935	undisclosed 0.31765	hidden 0.31713	private 0.31636	undercover 0.30939	unspoken 0.30344	concealed 0.30283	unknown 0.29802	unseen 0.29557	closed 0.29523	unpublished 0.29181	inner 0.28440	innermost 0.27774	classified 0.26674	spying 0.25680	intelligence 0.25511	coded 0.24144

Test context:
***************
secret.a	1970	5	maybe and fbi agent.... not __secret__ service ... .
Contexts for target secret are: ['punct_...', 'neg_not', 'amodI_service']
Contexts in vocabulary for target secret are: ['punct_...', 'neg_not', 'amodI_service']
Top most similar embeddings: secret 0.11345	foolproof 0.08451	risk-free 0.07913	auto-update 0.07777	onlie 0.07772	pukka 0.07747	hush-hush 0.07720	metrosexual 0.07613	purrfect 0.07604	acurate 0.07540

Generated lemmatized results
***************
GENERATED	secret.a 1970 ::: foolproof;onlie;pukka;metrosexual;purrfect;acurate;clandestine;confidential;apalling;discreet

Filtered results
***************
RANKED	secret.a 1970	clandestine 0.07529	confidential 0.07519	hidden 0.07220	undercover 0.07041	unknown 0.06941	undisclosed 0.06845	concealed 0.06660	unrevealed 0.06609	classified 0.06525	unspoken 0.06450	unseen 0.06196	closed 0.05964	private 0.05946	spying 0.05709	coded 0.05666	unpublished 0.05614	inner 0.05217	intelligence 0.05060	innermost 0.04811

Test context:
***************
shot.n	1971	20	thomas golf irons give you an exceptional advantage over other brands by making it easier to aim and align your __shot__ to the target .
Contexts for target shot are: ['poss_your', 'depI_align', 'prep:to_target']
Contexts in vocabulary for target shot are: ['poss_your', 'depI_align', 'prep:to_target']
Top most similar embeddings: shot 0.09146	shots 0.07848	header 0.07781	cursor 0.07542	reticule 0.07010	pointer 0.06917	keycode 0.06916	down-arrow 0.06865	order 0.06857	flick 0.06840

Generated lemmatized results
***************
GENERATED	shot.n 1971 ::: header;cursor;reticule;pointer;keycode;order;flick;rfree;crosshair;angle

Filtered results
***************
RANKED	shot.n 1971	bullet 0.06616	pellet 0.06568	projectile 0.06523	move 0.06390	jab 0.06334	drive 0.06101	manoeuvre 0.05994	firing 0.05900	photograph 0.05866	photo 0.05834	ammunition 0.05824	strike 0.05809	picture 0.05759	stroke 0.05721	injection 0.05575	round 0.05493	inoculation 0.05470	attempt 0.05470	hit 0.05461	discharge 0.05368	vaccination 0.05353	blast 0.05282	aim 0.05121	portrait 0.05072	play 0.04819	noise 0.04523

Test context:
***************
shot.n	1972	5	in actuality , ready service __shot__ was kept on the gun or spar decks in shot racks ( also known as shot garlands in the royal navy ) which consisted of longitudinal wooden planks with holes bored into them , into which round shot ( cannon balls ) were inserted for ready use by the gun crew .
Contexts for target shot are: ['amod_ready', 'nn_service', 'nsubjpassI_kept']
Contexts in vocabulary for target shot are: ['amod_ready', 'nn_service', 'nsubjpassI_kept']
Top most similar embeddings: shot 0.09207	shots 0.08672	pistol 0.08025	shotgun 0.07648	revolvers 0.07638	ambulances 0.07615	gritters 0.07607	shotguns 0.07600	rifle 0.07545	revolver 0.07493

Generated lemmatized results
***************
GENERATED	shot.n 1972 ::: pistol;shotgun;revolver;ambulance;gritters;rifle;battalion;volley;amidships;crew

Filtered results
***************
RANKED	shot.n 1972	ammunition 0.07165	firing 0.07066	bullet 0.06655	pellet 0.06627	projectile 0.06606	photograph 0.06353	photo 0.06176	vaccination 0.06085	inoculation 0.06058	injection 0.06042	blast 0.06001	round 0.05919	noise 0.05910	jab 0.05892	portrait 0.05869	manoeuvre 0.05858	picture 0.05826	strike 0.05826	stroke 0.05759	discharge 0.05643	hit 0.05445	drive 0.05430	move 0.05370	attempt 0.05243	aim 0.05115	play 0.04406

Test context:
***************
shot.n	1973	3	moore fired two __shots__ , the first a warning shot in the air and the second at the man .
Contexts for target shots are: ['num_two', 'dobjI_fired']
Contexts in vocabulary for target shots are: ['num_two', 'dobjI_fired']
Top most similar embeddings: shots 0.28312	salvos 0.21356	volleys 0.21202	half-chances 0.19865	shot 0.19795	gunshots 0.19768	putts 0.19421	pounders 0.19410	touchdowns 0.19383	free-kicks 0.19377

Generated lemmatized results
***************
GENERATED	shot.n 1973 ::: salvo;volley;gunshot;putt;pounder;touchdown;bullet;carronades;tomahawk;torpedo

Filtered results
***************
RANKED	shot.n 1973	bullet 0.19348	round 0.18929	projectile 0.18366	firing 0.17933	photo 0.17276	stroke 0.17084	photograph 0.17021	picture 0.16638	portrait 0.16431	pellet 0.16355	blast 0.16235	strike 0.15353	manoeuvre 0.14952	ammunition 0.14742	jab 0.14661	noise 0.14165	injection 0.14021	hit 0.13917	drive 0.13876	attempt 0.13655	move 0.13310	inoculation 0.13233	vaccination 0.12843	discharge 0.12502	play 0.12395	aim 0.11198

Test context:
***************
shot.n	1974	17	you will more and more be able to make the ball do what is needed for the __shot__ .
Contexts for target shot are: ['det_the', 'prep:forI_needed']
Contexts in vocabulary for target shot are: ['det_the', 'prep:forI_needed']
Top most similar embeddings: shot 0.21658	shots 0.19989	shooting 0.17235	spot-kick 0.16772	cmd53 0.16751	shoot 0.16700	toe-off 0.16697	pull-back 0.16648	right-hander 0.16647	tejon 0.16617

Generated lemmatized results
***************
GENERATED	shot.n 1974 ::: shooting;shoot;tejon;header;backswing;decipherment;triennium;volley;instalation;impregnation

Filtered results
***************
RANKED	shot.n 1974	firing 0.15570	manoeuvre 0.15161	projectile 0.15017	picture 0.14874	photograph 0.14763	bullet 0.14572	blast 0.14542	jab 0.14490	vaccination 0.14381	stroke 0.14352	strike 0.14343	photo 0.14274	round 0.14205	inoculation 0.14123	pellet 0.14018	injection 0.13944	portrait 0.13912	ammunition 0.13714	discharge 0.13531	drive 0.12964	noise 0.12806	move 0.12698	aim 0.12692	attempt 0.12587	play 0.12217	hit 0.12061

Test context:
***************
shot.n	1975	19	he slashed open a tent on a campsite at san casciano , south of florence , and fired several __shots__ into the bodies of french tourists jean michel kraveichvilj and nadine mauriot .
Contexts for target shots are: ['amod_several', 'dobjI_fired']
Contexts in vocabulary for target shots are: ['amod_several', 'dobjI_fired']
Top most similar embeddings: shots 0.28153	salvos 0.21047	volleys 0.20984	gunshots 0.19672	shot 0.19660	half-chances 0.19250	free-kicks 0.19097	tomahawks 0.18895	putts 0.18704	bullets 0.18632

Generated lemmatized results
***************
GENERATED	shot.n 1975 ::: salvo;volley;gunshot;tomahawk;putt;bullet;lob;still;round;machineguns

Filtered results
***************
RANKED	shot.n 1975	bullet 0.18632	round 0.18349	projectile 0.17881	firing 0.17861	photo 0.17308	photograph 0.16939	stroke 0.16758	picture 0.16497	pellet 0.16405	portrait 0.16351	blast 0.15899	manoeuvre 0.15097	strike 0.14999	jab 0.14652	noise 0.14409	ammunition 0.14359	attempt 0.14224	hit 0.13942	injection 0.13908	move 0.13497	drive 0.13334	inoculation 0.13170	vaccination 0.12840	discharge 0.12791	play 0.12308	aim 0.10501

Test context:
***************
shot.n	1976	18	settlers ' accounts of the prairie conquest mention a sound , a series of pops , like pistol __shots__ , the sound of stout grass roots breaking before a moldboard plow .
Contexts for target shots are: ['nn_pistol', 'prep:likeI_sound']
Contexts in vocabulary for target shots are: ['nn_pistol', 'prep:likeI_sound']
Top most similar embeddings: shots 0.25741	shot 0.20464	gunshots 0.19268	gunshot 0.18011	blasters 0.17915	bullets 0.17904	pistol 0.17887	cannonballs 0.17474	pistols 0.17369	javelins 0.17365

Generated lemmatized results
***************
GENERATED	shot.n 1976 ::: gunshot;blaster;bullet;pistol;cannonball;javelin;gunfire;cannon;shotgun;piledriver

Filtered results
***************
RANKED	shot.n 1976	bullet 0.17904	projectile 0.16725	firing 0.16375	round 0.16041	noise 0.15806	manoeuvre 0.15642	stroke 0.15364	blast 0.15261	pellet 0.15188	ammunition 0.15061	jab 0.14907	photo 0.14594	injection 0.14132	picture 0.14066	photograph 0.14052	portrait 0.13640	strike 0.13076	inoculation 0.12883	hit 0.12833	move 0.12420	discharge 0.12129	vaccination 0.11943	attempt 0.11890	drive 0.11561	play 0.10600	aim 0.10431

Test context:
***************
shot.n	1977	20	so , i ca n't apply them to a pool table and my stroke , cue ball hit and distance __shots__ .
Contexts for target shots are: ['nn_distance', 'conjI_stroke']
Contexts in vocabulary for target shots are: ['nn_distance', 'conjI_stroke']
Top most similar embeddings: shots 0.23656	shot 0.18286	strokes 0.18031	volley 0.16873	close-ups 0.16799	stroke 0.16705	cross-shot 0.16686	volleys 0.16675	curler 0.16518	takedowns 0.16317

Generated lemmatized results
***************
GENERATED	shot.n 1977 ::: stroke;volley;curler;takedown;sprint;gunshot;putt;occlusion;amputation;lob

Filtered results
***************
RANKED	shot.n 1977	stroke 0.18031	firing 0.15030	photo 0.14920	photograph 0.14840	round 0.14827	blast 0.14567	manoeuvre 0.14545	pellet 0.14412	jab 0.14331	portrait 0.14276	injection 0.14217	noise 0.14203	projectile 0.14196	bullet 0.13796	strike 0.13561	picture 0.13355	move 0.13189	inoculation 0.12858	vaccination 0.12748	drive 0.12705	hit 0.12474	ammunition 0.12395	discharge 0.12071	attempt 0.11835	play 0.11233	aim 0.10984

Test context:
***************
shot.n	1978	8	thanks to ben i have a good head __shot__ of chad for hugh 's latest assault .
Contexts for target shot are: ['det_a', 'amod_good', 'nn_head', 'dobjI_have', 'prep:of_chad', 'prep:for_assault']
Contexts in vocabulary for target shot are: ['det_a', 'amod_good', 'nn_head', 'dobjI_have', 'prep:of_chad', 'prep:for_assault']
Top most similar embeddings: shot 0.01205	shots 0.01001	portrait 0.00848	freekick 0.00842	volley 0.00833	sing-song 0.00827	stab 0.00825	tap-in 0.00825	picture 0.00823	laceration 0.00818

Generated lemmatized results
***************
GENERATED	shot.n 1978 ::: portrait;freekick;volley;stab;picture;laceration;header;clearance;clue;gander

Filtered results
***************
RANKED	shot.n 1978	portrait 0.00848	picture 0.00823	photograph 0.00783	stroke 0.00726	jab 0.00713	blast 0.00712	photo 0.00700	pellet 0.00690	bullet 0.00689	round 0.00659	strike 0.00655	injection 0.00652	ammunition 0.00608	firing 0.00594	drive 0.00590	inoculation 0.00584	discharge 0.00581	vaccination 0.00573	projectile 0.00558	hit 0.00553	manoeuvre 0.00546	move 0.00532	noise 0.00522	attempt 0.00510	aim 0.00447	play 0.00435

Test context:
***************
shot.n	1979	50	episode also introduces several changes : uncle secretaries have a new uniform of yellow turtlenecks or blouses with brown skirts ; uncle hqs has more computers ( actually surplus nasa equipment ) ; and titles have been redone , with new robert vaughn , david mccallum and leo g. carroll __shots__ .
Contexts for target shots are: ['nn_leo', 'nn_g.', 'nn_carroll', 'conjI_vaughn']
Contexts in vocabulary for target shots are: ['nn_leo', 'nn_g.', 'nn_carroll', 'conjI_vaughn']
Top most similar embeddings: mckern 0.04439	lipinski 0.04333	macdowell 0.04294	pederson 0.04270	fehr 0.04241	meaney 0.04221	paulsen 0.04211	iverson 0.04181	wignall 0.04172	carlson 0.04163

Generated lemmatized results
***************
GENERATED	shot.n 1979 ::: mckern;lipinski;macdowell;pederson;fehr;meaney;paulsen;iverson;wignall;carlson

Filtered results
***************
RANKED	shot.n 1979	photo 0.02990	portrait 0.02954	photograph 0.02936	blast 0.02741	picture 0.02729	bullet 0.02719	jab 0.02600	stroke 0.02579	firing 0.02569	projectile 0.02441	injection 0.02418	round 0.02367	strike 0.02306	pellet 0.02276	manoeuvre 0.02267	noise 0.02175	vaccination 0.02150	inoculation 0.02106	hit 0.02049	drive 0.02033	move 0.01931	attempt 0.01858	ammunition 0.01849	discharge 0.01841	play 0.01810	aim 0.01782

Test context:
***************
shot.n	1980	26	this 78-page ( paperback ) book is well worth reading , especially if you have children or if you are being pressured to get a flu __shot__ .
Contexts for target shot are: ['det_a', 'nn_flu', 'dobjI_get']
Contexts in vocabulary for target shot are: ['det_a', 'nn_flu', 'dobjI_get']
Top most similar embeddings: shot 0.13498	shots 0.10592	piledriver 0.09973	half-volley 0.09758	headshot 0.09443	freekick 0.09356	cross-shot 0.09342	spot-kick 0.09203	curler 0.09080	volley 0.09046

Generated lemmatized results
***************
GENERATED	shot.n 1980 ::: piledriver;headshot;freekick;curler;volley;jab;bollocking;nosebleed;kick;piccie

Filtered results
***************
RANKED	shot.n 1980	jab 0.08969	bullet 0.08338	vaccination 0.08260	picture 0.07986	injection 0.07701	blast 0.07615	pellet 0.07591	strike 0.07585	photograph 0.07321	projectile 0.07307	portrait 0.07143	photo 0.07002	stroke 0.06876	hit 0.06859	round 0.06833	inoculation 0.06732	firing 0.06528	manoeuvre 0.06486	drive 0.06269	noise 0.06054	move 0.05958	discharge 0.05941	attempt 0.05901	ammunition 0.05849	play 0.05179	aim 0.04906

Test context:
***************
show.v	1981	20	std 5.5.3 loop detectors installed at signalized intersections should be sensitive enough to detect bicycles and the pavement marked to __show__ the cyclist where the trigger is located .
Contexts for target show are: ['aux_to', 'xcompI_marked', 'dobj_cyclist']
Contexts in vocabulary for target show are: ['aux_to', 'xcompI_marked', 'dobj_cyclist']
Top most similar embeddings: show 0.12244	unnerve 0.08975	re-assure 0.08840	outclass 0.08638	incriminate 0.08569	overtake 0.08532	entrap 0.08485	indicate 0.08389	rile 0.08352	bewilder 0.08307

Generated lemmatized results
***************
GENERATED	show.v 1981 ::: unnerve;outclass;incriminate;overtake;entrap;indicate;rile;bewilder;propitiate;demonstrate

Filtered results
***************
RANKED	show.v 1981	indicate 0.08389	depict 0.08107	reveal 0.07967	exhibit 0.07680	illustrate 0.07507	give 0.07005	instruct 0.06987	display 0.06986	offer 0.06798	play 0.06712	present 0.06373	air 0.05882	guide 0.05841	picture 0.05811	come 0.05745	appear 0.05689

Test context:
***************
show.v	1982	9	i cannot connect and my access point is not __shown__ by " iwlist scan " .
Contexts for target shown are: ['nsubjpass_point', 'auxpass_is', 'neg_not', 'conjI_connect']
Contexts in vocabulary for target shown are: ['nsubjpass_point', 'auxpass_is', 'neg_not', 'conjI_connect']
Top most similar embeddings: shown 0.05434	displayed 0.04455	overriden 0.04308	demonstrated 0.04198	guaranteed 0.04186	connected 0.04175	dereferenced 0.04148	indicated 0.04137	toggled 0.04111	confused 0.04081

Generated lemmatized results
***************
GENERATED	show.v 1982 ::: display;overriden;demonstrate;guarantee;connect;dereferenced;indicate;toggle;confuse;prove

Filtered results
***************
RANKED	show.v 1982	display 0.04455	indicate 0.04137	illustrate 0.03906	depict 0.03812	give 0.03685	reveal 0.03480	air 0.03430	present 0.03426	picture 0.03424	play 0.03219	instruct 0.03188	offer 0.03184	exhibit 0.03119	guide 0.02858	appear 0.02779	come 0.02656

Test context:
***************
show.v	1983	0	__show__ yet once more the dreadful film of her children 's death , and she does n't come out again .
Contexts for target show are: ['rootI_*root*', 'advmod_yet', 'conj_more', 'punct_,', 'cc_and', 'conj_come', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target show are: ['rootI_*root*', 'advmod_yet', 'conj_more', 'punct_,', 'cc_and', 'conj_come', 'punct_.']
Top most similar embeddings: superted 0.00521	self-working 0.00511	huffed 0.00510	t'was 0.00499	curiouser 0.00498	methought 0.00487	abound 0.00487	swooned 0.00486	persevered 0.00486	nay 0.00480

Generated lemmatized results
***************
GENERATED	show.v 1983 ::: superted;huff;curiouser;methought;abound;swoon;persevere;nay;howbeit;tutted

Filtered results
***************
RANKED	show.v 1983	appear 0.00405	come 0.00396	exhibit 0.00388	play 0.00387	reveal 0.00376	present 0.00375	offer 0.00370	depict 0.00364	display 0.00352	illustrate 0.00347	give 0.00332	air 0.00327	indicate 0.00327	instruct 0.00314	guide 0.00303	picture 0.00301

Test context:
***************
show.v	1984	3	one example is __shown__ in fig .
Contexts for target shown are: ['nsubjpass_example', 'auxpass_is', 'rootI_*root*', 'prep:in_fig', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target shown are: ['nsubjpass_example', 'auxpass_is', 'rootI_*root*', 'prep:in_fig', 'punct_.']
Top most similar embeddings: shown 0.04461	demonstrated 0.03042	depicted 0.02905	illustrated 0.02855	convolved 0.02785	seen 0.02736	displayed 0.02731	decribed 0.02711	indicated 0.02676	highlighted 0.02653

Generated lemmatized results
***************
GENERATED	show.v 1984 ::: demonstrate;depict;illustrate;convolve;see;display;decribed;indicate;highlight;diagram

Filtered results
***************
RANKED	show.v 1984	depict 0.02905	illustrate 0.02855	display 0.02731	indicate 0.02676	present 0.02582	give 0.02576	picture 0.02415	reveal 0.02348	exhibit 0.02338	offer 0.02012	air 0.01869	play 0.01795	instruct 0.01778	guide 0.01705	appear 0.01513	come 0.01292

Test context:
***************
show.v	1985	37	case sensitive : if you you check the case sensitive box , capitalization will matter ( for example , if you search for " star " , then listings with the word " star " will not __show__ up ) .
Contexts for target show are: ['nsubj_star', "punct_''", 'aux_will', 'neg_not', 'rcmodI_word', 'prt_up']
Contexts in vocabulary for target show are: ['nsubj_star', 'aux_will', 'neg_not', 'rcmodI_word', 'prt_up']
Top most similar embeddings: show 0.02515	apear 0.02059	dissapoint 0.02005	conjure 0.01993	waken 0.01963	transpire 0.01894	brighten 0.01875	shew 0.01867	outclass 0.01850	spew 0.01845

Generated lemmatized results
***************
GENERATED	show.v 1985 ::: apear;dissapoint;conjure;waken;transpire;brighten;shew;outclass;spew;appear

Filtered results
***************
RANKED	show.v 1985	appear 0.01841	reveal 0.01824	come 0.01714	give 0.01670	indicate 0.01657	exhibit 0.01657	depict 0.01598	display 0.01583	play 0.01522	present 0.01436	offer 0.01423	air 0.01418	picture 0.01392	illustrate 0.01355	instruct 0.01337	guide 0.01234

Test context:
***************
show.v	1986	0	__showing__ it as a fall apple tree ( before we do the color change on the leaves ) .
Contexts for target showing are: ['rootI_*root*', 'dobj_it', 'prep:as_tree', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target showing are: ['rootI_*root*', 'dobj_it', 'prep:as_tree', 'punct_.']
Top most similar embeddings: showing 0.05170	showed 0.04836	decribed 0.04819	depicts 0.04706	describes 0.04567	portrays 0.04449	embellishes 0.04443	shows 0.04400	described 0.04359	depict 0.04356

Generated lemmatized results
***************
GENERATED	show.v 1986 ::: decribed;depict;describe;portray;embellish;see;foreshadow;saw;liken;define

Filtered results
***************
RANKED	show.v 1986	depict 0.04706	display 0.04252	reveal 0.04088	illustrate 0.04078	exhibit 0.03963	present 0.03934	picture 0.03763	indicate 0.03730	give 0.03662	play 0.03655	appear 0.03560	air 0.03328	offer 0.03267	come 0.03259	instruct 0.03209	guide 0.03093

Test context:
***************
show.v	1987	13	also , when combined with a multiple hazard map , a cfm can __show__ which areas require more information , which ones require different hazard reduction techniques , and which need immediate attention when a hazardous event occurs .
Contexts for target show are: ['nsubj_cfm', 'aux_can', 'rcmodI_map', 'ccomp_require']
Contexts in vocabulary for target show are: ['nsubj_cfm', 'aux_can', 'rcmodI_map', 'ccomp_require']
Top most similar embeddings: show 0.06188	indicate 0.05065	specifiy 0.05015	added 0.04987	shows 0.04980	re-sized 0.04901	hypothesize 0.04823	shown 0.04820	demonstrate 0.04779	assume 0.04743

Generated lemmatized results
***************
GENERATED	show.v 1987 ::: indicate;specifiy;add;hypothesize;demonstrate;assume;apear;specify;find;suggest

Filtered results
***************
RANKED	show.v 1987	indicate 0.05065	display 0.04516	reveal 0.04513	illustrate 0.04485	exhibit 0.04295	appear 0.04001	depict 0.03991	offer 0.03912	give 0.03817	play 0.03660	instruct 0.03608	present 0.03446	come 0.03428	air 0.03232	guide 0.03223	picture 0.02906

Test context:
***************
show.v	1988	16	i 'd like to upload my own personal videos to the tivo , so i can __show__ them to guests using my tv .
Contexts for target show are: ['nsubj_i', 'aux_can', 'ccompI_like', 'dobj_them', 'prep:to_guests']
Contexts in vocabulary for target show are: ['nsubj_i', 'aux_can', 'ccompI_like', 'dobj_them', 'prep:to_guests']
Top most similar embeddings: show 0.03403	tell 0.02927	patronize 0.02902	embarass 0.02823	disabuse 0.02808	gainsay 0.02769	re-send 0.02757	send 0.02753	re-assure 0.02753	unburden 0.02738

Generated lemmatized results
***************
GENERATED	show.v 1988 ::: tell;patronize;embarass;disabuse;gainsay;send;unburden;fondle;proove;electrocute

Filtered results
***************
RANKED	show.v 1988	give 0.02710	offer 0.02622	play 0.02482	reveal 0.02437	exhibit 0.02367	illustrate 0.02294	depict 0.02271	display 0.02249	instruct 0.02181	indicate 0.02149	present 0.02104	air 0.02041	come 0.01924	appear 0.01795	picture 0.01725	guide 0.01708

Test context:
***************
show.v	1989	5	navajo and european-american mothers were __shown__ videotaped episodes of navajo and european-american children participating in a classroom .
Contexts for target shown are: ['nsubjpass_mothers', 'auxpass_were', 'rootI_*root*', 'dobj_episodes', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target shown are: ['nsubjpass_mothers', 'auxpass_were', 'rootI_*root*', 'dobj_episodes', 'punct_.']
Top most similar embeddings: shown 0.03145	seen 0.02425	depicted 0.02409	videotaped 0.02367	screened 0.02351	examined 0.02351	highlighted 0.02350	included 0.02326	observed 0.02312	reported 0.02310

Generated lemmatized results
***************
GENERATED	show.v 1989 ::: see;depict;videotape;screen;examine;highlight;include;observe;report;portray

Filtered results
***************
RANKED	show.v 1989	depict 0.02409	give 0.02267	present 0.02240	reveal 0.02139	offer 0.02114	instruct 0.02112	air 0.02101	indicate 0.02066	display 0.02052	exhibit 0.02028	illustrate 0.01958	picture 0.01941	play 0.01782	guide 0.01579	appear 0.01491	come 0.01261

Test context:
***************
show.v	1990	2	the corporal __shown__ above is wearing the regulation cork helmet covered in blue cloth .
Contexts for target shown are: ['partmodI_corporal', 'advmod_above']
Contexts in vocabulary for target shown are: ['advmod_above']
Top most similar embeddings: shown 0.53874	indicated 0.40630	mentionned 0.40060	outlined 0.39435	mentioned 0.38973	described 0.38926	demonstrated 0.38827	decribed 0.38694	highlighted 0.37798	3.8.2 0.37797

Generated lemmatized results
***************
GENERATED	show.v 1990 ::: indicate;mentionned;outline;mention;describe;demonstrate;decribed;highlight;diagram;picture

Filtered results
***************
RANKED	show.v 1990	indicate 0.40630	picture 0.37345	display 0.36876	depict 0.36797	give 0.35831	illustrate 0.35097	present 0.33794	exhibit 0.33263	appear 0.32681	reveal 0.32218	air 0.30948	offer 0.30764	instruct 0.30248	play 0.28734	come 0.27931	guide 0.27597

Test context:
***************
wind.v	1991	0	__wind__ the power cable into a gentle loop when storing it in the bag .
Contexts for target wind are: ['rootI_*root*', 'dobj_cable', 'prep:into_loop', 'advcl_storing', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target wind are: ['rootI_*root*', 'dobj_cable', 'prep:into_loop', 'advcl_storing', 'punct_.']
Top most similar embeddings: reattach 0.02160	unbolt 0.02138	reinsert 0.01979	unplug 0.01975	retracts 0.01975	unclip 0.01964	unroll 0.01889	fasten 0.01854	wind 0.01854	disconnect 0.01854

Generated lemmatized results
***************
GENERATED	wind.v 1991 ::: reattach;unbolt;reinsert;unplug;retract;unclip;unroll;fasten;disconnect;transmit

Filtered results
***************
RANKED	wind.v 1991	tighten 0.01665	weave 0.01607	coil 0.01586	snake 0.01577	bend 0.01492	wrap 0.01467	end 0.01464	choke 0.01462	twist 0.01449	navigate 0.01383	meander 0.01382	wend 0.01335	proceed 0.01328	tease 0.01313	progress 0.01241	mislead 0.01068

Test context:
***************
wind.v	1992	12	the southern forests travelling east and inland from augusta , the roads __wind__ their way through some of the most incredible forests found anywhere in the world .
Contexts for target wind are: ['nsubj_roads', 'rcmodI_forests', 'dobj_way', 'prep:through_some', 'dep_found']
Contexts in vocabulary for target wind are: ['nsubj_roads', 'rcmodI_forests', 'dobj_way', 'prep:through_some', 'dep_found']
Top most similar embeddings: wind 0.02368	meandered 0.02087	winds 0.02053	snaked 0.01948	snaking 0.01893	meander 0.01881	weaved 0.01870	weave 0.01852	wended 0.01842	meanders 0.01833

Generated lemmatized results
***************
GENERATED	wind.v 1992 ::: meander;snake;weave;wend;tunnel;crisscross;blanket;trek;slither;plough

Filtered results
***************
RANKED	wind.v 1992	meander 0.02087	snake 0.01948	weave 0.01870	wend 0.01842	navigate 0.01633	choke 0.01396	twist 0.01372	bend 0.01366	wrap 0.01326	coil 0.01278	progress 0.01265	proceed 0.01254	tease 0.01251	end 0.01173	tighten 0.01086	mislead 0.01018

Test context:
***************
wind.v	1993	6	jury wonders , is harry johnson __winding__ him up ?
Contexts for target winding are: ['nsubj_wonders', 'aux_is', 'advmod_harry', 'nsubj_johnson', 'rootI_*root*', 'dobj_him', 'prt_up', 'punct_?', 'dep_<eol>']
Contexts in vocabulary for target winding are: ['nsubj_wonders', 'aux_is', 'nsubj_johnson', 'rootI_*root*', 'dobj_him', 'prt_up', 'punct_?']
Top most similar embeddings: winding 0.00592	limbering 0.00454	eyeing 0.00452	eying 0.00442	bigging 0.00435	lined 0.00430	inching 0.00426	panted 0.00415	choking 0.00412	hyping 0.00409

Generated lemmatized results
***************
GENERATED	wind.v 1993 ::: limber;eye;bigging;line;inch;pant;choke;hype;gear;rush

Filtered results
***************
RANKED	wind.v 1993	choke 0.00412	tease 0.00342	twist 0.00342	wrap 0.00334	weave 0.00324	proceed 0.00320	progress 0.00313	navigate 0.00311	end 0.00310	meander 0.00304	tighten 0.00300	snake 0.00296	wend 0.00295	bend 0.00294	coil 0.00290	mislead 0.00271

Test context:
***************
wind.v	1994	16	palestinians know that israelis are reluctant to shoot at children ; and if a child does __wind__ up getting killed , it makes for excellent anti-israel propaganda .
Contexts for target wind are: ['mark_if', 'nsubj_child', 'aux_does', 'advclI_makes', 'prt_up', 'ccomp_killed']
Contexts in vocabulary for target wind are: ['mark_if', 'nsubj_child', 'aux_does', 'advclI_makes', 'prt_up', 'ccomp_killed']
Top most similar embeddings: wind 0.00906	vomits 0.00903	misbehaves 0.00894	misbehave 0.00868	wake 0.00864	wakes 0.00864	eats 0.00846	dies 0.00829	sneeze 0.00827	gobble 0.00814

Generated lemmatized results
***************
GENERATED	wind.v 1994 ::: vomit;misbehave;wake;eat;die;sneeze;gobble;suck;yell;forget

Filtered results
***************
RANKED	wind.v 1994	choke 0.00733	end 0.00703	progress 0.00703	wrap 0.00694	tighten 0.00668	bend 0.00660	proceed 0.00656	wend 0.00647	tease 0.00639	mislead 0.00634	navigate 0.00604	coil 0.00600	meander 0.00584	weave 0.00574	twist 0.00560	snake 0.00540

Test context:
***************
wind.v	1995	10	half a mile further was fox 's hill , and __winding__ up the long hollow between them was taylor 's lane , which led first to their driveway about a quarter of a mile in , and then to three other quaker farms further on .
Contexts for target winding are: ['conjI_hill', 'prt_up', 'dobj_hollow']
Contexts in vocabulary for target winding are: ['conjI_hill', 'prt_up', 'dobj_hollow']
Top most similar embeddings: winding 0.12687	snaking 0.08307	lined 0.08132	zig-zagging 0.08112	cresting 0.07997	zigzagging 0.07986	hushing 0.07969	lapping 0.07930	cocking 0.07858	meandering 0.07845

Generated lemmatized results
***************
GENERATED	wind.v 1995 ::: snake;line;crest;zigzag;hush;lap;cock;meander;silt;pucker

Filtered results
***************
RANKED	wind.v 1995	snake 0.08307	meander 0.07845	twist 0.07392	choke 0.07363	end 0.07266	coil 0.07226	wend 0.06888	weave 0.06686	tighten 0.06482	bend 0.06448	wrap 0.06445	navigate 0.05998	proceed 0.05912	tease 0.05743	progress 0.05575	mislead 0.04551

Test context:
***************
wind.v	1996	3	so they all __wind__ up in that loaf of bread .
Contexts for target wind are: ['mark_so', 'nsubj_they', 'rootI_*root*', 'prt_up', 'prep:in_that']
Contexts in vocabulary for target wind are: ['mark_so', 'nsubj_they', 'rootI_*root*', 'prt_up', 'prep:in_that']
Top most similar embeddings: wind 0.02146	plodded 0.01977	mucked 0.01952	perked 0.01939	bunged 0.01934	wised 0.01932	livened 0.01911	cheered 0.01909	sewed 0.01906	meandered 0.01895

Generated lemmatized results
***************
GENERATED	wind.v 1996 ::: plod;muck;perk;bung;wised;liven;cheer;sew;meander;moor

Filtered results
***************
RANKED	wind.v 1996	meander 0.01895	end 0.01817	snake 0.01770	proceed 0.01717	wend 0.01708	wrap 0.01686	weave 0.01656	navigate 0.01599	tighten 0.01599	choke 0.01556	twist 0.01551	coil 0.01527	bend 0.01514	progress 0.01503	tease 0.01474	mislead 0.01403

Test context:
***************
wind.v	1997	13	the lawsuits that threaten to cripple a a number of the churches are __winding__ their way through the courts .
Contexts for target winding are: ['nsubj_lawsuits', 'aux_are', 'rootI_*root*', 'dobj_way', 'prep:through_courts', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target winding are: ['nsubj_lawsuits', 'aux_are', 'rootI_*root*', 'dobj_way', 'prep:through_courts', 'punct_.']
Top most similar embeddings: winding 0.01375	winging 0.01100	wending 0.01062	suing 0.01054	pursued 0.01034	inching 0.01003	proceeding 0.01003	fast-tracked 0.00994	pursuing 0.00985	battling 0.00969

Generated lemmatized results
***************
GENERATED	wind.v 1997 ::: wing;wend;sue;pursue;inch;proceed;battle;prove;progress;muddle

Filtered results
***************
RANKED	wind.v 1997	wend 0.01062	proceed 0.01003	progress 0.00960	meander 0.00813	twist 0.00808	snake 0.00806	navigate 0.00787	weave 0.00779	tighten 0.00770	choke 0.00759	end 0.00734	coil 0.00713	bend 0.00656	tease 0.00643	mislead 0.00636	wrap 0.00635

Test context:
***************
wind.v	1998	34	now however she was falling through that skylight , the strong dark figure that had appeared out of nowhere falling through with her , his arms tightly entwined about her , his shoulder having __winded__ her .
Contexts for target winded are: ['xcompI_having', 'dobj_her']
Contexts in vocabulary for target winded are: ['xcompI_having', 'dobj_her']
Top most similar embeddings: winded 0.23094	manhandle 0.19244	waylaid 0.18751	disabuse 0.18442	amputate 0.18349	manhandled 0.18340	embarass 0.18088	unhook 0.17942	bossed 0.17864	harrass 0.17860

Generated lemmatized results
***************
GENERATED	wind.v 1998 ::: manhandle;waylay;disabuse;amputate;embarass;unhook;boss;harrass;goad;anaesthetise

Filtered results
***************
RANKED	wind.v 1998	tease 0.16845	navigate 0.16081	choke 0.15376	bend 0.15062	mislead 0.14900	tighten 0.14492	meander 0.14398	weave 0.14338	twist 0.14334	wrap 0.14045	wend 0.13953	coil 0.13916	snake 0.13533	proceed 0.12806	end 0.12201	progress 0.11391

Test context:
***************
wind.v	1999	10	experience outdoor adventure , mini golf , horse trekking , __wind__ your way though a maze , mountain biking and relaxing in the famous hanmer springs hot pools .
Contexts for target wind are: ['nnI_way']
Contexts in vocabulary for target wind are: ['nnI_way']
Top most similar embeddings: wind 0.47433	winds 0.39874	peddars 0.38832	icknield 0.38447	breeze 0.38136	waskerley 0.36419	epinal 0.35526	blackhorse 0.35253	headwind 0.34828	gardiners 0.34536

Generated lemmatized results
***************
GENERATED	wind.v 1999 ::: peddars;icknield;breeze;waskerley;epinal;blackhorse;headwind;gardiners;gales;tother

Filtered results
***************
RANKED	wind.v 1999	snake 0.31745	wend 0.31211	meander 0.30327	bend 0.29447	weave 0.28853	coil 0.28052	twist 0.27755	end 0.27196	navigate 0.26838	wrap 0.26763	mislead 0.26433	progress 0.26368	tease 0.25485	choke 0.25420	proceed 0.25275	tighten 0.23475

Test context:
***************
wind.v	2000	17	the history of message encryption goes back to ancient greece where messages were written on a tape __wound__ around a stick .
Contexts for target wound are: ['partmodI_tape', 'prep:around_stick']
Contexts in vocabulary for target wound are: ['partmodI_tape']
Top most similar embeddings: wound 0.47692	taped 0.34424	wounds 0.33452	stitched 0.33149	sewn 0.33100	wrapped 0.32835	sutured 0.32735	winding 0.32277	attatched 0.32231	sheeted 0.32175

Generated lemmatized results
***************
GENERATED	wind.v 2000 ::: tap;wound;stitch;sew;wrap;suture;attatched;sheet;glue;bandage

Filtered results
***************
RANKED	wind.v 2000	wrap 0.32835	bend 0.31257	coil 0.30307	wend 0.30012	weave 0.29928	snake 0.29644	choke 0.29467	end 0.28936	twist 0.28878	tighten 0.28630	meander 0.28491	tease 0.26973	navigate 0.26508	proceed 0.24998	progress 0.24845	mislead 0.24696

Test context:
***************
work.v	2001	6	i managed to get a position __working__ on the phylogeography of some new zealand animals this summer .
Contexts for target working are: ['partmodI_position', 'prep:on_phylogeography', 'tmod_summer']
Contexts in vocabulary for target working are: ['partmodI_position', 'tmod_summer']
Top most similar embeddings: working 0.23893	holidaying 0.17193	circumnavigating 0.17007	honeymooning 0.16921	debuting 0.16916	laboring 0.16783	captaining 0.16646	beavering 0.16634	taking 0.16542	enjoying 0.16528

Generated lemmatized results
***************
GENERATED	work.v 2001 ::: holiday;circumnavigate;honeymoon;debut;labor;captain;beaver;take;enjoy;summit

Filtered results
***************
RANKED	work.v 2001	collaborate 0.16370	operate 0.15758	move 0.15538	participate 0.15378	labour 0.15345	employ 0.14713	cooperate 0.14471	toil 0.14352	investigate 0.14242	research 0.14042	act 0.13945	task 0.13561	engage 0.13411	function 0.13325

Test context:
***************
work.v	2002	34	in september , i wrote a post with the title , " did the president of cbs news have anyone in charge of reading the internet and sending alerts? " by asking people who __work__ there , i have since determined that he didn 't .
Contexts for target work are: ['nsubj_who', 'rcmodI_people', 'advmod_there']
Contexts in vocabulary for target work are: ['nsubj_who', 'rcmodI_people', 'advmod_there']
Top most similar embeddings: work 0.11491	holidayed 0.09399	self-injure 0.09361	worked 0.09336	mistreat 0.08953	misbehave 0.08929	live 0.08867	lived 0.08853	reside 0.08822	immigrate 0.08802

Generated lemmatized results
***************
GENERATED	work.v 2002 ::: holiday;mistreat;misbehave;live;reside;immigrate;toil;skulk;sojourn;cohabit

Filtered results
***************
RANKED	work.v 2002	toil 0.08718	labour 0.07938	participate 0.07682	employ 0.07405	operate 0.07363	collaborate 0.07234	cooperate 0.07144	move 0.06888	engage 0.06717	function 0.06676	research 0.06647	act 0.06495	task 0.05705	investigate 0.05583

Test context:
***************
work.v	2003	13	teachers were introduced to content by experienced mentor teachers and scientists , who __worked__ with them as they used the kits ( marsh and sevilla , 1991 ) .
Contexts for target worked are: ['nsubj_who', 'rcmodI_teachers', 'prep:with_them', 'advcl_used']
Contexts in vocabulary for target worked are: ['nsubj_who', 'rcmodI_teachers', 'prep:with_them', 'advcl_used']
Top most similar embeddings: worked 0.06337	interacted 0.04569	cooperated 0.04485	collaborated 0.04478	liased 0.04445	liaised 0.04423	co-operated 0.04420	toiled 0.04409	participated 0.04393	campaigned 0.04373

Generated lemmatized results
***************
GENERATED	work.v 2003 ::: interact;cooperate;collaborate;liased;liaise;toil;participate;campaign;labor;intermarry

Filtered results
***************
RANKED	work.v 2003	cooperate 0.04485	collaborate 0.04478	toil 0.04409	participate 0.04393	labour 0.04294	act 0.03997	employ 0.03681	move 0.03539	function 0.03530	engage 0.03508	operate 0.03481	research 0.03439	investigate 0.03111	task 0.02864

Test context:
***************
work.v	2004	2	mary then __worked__ for a few years before returning to the university of michigan for a master 's degree in civil engineering in 1944 .
Contexts for target worked are: ['nsubj_mary', 'advmod_then', 'rootI_*root*', 'prep:for_years', 'punct_.', 'dep_<eol>']
Contexts in vocabulary for target worked are: ['nsubj_mary', 'advmod_then', 'rootI_*root*', 'prep:for_years', 'punct_.']
Top most similar embeddings: worked 0.03682	freelanced 0.03404	collaborated 0.02647	lived 0.02620	honeymooned 0.02607	ran 0.02586	dallied 0.02575	deputised 0.02556	stayed 0.02550	loitered 0.02534

Generated lemmatized results
***************
GENERATED	work.v 2004 ::: freelance;collaborate;live;honeymoon;run;dally;deputise;stay;loiter;bid

Filtered results
***************
RANKED	work.v 2004	collaborate 0.02647	toil 0.02374	labour 0.02349	act 0.02334	move 0.02318	function 0.02288	participate 0.02209	cooperate 0.02134	operate 0.02000	research 0.01946	engage 0.01925	employ 0.01914	investigate 0.01908	task 0.01578

Test context:
***************
work.v	2005	53	until the 1800s , most americans rarely tasted anything containing refined sugar. ) as you dig into your turkey , stuffing and pecan pie , washed down with a $ 10 bottle of wine superior in quality to any wine available to the 17th-century kings of france , remember how hard your ancestors __worked__ , and how they sacrificed , in the dream that someday their descendants would be warm , well-fed and secure against nature .
Contexts for target worked are: ['advmod_hard', 'nsubj_ancestors', 'ccompI_remember']
Contexts in vocabulary for target worked are: ['advmod_hard', 'nsubj_ancestors', 'ccompI_remember']
Top most similar embeddings: worked 0.12527	fought 0.09619	toiled 0.09442	lived 0.09108	battled 0.08878	slaved 0.08829	rained 0.08712	played 0.08687	campaigned 0.08686	laughed 0.08634

Generated lemmatized results
***************
GENERATED	work.v 2005 ::: fight;toil;live;battle;slave;rain;play;campaign;laugh;labor

Filtered results
***************
RANKED	work.v 2005	toil 0.09442	labour 0.08437	collaborate 0.08070	act 0.07983	function 0.07541	cooperate 0.07159	operate 0.06923	research 0.06859	move 0.06742	participate 0.06692	employ 0.06420	engage 0.06319	investigate 0.05607	task 0.05057

Test context:
***************
work.v	2006	15	close to 5,000 people are still employed in textiles , and our task is to __work__ with those companies on an individual basis to assist them to reposition themselves in higher-value markets .
Contexts for target work are: ['aux_to', 'xcompI_is', 'prep:with_companies', 'prep:on_basis', 'xcomp_assist']
Contexts in vocabulary for target work are: ['aux_to', 'xcompI_is', 'prep:with_companies', 'prep:on_basis', 'xcomp_assist']
Top most similar embeddings: work 0.02927	co-locate 0.02556	collaborate 0.02449	liase 0.02348	liaise 0.02334	co-operate 0.02266	cooperate 0.02264	federate 0.02195	negotiate 0.02183	interoperate 0.02174

Generated lemmatized results
***************
GENERATED	work.v 2006 ::: collaborate;liase;liaise;cooperate;federate;negotiate;interoperate;disburse;engage;underwrite

Filtered results
***************
RANKED	work.v 2006	collaborate 0.02449	cooperate 0.02264	engage 0.02125	employ 0.02071	operate 0.02043	participate 0.01866	investigate 0.01692	move 0.01545	task 0.01446	act 0.01445	labour 0.01426	function 0.01370	research 0.01325	toil 0.01291

Test context:
***************
work.v	2007	11	" in the future , i can see the two superpowers __working__ in tandem - one big red state and one big blue state , if you will - moderating each others excesses , as well as setting the agenda for the rest of the world along the lines of our shared values .
Contexts for target working are: ['partmodI_superpowers', 'prep:in_tandem']
Contexts in vocabulary for target working are: ['prep:in_tandem']
Top most similar embeddings: working 0.52519	worked 0.40092	operating 0.36091	laboring 0.35705	beavering 0.35383	work 0.35145	joint-working 0.34720	co-teaching 0.34580	co-working 0.34452	running 0.34423

Generated lemmatized results
***************
GENERATED	work.v 2007 ::: operate;labor;beaver;run;study;interoperating;develop;function;progress;teamworking

Filtered results
***************
RANKED	work.v 2007	operate 0.36091	function 0.33627	collaborate 0.32765	labour 0.32635	cooperate 0.32537	move 0.32483	act 0.32287	employ 0.31730	toil 0.31151	task 0.30433	participate 0.30384	investigate 0.29379	engage 0.29202	research 0.28980

Test context:
***************
work.v	2008	32	( media materials &gt; press releases & rmi announcements ) 22 may 2005 a cuyahoga river makeover ' plan aims to bolster environment while sustaining industry the planners stress they want to __work__ with industry .
Contexts for target work are: ['aux_to', 'xcompI_want', 'prep:with_industry']
Contexts in vocabulary for target work are: ['aux_to', 'xcompI_want', 'prep:with_industry']
Top most similar embeddings: work 0.13232	reacquaint 0.09598	collaborate 0.09532	federate 0.09481	co-locate 0.09369	interoperate 0.09302	co-produce 0.09295	suceed 0.09227	co-operate 0.09165	re-connect 0.09122

Generated lemmatized results
***************
GENERATED	work.v 2008 ::: reacquaint;collaborate;federate;interoperate;suceed;cooperate;ingratiate;engage;interact;remonstrate

Filtered results
***************
RANKED	work.v 2008	collaborate 0.09532	cooperate 0.09056	engage 0.08915	participate 0.07957	operate 0.07830	move 0.07683	employ 0.07269	toil 0.07027	investigate 0.07005	act 0.06462	labour 0.06315	research 0.05960	task 0.05698	function 0.05543

Test context:
***************
work.v	2009	33	one of the areas that has been changed in these new codes is to take into account the fact that local authorities and the national health service are , more and more , __working__ either with each other or with other bodies ' local authorities , social services , voluntary bodies .
Contexts for target working are: ['xcompI_are', 'prep:with_other', 'cc_or', 'conj_with', 'conj:with_authorities', 'dep_<eol>']
Contexts in vocabulary for target working are: ['xcompI_are', 'prep:with_other', 'cc_or', 'conj_with', 'conj:with_authorities']
Top most similar embeddings: working 0.02682	collaborate 0.02341	co-operating 0.02235	cooperate 0.02203	co-operate 0.02196	interacting 0.02161	cooperating 0.02102	liaise 0.02086	cohabit 0.02043	co-operatively 0.02040

Generated lemmatized results
***************
GENERATED	work.v 2009 ::: collaborate;cooperate;interact;liaise;cohabit;federate;liasing;bilaterally;communicate;empathise

Filtered results
***************
RANKED	work.v 2009	collaborate 0.02341	cooperate 0.02203	engage 0.01681	act 0.01613	operate 0.01541	employ 0.01503	function 0.01476	labour 0.01465	participate 0.01461	toil 0.01310	move 0.01280	task 0.01271	research 0.01248	investigate 0.01227

Test context:
***************
work.v	2010	7	knowledge of southern california history and experience __working__ with non-profit museum highly desirable .
Contexts for target working are: ['depI_desirable']
Contexts in vocabulary for target working are: ['depI_desirable']
Top most similar embeddings: working 0.45340	co-working 0.34604	non-working 0.33979	worked 0.33841	joint-working 0.33752	home-working 0.33656	interworking 0.33597	knowledge/experience 0.33472	desirable 0.33225	laboring 0.33164

Generated lemmatized results
***************
GENERATED	work.v 2010 ::: interworking;desirable;labor;cooperate;desireable;teamworking;holiday;slave;abap;essential

Filtered results
***************
RANKED	work.v 2010	cooperate 0.32975	function 0.31539	labour 0.31442	participate 0.30958	collaborate 0.30414	toil 0.29773	operate 0.29697	move 0.29630	research 0.29600	task 0.29086	act 0.28637	engage 0.28384	employ 0.28012	investigate 0.27285
